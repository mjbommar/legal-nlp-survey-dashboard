[{"id":"3e269c58ea4348bd1c1212c5fc3cb7d62b06de3fca4ab9e2304489a9ba4b0f3db6632fc21bd89215e658f872292ca3148415a0afeefa88f76826c2af6bade5f9","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-emnlp.43.pdf","title":"","llm_title":"Enabling Discriminative Reasoning in LLMs for Legal Judgment Prediction","authors":["Chenlong Deng","Kelong Mao","Yuyao Zhang","Zhicheng Dou"],"llm_authors":"Chenlong Deng, Kelong Mao, Yuyao Zhang, Zhicheng Dou","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal judgment prediction is essential for enhancing judicial efficiency. In this work, we identify that existing large language models (LLMs) underperform in this domain due to challenges in understanding case complexities and distinguishing between similar charges. To adapt LLMs for effective legal judgment prediction, we introduce the Ask-DiscriminAte-PredicT (ADAPT) reasoning framework inspired by human judicial reasoning. ADAPT involves decomposing case facts, discriminating among potential charges, and predicting the final judgment. We further enhance LLMs through fine-tuning with multi-task synthetic trajectories to improve legal judgment prediction accuracy and efficiency under our ADAPT framework. Extensive experiments conducted on two widely-used datasets demonstrate the superior performance of our framework in legal judgment prediction, particularly when dealing with complex and confusing charges.","llm_keywords":["Legal Judgment Prediction","Large Language Models","ADAPT Framework","Discriminative Reasoning","Judicial Efficiency","Legal NLP","Case Complexity","Fine-Tuning","Synthetic Trajectories","Legal Charges Differentiation"],"classifications":["Classification","Pre-Processing"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":13},{"id":"e50eeca4c235d0e200b4f865994ba6422efb48bf728355b38ef30a9a9fa3a459dcb50e7e318110d99beee27547f508a175e7225ebdeba3e43f9d0bd1b2607983","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2023.findings-emnlp.831.pdf","title":"","llm_title":"LLMs – the Good, the Bad or the Indispensable?: A Use Case on Legal Statute Prediction and Legal Judgment Prediction on Indian Court Cases","authors":["Shaurya Vats","Atharva Zope","Somsubhra De","Anurag Sharma","Upal Bhattacharya","Shubham Kumar Nigam","Shouvik Kumar Guha","Koustav Rudra","Kripabandhu Ghosh"],"llm_authors":"Shaurya Vats, Atharva Zope, Somsubhra De, Anurag Sharma, Upal Bhattacharya, Shubham Kumar Nigam, Shouvik Kumar Guha, Koustav Rudra, Kripabandhu Ghosh","author_string":"","year":2023,"abstract":"","llm_abstract":"The Large Language Models (LLMs) have impacted many real-life tasks. To examine the efficacy of LLMs in a high-stake domain like law, we have applied state-of-the-art LLMs for two popular tasks: Statute Prediction and Judgment Prediction, on Indian Supreme Court cases. We see that while LLMs exhibit excellent predictive performance in Statute Prediction, their performance dips in Judgment Prediction when compared with many standard models. The explanations generated by LLMs (along with prediction) are of moderate to decent quality. We also see evidence of gender and religious bias in the LLM-predicted results. In addition, we present a note from a senior legal expert on the ethical concerns of deploying LLMs in these critical legal tasks.","llm_keywords":["Large Language Models","Statute Prediction","Judgment Prediction","Indian Supreme Court","Bias","Ethical Concerns","Legal Domain","Predictive Performance","Explanations"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":24},{"id":"13e104bdcad8f7394c9c9c7617536cbb06bfcf962f2209cc9d3d9838fad695c69c8e86859ed48c4c554df46b9af96792aa6e0523f3e13b852760ef262a4ac989","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.findings-acl.187.pdf","title":"","llm_title":"Automated Refugee Case Analysis: An NLP Pipeline for Supporting Legal Practitioners","authors":["Claire Barale","Michael Rovatsos","Nehal Bhuta"],"llm_authors":"Claire Barale, Michael Rovatsos, Nehal Bhuta","author_string":"","year":2023,"abstract":"","llm_abstract":"In this paper, we introduce an end-to-end pipeline for retrieving, processing, and extracting targeted information from legal cases. We investigate an under-studied legal domain with a case study on refugee law in Canada. Searching case law for past similar cases is a key part of legal work for both lawyers and judges, the potential end-users of our prototype. While traditional named-entity recognition labels such as dates provide meaningful information in legal work, we propose to extend existing models and retrieve a total of 19 useful categories of items from refugee cases. After creating a novel data set of cases, we perform information extraction based on state-of-the-art neural named-entity recognition (NER). We test different architectures including two transformer models, using contextual and non-contextual embeddings, and compare general purpose versus domain-specific pre-training. The results demonstrate that models pre-trained on legal data perform best despite their smaller size, suggesting that domain matching had a larger effect than network architecture. We achieve a F1 score above 90% on five of the targeted categories and over 80% on four further categories.","llm_keywords":["NLP","legal cases","refugee law","information extraction","named-entity recognition","legal search tools","case law analysis","transformer models","domain-specific pre-training","legal data"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":14},{"id":"36b4c9a87c82d1153413134897d1bef3128ff3db9267265bc3d3085198e438d35000e0c36586b62bcef68bbe4b8bd08e0edb3183e71cb88e63935a62bb9bf497","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2023.findings-emnlp.929.pdf","title":"","llm_title":"Can ChatGPT Perform Reasoning Using the IRAC Method in Analyzing Legal Scenarios Like a Lawyer?","authors":["Xiaoxi Kang","Lizhen Qu","Lay-Ki Soon","Adnan Trakic","Terry Yue Zhuo","Patrick Charles Emerton","Genevieve Grant"],"llm_authors":"Xiaoxi Kang, Lizhen Qu, Lay-Ki Soon, Adnan Trakic, Terry Yue Zhuo, Patrick Charles Emerton, Genevieve Grant","author_string":"","year":2023,"abstract":"","llm_abstract":"Large Language Models (LLMs), such as CHATGPT, have drawn a lot of attentions recently in the legal domain due to its emergent ability to tackle a variety of legal tasks. However, it is still unknown if LLMs are able to analyze a legal case and perform reasoning in the same manner as lawyers. Therefore, we constructed a novel corpus consisting of scenarios pertain to Contract Acts Malaysia and Australian Social Act for Dependent Child. CHATGPT is applied to perform analysis on the corpus using the IRAC method, which is a framework widely used by legal professionals for organizing legal analysis. Each scenario in the corpus is annotated with a complete IRAC analysis in a semi-structured format so that both machines and legal professionals are able to interpret and understand the annotations. In addition, we conducted the first empirical assessment of CHATGPT for IRAC analysis in order to understand how well it aligns with the analysis of legal professionals. Our experimental results shed lights on possible future research directions to improve alignments between LLMs and legal experts in terms of legal reasoning.","llm_keywords":["Large Language Models","ChatGPT","Legal Reasoning","IRAC Method","Contract Acts Malaysia","Australian Social Act","Legal Analysis","Artificial Intelligence","Machine Learning"],"classifications":["Classification","Resources"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":24},{"id":"0f48609ea03329bc19019bf2f096b9c16adb47b0a8db50ae7eb926c0320cd3a08e4d3168f688e58799b3b42ee5701b19895177ff3c865c5cade6597107520ff1","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-emnlp.433.pdf","title":"","llm_title":"HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents","authors":["Santosh T.Y.S.S","Apolline Isaia","Shiyu Hong","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Apolline Isaia, Shiyu Hong, Matthias Grabmair","author_string":"","year":2024,"abstract":"","llm_abstract":"Rhetorical Role Labeling (RRL) of legal documents is pivotal for various downstream tasks such as summarization, semantic case search and argument mining. Existing approaches often overlook the varying difficulty levels inherent in legal document discourse styles and rhetorical roles. In this work, we propose HiCuLR, a hierarchical curriculum learning framework for RRL. It nests two curricula: Rhetorical Role-level Curriculum (RC) on the outer layer and Document-level Curriculum (DC) on the inner layer. DC categorizes documents based on their difficulty, utilizing metrics like deviation from a standard discourse structure and exposes the model to them in an easy-to-difficult fashion. RC progressively strengthens the model to discern coarse-to-fine-grained distinctions between rhetorical roles. Our experiments on four RRL datasets demonstrate the efficacy of HiCuLR, highlighting the complementary nature of DC and RC.","llm_keywords":["Rhetorical Role Labeling","Legal Documents","Curriculum Learning","Hierarchical Framework","Semantic Search","Argument Mining","Document Difficulty","Sequential Classification","Natural Language Processing","Legal AI"],"classifications":["Pre-Processing","Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":8},{"id":"d980ea34208ed3929f612164ce695aaca44d85d166a6a3ce40e7399a80d0193afb81a8957ad9df9fed87d76f93811b7289208b6bd5f39a2b3de89088d3ddce1d","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2023.findings-emnlp.287.pdf","title":"","llm_title":"Information Extraction from Legal Wills: How Well Does GPT-4 Do?","authors":["Alice Saebom Kwak","Cheonkam Jeong","Gaetano Vincent Forte","Derek E. Bambauer","Clayton T. Morrison","Mihai Surdeanu"],"llm_authors":"Alice Saebom Kwak, Cheonkam Jeong, Gaetano Vincent Forte, Derek E. Bambauer, Clayton T. Morrison, Mihai Surdeanu","author_string":"","year":2023,"abstract":"","llm_abstract":"This work presents a manually annotated dataset for Information Extraction (IE) from legal wills, and relevant in-context learning experiments on the dataset. The dataset consists of entities, binary relations between the entities (e.g., relations between testator and beneficiary), and n-ary events (e.g., bequest) extracted from 45 legal wills from two US states. This dataset can serve as a foundation for downstream tasks in the legal domain. Another use case of this dataset is evaluating the performance of large language models (LLMs) on this IE task. We evaluated GPT-4 with our dataset to investigate its ability to extract information from legal wills. Our evaluation result demonstrates that the model is capable of handling the task reasonably well. When given instructions and examples as a prompt, GPT-4 shows decent performance for both entity extraction and relation extraction tasks. Nevertheless, the evaluation result also reveals that the model is not perfect. We observed inconsistent outputs (given a prompt) as well as prompt over-generalization.","llm_keywords":["Information Extraction","Legal Wills","GPT-4","Annotated Dataset","Large Language Models","Entity Extraction","Relation Extraction","Legal Domain","NLP"],"classifications":["Information Extraction","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":18},{"id":"416898e3ee21bf81f3612dad7fe6f4118a3860a4ef7e021a798efe799be80b79e5323a708abb0d33d41c425287a0afd0a620eded892ad84857951d0b1fb94b15","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2023.findings-emnlp.224.pdf","title":"","llm_title":"The Law and NLP: Bridging Disciplinary Disconnects","authors":["Robert Mahari","Dominik Stammbach","Elliott Ash","Alex 'Sandy' Pentland"],"llm_authors":"Robert Mahari, Dominik Stammbach, Elliott Ash, Alex 'Sandy' Pentland","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal practice is intrinsically rooted in the fabric of language, yet legal practitioners and scholars have been slow to adopt tools from natural language processing (NLP). At the same time, the legal system is experiencing an access to justice crisis, which could be partially alleviated with NLP. In this position paper, we argue that the slow uptake of NLP in legal practice is exacerbated by a disconnect between the needs of the legal community and the focus of NLP researchers. In a review of recent trends in the legal NLP literature, we find limited overlap between the legal NLP community and legal academia. Our interpretation is that some of the most popular legal NLP tasks fail to address the needs of legal practitioners. We discuss examples of legal NLP tasks that promise to bridge disciplinary disconnects and highlight interesting areas for legal NLP research that remain underexplored.","llm_keywords":["NLP","legal practice","access to justice","legal technology","disciplinary disconnects","legal NLP tasks"],"classifications":["Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":10},{"id":"3fbf7b43bb013841a4dca7a92180511ae5e66ece8d9379a9762cb67bf97732a86c1c86cfa8e7dc6023142827c2ef75cc2cc55663034087b4d5156a385c368e45","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-emnlp.214.pdf","title":"","llm_title":"Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases","authors":["Santosh T.Y.S.S","Mohamed Hesham Elganayni","Stanisław Sójka","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Mohamed Hesham Elganayni, Stanisław Sójka, Matthias Grabmair","author_string":"","year":2024,"abstract":"","llm_abstract":"Inspired by the legal doctrine of stare decisis, which leverages precedents (prior cases) for informed decision-making, we explore methods to integrate them into LJP models. To facilitate precedent retrieval, we train a retriever with a fine-grained relevance signal based on the overlap ratio of alleged articles between cases. We investigate two strategies to integrate precedents: direct incorporation at inference via label interpolation based on case proximity and during training via a precedent fusion module using a stacked-cross attention model. We employ joint training of the retriever and LJP models to address latent space divergence between them. Our experiments on LJP tasks from the ECHR jurisdiction reveal that integrating precedents during training coupled with joint training of the retriever and LJP model, outperforms models without precedents or with precedents incorporated only at inference, particularly benefiting sparser articles.","llm_keywords":["legal judgement prediction","precedents","stare decisis","ECHR","retriever","joint training","label interpolation","precedent fusion module","latent space divergence","deep learning"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":8},{"id":"921a6f96a394e16bcd3c1a395bcc20bfaafe4b62a211cd736edfa66f33297faf31f17bd0f4d1755606447fef259e0f7f5528f62ad4410a02731292ca2d77f7a0","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.findings-acl.139.pdf","title":"","llm_title":"An Element is Worth a Thousand Words: Enhancing Legal Case Retrieval by Incorporating Legal Elements","authors":["Chenlong Deng","Zhicheng Dou","Yujia Zhou","Peitian Zhang","Kelong Mao"],"llm_authors":"Chenlong Deng, Zhicheng Dou, Yujia Zhou, Peitian Zhang, Kelong Mao","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal case retrieval plays an important role in promoting judicial justice and fairness. One of its greatest challenges is that the definition of relevance goes far beyond the common semantic relevance as in ad-hoc retrieval. In this paper, we reveal that the legal elements, which typically comprise key facts in a specialized legal context, can largely improve the relevance matching in legal case retrieval. To facilitate the use of legal elements, we construct a Chinese legal element dataset called LeCaRD-Elem based on the widely-used LeCaRD dataset (Ma et al., 2021), through a two-stage semi-automatic method with a minimized reliance on human labor. Meanwhile, we introduce two new models that enhance legal search using legal elements. The first, namely Elem4LCR-E, is a two-stage model that explicitly predicts legal elements from texts and then leverages them for improved ranking. Recognizing the potential benefits of more seamless integration, we further propose an end-to-end model called Elem4LCR-I, which internalizes the legal element knowledge into its model parameters using a tailored teacher-student training framework. Extensive experiments underscore the significant value of legal elements and demonstrate the superiority of our two proposed models in enhancing legal search over existing methods. Our code and LeCaRD-Elem dataset are accessible at https://github.com/ChenlongDeng/Elem4LCR.","llm_keywords":["legal case retrieval","legal elements","relevance matching","Chinese legal dataset","model integration"],"classifications":["Information Retrieval","Classification","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":12},{"id":"71f143b07970ffae14c98e58207cb84bab78c18e28cfaf12e88b7ddc3f30655e9e2bfaf45d0ae963711dd8e26a2a79f554d7881c921ac4720c99e7935fdee247","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.findings-acl.350.pdf","title":"","llm_title":"LJPCHECK: Functional Tests for Legal Judgment Prediction","authors":["Yuan Zhang","Wanhong Huang","Yi Feng","Chuanyi Li","Zhiwei Fei","Jidong Ge","Bin Luo","Vincent Ng"],"llm_authors":"Yuan Zhang, Wanhong Huang, Yi Feng, Chuanyi Li, Zhiwei Fei, Jidong Ge, Bin Luo, Vincent Ng","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal Judgment Prediction (LJP) refers to the task of automatically predicting judgment results (e.g., charges, law articles and term of penalty) given the fact description of cases. While SOTA models have achieved high accuracy and F1 scores on public datasets, existing datasets fail to evaluate specific aspects of these models (e.g., legal fairness, which significantly impact their applications in real scenarios). Inspired by functional testing in software engineering, we introduce LJPCHECK, a suite of functional tests for LJP models, to comprehend LJP models’ behaviors and offer diagnostic insights. We illustrate the utility of LJPCHECK on five SOTA LJP models. Extensive experiments reveal vulnerabilities in these models, prompting an in-depth discussion into the underlying reasons of their shortcomings.","llm_keywords":["Legal Judgment Prediction","functional testing","diagnostic insights","fairness","natural language processing","model evaluation","software engineering","Chinese LJP models","diagnostic tests","SOTA models analysis"],"classifications":["Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":17},{"id":"fc6fe481815dc440e3f1cb8282b35aa5f1d5d032cd856f4c9f64213bc33f9fa97f16d1d11f4d7093bed14b27088b2d36f1e9e897fda7c0561283268fd59b9b68","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2023.findings-emnlp.730.pdf","title":"","llm_title":"Legally Enforceable Hate Speech Detection for Public Forums","authors":["Chu Fei Luo","Rohan Bhambhoria","Samuel Dahan","Xiaodan Zhu"],"llm_authors":"Chu Fei Luo, Rohan Bhambhoria, Samuel Dahan, and Xiaodan Zhu","author_string":"","year":2023,"abstract":"","llm_abstract":"Hate speech causes widespread and deep-seated societal issues. Proper enforcement of hate speech laws is key for protecting groups of people against harmful and discriminatory language. However, determining what constitutes hate speech is a complex task that is highly open to subjective interpretations. Existing works do not align their systems with enforceable definitions of hate speech, which can make their outputs inconsistent with the goals of regulators. This research introduces a new perspective and task for enforceable hate speech detection centred around legal definitions, and a dataset annotated on violations of eleven possible definitions by legal experts. Given the challenge of identifying clear, legally enforceable instances of hate speech, we augment the dataset with expert-generated samples and an automatically mined challenge set. We experiment with grounding the model decision in these definitions using zero-shot and few-shot prompting. We then report results on several large language models (LLMs). With this task definition, automatic hate speech detection can be more closely aligned to enforceable laws, and hence assist in more rigorous enforcement of legal protections against harmful speech in public forums.","llm_keywords":["hate speech detection","legal definitions","public forums","machine learning","large language models"],"classifications":[],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":16},{"id":"bfeaa881b1a6aacd42a734e86d7fa52318a0bd152ad64a575a4735ec3a3b3c1ea0830638bd5b302f375dad1d0577910e5931fa31f8c47a1c61953de671747ea1","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2022.findings-acl.278v2.pdf","title":"","llm_title":"HLDC: Hindi Legal Documents Corpus","authors":["Arnav Kapoor","Mudit Dhawan","Anmol Goel","T.H. Arjun","Akshala Bhatnagar","Vibhu Agrawal","Amul Agrawal","Arnab Bhattacharya","Ponnurangam Kumaraguru","Ashutosh Modi"],"llm_authors":"Arnav Kapoor, Mudit Dhawan, Anmol Goel, T.H. Arjun, Akshala Bhatnagar, Vibhu Agrawal, Amul Agrawal, Arnab Bhattacharya, Ponnurangam Kumaraguru, Ashutosh Modi","author_string":"","year":2024,"abstract":"","llm_abstract":"Many populous countries including India are burdened with a considerable backlog of legal cases. Development of automated systems that could process legal documents and augment legal practitioners can mitigate this. However, there is a dearth of high-quality corpora that is needed to develop such data-driven systems. The problem gets even more pronounced in the case of low resource languages such as Hindi. In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of more than 900K legal documents in Hindi. Documents are cleaned and structured to enable the development of downstream applications. Further, as a use-case for the corpus, we introduce the task of bail prediction. We experiment with a battery of models and propose a Multi-Task Learning (MTL) based model for the same. MTL models use summarization as an auxiliary task along with bail prediction as the main task. Experiments with different models are indicative of the need for further research in this area. We release the corpus and model implementation code with this paper: https://github.com/ Exploration-Lab/HLDC.","llm_keywords":["Hindi Legal Documents","Corpus","Bail Prediction","Multi-Task Learning","Automated Legal Systems","Natural Language Processing","Low Resource Languages","Legal NLP","Data-Driven Systems","Legal Applications"],"classifications":["Resources","Machine Summarization","Classification"],"num_cited_by":32,"num_cited_by_title_only":32,"num_pages":16},{"id":"d148e6ab868a18afe32a830e36f71131960e35e144324c42d19be256e75c0e31c27bcf957702ac873fa870386fb009f32a981628f0609faee0f89931f808c2be","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.findings-acl.145.pdf","title":"","llm_title":"Structured Persuasive Writing Support in Legal Education: A Model and Tool for German Legal Case Solutions","authors":["Florian Weber","Thiemo Wambsganss","Seyed Parsa Neshaei","Matthias Söllner"],"llm_authors":"Florian Weber, Thiemo Wambsganss, Seyed Parsa Neshaei, Matthias Söllner","author_string":"","year":2023,"abstract":"","llm_abstract":"We present an annotation approach for capturing structured components and arguments in legal case solutions of German students. Based on the appraisal style, which dictates the structured way of persuasive writing in German law, we propose an annotation scheme with annotation guidelines that identify structured writing in legal case solutions. We conducted an annotation study with two annotators and annotated legal case solutions to capture the structures of a persuasive legal text. Based on our dataset, we trained three transformer-based models to show that the annotated components can be successfully predicted, e.g. to provide users with writing assistance for legal texts. We evaluated a writing support system in which our models were integrated in an online experiment with law students and found positive learning success and users’ perceptions. Finally, we present our freely available corpus of 413 law student case studies to support the development of intelligent writing support systems.","llm_keywords":["annotation approach","legal education","persuasive writing","German law","writing support systems","transformer-based models","intelligent writing support","annotation scheme","annotation study","appraisal style"],"classifications":["Text Generation","Resources"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":18},{"id":"49656563e3f6b200e86e8e0a64ae3387bebbfc54392fe3db854345956d8ee00c2482b7b905cb728eb13a8a612617aadcf1467b7130d91ec125be10683b7e371e","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.findings-acl.255.pdf","title":"","llm_title":"Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts","authors":["Shubham Kumar Nigam","Anurag Sharma","Danush Khanna","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"llm_authors":"Shubham Kumar Nigam, Anurag Sharma, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya","author_string":"","year":2024,"abstract":"","llm_abstract":"In the era of Large Language Models (LLMs), predicting judicial outcomes poses significant challenges due to the complexity of legal proceedings and the scarcity of expert-annotated datasets. Addressing this, we introduce Prediction with Explanation (PredEx), the largest expert-annotated dataset for legal judgment prediction and explanation in the Indian context, featuring over 15,000 annotations. This groundbreaking corpus significantly enhances the training and evaluation of AI models in legal analysis, with innovations including the application of instruction tuning to LLMs. This method has markedly improved the predictive accuracy and explanatory depth of these models for legal judgments. We employed various transformer-based models, tailored for both general and Indian legal contexts. Through rigorous lexical, semantic, and expert assessments, our models effectively leverage PredEx to provide precise predictions and meaningful explanations, establishing it as a valuable benchmark for both the legal profession and the NLP community.","llm_keywords":["Legal judgment prediction","Indian courts","Large Language Models","Instruction tuning","AI in legal analysis","Expert-annotated dataset","Transformers","Artificial intelligence","Machine learning","Legal technology"],"classifications":["Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":20},{"id":"922d12cf4320f33386d6f4ff68d25e998ce537e99ec6b8c1ce9187104968b49ec09061156067c1e131ebbf1d9bc5e88edc4e012a26fcb6b4fbdf2c854b97dadc","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-naacl.177.pdf","title":"","llm_title":"Unleashing the Power of LLMs in Court View Generation by Stimulating Internal Knowledge and Incorporating External Knowledge","authors":["Yifei Liu","Yiquan Wu","Ang Li","Yating Zhang","Changlong Sun","Weiming Lu","Fei Wu","Kun Kuang"],"llm_authors":"Yifei Liu, Yiquan Wu, Ang Li, Yating Zhang, Changlong Sun, Weiming Lu, Fei Wu, Kun Kuang","author_string":"","year":2024,"abstract":"","llm_abstract":"Court View Generation (CVG) plays a vital role in the realm of legal artificial intelligence, which aims to support judges in crafting legal judgment documents. The court view consists of three essential judgment parts: the charge-related, law article-related, and prison term-related parts, each requiring specialized legal knowledge, rendering CVG a challenging task. Although Large Language Models (LLMs) have made remarkable strides in language generation, they encounter difficulties in the knowledge-intensive legal domain. Actually, there can be two types of knowledge: internal knowledge stored within LLMs’ parameters and external knowledge sourced from legal documents outside the models. In this paper, we decompose court views into different parts, stimulate internal knowledge, and incorporate external information to unleash the power of LLMs in the CVG task. To validate our method, we conduct a series of experiment results on two real-world datasets LAIC2021 and CJO2022. The experiments demonstrate that our method is capable of generating more accurate and reliable court views.","llm_keywords":["Court View Generation","Legal AI","Large Language Models","Legal Knowledge","Text Generation"],"classifications":["Text Generation"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":11},{"id":"1e31d0cd442cc9fc1525c6bfd9ed2a1e55bceac1bdc9e1602330e8e64569983b6bc48287c35e112609f5c3ca39bed9954cc4438d4623821c84eeeda809bfb587","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.findings-acl.351.pdf","title":"","llm_title":"CMDL: A Large-Scale Chinese Multi-Defendant Legal Judgment Prediction Dataset","authors":["Wanhong Huang","Yi Feng","Chuanyi Li","Honghan Wu","Jidong Ge","Vincent Ng"],"llm_authors":"Wanhong Huang, Yi Feng, Chuanyi Li, Honghan Wu, Jidong Ge, Vincent Ng","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal Judgment Prediction (LJP) has attracted significant attention in recent years. However, previous studies have primarily focused on cases involving only a single defendant, skipping multi-defendant cases due to complexity and difficulty. To advance research, we introduce CMDL, a large-scale real-world Chinese Multi-Defendant LJP dataset, which consists of over 393,945 cases with nearly 1.2 million defendants in total. For performance evaluation, we propose case-level evaluation metrics dedicated for the multi-defendant scenario. Experimental results on CMDL show existing SOTA approaches demonstrate weakness when applied to cases involving multiple defendants. We highlight several challenges that require attention and resolution. The dataset is available at https://github.com/littlebowlnju/CMDL.","llm_keywords":["Legal Judgment Prediction","multi-defendant cases","Chinese dataset","case evaluation metrics","legal document analysis","judgment outcomes","criminal law","multi-task learning","pre-trained models"],"classifications":["Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":12},{"id":"09dfdca78721393f5ee6998c75c0ca6e745d1fecdff4a2dfda089c514fd6f18c6585c4051de2b6d8d74d68b9c68bad6c0bd349685dfa68b7995202916e527ade","file_path":"legal-nlp-survey-20250328-002/original/Feng_2022_0524.pdf","title":"","llm_title":"Legal Judgment Prediction via Event Extraction with Constraints","authors":["Yi Feng","Chuanyi Li","Vincent Ng"],"llm_authors":"Yi Feng, Chuanyi Li, Vincent Ng","author_string":"","year":2022,"abstract":"","llm_abstract":"While significant progress has been made on the task of Legal Judgment Prediction (LJP) in recent years, the incorrect predictions made by SOTA LJP models can be attributed in part to their failure to (1) locate the key event information that determines the judgment, and (2) exploit the cross-task consistency constraints that exist among the subtasks of LJP. To address these weaknesses, we propose EPM, an Event-based Prediction Model with constraints, which surpasses existing SOTA models in performance on a standard LJP dataset.","llm_keywords":["Legal Judgment Prediction","Event Extraction","Constraints","Machine Learning","Natural Language Processing","Legal Informatics","Judicial System","Court Decisions","Chinese Legal System","Hierarchical Event Definition"],"classifications":["Classification"],"num_cited_by":84,"num_cited_by_title_only":84,"num_pages":17},{"id":"02abb89d7f4f403e52ddf6908a806ccaf9fabd596fe0745d60298f149f62871e50a8646d4390e545b0e3d846cb0fb0019e83794d7283acbb7880f4d2d7fe338e","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2022_0530.pdf","title":"","llm_title":"LexGLUE: A Benchmark Dataset for Legal Language Understanding in English","authors":["Ilias Chalkidis","Abhik Jana","Dirk Hartung","Michael Bommarito","Ion Androutsopoulos","Daniel Martin Katz","Nikolaos Aletras"],"llm_authors":"Ilias Chalkidis, Abhik Jana, Dirk Hartung, Michael Bommarito, Ion Androutsopoulos, Daniel Martin Katz, Nikolaos Aletras","author_string":"","year":2022,"abstract":"","llm_abstract":"Laws and their interpretations, legal arguments and agreements are typically expressed in writing, leading to the production of vast corpora of legal text. Their analysis, which is at the center of legal practice, becomes increasingly elaborate as these collections grow in size. Natural language understanding (NLU) technologies can be a valuable tool to support legal practitioners in these endeavors. Their usefulness, however, largely depends on whether current state-of-the-art models can generalize across various tasks in the legal domain. To answer this currently open question, we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way. We also provide an evaluation and analysis of several generic and legal-oriented models demonstrating that the latter consistently offer performance improvements across multiple tasks.","llm_keywords":["LexGLUE","legal language understanding","natural language processing","benchmark dataset","legal text","NLU models","legal domain","evaluation","Transformer models"],"classifications":["Classification"],"num_cited_by":59,"num_cited_by_title_only":272,"num_pages":21},{"id":"539d0afef58aaaec6d86679d6cc7bd452cfe25fc5364c0ce093023e123a2f4d167eab8fa00e16c145c9b27bda9232907a3443b74467027728703a526c690bd6e","file_path":"legal-nlp-survey-20250328-002/team 1/5 - AACL (Asian Chapter of the Association for Computational Linguistics)/2023.findings-ijcnlp.37.pdf","title":"STRONG – Structure Controllable Legal Opinion Summary Generation","llm_title":"STRONG – Structure Controllable Legal Opinion Summary Generation","authors":["Yang Zhong","Diane Litman"],"llm_authors":"Yang Zhong, Diane Litman","author_string":"Yang Zhong ; Diane Litman","year":2023,"abstract":"","llm_abstract":"We propose an approach for the structure controllable summarization of long legal opinions that considers the argument structure of the document. Our approach involves using predicted argument role information to guide the model in generating coherent summaries that follow a provided structure pattern. We demonstrate the effectiveness of our approach on a dataset of legal opinions and show that it outperforms several strong baselines with respect to ROUGE, BERTScore, and structure similarity.","llm_keywords":["Legal Opinion Summarization","Structure Controllable Summarization","Argument Structure","Abstractive Summarization","Legal Text Generation"],"classifications":["Machine Summarization","Text Generation"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":18},{"id":"3e5d0cc21c04170b220b6e120de34f38f7ab369514dbb56ab9ede72f7dca64d8060f0c463b21726dac186f2dff60c7770c86331a020b4c70e52f2b0df759bacd","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-emnlp.194.pdf","title":"","llm_title":"Divide and Conquer: Legal Concept-guided Criminal Court View Generation","authors":["Qi Xu","Xiao Wei","Hang Yu","Qian Liu","Hao Fei"],"llm_authors":"Qi Xu, Xiao Wei, Hang Yu, Qian Liu, Hao Fei","author_string":"","year":2024,"abstract":"","llm_abstract":"The Criminal Court View Generation task aims to produce explanations that inform judicial decisions. This necessitates a nuanced understanding of diverse legal concepts, such as Recidivism, Confess, and Robbery, which often coexist within cases, complicating holistic analysis. However, existing methods mainly rely on the generation capability of language models, without paying enough attention to the important legal concepts. To enhance the precision and depth of such explanations, we introduce Legal Concept-guided Criminal Court Views Generation (LeGen), a three-stage approach designed for iterative reasoning tailored to individual legal concepts. Specifically, in the first stage, we design a decomposer to divide the court views into focused sub-views, each anchored around a distinct legal concept. Next, a concept reasoning module generates targeted rationales by intertwining the deconstructed facts with their corresponding legal frameworks, ensuring contextually relevant interpretations. Finally, a verifier and a generator are employed to align the rationale with the case fact and obtain synthesized comprehensive and legally sound final court views, respectively. We evaluate LeGen by conducting extensive experiments on a real-world dataset and experimental results validate the effectiveness of our proposed model. Our codes and dataset are available at https://github.com/xuqi220/LeGen.","llm_keywords":["Criminal Court View Generation","Legal Concepts","Iterative Reasoning","Language Models","LegalAI","Legal Frameworks","Court Views","Legal Judgments","Text Summarization","China Criminal Law"],"classifications":["Text Generation","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":16},{"id":"8c401e731028c3bea8d32141e24dd73302cfcb6ac6f14d0af6529919135a0dde5b322cda9525fb1e546926699ec8caae31272cc2e5a2637e538a1c616ba9dc4a","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.findings-acl.858.pdf","title":"","llm_title":"Exploring the Effectiveness of Prompt Engineering for Legal Reasoning Tasks","authors":["Fangyi Yu","Lee Quartey","Frank Schilder"],"llm_authors":"Fangyi Yu, Lee Quartey, Frank Schilder","author_string":"","year":2023,"abstract":"","llm_abstract":"The use of large language models (LLMs) for zero- or few-shot prompting in natural language processing has given rise to a new research area known as prompt engineering, which shows promising improvement in tasks such as arithmetic and common-sense reasoning. This paper explores the use of such approaches in legal reasoning tasks by conducting experiments on the COLIEE entailment task, which is based on the Japanese Bar exam. We further evaluate zero-shot/few-shot and fine-tuning approaches with and without explanations, alongside various prompting strategies. Our results indicate that while these techniques can improve general performance, the best results are achieved with prompts derived from specific legal reasoning techniques, such as IRAC (Issue, Rule, Application, Conclusion). In addition, we observe that few-shot learning with demonstrations derived from clustering past training data consistently yields high performance on the most recent COLIEE entailment tasks. Through our experiments, we improve the previous best result on the 2021 COLIEE task from 0.7037 to 0.8025 and surpass the best system from 2022 with an accuracy of 0.789.","llm_keywords":["prompt engineering","legal reasoning","large language models","zero-shot learning","few-shot learning","legal entailment","IRAC","COLIEE"],"classifications":["Classification","Resources","Information Retrieval"],"num_cited_by":49,"num_cited_by_title_only":49,"num_pages":15},{"id":"54c8344d303b7b0640fd778f6b478c35d9cdc03ff9fcbb7ddaeaea3d7fbf79dc656c0b33a3497f246e188819551999466e4c2b37e7eb1bd593c8707b8ae79749","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2022_0509.pdf","title":"","llm_title":"FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing","authors":["Ilias Chalkidis","Tommaso Pasini","Sheng Zhang","Letizia Tomada","Sebastian Felix Schwemer","Anders Søgaard"],"llm_authors":"Ilias Chalkidis, Tommaso Pasini, Sheng Zhang, Letizia Tomada, Sebastian Felix Schwemer, Anders Søgaard","author_string":"","year":2022,"abstract":"","llm_abstract":"We present a benchmark suite of four datasets for evaluating the fairness of pre-trained language models and the techniques used to fine-tune them for downstream tasks. Our benchmarks cover four jurisdictions (European Council, USA, Switzerland, and China), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, region, language, and legal area). In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that performance group disparities are vibrant in many cases, while none of these techniques guarantee fairness, nor consistently mitigate group disparities. Furthermore, we provide a quantitative and qualitative analysis of our results, highlighting open challenges in the development of robustness methods in legal NLP.","llm_keywords":["fairness","legal text processing","multilingual benchmark","language models","group disparity","NLP","legal NLP","bias","performance parity","equality"],"classifications":[],"num_cited_by":59,"num_cited_by_title_only":59,"num_pages":18},{"id":"811eda4baf432c8d9288a2d2cdbd159a1c2e8df424f03d522655605bb7bf6e603839bd69487185037b0f8e84414efc14b9650017257dc87d0d9ba1b3cb876c64","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2020.acl-main.393.pdf","title":"Identifying Principals and Accessories in a Complex Case based on the Comprehension of Fact Description","llm_title":"Identifying Principals and Accessories in a Complex Case based on the Comprehension of Fact Description","authors":["Yakun Hu","Zhunchen Luo","Wenhan Chao"],"llm_authors":"Yakun Hu, Zhunchen Luo, Wenhan Chao","author_string":"Yakun Hu ; Zhunchen Luo ; Wenhan Chao","year":2020,"abstract":"","llm_abstract":"In this paper, we study the problem of identifying the principals and accessories from the fact description with multiple defendants in a criminal case. We treat the fact descriptions as narrative texts and the defendants as roles over the narrative story. We propose to model the defendants with behavioral semantic information and statistical characteristics, then learning the importances of defendants within a learning-to-rank framework. Experimental results on a real-world dataset demonstrate the behavior analysis can effectively model the defendants’ impacts in a complex case.","llm_keywords":["legal assistant systems","narrative comprehension","machine learning","criminal case analysis","defendant role modeling"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":5},{"id":"42ba5befc84f1d2683e3ad1e5b9940b17613644e52d2f115a9230b734659c768cff763d733fca7c565390d7c7246585e1d5e017e44951514c2419060ff12e78a","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-emnlp.856.pdf","title":"","llm_title":"H-LegalKI: A Hierarchical Legal Knowledge Integration Framework for Legal Community Question Answering","authors":["Yue Jiang","Ziyu Guan","Jie Zhao","Wei Zhao","Jiaqi Yang"],"llm_authors":"Yue Jiang, Ziyu Guan, Jie Zhao, Wei Zhao and Jiaqi Yang","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal question answering (LQA) aims to bridge the gap between the limited availability of legal professionals and the high demand for legal assistance. Traditional LQA approaches typically either select the optimal answers from an answer set or extract answers from law texts. However, they often struggle to provide relevant answers to complex, real-world questions due to the rigidity of predetermined answers. Although recent advancements in legal large language models have shown some potential in enhancing answer relevance, they fail to address the multiple user-specific circumstances, i.e., factual details in questions. To address these issues, we (1) construct the first publicly available legal community question-answering (LegalCQA) dataset; and (2) propose a Hierarchical Legal Knowledge Integration (H-LegalKI) framework. LegalCQA is collected from two widely used legal forums for developing user-centered LQA models. For H-LegalKI, we design a legal knowledge retriever that gathers comprehensive legal knowledge based on both entire questions and individual sentences. And an answer generation model is designed to understand question- and sentence-level factual details and integrate corresponding legal knowledge in a hierarchical way. Additionally, we design a de-redundancy module to remove redundant legal knowledge. Experiments on LegalCQA demonstrate the superiority of our framework over competitive baselines.","llm_keywords":["Legal Question Answering","Hierarchical Knowledge Integration","LegalCommunity Question Answering","LegalCQA Dataset","Large Language Models","Legal Forums","User-Centered Models"],"classifications":["Resources","Information Retrieval","Text Generation"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":12},{"id":"4d2f0fbc593150451acdd464f2f491619639fdec8f3c0e8db63c92dba57fb91a1e2d0ada8f1326d808acd6355fa9381a0d09beac2adefbdf626c05255d0e28d0","file_path":"legal-nlp-survey-20250328-002/original/Malik_2021_0429.pdf","title":"ILDC for CJPE: Indian Legal Documents Corpus for Court Judgment Prediction and Explanation","llm_title":"ILDC for CJPE: Indian Legal Documents Corpus for Court Judgment Prediction and Explanation","authors":["Vijit Malik","Rishabh Sanjay","Shubham Kumar Nigam","Kripabandhu Ghosh","Shouvik Kumar Guha","Arnab Bhattacharya","Ashutosh Modi"],"llm_authors":"Vijit Malik, Rishabh Sanjay, Shubham Kumar Nigam, Kripa Ghosh, Shouvik Kumar Guha, Arnab Bhattacharya, Ashutosh Modi","author_string":"Vijit Malik ; Rishabh Sanjay ; Shubham Kumar Nigam ; Kripabandhu Ghosh ; Shouvik Kumar Guha ; Arnab Bhattacharya ; Ashutosh Modi","year":2021,"abstract":"","llm_abstract":"An automated system that could assist a judge in predicting the outcome of a case would help expedite the judicial process. For such a system to be practically useful, predictions by the system should be explainable. To promote research in developing such a system, we introduce ILDC (Indian Legal Documents Corpus). ILDC is a large corpus of 35k Indian Supreme Court cases annotated with original court decisions. A portion of the corpus (a separate test set) is annotated with gold standard explanations by legal experts. Based on ILDC, we propose the task of Court Judgment Prediction and Explanation (CJPE). The task requires an automated system to predict an explainable outcome of a case. We experiment with a battery of baseline models for case predictions and propose a hierarchical occlusion based model for explainability. Our best prediction model has an accuracy of 78% versus 94% for human legal experts, pointing towards the complexity of the prediction task. The analysis of explanations by the proposed algorithm reveals a significant difference in the point of view of the algorithm and legal experts for explaining the judgments, pointing towards scope for future research.","llm_keywords":["Legal AI","Judgment Prediction","Explainable AI","Indian Legal Documents","Machine Learning","Corpus Annotation","Natural Language Processing"],"classifications":["Classification","Resources","Information Extraction"],"num_cited_by":147,"num_cited_by_title_only":147,"num_pages":17},{"id":"8c9601e76c157b6b116f9ef7b087fa98f4078ba0ce307da24b95a78c704398abb2571db20f7df5172bc4535c9b02b272941c75eb881045d63abc90cf94ddbeeb","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-naacl.157.pdf","title":"","llm_title":"Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models in Court Decisions","authors":["Alex Nyffenegger","Matthias Stürmer","Joel Niklaus"],"llm_authors":"Alex Nyffenegger, Matthias Stürmer, Joel Niklaus","author_string":"","year":2024,"abstract":"","llm_abstract":"Anonymity in court rulings is a critical aspect of privacy protection in the European Union and Switzerland but with the advent of LLMs, concerns about large-scale re-identification of anonymized persons are growing. In accordance with the Federal Supreme Court of Switzerland (FSCS), we study re-identification risks using actual legal data. Following the initial experiment, we constructed an anonymized Wikipedia dataset as a more rigorous testing ground to further investigate the findings. In addition to the datasets, we also introduce new metrics to measure performance. We systematically analyze the factors that influence successful re-identifications, identifying model size, input length, and instruction tuning among the most critical determinants. Despite high re-identification rates on Wikipedia, even the best LLMs struggled with court decisions. We demonstrate that for now, the risk of re-identifications using LLMs is minimal in the vast majority of cases. We hope that our system can help enhance the confidence in the security of anonymized decisions, thus leading the courts to publish more decisions.","llm_keywords":["anonymity","re-identification","large language models","privacy protection","court rulings","data privacy","legal data","NLP","model size","instruction tuning"],"classifications":[],"num_cited_by":3,"num_cited_by_title_only":1,"num_pages":30},{"id":"a8e95eb0d12c949e1f947ab260bb598195b7e470a89396650f010275ec768928c1757fe4ea7c4b23b28975dfc555e1f85cf666b5bcaeda5e0bd5a285e5daa558","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2021.gebnlp-1.6.pdf","title":"Sexism in the Judiciary: The Importance of Bias Definition in NLP and In Our Courts","llm_title":"Sexism in the Judiciary: Bias Definition in NLP and in Our Courts","authors":["Noa Baker Gillis"],"llm_authors":"Noa Baker Gillis","author_string":"Noa Baker Gillis","year":2021,"abstract":"","llm_abstract":"We analyze 6.7 million case law documents to determine the presence of gender bias within our judicial system. We find that current bias detection methods in NLP are insufficient to determine gender bias in our case law database and propose an alternative approach. We show that existing algorithms’ inconsistent results are consequences of prior research’s inconsistent definitions of biases themselves. Bias detection algorithms rely on groups of words to represent bias (e.g., ‘salary,’ ‘job,’ and ‘boss’ to represent employment as a potentially biased theme against women in text). However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers’ own intuitions. We suggest two new methods of automating the creation of word lists to represent biases. We find that our methods outperform current NLP bias detection methods. Our research improves the capabilities of NLP technology to detect bias and highlights gender biases present in influential case law. In order to test our NLP bias detection method’s performance, we regress our results of bias in case law against U.S census data of women’s participation in the workforce in the last 100 years.","llm_keywords":["gender bias","NLP","case law","bias detection","word lists","judicial system","gender stereotypes","machine learning","algorithms"],"classifications":["Information Extraction","Pre-Processing"],"num_cited_by":1,"num_cited_by_title_only":9,"num_pages":10},{"id":"77f88089af1637653798c911d3ce7dc59ec78adc101b86ad94e6148eefd8d3402b64a635f6db9cfc1189c77db322d8ecff0eae4c5b579f62b8f3a821130fbaf6","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2022.acl-long.377.pdf","title":"","llm_title":"CaMEL: Case Marker Extraction without Labels","authors":["Leonie Weissweiler","Valentin Hofmann","Masoud Jalili Sabet","Hinrich Schütze"],"llm_authors":"Leonie Weissweiler, Valentin Hofmann, Masoud Jalili Sabet, Hinrich Schütze","author_string":"","year":2022,"abstract":"","llm_abstract":"We introduce CaMEL (Case Marker Extraction without Labels), a novel and challenging task in computational morphology that is especially relevant for low-resource languages. We propose a first model for CaMEL that uses a massively multilingual corpus to extract case markers in 83 languages based only on a noun phrase chunker and an alignment system. To evaluate CaMEL, we automatically construct a silver standard from UniMorph. The case markers extracted by our model can be used to detect and visualise similarities and differences between the case systems of different languages as well as to annotate fine-grained deep cases in languages in which they are not overtly marked.","llm_keywords":["CaMEL","case markers","computational morphology","multilingual corpus","low-resource languages","semantic categories","language processing","noun phrases"],"classifications":["Information Extraction","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"f003d6e89105bfa9350ffd1684b99d018f766c8a2df26c32941c620581c8f5d04ff39e3a05f88576ec2c66f7426bd3696e9e4c78434a8648715b68628da3ed85","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-naacl.69.pdf","title":"","llm_title":"SELF-EXPERTISE: Knowledge-based Instruction Dataset Augmentation for a Legal Expert Language Model","authors":["Minju Kim","Haein Jung","Myoung-wan Koo"],"llm_authors":"Minju Kim, Haein Jung, Myoung-wan Koo","author_string":"","year":2024,"abstract":"","llm_abstract":"The advent of instruction-tuned large language models (LLMs) has significantly advanced the field of automatic instruction dataset augmentation. However, the method of generating instructions and outputs from inherent knowledge of LLM can unintentionally produce hallucinations — instances of generating factually incorrect or misleading information. To overcome this, we propose SELF-EXPERTISE, automatically generating instruction dataset in the legal domain from a seed dataset. SELF-EXPERTISE extracts knowledge from the outputs of the seed dataset, and generates new instructions, inputs, and outputs. In this way, the proposed method reduces hallucination in automatic instruction augmentation. We trained an SELF-EXPERTISE augmented instruction dataset on the LLaMA-2 7B model to construct Korean legal specialized model, called LxPERT. LxPERT has demonstrated performance surpassing GPT-3.5-turbo in both in-domain and out-of-domain datasets. The SELF-EXPERTISE augmentation pipeline is not only applicable to the legal field but is also expected to be extendable to various domains, potentially advancing domain-specialized LLMs.","llm_keywords":["SELF-EXPERTISE","instruction dataset augmentation","legal domain","large language models","LxPERT"],"classifications":["Text Generation"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":15},{"id":"968e817e10ef26e24b3235c205f90f863b0c3118c326db090a4f577dc2877bb41c952123bdf41f773b36fb882c15c5a16f231336c59a9a0e389347a3292ea7cc","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/EACL 2023/2023.findings-eacl.44.pdf","title":"","llm_title":"Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases","authors":["Santosh T.Y.S.S","Oana Ichim","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Oana Ichim, Matthias Grabmair","author_string":"","year":2023,"abstract":"","llm_abstract":"In this paper, we cast Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles. This configuration facilitates the model learning some legal reasoning ability in mapping article text to specific case fact text. It also provides an opportunity to evaluate the model’s ability to generalize to zero-shot settings when asked to classify the case outcome with respect to articles not seen during training. We devise zero-shot experiments and apply domain adaptation methods based on domain discrimination and Wasserstein distance. Our results demonstrate that the article-aware architecture outperforms straightforward fact classification. We also find that domain adaptation methods improve zero-shot transfer performance, with article relatedness and encoder pre-training influencing the effect.","llm_keywords":["Legal Judgment Prediction","zero-shot learning","article-aware classification","domain adaptation","European Court of Human Rights","legal reasoning","NLP","Wasserstein distance"],"classifications":["Classification"],"num_cited_by":7,"num_cited_by_title_only":20,"num_pages":13},{"id":"481702985bd4d7ec59fc002fd1bdf36571cbdf4814bc3348191151ef4bf7effb5a9854da3e18245ffecf8d415d2193532a03cd0df8148c45d051e01ae1f930b8","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/EACL 2023/2023.findings-eacl.190.pdf","title":"","llm_title":"Exploiting Language Characteristics for Legal Domain-Specific Language Model Pretraining","authors":["Inderjeet Nair","Natwar Modani"],"llm_authors":"Inderjeet Nair and Natwar Modani","author_string":"","year":2023,"abstract":"","llm_abstract":"Pretraining large language models has resulted in tremendous performance improvement for many natural language processing (NLP) tasks. While for non-domain specific tasks, such models can be used directly, a common strategy to achieve better performance for specific domains involves pretraining these language models over domain specific data using objectives like Masked Language Modelling (MLM), Autoregressive Language Modelling, etc. While such pretraining addresses the change in vocabulary and style of language for the domain, it is otherwise a domain agnostic approach. In this work, we investigate the effect of incorporating pretraining objectives that explicitly tries to exploit the domain specific language characteristics in addition to such MLM based pretraining. Particularly, we examine two distinct characteristics associated with the legal domain and propose pretraining objectives modelling these characteristics. The proposed objectives target improvement of token-level feature representation, as well as aim to incorporate sentence level semantics. We demonstrate superiority in the performance of the models pretrained using our objectives against those trained using domain-agnostic objectives over several legal downstream tasks.","llm_keywords":["language model pretraining","legal domain","natural language processing","Masked Language Modelling","domain-specific language","token-level feature representation","sentence level semantics","legal AI","domain adaptation","pretraining objectives"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":11},{"id":"35e9be86269ac19adef282760de504ba668d7f896de782d1743f419ca32ece65d7763cd42bfad470bf3c0b6b1f64758e58708a20f80bd99ec5bf7167f79e6894","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2020.acl-main.466.pdf","title":"How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence","llm_title":"How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence","authors":["Haoxi Zhong","Chaojun Xiao","Cunchao Tu","Tianyang Zhang","Zhiyuan Liu","Maosong Sun"],"llm_authors":"Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun","author_string":"Haoxi Zhong ; Chaojun Xiao ; Cunchao Tu ; Tianyang Zhang ; Zhiyuan Liu ; Maosong Sun","year":2020,"abstract":"","llm_abstract":"Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from both AI researchers and legal professionals, as LegalAI is beneficial to the legal system for liberating legal professionals from a maze of paperwork. Legal professionals often think about how to solve tasks from rule-based and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we describe the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an in-depth analysis of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github.com/thunlp/CLAIM.","llm_keywords":["LegalAI","Natural Language Processing","Artificial Intelligence","Legal System","Deep Learning","Legal Judgment Prediction","Symbol-based Methods","Embedding-based Methods","Legal Question Answering","Legal Technology"],"classifications":[],"num_cited_by":411,"num_cited_by_title_only":411,"num_pages":13},{"id":"28774cfcff0c5903ddbc0df4e2a72c806adbcc7398046d6829b646a3b8bd04c5b30239d2945f482b7595345f1207571619117020e2bbdea68459bdcd7cea4242","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.findings-acl.918.pdf","title":"","llm_title":"Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning","authors":["Yang Wu","Chenghao Wang","Ece Gumusel","Xiaozhong Liu"],"llm_authors":"Yang Wu, Chenghao Wang, Ece Gumusel, Xiaozhong Liu","author_string":"","year":2024,"abstract":"","llm_abstract":"The integration of generative Large Language Models (LLMs) into various applications, including the legal domain, has been accelerated by their expansive and versatile nature. However, when facing a legal case, users without a legal background often struggle to formulate professional queries and may inadvertently overlook critical legal factors when presenting their case narrative to LLMs. To address this issue, we propose the Diagnostic Legal Large Language Model (D3LM), which utilizes adaptive lawyer-like diagnostic questions to collect additional case information and then provides high-quality feedback. D3LM incorporates an innovative graph-based Positive-Unlabeled Reinforcement Learning (PURL) algorithm, enabling the generation of critical questions and enhancing user-LLM interactions. Moreover, an integrated LLM-based stopping criterion facilitates precise Court Views Generation (CVG). Our research also introduces a new English-language CVG dataset based on the US case law database, enriching the realm of LLM research and deployment with a vital dimension. D3LM surpasses classical LLMs by delivering outstanding performance and a remarkable user experience in the legal domain.","llm_keywords":["Large Language Models","Legal Domain","Diagnostic Questions","Positive-Unlabeled Reinforcement Learning","Court Views Generation","D3LM","Legal Assistance","Graph-based Algorithms","Legal Services"],"classifications":["Text Generation"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":14},{"id":"f5ce7bd9ef531e63aaffc28e37dc01ad9a2e0a8a01532ad31d9c3b3e387c1095ca4a30fd2eaed0590638627b820af4bc6abce002eef0dae386cedbe506151c53","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.findings-acl.299.pdf","title":"","llm_title":"Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise: A Case Study on Chinese Legal Domain","authors":["Zhen Wan","Yating Zhang","Yexiang Wang","Fei Cheng","Sadao Kurohashi"],"llm_authors":"Zhen Wan, Yating Zhang, Yexiang Wang, Fei Cheng, Sadao Kurohashi","author_string":"","year":2024,"abstract":"","llm_abstract":"While large language models (LLMs) like GPT-4 have recently demonstrated astonishing zero-shot capabilities in general domain tasks, they often generate content with hallucinations in specific domains such as Chinese law, hindering their application in these areas. This is typically due to the absence of training data that encompasses such a specific domain, preventing GPT-4 from acquiring in-domain knowledge. A pressing challenge is that it’s not plausible to continue training LLMs of the GPT-4’s scale on in-domain data. This paper introduces a simple yet effective domain adaptation framework for GPT-4 by reformulating generation as an adapt-retrieve-revise process. The initial step is to adapt an affordable 7B LLM to the Chinese legal domain by continuing learning in-domain data. When solving an in-domain task, we leverage the adapted LLM to generate a draft answer given a task query. Then, the draft answer will be used to retrieve supporting evidence candidates from an external in-domain knowledge base. Finally, the draft answer and retrieved evidence are concatenated into a whole prompt to let GPT-4 assess the evidence and revise the draft answer to generate the final answer. Our proposal combines the advantages of the efficiency of adapting a smaller 7B model with the evidence-assessing capability of GPT-4 and effectively prevents GPT-4 from generating hallucinatory content. In the zero-shot setting of four Chinese legal tasks, our method improves the average score by +33.6 points, compared to GPT-4 direct generation. When compared to two stronger retrieval-based baselines, our method outperforms them by +17.0 and +23.5.","llm_keywords":["domain adaptation","large language models","GPT-4","Chinese legal domain","hallucinations","adapt-retrieve-revise","in-domain knowledge","retrieval-based methods","evidence assessment","zero-shot learning"],"classifications":["Machine Summarization"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":12},{"id":"7cd1a4515091dadecdfa0eabad51f69e6379af3278463b34fc9d590a1cdfd51f823c6f2c9a5c1951ad5c5333232f8730e50f6d40c5fc2b890ab091cf0537371d","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-naacl.76.pdf","title":"","llm_title":"Explanation Extraction from Hierarchical Classification Frameworks for Long Legal Documents","authors":["Nishchal Prasad","Taoufiq Dkaki","Mohand Boughanem"],"llm_authors":"Nishchal Prasad, Taoufiq Dkaki, Mohand Boughanem","author_string":"","year":2024,"abstract":"","llm_abstract":"Hierarchical classification frameworks have been widely used to process long sequences, especially in the legal domain for predictions from long legal documents. But being black-box models they are unable to explain their predictions making them less reliable for practical applications, more so in the legal domain. In this work, we develop an extractive explanation algorithm for hierarchical frameworks for long sequences based on the sensitivity of the trained model to its input perturbations. We perturb using occlusion and develop Ob-HEx; an Occlusion-based Hierarchical Explanation-extractor. We adapt Ob-HEx to Hierarchical Transformer models trained on long Indian legal texts. And use Ob-HEx to analyze them and extract their explanations for the ILDC-Expert dataset, achieving a minimum gain of 1 point over the previous benchmark on most of our performance evaluation metrics.","llm_keywords":["hierarchical classification","explanation extraction","black-box models","long legal documents","occlusion sensitivity","hierarchical transformers","legal NLP"],"classifications":["Classification","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"b4ef02081428b0c2cdc50a077a33ced0835512e579823cc02e868534e4e52279f4baf2f05a8e7978fd045645fdb45e82e6a8261043988b23225e7e6190a33f6e","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2023.findings-emnlp.490 (1).pdf","title":"","llm_title":"A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction","authors":["Ruihao Shui","Yixin Cao","Wang Xiang","Tat-Seng Chua"],"llm_authors":"Ruihao Shui, Yixin Cao, Wang Xiang, Tat-Seng Chua","author_string":"","year":2023,"abstract":"","llm_abstract":"Large language models (LLMs) have demonstrated great potential for domain-specific applications, such as the law domain. However, recent disputes over GPT-4’s law evaluation raise questions concerning their performance in real-world legal tasks. To systematically investigate their competency in the law, we design practical baseline solutions based on LLMs and test on the task of legal judgment prediction. In our solutions, LLMs can work alone to answer open questions or coordinate with an information retrieval (IR) system to learn from similar cases or solve simplified multi-choice questions. We show that similar cases and multi-choice options, namely label candidates, included in prompts can help LLMs recall domain knowledge that is critical for expertise legal reasoning. We additionally present an intriguing paradox wherein an IR system surpasses the performance of LLM+IR due to limited gains acquired by weaker LLMs from powerful IR systems. In such cases, the role of LLMs becomes redundant. Our evaluation pipeline can be easily extended into other tasks to facilitate evaluations in other domains.","llm_keywords":["Large Language Models","Legal Judgment Prediction","Information Retrieval","Domain-specific Applications","Legal Reasoning"],"classifications":["Information Retrieval","Classification"],"num_cited_by":19,"num_cited_by_title_only":19,"num_pages":12},{"id":"e0c5201a4bd7df8506c680e26646f35380b245add33e980b41467a86768b22253ebaf30bbb45260605d34358b534d06d7b65eaaa829c4dce347fff4cfc3c0d7c","file_path":"legal-nlp-survey-20250328-002/original/Xu_2020_0317.pdf","title":"Distinguish Confusing Law Articles for Legal Judgment Prediction","llm_title":"Distinguish Confusing Law Articles for Legal Judgment Prediction","authors":["Nuo Xu","Pinghui Wang","Long Chen","Li Pan","Xiaoyan Wang","Junzhou Zhao"],"llm_authors":"Nuo Xu, Pinghui Wang, Long Chen, Li Pan, Xiaoyan Wang, Junzhou Zhao","author_string":"Nuo Xu ; Pinghui Wang ; Long Chen ; Li Pan ; Xiaoyan Wang ; Junzhou Zhao","year":2020,"abstract":"","llm_abstract":"Legal Judgment Prediction (LJP) is the task of automatically predicting a law case’s judgment results given a text describing its facts, which has excellent prospects in judicial assistance systems and convenient services for the public. In practice, confusing charges are frequent, because law cases applicable to similar law articles are easily misjudged. For addressing this issue, the existing method relies heavily on domain experts, which hinders its application in different law systems. In this paper, we present an end-to-end model, LADAN, to solve the task of LJP. To distinguish confusing charges, we propose a novel graph neural network to automatically learn subtle differences between confusing law articles and design a novel attention mechanism that fully exploits the learned differences to extract compelling discriminative features from fact descriptions attentively. Experiments conducted on real-world datasets demonstrate the superiority of our LADAN.","llm_keywords":["Legal Judgment Prediction","confusing charges","graph neural network","judicial assistance","attention mechanism"],"classifications":[],"num_cited_by":177,"num_cited_by_title_only":177,"num_pages":10},{"id":"494020870ef56d9b11a660ec5ab9c2434a4d1f7fd45cd99a2ad95a00d69e4af31c8f19641a832f3b509ee3d898c80c70f58f6149d4f279c84946087d2a62cb26","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2022.ecnlp-1.23.pdf","title":"","llm_title":"Clause Topic Classification in German and English Standard Form Contracts","authors":["Daniel Braun","Florian Matthes"],"llm_authors":"Daniel Braun, Florian Matthes","author_string":"","year":2022,"abstract":"","llm_abstract":"So-called standard form contracts, i.e. contracts that are drafted unilaterally by one party, like terms and conditions of online shops or terms of services of social networks, are cornerstones of our modern economy. Their processing is, therefore, of significant practical value. Often, the sheer size of these contracts allows the drafting party to hide unfavourable terms from the other party. In this paper, we compare different approaches for automatically classifying the topics of clauses in standard form contracts, based on a data-set of more than 6,000 clauses from more than 170 contracts, which we collected from German and English online shops and annotated based on a taxonomy of clause topics, that we developed together with legal experts. We will show that, in our comparison of seven approaches, from simple keyword matching to transformer language models, BERT performed best with an F1-score of up to 0.91, however much simpler and computationally cheaper models like logistic regression also achieved similarly good results of up to 0.87.","llm_keywords":["standard form contracts","NLP","clause topic classification","BERT","logistic regression","consumer protection","taxonomy of clause topics"],"classifications":["Classification","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":11},{"id":"5d57afec73163d374b9ebddde9e801c9a3859c54ddfe0aa4d6a06bfe89b7fd8558d97fc5847dbe1a67c7ae3c80e8f355f7b4fcdb30400b0f523b81469c85d515","file_path":"legal-nlp-survey-20250328-002/original/Tsarapatsanis_2021_0453.pdf","title":"On the Ethical Limits of Natural Language Processing on Legal Text","llm_title":"On the Ethical Limits of Natural Language Processing on Legal Text","authors":["Dimitrios Tsarapatsanis","Nikolaos Aletras"],"llm_authors":"Dimitrios Tsarapatsanis, Nikolaos Aletras","author_string":"Dimitrios Tsarapatsanis ; Nikolaos Aletras","year":2021,"abstract":"","llm_abstract":"Natural language processing (NLP) methods for analyzing legal text offer legal scholars and practitioners a range of tools allowing to empirically analyze law on a large scale. However, researchers seem to struggle when it comes to identifying ethical limits to using NLP systems for acquiring genuine insights both about the law and the systems’ predictive capacity. In this paper we set out a number of ways in which to think systematically about such issues. We place emphasis on three crucial normative parameters which have, to the best of our knowledge, been underestimated by current debates: (a) the importance of academic freedom, (b) the existence of a wide diversity of legal and ethical norms domestically but even more so internationally and (c) the threat of moralism in research related to computational law. For each of these three parameters we provide specific recommendations for the legal NLP community. Our discussion is structured around the study of a real-life scenario that has prompted recent debate in the legal NLP research community.","llm_keywords":["Natural Language Processing","Legal Text","Ethical Limits","Academic Freedom","Legal Norms","Moralism","Computational Law","Legal NLP","Empirical Analysis"],"classifications":[],"num_cited_by":33,"num_cited_by_title_only":33,"num_pages":10},{"id":"3681a10735c99666aa3f46741ea7059d140b0aa18ad98663d9aef6f46d5ff4ea8e0153a138e3b2c59e746b1fc382c0dedccd2024c56f2a5abc25e8b31f898f53","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-emnlp.208.pdf","title":"","llm_title":"The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases","authors":["Santosh T.Y.S.S","Irtiza Chowdhury","Shanshan Xu","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Irtiza Chowdhury, Shanshan Xu, Matthias Grabmair","author_string":"","year":2024,"abstract":"","llm_abstract":"In high-stakes decision-making tasks within legal NLP, such as Case Outcome Classification (COC), quantifying a model’s predictive confidence is crucial. Confidence estimation enables humans to make more informed decisions, particularly when the model’s certainty is low, or where the consequences of a mistake are significant. However, most existing COC works prioritize high task performance over model reliability. This paper conducts an empirical investigation into how various design choices—including pre-training corpus, confidence estimator and fine-tuning loss—affect the reliability of COC models within the framework of selective prediction. Our experiments on the multi-label COC task, focusing on European Court of Human Rights (ECtHR) cases, highlight the importance of a diverse yet domain-specific pre-training corpus for better calibration. Additionally, we demonstrate that larger models tend to exhibit overconfidence, Monte Carlo dropout methods produce reliable confidence estimates, and confident error regularization effectively mitigates overconfidence. To our knowledge, this is the first systematic exploration of selective prediction in legal NLP. Our findings underscore the need for further research on enhancing confidence measurement and improving the trustworthiness of models in the legal domain.","llm_keywords":["Selective Prediction","Case Outcome Classification","Legal NLP","Confidence Estimation","European Court of Human Rights","Pre-training Corpus","Monte Carlo Dropout","Model Reliability","Trustworthiness","Legal Domain"],"classifications":["Pre-Processing","Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":19},{"id":"fd75e418ed140d0a9a0b9b72e765db02ef0b88362659605137eceb8d76ca72ce3e442445df7c32468b2bb3d1fce254865d22271b9f950d0561d3f8013682eb13","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2024.findings-emnlp.319.pdf","title":"","llm_title":"Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models","authors":["Yeeun Kim","Young Rok Choi","Eunkyung Choi","Jinhwan Choi","Hai Jin Park","Wonseok Hwang"],"llm_authors":"Yeeun Kim, Young Rok Choi, Eunkyung Choi, Jinhwan Choi, Hai Jin Park, Wonseok Hwang","author_string":"","year":2024,"abstract":"","llm_abstract":"Large language models (LLMs) have demonstrated remarkable performance in the legal domain, with GPT-4 even passing the Uniform Bar Exam in the U.S. However their efficacy remains limited for non-standardized tasks and tasks in languages other than English. This underscores the need for careful evaluation of LLMs within each legal system before application. Here, we introduce KBL, a benchmark for assessing the Korean legal language understanding of LLMs, consisting of (1) 7 legal knowledge tasks (510 examples), (2) 4 legal reasoning tasks (288 examples), and (3) the Korean bar exam (4 domains, 53 tasks, 2,510 examples). First two datasets were developed in close collaboration with lawyers to evaluate LLMs in practical scenarios in a certified manner. Furthermore, considering legal practitioners’ frequent use of extensive legal documents for research, we assess LLMs in both a closed book setting, where they rely solely on internal knowledge, and a retrieval-augmented generation (RAG) setting, using a corpus of Korean statutes and precedents. The results indicate substantial room and opportunities for improvement.","llm_keywords":["Large Language Models","Korean Legal Language","Benchmarking","Legal Tasks","Retrieval-Augmented Generation","GPT-4","Legal Reasoning"],"classifications":["Resources","Information Retrieval","Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":23},{"id":"de46e4fd35b00672d3e20f2feb19fc06e491a03c88f2068a40f9a41cc16dd6eac21669e5b6fea81d043af61aafb8b5440a7b4cbb33759408c240e809caadcb1f","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.findings-acl.301.pdf","title":"","llm_title":"Prototype-Based Interpretability for Legal Citation Prediction","authors":["Chu Fei Luo","Rohan Bhambhoria","Samuel Dahan","Xiaodan Zhu"],"llm_authors":"Chu Fei Luo, Rohan Bhambhoria, Samuel Dahan, Xiaodan Zhu","author_string":"","year":2023,"abstract":"","llm_abstract":"Deep learning has made significant progress in the past decade, and demonstrates potential to solve problems with extensive social impact. In high-stakes decision making areas such as law, experts often require interpretability for automatic systems to be utilized in practical settings. In this work, we attempt to address these requirements applied to the important problem of legal citation prediction (LCP). We design the task with parallels to the thought-process of lawyers, i.e., with reference to both precedents and legislative provisions. After initial experimental results, we refine the target citation predictions with the feedback of legal experts. Additionally, we introduce a prototype architecture to add interpretability, achieving strong performance while adhering to decision parameters used by lawyers. Our study builds on and leverages the state-of-the-art language processing models for law, while addressing vital considerations for high-stakes tasks with practical societal impact.","llm_keywords":["deep learning","legal citation prediction","law","interpretability","prototype architecture","natural language processing","high-stakes decision making","precedents","legislative provisions","language models"],"classifications":[],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":16},{"id":"f80c3dd518ac82d5a3fd2882571a53a6d530d24169e45fb2c5177122bec91cb045e237a2bb78a2648a9ecff7c5cff28511dad1986de2dcd23dc9f5545ecbf4f4","file_path":"legal-nlp-survey-20250328-002/ACL Findings/2023.findings-emnlp.145.pdf","title":"","llm_title":"Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning","authors":["Yougang Lyu","Jitai Hao","Zihan Wang","Kai Zhao","Shen Gao","Pengjie Ren","Zhumin Chen","Fang Wang","Zhaochun Ren"],"llm_authors":"Yougang Lyu, Jitai Hao, Zihan Wang, Kai Zhao, Shen Gao, Pengjie Ren, Zhumin Chen, Fang Wang, Zhaochun Ren","author_string":"","year":2023,"abstract":"","llm_abstract":"Multiple defendants in a criminal fact description generally exhibit complex interactions, and cannot be well handled by existing Legal Judgment Prediction (LJP) methods which focus on predicting judgment results (e.g., law articles, charges, and terms of penalty) for single-defendant cases. To address this problem, we propose the task of multi-defendant LJP, which aims to automatically predict the judgment results for each defendant of multi-defendant cases. Two challenges arise with the task of multi-defendant LJP: (1) indistinguishable judgment results among various defendants; and (2) the lack of a real-world dataset for training and evaluation. To tackle the first challenge, we formalize the multi-defendant judgment process as hierarchical reasoning chains and introduce a multi-defendant LJP method, named Hierarchical Reasoning Network (HRN), which follows the hierarchical reasoning chains to determine criminal relationships, sentencing circumstances, law articles, charges, and terms of penalty for each defendant. To tackle the second challenge, we collect a real-world multi-defendant LJP dataset, namely MultiLJP, to accelerate the relevant research in the future. Extensive experiments on MultiLJP verify the effectiveness of our proposed HRN.","llm_keywords":["Legal Judgment Prediction","multi-defendant cases","hierarchical reasoning","criminal interactions","dataset","Hierarchical Reasoning Network","MultiLJP","legal reasoning","judgment results"],"classifications":["Information Extraction","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":12},{"id":"4b1c29aa776e2669cfead9fff57f89a68fc7535e3af19dea4088b40e46570d294d712d8fb8de908f7e99af1b40eb14902a0bb9ec290a96917817252d44cd04fc","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.findings-acl.481.pdf","title":"","llm_title":"Towards Argument-Aware Abstractive Summarization of Long Legal Opinions with Summary Reranking","authors":["Mohamed Elaraby","Yang Zhong","Diane Litman"],"llm_authors":"Mohamed Elaraby, Yang Zhong, Diane Litman","author_string":"","year":2023,"abstract":"","llm_abstract":"We propose a simple approach for the abstractive summarization of long legal opinions that considers the argument structure of the document. Legal opinions often contain complex and nuanced argumentation, making it challenging to generate a concise summary that accurately captures the main points of the legal opinion. Our approach involves using argument role information to generate multiple candidate summaries, then reranking these candidates based on alignment with the document’s argument structure. We demonstrate the effectiveness of our approach on a dataset of long legal opinions and show that it outperforms several strong baselines.","llm_keywords":["abstractive summarization","legal opinions","argument structure","summary reranking","Longformer-Encoder-Decoder","candidate summaries","empirical results"],"classifications":["Machine Summarization"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":12},{"id":"ec8839b102375c02c2686e48bfd2706f3787d8cdcf891a0a33f0ae833095d00216634989381a1abe00ae6e6584c51d3f55616799c5b71c3a11b8919e0036e52a","file_path":"legal-nlp-survey-20250328-002/original/Hong_2021_0404.pdf","title":"Challenges for Information Extraction from Dialogue in Criminal Law","llm_title":"Challenges for Information Extraction from Dialogue in Criminal Law","authors":["Jenny Hong","Catalin Voss","Christopher Manning"],"llm_authors":"Jenny Hong, Catalin Voss, Christopher D. Manning","author_string":"Jenny Hong ; Catalin Voss ; Christopher Manning","year":2021,"abstract":"","llm_abstract":"Information extraction and question answering have the potential to introduce a new paradigm for how machine learning is applied to criminal law. Existing approaches generally use tabular data for predictive metrics. An alternative approach is needed for matters of equitable justice, where individuals are judged on a case-by-case basis, in a process involving verbal or written discussion and interpretation of case factors. Such discussions are individualized, but they nonetheless rely on underlying facts. Information extraction can play an important role in surfacing these facts, which are still important to understand. We analyze unsupervised, weakly supervised, and pre-trained models’ ability to extract such factual information from the free-form dialogue of California parole hearings. With a few exceptions, most F1 scores are below 0.85. We use this opportunity to highlight some opportunities for further research for information extraction and question answering. We encourage new developments in NLP to enable analysis and review of legal cases to be done in a post-hoc, not predictive, manner.","llm_keywords":["Information Extraction","Dialogue","Criminal Law","Equitable Justice","Machine Learning","Natural Language Processing","Parole Hearings","Statistical Analyses","California","Weak Supervision"],"classifications":["Information Extraction"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":11},{"id":"2fde59f0c1367b422c8c0d66bb4fc915a1672ae16f405377b1b016d5ddc2c7cd9bad50a4a801890f5a5d9b0d05edbf350be95d5c66d940c26aa53112e988e01d","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.eacl-long.122.pdf","title":"","llm_title":"Answering legal questions from laymen in German civil law system","authors":["Marius Büttner","Ivan Habernal"],"llm_authors":"Marius Büttner and Ivan Habernal","author_string":"","year":2024,"abstract":"","llm_abstract":"What is preventing us from building a NLP system that could help real people in real situations, for instance when they need legal advice but don’t understand law? This question is trickier than one might think, because legal systems vary from country to country, so do the law books, availability of data, and incomprehensibility of legalese. In this paper we focus Germany (which employs the civil-law system where, roughly speaking, interpretation of law codes dominates over precedence) and lay a foundational work to address the laymen’s legal question answering empirically. We create GerLayQA, a new dataset comprising of 21k laymen’s legal questions paired with answers from lawyers and grounded to concrete law book paragraphs. We experiment with a variety of retrieval and answer generation models and provide an in-depth analysis of limitations, which helps us to provide first empirical answers to the question above.","llm_keywords":["NLP","legal question answering","German civil law","laymen","dataset","retrieval models","answer generation","GerLayQA","semantic retrieval"],"classifications":["Information Retrieval","Text Generation","Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":13},{"id":"32352f40394f5df53abfbd6f1ead29ee1ea6810aedd378dae23cb738a69b961f32ab6dfc4f8500e020c946fb3c78d1f37f9cc85433a1be92075192f4d37d9672","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.findings-eacl.79.pdf","title":"","llm_title":"MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim Verification","authors":["Xia Zeng","Arkaitz Zubiaga"],"llm_authors":"Xia Zeng, Arkaitz Zubiaga","author_string":"","year":2024,"abstract":"","llm_abstract":"Claim verification is an essential step in the automated fact-checking pipeline which assesses the veracity of a claim against a piece of evidence. In this work, we explore the potential of few-shot claim verification, where only very limited data is available for supervision. We propose MAPLE (Micro Analysis of Pairwise Language Evolution), a pioneering approach that explores the alignment between a claim and its evidence with a small seq2seq model and a novel semantic measure. Its innovative utilization of micro language evolution path leverages unlabelled pairwise data to facilitate claim verification while imposing low demand on data annotations and computing resources. MAPLE demonstrates significant performance improvements over SOTA baselines SEED, PET and LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, and SciFact. Data and code are available here.","llm_keywords":["claim verification","few-shot learning","fact-checking","language evolution","semantic measures","NLP","micro analysis","seq2seq models","SOTA baselines","misinformation"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":1,"num_cited_by_title_only":5,"num_pages":20},{"id":"a01140b4cb9488338c780973c90943806eff1b2ae1f3d1e5acadde423af803dd0ae048620ab1d31cca95dc221a2c76836dfab800454ab45265ba9efde0895d5a","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.findings-eacl.42.pdf","title":"","llm_title":"Towards Context-Based Violence Detection: A Korean Crime Dialogue Dataset","authors":["Minju Kim","Heui-Yeen Yeen","Myoung-Wan Koo"],"llm_authors":"Minju Kim, Heui-Yeen Yeen, Myoung-Wan Koo","author_string":"","year":2024,"abstract":"","llm_abstract":"In order to enhance the security of society, there is rising interest in artificial intelligence (AI) to help detect and classify in advanced violence in daily life. The field of violence detection has introduced various datasets, yet context-based violence detection predominantly focuses on vision data, with a notable lack of NLP datasets. To overcome this, this paper presents the first Korean dialogue dataset for classifying violence that occurs in online settings: the Korean Crime Dialogue Dataset (KCDD). KCDD contains 22,249 dialogues created by crowd workers assuming offline scenarios. It has four criminal classes that meet international legal standards and one clean class (Serious Threats, Extortion or Blackmail, Harassment in the Workplace, Other Harassment, and Clean Dialogue). Plus, we propose a strong baseline for the proposed dataset, Relationship-Aware BERT. The model shows that understanding varying relationships among interlocutors improves the performance of crime dialogue classification. We hope that the proposed dataset will be used to detect cases of violence and aid people in danger. The KCDD dataset and corresponding baseline implementations can be found at the following link: https://sites.google.com/view/kcdd","llm_keywords":["violence detection","Korean Crime Dialogue Dataset","context-based detection","NLP datasets","Relationship-Aware BERT","crime classification","machine learning","contextualized conversations","artificial intelligence"],"classifications":["Classification","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":21},{"id":"c6d2c56e6d657da66a4d23a0b9de75ac77680c8a254d94a1d38e4c784cfa56bc415709a815ac04a9217998601484219a3ea0cbe852fe79243c36bc9a2b6dc596","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.law-1.7.pdf","title":"","llm_title":"Building a corpus for the anonymization of Romanian jurisprudence","authors":["Vasile Pais","Dan Tufis","Elena Irimia","Verginica Barbu Mititelu"],"llm_authors":"Vasile Pais, Dan Tufis, Elena Irimia, and Verginica Barbu Mititelu","author_string":"","year":2024,"abstract":"","llm_abstract":"Access to jurisprudence is of paramount importance both for law professionals (judges, lawyers, law students) and for the larger public. In Romania, the Superior Council of Magistracy holds a large database of jurisprudence from different courts in the country, which is updated daily. However, granting public access to it requires its anonymization. This paper presents the efforts behind building a corpus for the anonymization process. We present the annotation scheme, the manual annotation methods, and the platform used.","llm_keywords":["anonymization","Romanian jurisprudence","legal corpus","named entity recognition","data protection","machine learning","artificial intelligence","Romanian language BERT","legal domain"],"classifications":["Pre-Processing","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"206fb9c8be22aeb7c87b73884dc4eb782219c0729aa26b98f88c31d5d87b0c83bf908667c058954b32cf6822a0205cb76bcdb067056a03c021c8d875c68b9a31","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.eacl-long.156.pdf","title":"","llm_title":"Leveraging fine-tuned Large Language Models with LoRA for Effective Claim, Claimer, and Claim Object Detection","authors":["Sotiris Kotitsas","Panagiotis Kounoudis","Eleni Koutli","Haris Papageorgiou"],"llm_authors":"Sotiris Kotitsas, Panagiotis Kounoudis, Eleni Koutli, Haris Papageorgiou","author_string":"","year":2024,"abstract":"","llm_abstract":"Misinformation and disinformation phenomena existed long before the advent of digital technologies. The exponential use of social media platforms, whose information feeds have created the conditions for many to many communication and instant amplification of the news has accelerated the diffusion of inaccurate and misleading information. As a result, the identification of claims have emerged as a pivotal technology for combating the influence of misinformation and disinformation within news media. Most existing work has concentrated on claim analysis at the sentence level, neglecting the crucial exploration of supplementary attributes such as the claimer and the claim object of the claim or confining it by limiting its scope to a predefined list of topics. Furthermore, previous research has been mostly centered around political debates, Wikipedia articles, and COVID-19 related content. By leveraging the advanced capabilities of Large Language Models (LLMs) in Natural Language Understanding (NLU) and text generation, we propose a novel architecture utilizing LLMs finetuned with LoRA to transform the claim, claimer and claim object detection task into a Question Answering (QA) setting. We evaluate our approach in a dataset of 867 scientific news articles of 3 domains (Health, Climate Change, Nutrition) (HCN), which are human annotated with the major claim, the claimer and the object of the major claim. We also evaluate our proposed model in the benchmark dataset of NEWSCLAIMS. Experimental and qualitative results showcase the effectiveness of the proposed approach. We make our dataset publicly available to encourage further research.","llm_keywords":["Large Language Models","Claim Detection","Misinformation","Disinformation","Natural Language Understanding","Question Answering","LoRA","Argumentation Mining","Fact-checking","Claim Object"],"classifications":["Information Extraction","Text Generation","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":15},{"id":"440669c6437b33fcb1b4a8b552a484a36b7b9bbe72feb99e3ad8c989c310220c925638a85b6e1d43f0a1a9c949ad5b15f0033886379e903000addae121dafcfa","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.caldpseudo-1.3.pdf","title":"","llm_title":"Automatic Detection and Labelling of Personal Data in Case Reports from the ECHR in Spanish: Evaluation of Two Different Annotation Approaches","authors":["Maria Sierro","Begoña Altuna","Itziar Gonzalez-Dios"],"llm_authors":"Maria Sierro, Begoña Altuna, Itziar Gonzalez-Dios","author_string":"","year":2024,"abstract":"","llm_abstract":"In this paper we evaluate two annotation approaches for automatic detection and labelling of personal information in legal texts in relation to the ambiguity of the labels and the homogeneity of the annotations. For this purpose, we built a corpus of 44 case reports from the European Court of Human Rights in Spanish language and we annotated it following two different annotation approaches: automatic projection of the annotations of an existing English corpus, and manual annotation with our reinterpretation of their guidelines. Moreover, we employ Flair on a Named Entity Recognition task to compare its performance in the two annotation schemes.","llm_keywords":["automatic detection","personal data","legal texts","annotation approaches","Named Entity Recognition","Flair","European Court of Human Rights","Spanish corpus","ambiguity","homogeneity"],"classifications":["Information Extraction","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":7},{"id":"8c6a61df77a05ee19939427a55dc6fdf8887c14a467f6315c8aeda4a30089c00afb9e6066170b46cc96928f01b83d4c7bfb02778d1997f4d397c661c85554c8a","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.law-1.1.pdf","title":"","llm_title":"TreeForm: End-to-end Annotation and Evaluation for Form Document Parsing","authors":["Ran Zmigrod","Zhiqiang Ma","Armineh Nourbakhsh","Sameena Shah"],"llm_authors":"Ran Zmigrod, Zhiqiang Ma, Armineh Nourbakhsh, Sameena Shah","author_string":"","year":2024,"abstract":"","llm_abstract":"Visually Rich Form Understanding (VRFU) poses a complex research problem due to the documents’ highly structured nature and yet highly variable style and content. Current annotation schemes decompose form understanding and omit key hierarchical structure, making development and evaluation of end-to-end models difficult. In this paper, we propose a novel F1 metric to evaluate form parsers and describe a new content-agnostic, tree-based annotation scheme for VRFU: TreeForm. We provide methods to convert previous annotation schemes into TreeForm structures and evaluate TreeForm predictions using a modified version of the normalized tree-edit distance. We present initial baselines for our end-to-end performance metric and the TreeForm edit distance, averaged over the FUNSD and XFUND datasets, of 61.5 and 26.4 respectively. We hope that TreeForm encourages deeper research in annotating, modeling, and evaluating the complexities of form-like documents.","llm_keywords":["Visually Rich Form Understanding","form parsing","TreeForm","annotation scheme","evaluation metric","FUNSD dataset","XFUND dataset","tree-edit distance","multimodal AI"],"classifications":["Resources","Pre-Processing"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"f993c1dc162e8a177d6c061548e710c61cd7d6381e7f8fb738848824d9b417cac555b4bc701cc1a13923ee34a568aab1201db73535729d32d071ef5663d969ec","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/EACL 2023/2023.unlp-1.10.pdf","title":"","llm_title":"The Parliamentary Code-Switching Corpus: Bilingualism in the Ukrainian Parliament in the 1990s-2020s","authors":["Olha Kanishcheva","Maria Shvedova","Tetiana Kovalova","Ruprecht von Waldenfels"],"llm_authors":"Olha Kanishcheva, Maria Shvedova, Tetiana Kovalova, Ruprecht von Waldenfels","author_string":"","year":2023,"abstract":"","llm_abstract":"We describe a Ukrainian-Russian code-switching corpus of Ukrainian Parliamentary Session Transcripts. The corpus includes speeches entirely in Ukrainian, Russian, or various types of mixed speech and allows us to see how speakers switch between these languages depending on the communicative situation. The paper describes the process of creating this corpus from the official multilingual transcripts using automatic language detecting and publicly available metadata on the speakers. On this basis, we consider possible reasons for the change in the number of Ukrainian speakers in the parliament and present the most common patterns of bilingual Ukrainian and Russian code-switching in parliamentarians’ speeches.","llm_keywords":["code-switching","bilingualism","Ukrainian Parliament","Ukrainian language","Russian language","sociolinguistics","linguistic corpus","Surzhyk","language use","political linguistics"],"classifications":["Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":12},{"id":"0c2e9c03ed7fa2d5fb3631985f112600784800c2145c6b1ae30313a9772d0b50ed058291e5bec9f8838f7e55560278e2546317a02b54481bd4cf6494fb99592c","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/EACL 2023/2023.eacl-main.203.pdf","title":"","llm_title":"Finding the Law: Enhancing Statutory Article Retrieval via Graph Neural Networks","authors":["Antoine Louis","Gijs van Dijck","Gerasimos Spanakis"],"llm_authors":"Antoine Louis, Gijs van Dijck, Gerasimos Spanakis","author_string":"","year":2023,"abstract":"","llm_abstract":"Statutory article retrieval (SAR), the task of retrieving statute law articles relevant to a legal question, is a promising application of legal text processing. In particular, high-quality SAR systems can improve the work efficiency of legal professionals and provide basic legal assistance to citizens in need at no cost. Unlike traditional ad-hoc information retrieval, where each document is considered a complete source of information, SAR deals with texts whose full sense depends on complementary information from the topological organization of statute law. While existing works ignore these domain-specific dependencies, we propose a novel graph-augmented dense statute retriever (G-DSR) model that incorporates the structure of legislation via a graph neural network to improve dense retrieval performance. Experimental results show that our approach outperforms strong retrieval baselines on a real-world expert-annotated SAR dataset.","llm_keywords":["Statutory article retrieval","Graph neural networks","Legal text processing","Information retrieval","Dense statute retriever","Legislation structure"],"classifications":["Information Retrieval"],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":16},{"id":"8b7875b5ac8c1db34512c58e51334f3bc364bcdead871e4f44251a3651e4781601d53b4290c9a11ea5ad21f99e46ae885e7e2b9665c2ccba20d809b06c3c46a3","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.eacl-long.130.pdf","title":"","llm_title":"LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text","authors":["Dor Bernsohn","Gil Semo","Yaron Vazana","Gila Hayat","Ben Hagag","Joel Niklaus","Rohit Saha","Kyryl Truskovskyi"],"llm_authors":"Dor Bernsohn, Gil Semo, Yaron Vazana, Gila Hayat, Ben Hagag, Joel Niklaus, Rohit Saha, Kyryl Truskovskyi","author_string":"","year":2024,"abstract":"","llm_abstract":"In this study, we focus on two main tasks, the first for detecting legal violations within unstructured textual data, and the second for associating these violations with potentially affected individuals. We constructed two datasets using Large Language Models (LLMs) which were subsequently validated by domain expert annotators. Both tasks were designed specifically for the context of class-action cases. The experimental design incorporated fine-tuning models from the BERT family and open-source LLMs, and conducting few-shot experiments using closed-source LLMs. Our results, with an F1-score of 62.69% (violation identification) and 81.02% (associating victims), show that our datasets and setups can be used for both tasks. Finally, we publicly release the datasets and the code used for the experiments in order to advance further research in the area of legal natural language processing (NLP).","llm_keywords":["Legal Violation Identification","Large Language Models","Unstructured Text","Named Entity Recognition","Natural Language Inference","Synthetic Data Generation","Legal NLP","Class-action Cases","BERT","GPT-4"],"classifications":["Resources","Information Extraction","Classification"],"num_cited_by":3,"num_cited_by_title_only":15,"num_pages":17},{"id":"6067b623190343826bc2d04f0fe53660c57a9ecb8b9d8159d4044da90ca2428b38dd21c507a08ea404c144f2cc400a5d1d4f110032f8174e816c78fd45a5e0b5","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.eacl-srw.26.pdf","title":"","llm_title":"Forged-GAN-BERT: Authorship Attribution for LLM-Generated Forged Novels","authors":["Kanishka Silva","Ingo Frommholz","Burcu Can","Frédéric Blain","Raheem Sarwar","Laura Ugolini"],"llm_authors":"Kanishka Silva, Ingo Frommholz, Burcu Can, Frédéric Blain, Raheem Sarwar, Laura Ugolini","author_string":"","year":2024,"abstract":"","llm_abstract":"The advancement of generative Large Language Models (LLMs), capable of producing human-like texts, introduces challenges related to the authenticity of the text documents. This requires exploring potential forgery scenarios within the context of authorship attribution, especially in the literary domain. Particularly, two aspects of doubted authorship may arise in novels, as a novel may be imposed by a renowned author or include a copied writing style of a well-known novel. To address these concerns, we introduce Forged-GAN-BERT, a modified GAN-BERT-based model to improve the classification of forged novels in two data-augmentation aspects: via the Forged Novels Generator (i.e., ChatGPT) and the generator in GAN. Compared to other transformer-based models, the proposed Forged-GAN-BERT model demonstrates an improved performance with F1 scores of 0.97 and 0.71 for identifying forged novels in single-author and multi-author classification settings. Additionally, we explore different prompt categories for generating the forged novels to analyse the quality of the generated texts using different similarity distance measures, including ROUGE-1, Jaccard Similarity, Overlap Confident, and Cosine Similarity.","llm_keywords":["Forged-GAN-BERT","authorship attribution","LLM-generated novels","text forgery","GAN-BERT","ChatGPT","literary domain","text similarity measures","data augmentation","transformer-based models"],"classifications":["Classification","Text Generation"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":13},{"id":"a7844d141eb82610496cc84e0d15becaecedd75dad2bdb94843969cdc51895f59e00d202a08a6f374d815739b784aa67727af2fdf6ce08915674a8f00dffc94c","file_path":"legal-nlp-survey-20250328-002/team 1/6 - EACL European Chapter of the Association for Computational Linguistics/2024.eacl-demo.7.pdf","title":"","llm_title":"NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus","authors":["Kyoungyeon Cho","Seungkum Han","Young Rok Choi","Wonseok Hwang"],"llm_authors":"Kyoungyeon Cho, Seungkum Han, Young Rok Choi, Wonseok Hwang","author_string":"","year":2024,"abstract":"","llm_abstract":"The statistical analysis of large scale legal corpus can provide valuable legal insights. For such analysis one needs to (1) select a subset of the corpus using document retrieval tools, (2) structure text using information extraction (IE) systems, and (3) visualize the data for the statistical analysis. Each process demands either specialized tools or programming skills whereas no comprehensive unified “no-code” tools have been available. Here we provide NESTLE, a no-code tool for large-scale statistical analysis of legal corpus. Powered by a Large Language Model (LLM) and the internal custom end-to-end IE system, NESTLE can extract any type of information that has not been predefined in the IE system opening up the possibility of unlimited customizable statistical analysis of the corpus without writing a single line of code. We validate our system on 15 Korean precedent IE tasks and 3 legal text classification tasks from LEXGLUE. The comprehensive experiments reveal NESTLE can achieve GPT-4 comparable performance by training the internal IE module with 4 human-labeled, and 192 LLM-labeled examples.","llm_keywords":["no-code tool","statistical analysis","legal corpus","information extraction","large language model","legal documents","Korean precedents","LEXGLUE","customizable analysis","machine learning"],"classifications":["Information Retrieval","Information Extraction","Classification","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"d87dd22dcf12b3576552394298466419653ab5bbd784bb77ccb3f39aeefd50f9eabd78abdd1220f14190cee1d6f380c10f7bb998fcb7fac77af903d9d93b8a5a","file_path":"legal-nlp-survey-20250328-002/team 1/3 - TACL (Transations of the Assoiation for Computational Linguistics)/2023.tacl-1.3.pdf","title":"","llm_title":"On the Role of Negative Precedent in Legal Outcome Prediction","authors":["Josef Valvoda","Ryan Cotterell","Simone Teufel"],"llm_authors":"Josef Valvoda, Ryan Cotterell, Simone Teufel","author_string":"","year":2023,"abstract":"","llm_abstract":"Every legal case sets a precedent by developing the law in one of the following two ways. It either expands its scope, in which case it sets positive precedent, or it narrows it, in which case it sets negative precedent. Legal outcome prediction, the prediction of positive outcome, is an increasingly popular task in AI. In contrast, we turn our focus to negative outcomes here, and introduce a new task of negative outcome prediction. We discover an asymmetry in existing models’ ability to predict positive and negative outcomes. Where the state-of-the-art outcome prediction model we used predicts positive outcomes at 75.06 F1, it predicts negative outcomes at only 10.09 F1, worse than a random baseline. To address this performance gap, we develop two new models inspired by the dynamics of a court process. Our first model significantly improves positive outcome prediction score to 77.15 F1 and our second model more than doubles the negative outcome prediction performance to 24.01 F1. Despite this improvement, shifting focus to negative outcomes reveals that there is still much room for improvement for outcome prediction models.","llm_keywords":["negative precedent","legal outcome prediction","AI","positive outcomes","negative outcomes","court process","model performance","legal systems","BERT-based model"],"classifications":["Classification"],"num_cited_by":31,"num_cited_by_title_only":31,"num_pages":15},{"id":"4b8ed1bec24722f863830edc03660cb0e0f653c1f6d9ec3395bd9aad9db562d6da62a11817c7765a2e0f1e4a677a03fd7ff336bfc6241ab947ef7a7ca635aa24","file_path":"legal-nlp-survey-20250328-002/team 1/5 - AACL (Asian Chapter of the Association for Computational Linguistics)/2023.ijcnlp-main.72.pdf","title":"VACASPATI: A Diverse Corpus of Bangla Literature","llm_title":"VACASPATI: A Diverse Corpus of Bangla Literature","authors":["Pramit Bhattacharyya","Joydeep Mondal","Subhadip Maji","Arnab Bhattacharya"],"llm_authors":"Pramit Bhattacharyya, Joydeep Mondal, Subhadip Maji, Arnab Bhattacharya","author_string":"Pramit Bhattacharyya ; Joydeep Mondal ; Subhadip Maji ; Arnab Bhattacharya","year":2023,"abstract":"","llm_abstract":"Bangla (or Bengali) is the fifth most spoken language globally; yet, the state-of-the-art NLP in Bangla is lagging for even simple tasks such as lemmatization, POS tagging, etc. This is partly due to lack of a varied quality corpus. To alleviate this need, we build VACASPATI ¯ , a diverse corpus of Bangla literature. The literary works are collected from various websites; only those works that are publicly available without copyright violations or restrictions are collected. We believe that published literature captures the features of a language much better than newspapers, blogs or social media posts which tend to follow only a certain literary pattern and, therefore, miss out on language variety and vocabulary. Our corpus VACASPATI ¯ is varied from multiple aspects, including type of composition, topic, author, time, space, etc. It contains more than 11 million sentences and 115 million words. We have also built a word embedding model, VAC¯ -FT, using FastText from VACASPATI ¯ as well as trained an Electra model, VAC¯ -BERT, using the corpus. VAC¯ -BERT has far fewer parameters and requires only a fraction of resources compared to other state-of-the-art transformer models and yet performs either better or similar on various downstream tasks. Similarly, VAC¯ -FT outperforms other FastText-based models on multiple downstream tasks. We also demonstrate the efficacy of VACASPATI ¯ as a corpus by showing that similar models built from other corpora are not as effective.","llm_keywords":["Bangla literature","NLP","corpus","word embeddings","transformer models","language variety","VACASPATI","word similarity","sentiment classification","spelling error detection"],"classifications":["Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":13},{"id":"01090e37f168106566f068116d5223f9d4d0bb704fc829a69783603fa846c51479d472695da29e36449a28e8d7340d61b59ee3b1f0eb1db892c233aa06b4a9ff","file_path":"legal-nlp-survey-20250328-002/team 1/1-Language Resources and Evaluation/s10579-024-09747-7.pdf","title":"BRISE-plandok: a German legal corpus of building regulations","llm_title":"BRISE‑plandok: a German legal corpus of building regulations","authors":["Gábor Recski","Eszter Iklódi","Björn Lellmann","Ádám Kovács","Allan Hanbury"],"llm_authors":"Gábor Recski, Eszter Iklódi, Björn Lellmann, Ádám Kovács, Allan Hanbury","author_string":"Gábor Recski","year":2024,"abstract":"","llm_abstract":"We present the BRISE-Plandok corpus, a collection of 250 text documents with a total of over 7000 sentences from the Zoning Map of the City of Vienna, annotated manually with formal representations of the rules they convey. The generic rule format used by the corpus enables automated compliance checking of building plans, a process developed as part of the BRISE (https://smartcity.wien.gv.at/en/brise/) project. The format also allows for conversion to multiple logic formalisms, including dyadic deontic logic, enabling automated reasoning. Annotation guidelines were developed in collaboration with experts of the city’s building inspection office, describing nearly 100 domain-specific attributes with examples. Each document was annotated independently by two trained annotators and subsequently reviewed by the authors. A rule-based system for the automatic extraction of rules from text was developed and used in the annotation process to provide suggestions. The reviewed dataset was also used to train a set of baseline machine learning models for the task of attribute extraction, the main step in the rule extraction process. Both the rule-based system and the ML baselines are evaluated on the annotated dataset and released as open-source software. We also describe and release the framework used for generating and parsing the interactive xlsx spreadsheets used by annotators.","llm_keywords":["Rule corpus","Rule extraction","Annotation","Rule-based methods","Deontic logic","Automated compliance checking"],"classifications":["Information Extraction","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":40},{"id":"f6f747191c528f82904a8c7806a7aa57797f65297e4605e0dff6c541e1282237d73d8e15e49c0052ab35b636cd909e883cb11603ac9c6d1925ed9d809b64e4f6","file_path":"legal-nlp-survey-20250328-002/team 1/1-Language Resources and Evaluation/s10579-024-09748-6.pdf","title":"Parlamint-it: an 18-karat UD treebank of Italian parliamentary speeches","llm_title":"Parlamint-it: an 18-karat UD treebank of Italian parliamentary speeches","authors":["Chiara Alzetta","Simonetta Montemagni","Marta Sartor","Giulia Venturi"],"llm_authors":"Chiara Alzetta, Simonetta Montemagni, Marta Sartor, Giulia Venturi","author_string":"Chiara Alzetta","year":2024,"abstract":"","llm_abstract":"The paper presents ParlaMint-It, a new treebank of Italian parliamentary debates, linguistically annotated based on the Universal Dependencies (UD) framework. The resource comprises 20,460 tokens and represents a hybrid language variety that is underrepresented in the UD initiative. ParlaMint-It results from a manual revision process that relies on a semi-automatic methodology able to identify sentences that are most likely to contain inconsistencies and recurrent error patterns generated by the automatic annotation. Such a method made the revision process faster and more efficient than revising the entire treebank. In addition, it allowed the identification and correction of annotation errors resulting from linguistic constructions inconsistently represented in UD treebanks and from characteristics specific to parliamentary speeches. Hence, the treebank is deemed as an 18-karat resource, since, although not fully manually revised, it is a valuable resource for researchers working on Italian language processing tasks.","llm_keywords":["Universal Dependencies","treebanks","Italian parliamentary debates","linguistic annotation","annotation revision"],"classifications":["Resources","Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":25},{"id":"a0257fc8a37a8ec080124262bbd1a3b1df848fd7798993b45609f977905de849510a05c04f6118da13132eaebc92d63bdc89beaf445010a0a221e8dde8482563","file_path":"legal-nlp-survey-20250328-002/team 1/1-Language Resources and Evaluation/v1_covered_e3357ed4-a816-4de1-b4fa-57891bc965c3.pdf","title":"","llm_title":"Building a Relevance Feedback Corpus for Legal Information Retrieval in the Real-Case Scenario of the Brazilian Chamber of Deputies","authors":["Douglas Vitório","Ellen Souza","Lucas Martins","Nádia F. F. da Silva","André Carlos Ponce de Leon de Carvalho","Adriano L. I. Oliveira","Francisco Edmundo de Andrade"],"llm_authors":"Douglas Vitório, Ellen Souza, Lucas Martins, Nádia F. F. da Silva, André Carlos Ponce de Leon de Carvalho, Adriano L. I. Oliveira, Francisco Edmundo de Andrade","author_string":"","year":2024,"abstract":"","llm_abstract":"The proper functioning of judicial and legislative institutions requires the efficient retrieval of legal documents from extensive datasets. Legal Information Retrieval focuses on investigating how to efficiently handle these datasets, enabling the retrieval of pertinent information from them. Relevance Feedback, an important aspect of Information Retrieval systems, utilizes the relevance information provided by the user to enhance document retrieval for a specific request. However, there is a lack of available corpora containing this information, particularly for the legislative scenario. Thus, this paper presents Ulysses-RFCorpus, a Relevance Feedback corpus for legislative information retrieval, built in the real-case scenario of the Brazilian Chamber of Deputies. To the best of our knowledge, this corpus is the first publicly available of its kind for the Brazilian Portuguese language. It is also the only corpus that contains feedback information for legislative documents, as the other corpora found in the literature primarily focus on judicial texts. We also used the corpus to evaluate the performance of the Brazilian Chamber of Deputies’ Information Retrieval system. Thereby, we highlighted the model’s strong performance and emphasized the dataset’s significance in the field of Legal Information Retrieval.","llm_keywords":["corpus","relevance feedback","legal information retrieval","brazilian portuguese"],"classifications":["Information Retrieval","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":20},{"id":"fb08b8918303f677394d79dc2c195575d5d1a2d3a0c6b480c06e69b232095d25fdbee9568850046951b2582a0559248078854cf2ed2c23c97cd38975834ebaaf","file_path":"legal-nlp-survey-20250328-002/team 1/1-Language Resources and Evaluation/s10579-024-09798-w.pdf","title":"ParlaMint II: advancing comparable parliamentary corpora across Europe","llm_title":"ParlaMint II: advancing comparable parliamentary corpora across Europe","authors":["Tomaž Erjavec","Matyáš Kopp","Nikola Ljubešić","Taja Kuzman","Paul Rayson","Petya Osenova","Maciej Ogrodniczuk","Çağrı Çöltekin","Danijel Koržinek","Katja Meden","Jure Skubic","Peter Rupnik","Tommaso Agnoloni","José Aires","Starkaður Barkarson","Roberto Bartolini","Núria Bel","María Calzada Pérez","Roberts Darģis","Sascha Diwersy","Maria Gavriilidou","Ruben van Heusden","Mikel Iruskieta","Neeme Kahusk","Anna Kryvenko","Noémi Ligeti‑Nagy","Carmen Magariños","Martin Mölder","Costanza Navarretta","Kiril Simov","Lars Magne Tungland","Jouni Tuominen","John Vidler","Adina Ioana Vladu","Tanja Wissik","Väinö Yrjänäinen","Darja Fišer"],"llm_authors":"Tomaž Erjavec, Matyáš Kopp, Nikola Ljubešić, Taja Kuzman, Paul Rayson, Petya Osenova, Maciej Ogrodniczuk, Çağrı Çöltekin, Danijel Koržinek, Katja Meden, Jure Skubic, Peter Rupnik, Tommaso Agnoloni, José Aires, Starkaður Barkarson, Roberto Bartolini, Núria Bel, María Calzada Pérez, Roberts Darģis, Sascha Diwersy, Maria Gavriilidou, Ruben van Heusden, Mikel Iruskieta, Neeme Kahusk, Anna Kryvenko, Noémi Ligeti‑Nagy, Carmen Magariños, Martin Mölder, Costanza Navarretta, Kiril Simov, Lars Magne Tungland, Jouni Tuominen, John Vidler, Adina Ioana Vladu, Tanja Wissik, Väinö Yrjänäinen, Darja Fišer","author_string":"Tomaž Erjavec","year":2024,"abstract":"","llm_abstract":"The paper presents the results of the ParlaMint II project, which comprise comparable corpora of parliamentary debates of 29 European countries and autonomous regions, covering at least the period from 2015 to 2022, and containing over 1 billion words. The corpora are uniformly encoded, contain rich metadata about their 24 thousand speakers, and are linguistically annotated up to the level of Universal Dependencies syntax and named entities. The paper focuses on the enhancement made since the ParlaMint I project and presents the compilation of the corpora, including the encoding infrastructure, use of GitHub, the production of individual corpora, the common pipeline for producing their distribution, and use of CLARIN services for dissemination. It then gives a quantitative overview of the produced corpora, followed by the qualitative additions made within the ParlaMint II project, namely metadata localisation, the addition of new metadata, such as the political orientation of political parties, the machine translation of the corpora to English and its tagging with semantic classes, and the production of pilot speech corpora. Finally, outreach activities and further work are discussed.","llm_keywords":["Parliamentary proceedings","Comparable corpora","TEI","Metadata","Universal Dependencies","Machine translation","CLARIN","Linguistic annotation","Political parties","Speech corpora"],"classifications":["Text Generation","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":32},{"id":"bec6f326b4cf0899c0c1df732b4074b0dec093cc975485672bda1a8875076b17592765943082fac78ea5301f9f0014e834ac1c71b9b9241daabc4cf425c0d89f","file_path":"legal-nlp-survey-20250328-002/team 1/1-Language Resources and Evaluation/s10579-024-09762-8.pdf","title":"Ulysses Tesemõ: a new large corpus for Brazilian legal and governmental domain","llm_title":"Ulysses Tesemõ: a new large corpus for Brazilian legal and governmental domain","authors":["Felipe A. Siqueira","Douglas Vitório","Ellen Souza","José A. P. Santos","Hidelberg O. Albuquerque","Márcio S. Dias","Nádia F. F. Silva","André C. P. L. F. de Carvalho","Adriano L. I. Oliveira","Carmelo Bastos‑Filho"],"llm_authors":"Felipe A. Siqueira, Douglas Vitório, Ellen Souza, José A. P. Santos, Hidelberg O. Albuquerque, Márcio S. Dias, Nádia F. F. Silva, André C. P. L. F. de Carvalho, Adriano L. I. Oliveira, Carmelo Bastos‑Filho","author_string":"Felipe A. Siqueira","year":2024,"abstract":"","llm_abstract":"The increasing use of artifcial intelligence methods in the legal feld has sparked interest in applying Natural Language Processing techniques to handle legal tasks and reduce the workload of these professionals. However, the availability of legal corpora in Portuguese, especially for the Brazilian legal domain, is limited. Existing resources ofer some legal data but lack comprehensive coverage. To address this gap, we present Ulysses Tesemõ, a large corpus specifcally built for the Brazilian legal domain. The corpus consists of over 3.5 million fles, totaling 30.7 GiB of raw text, collected from 159 sources encompassing judicial, legislative, academic, news, and other related data. The data was collected by scraping public information from governmental websites, emphasizing contents generated over the past two decades. We categorized the obtained fles into 30 distinct categories, covering various branches of the Brazilian government and diferent types of texts. The corpus retains the original content with minimal data transformations, addressing the scarcity of Portuguese legal corpora and providing researchers with a valuable resource for advancing in the research area.","llm_keywords":["Corpus","Legal domain","Governmental domain","Portuguese language","Brazil","Natural Language Processing","Legal tasks","Judicial data","Legislative data","Public information"],"classifications":["Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":20},{"id":"d0d5993b67d72ba36ef766d8e5a332ce1b90183f01ec344fefa5d4347f023a59503392b3ecf63bdffa835a8862482bb808fa28366055a61ffb92be04145f31a5","file_path":"legal-nlp-survey-20250328-002/team 1/1-Language Resources and Evaluation/s10579-023-09650-7.pdf","title":"Finnish parliament ASR corpus","llm_title":"Finnish parliament ASR corpus\nAnalysis, benchmarks and statistics","authors":["Anja Virkkunen","Aku Rouhe","Nhan Phan","Mikko Kurimo"],"llm_authors":"Anja Virkkunen · Aku Rouhe · Nhan Phan · Mikko Kurimo","author_string":"Anja Virkkunen","year":2023,"abstract":"","llm_abstract":"Public sources like parliament meeting recordings and transcripts provide ever-growing material for the training and evaluation of automatic speech recognition (ASR) systems. In this paper, we publish and analyse the Finnish Parliament ASR Corpus, the most extensive publicly available collection of manually transcribed speech data for Finnish with over 3000 h of speech and 449 speakers for which it provides rich demographic metadata. This corpus builds on earlier initial work, and as a result the corpus has a natural split into two training subsets from two periods of time. Similarly, there are two official, corrected test sets covering different times, setting an ASR task with longitudinal distribution-shift characteristics. An official development set is also provided. We developed a complete Kaldi-based data preparation pipeline and ASR recipes for hidden Markov models (HMM), hybrid deep neural networks (HMM-DNN), and attention-based encoder-decoders (AED). For HMM-DNN systems, we provide results with time-delay neural networks (TDNN) as well as state-of-the-art wav2vec 2.0 pretrained acoustic models. We set benchmarks on the official test sets and multiple other recently used test sets. Both temporal corpus subsets are already large, and we observe that beyond their scale, HMM-TDNN ASR performance on the official test sets has reached a plateau. In contrast, other domains and larger wav2vec 2.0 models benefit from added data. The HMM-DNN and AED approaches are compared in a carefully matched equal data setting, with the HMM-DNN system consistently performing better. Finally, the variation of the ASR accuracy is compared between the speaker categories available in the parliament metadata to detect potential biases based on factors such as gender, age, and education.","llm_keywords":["Finnish","Speech recognition","Parliament speech data","HMM-DNN","AED","Wav2vec","Metadata"],"classifications":["Resources"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":26},{"id":"fc0934babffadaee5183be79c1d3a0fbcc8c5da2a98e0b7e911c071be135db018c14f0bd6ae7c2a8a7128aed3b5238d4c3dd76fe36f8335888f4dd88ea238fb6","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2023-capp-130-a-corpus-of-chinese-application-privacy-policy-summarization-and-interpretation-Paper-Datasets_and_Benchmarks.pdf","title":"","llm_title":"CAPP-130: A Corpus of Chinese Application Privacy Policy Summarization and Interpretation","authors":["Pengyun Zhu","Long Wen","Jinfei Liu","Feng Xue","Jian Lou","Zhibo Wang","Kui Ren"],"llm_authors":"Pengyun Zhu, Long Wen, Jinfei Liu, Feng Xue, Jian Lou, Zhibo Wang, Kui Ren","author_string":"","year":2024,"abstract":"","llm_abstract":"A privacy policy serves as an online internet protocol crafted by service providers, which details how service providers collect, process, store, manage, and use personal information when users engage with applications. However, these privacy policies are often filled with technobabble and legalese, making them “incomprehensible”. As a result, users often agree to all terms unknowingly, even some terms may conflict with the law, thereby posing a considerable risk to personal privacy information. One potential solution to alleviate this challenge is to automatically summarize privacy policies using NLP techniques. However, existing techniques primarily focus on extracting key sentences, resulting in comparatively shorter agreements, but failing to address the poor readability caused by the “incomprehensible” of technobabble and legalese. Moreover, research on Chinese application privacy policy summarization is currently almost nonexistent, and there is a lack of a high-quality corpus suitable for addressing readability issues. To tackle these challenges, we introduce a fine-grained CAPP-130 corpus and a TCSI-pp framework. CAPP-130 contains 130 Chinese privacy policies from popular applications that have been carefully annotated and interpreted by legal experts, resulting in 52, 489 annotations and 20, 555 rewritten sentences. TCSI-pp first extracts sentences related to the topic specified by users and then uses a generative model to rewrite the sentences into comprehensible summarization. Built upon TSCI-pp, we construct a summarization tool TSCI-pp-zh by selecting RoBERTa from six classification models for sentence extraction and selecting mT5 from five generative models for sentence rewriting. Experimental results show that TCSI-pp-zh outperforms GPT-4 and other baselines in Chinese application privacy policy summarization, demonstrating exceptional readability and reliability. Our data, annotation guidelines, benchmark models, and source code are publicly available at https: // github. com/ EnlightenedAI/ CAPP-130 .","llm_keywords":["Privacy Policy","Summarization","NLP","Chinese Applications","Legalese","CAPP-130","TCSI-pp Framework","Readability","RoBERTa","mT5"],"classifications":["Classification","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":13},{"id":"0528c12c6ad52b6e97707768336964165cc0c01e324112d87871d364e3dafdff6bff273b01ad989b24cb4901234fa8774137ab142df4e8ecd8212debe6f187fe","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2023-the-cambridge-law-corpus-a-dataset-for-legal-ai-research-Paper-Datasets_and_Benchmarks.pdf","title":"","llm_title":"The Cambridge Law Corpus: A Dataset for Legal AI Research","authors":["Andreas Östling","Holli Sargeant","Huiyuan Xie","Ludwig Bull","Alexander Terenin","Leif Jonsson","Måns Magnusson","Felix Steffek"],"llm_authors":"Andreas Östling, Holli Sargeant, Huiyuan Xie, Ludwig Bull, Alexander Terenin, Leif Jonsson, Måns Magnusson, Felix Steffek","author_string":"","year":2024,"abstract":"","llm_abstract":"We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.","llm_keywords":["Cambridge Law Corpus","legal AI","UK court cases","case outcome prediction","transformer-based models","data annotation","ethical discussion","legal datasets","large language models"],"classifications":["Resources"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":31},{"id":"015161037d247ee669de5a5e75b9a425dd7d9d7e1fa9a055ac542992b3ff1395dee7c5c8d000f1d69f306630990d5fb03f49ead0654e5f88058c8689eea9fbb0","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2023-wcld-curated-large-dataset-of-criminal-cases-from-wisconsin-circuit-courts-Paper-Datasets_and_Benchmarks.pdf","title":"","llm_title":"WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit Courts","authors":["Elliott Ash","Naman Goel","Nianyun Li","Claudia Marangon","Peiyao Sun"],"llm_authors":"Elliott Ash, Naman Goel, Nianyun Li, Claudia Marangon, Peiyao Sun","author_string":"","year":2023,"abstract":"","llm_abstract":"Machine learning based decision-support tools in criminal justice systems are subjects of intense discussions and academic research. There are important open questions about the utility and fairness of such tools. Academic researchers often rely on a few small datasets that are not sufficient to empirically study various real-world aspects of these questions. In this paper, we contribute WCLD, a curated large dataset of 1.5 million criminal cases from circuit courts in the U.S. state of Wisconsin. We used reliable public data from 1970 to 2020 to curate attributes like prior criminal counts and recidivism outcomes. The dataset contains large number of samples from five racial groups, in addition to information like sex and age (at judgment and first offense). Other attributes in this dataset include neighborhood characteristics obtained from census data, detailed types of offense, charge severity, case decisions, sentence lengths, year of filing etc. We also provide pseudo-identifiers for judge, county and zipcode. The dataset will not only enable researchers to more rigorously study algorithmic fairness in the context of criminal justice, but also relate algorithmic challenges with various systemic issues. We also discuss in detail the process of constructing the dataset and provide a datasheet. The WCLD dataset is available at https://clezdata.github.io/wcld/.","llm_keywords":["machine learning","criminal justice","algorithmic fairness","dataset","Wisconsin Circuit Courts","recidivism","racial groups","case decisions","sentence lengths","neighborhood characteristics"],"classifications":["Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":18},{"id":"6445a113574d6c99f98be0c95ffe281e0deb17847a518356e4d779b26593c64aacda94c5b511312f7f828a9eac83a8e089352750d37621026205df3d4c3f6f08","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2023-deep-contract-design-via-discontinuous-networks-Paper-Conference.pdf","title":"","llm_title":"Deep Contract Design via Discontinuous Networks","authors":["Tonghan Wang","Paul Dütting","Dmitry Ivanov","Inbal Talgam-Cohen","David C. Parkes"],"llm_authors":"Tonghan Wang, Paul Dütting, Dmitry Ivanov, Inbal Talgam-Cohen, David C. Parkes","author_string":"","year":2023,"abstract":"","llm_abstract":"Contract design involves a principal who establishes contractual agreements about payments for outcomes that arise from the actions of an agent. In this paper, we initiate the study of deep learning for the automated design of optimal contracts. We introduce a novel representation: the Discontinuous ReLU (DeLU) network, which models the principal’s utility as a discontinuous piecewise affine function of the design of a contract where each piece corresponds to the agent taking a particular action. DeLU networks implicitly learn closed-form expressions for the incentive compatibility constraints of the agent and the utility maximization objective of the principal, and support parallel inference on each piece through linear programming or interior-point methods that solve for optimal contracts. We provide empirical results that demonstrate success in approximating the principal’s utility function with a small number of training samples and scaling to find approximately optimal contracts on problems with a large number of actions and outcomes.","llm_keywords":["contract design","deep learning","discontinuous networks","utility maximization","piecewise affine functions"],"classifications":[],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":19},{"id":"27410678144b511c1542602ac3406bd0ab22c72148d9dec1756f8382e41886149b408597bb61358a72b86fbef5646df76ba359919db746bafbf578c03ed1af2c","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2023-domain-watermark-effective-and-harmless-dataset-copyright-protection-is-closed-at-hand-Paper-Conference.pdf","title":"","llm_title":"Domain Watermark: Effective and Harmless Dataset Copyright Protection is Closed at Hand","authors":["Junfeng Guo","Yiming Li","Lixu Wang","Shu-Tao Xia","Heng Huang","Cong Liu","Bo Li"],"llm_authors":"Junfeng Guo, Yiming Li, Lixu Wang, Shu-Tao Xia, Heng Huang, Cong Liu, Bo Li","author_string":"","year":2023,"abstract":"","llm_abstract":"The prosperity of deep neural networks (DNNs) is largely benefited from open-source datasets, based on which users can evaluate and improve their methods. In this paper, we revisit backdoor-based dataset ownership verification (DOV), which is currently the only feasible approach to protect the copyright of open-source datasets. We reveal that these methods are fundamentally harmful given that they could introduce malicious misclassification behaviors to watermarked DNNs by the adversaries. In this paper, we design DOV from another perspective by making watermarked models (trained on the protected dataset) correctly classify some ‘hard’ samples that will be misclassified by the benign model. Our method is inspired by the generalization property of DNNs, where we find a hardly-generalized domain for the original dataset (as its domain watermark). It can be easily learned with the protected dataset containing modified samples. Specifically, we formulate the domain generation as a bi-level optimization and propose to optimize a set of visually-indistinguishable clean-label modified data with similar effects to domain-watermarked samples from the hardly-generalized domain to ensure watermark stealthiness. We also design a hypothesis-test-guided ownership verification via our domain watermark and provide the theoretical analyses of our method. Extensive experiments on three benchmark datasets are conducted, which verify the effectiveness of our method and its resistance to potential adaptive methods. The code for reproducing main experiments is available at https://github.com/JunfengGo/Domain-Watermark.","llm_keywords":["deep neural networks","dataset ownership verification","backdoor attacks","domain watermark","data protection","generalization property","optimization","hypothesis testing"],"classifications":["Classification"],"num_cited_by":50,"num_cited_by_title_only":50,"num_pages":30},{"id":"0c2c2184bac2ef5d36310071ae147b36085490be538fd353a388efb529075fcac02df98dbb1c88912f8b13dd895e55b6e627caa7568df4adc108771dbc9f1252","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2023-legalbench-a-collaboratively-built-benchmark-for-measuring-legal-reasoning-in-large-language-models-Paper-Datasets_and_Benchmarks.pdf","title":"","llm_title":"LEGALBENCH: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models","authors":["Neel Guha","Julian Nyarko","Daniel E. Ho","Christopher Ré","Adam Chilton","Aditya Narayana","Alex Chohlas-Wood","Austin Peters","Brandon Waldon","Daniel N. Rockmore","Diego Zambrano","Dmitry Talisman","Enam Hoque","Faiz Surani","Frank Fagan","Galit Sarfaty","Gregory M. Dickinson","Haggai Porat","Jason Hegland","Jessica Wu","Joe Nudell","Joel Niklaus","John Nay","Jonathan H. Choi","Kevin Tobia","Margaret Hagan","Megan Ma","Michael Livermore","Nikon Rasumov-Rahe","Nils Holzenberger","Noam Kolt","Peter Henderson","Sean Rehaag","Sharad Goel","Shang Gao","Spencer Williams","Sunny Gandhi","Tom Zur","Varun Iyer","Zehua Li"],"llm_authors":"Neel Guha, Julian Nyarko, Daniel E. Ho, Christopher Ré, Adam Chilton, Aditya Narayana, Alex Chohlas-Wood, Austin Peters, Brandon Waldon, Daniel N. Rockmore, Diego Zambrano, Dmitry Talisman, Enam Hoque, Faiz Surani, Frank Fagan, Galit Sarfaty, Gregory M. Dickinson, Haggai Porat, Jason Hegland, Jessica Wu, Joe Nudell, Joel Niklaus, John Nay, Jonathan H. Choi, Kevin Tobia, Margaret Hagan, Megan Ma, Michael Livermore, Nikon Rasumov-Rahe, Nils Holzenberger, Noam Kolt, Peter Henderson, Sean Rehaag, Sharad Goel, Shang Gao, Spencer Williams, Sunny Gandhi, Tom Zur, Varun Iyer, Zehua Li","author_string":"","year":2023,"abstract":"","llm_abstract":"The advent of large language models (LLMs) and their adoption by the legal community has given rise to the question: what types of legal reasoning can LLMs perform? To enable greater study of this question, we present LEGALBENCH: a collaboratively constructed legal reasoning benchmark consisting of 162 tasks covering six different types of legal reasoning. LEGALBENCH was built through an interdisciplinary process, in which we collected tasks designed and hand-crafted by legal professionals. Because these subject matter experts took a leading role in construction, tasks either measure legal reasoning capabilities that are practically useful, or measure reasoning skills that lawyers find interesting. To enable cross-disciplinary conversations about LLMs in the law, we additionally show how popular legal frameworks for describing legal reasoning—which distinguish between its many forms—correspond to LEGALBENCH tasks, thus giving lawyers and LLM developers a common vocabulary. This paper describes LEGALBENCH, presents an empirical evaluation of 20 open-source and commercial LLMs, and illustrates the types of research explorations LEGALBENCH enables.","llm_keywords":["legal reasoning","large language models","LEGALBENCH","benchmark","legal professionals","interdisciplinary process","empirical evaluation","LLMs","legal frameworks"],"classifications":["Resources"],"num_cited_by":192,"num_cited_by_title_only":192,"num_pages":157},{"id":"603abd25c2845129b7b63d89e2d1cbf484e398e54defbbaeaa1c373bcddffe761c81229917d0037cc56e5ea213c8affbc1bc643c5686739f5290ee3f7bc697b3","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2024-saullm-54b-saullm-141b-scaling-up-domain-adaptation-for-the-legal-domain-Paper-Conference.pdf","title":"","llm_title":"SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain","authors":["Pierre Colombo","Telmo Pires","Malik Boudiaf","Rui Melo","Dominic Culver","Etienne Malaboeuf","Gabriel Hautreux","Johanne Charpentier","Michael Desa"],"llm_authors":"Pierre Colombo, Telmo Pires, Malik Boudiaf, Rui Melo, Dominic Culver, Etienne Malaboeuf, Gabriel Hautreux, Johanne Charpentier, Michael Desa","author_string":"","year":2025,"abstract":"","llm_abstract":"In this paper, we introduce SaulLM-54B and SaulLM-141B, two large language models (LLMs) tailored for the legal sector. These models, which feature architectures of 54 billion and 141 billion parameters, respectively, are based on the Mixtral architecture. The development of SaulLM-54B and SaulLM-141B is guided by large-scale domain adaptation, divided into three strategies: (1) the exploitation of continued pretraining involving a base corpus that includes over 540 billion of legal tokens, (2) the implementation of a specialized legal instruction-following protocol, and (3) the alignment of model outputs with human preferences in legal interpretations. The integration of synthetically generated data in the second and third steps enhances the models’ capabilities in interpreting and processing legal texts, effectively reaching state-of-the-art performance and outperforming previous open-source models on LegalBench-Instruct. This work explores the trade-offs involved in domain-specific adaptation at this scale, offering insights that may inform future studies on domain adaptation using strong decoder models. Building upon SaulLM-7B, this study refines the approach to produce an LLM better equipped for legal tasks. We are releasing base, instruct, and aligned versions on top of SaulLM-54B and SaulLM-141B under the MIT License to facilitate reuse and collaborative research.","llm_keywords":["large language models","legal domain","domain adaptation","SaulLM-54B","SaulLM-141B","Mixture of Experts","LegalBench-Instruct","synthetically generated data","neural networks","natural language processing"],"classifications":["Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":24},{"id":"950cbd15c70daaab4f826c2fc4fffe18c3364c47f6e0f1f0a439cc1ccef5f7a2ed6e6cd94675112a403db8f37e25c95c5d352b6d32c2bbdfa11f99f53a611ff9","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2023-the-harvard-uspto-patent-dataset-a-large-scale-well-structured-and-multi-purpose-corpus-of-patent-applications-Paper-Datasets_and_Benchmarks.pdf","title":"","llm_title":"The Harvard USPTO Patent Dataset: A Large-Scale, Well-Structured, and Multi-Purpose Corpus of Patent Applications","authors":["Mirac Suzgun","Luke Melas-Kyriazi","Suproteem K. Sarkar","Scott Duke Kominers","Stuart M. Shieber"],"llm_authors":"Mirac Suzgun, Luke Melas-Kyriazi, Suproteem K. Sarkar, Scott Duke Kominers, Stuart M. Shieber","author_string":"","year":2023,"abstract":"","llm_abstract":"In this paper, we introduce the Harvard USPTO Patent Dataset (HUPD), a large-scale, well-structured, and multi-purpose corpus of English-language patent applications filed to the United States Patent and Trademark Office (USPTO) between 2004 and 2018. With more than 4.5 million patent documents, HUPD is two to three times larger than comparable corpora. Unlike previously proposed patent datasets, HUPD contains the inventor-submitted versions of patent applications—not the final versions of granted patents—thereby allowing us to study patentability at the time of filing using NLP methods for the first time. It is also novel among NLP datasets in its inclusion of rich structured metadata alongside the text of patent filings, enabling researchers to perform new NLP tasks leveraging this metadata. As a case study on the types of research HUPD makes possible, we introduce a new task to the NLP community—patent acceptance prediction. Finally, we demonstrate how our dataset can be used for three additional tasks: multi-class classification of patent subject areas, language modeling, and summarization. Overall, HUPD is one of the largest multi-purpose NLP datasets containing domain-specific textual data, along with well-structured bibliographic metadata, and aims to advance research extending language and classification models to diverse and dynamic real-world data distributions.","llm_keywords":["patent dataset","NLP","USPTO","patent applications","structured metadata","patent acceptance prediction","multi-class classification","language modeling","summarization","broad-scale dataset"],"classifications":["Classification","Machine Summarization","Text Generation","Resources"],"num_cited_by":39,"num_cited_by_title_only":39,"num_pages":39},{"id":"43df72613d87e842c36a37172f727476dceae8eba709d986f2c421f99e7cc823cc9d879b3d3a4f39a2c015b6f3690ebccfffe1c45b8591d3d5330493d788f5f1","file_path":"legal-nlp-survey-20250328-002/team 1/2 - NeurIPS (ADvances in Neural Information Processing Systems))/NeurIPS-2024-lexeval-a-comprehensive-chinese-legal-benchmark-for-evaluating-large-language-models-Paper-Datasets_and_Benchmarks_Track.pdf","title":"","llm_title":"LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models","authors":["Haitao Li","You Chen","Qingyao Ai","Yueyue Wu","Ruizhe Zhang","Yiqun Liu"],"llm_authors":"Haitao Li, You Chen, Qingyao Ai, Yueyue Wu, Ruizhe Zhang, Yiqun Liu","author_string":"","year":2024,"abstract":"","llm_abstract":"Large language models (LLMs) have made significant progress in natural language processing tasks and demonstrate considerable potential in the legal domain. However, legal applications demand high standards of accuracy, reliability, and fairness. Applying existing LLMs to legal systems without careful evaluation of their potential and limitations could pose significant risks in legal practice. To this end, we introduce a standardized comprehensive Chinese legal benchmark LexEval. This benchmark is notable in the following three aspects: (1) Ability Modeling: We propose a new taxonomy of legal cognitive abilities to organize different tasks. (2) Scale: To our knowledge, LexEval is currently the largest Chinese legal evaluation dataset, comprising 23 tasks and 14,150 questions. (3) Data: we utilize formatted existing datasets, exam datasets and newly annotated datasets by legal experts to comprehensively evaluate the various capabilities of LLMs. LexEval not only focuses on the ability of LLMs to apply fundamental legal knowledge but also dedicates efforts to examining the ethical issues involved in their application. We evaluated 38 open-source and commercial LLMs and obtained some interesting findings. The experiments and findings offer valuable insights into the challenges and potential solutions for developing Chinese legal systems and LLM evaluation pipelines. The LexEval dataset and leaderboard are publicly available at https://github.com/CSHaitao/LexEval and will be continuously updated.","llm_keywords":["large language models","Chinese legal benchmark","natural language processing","legal applications","accuracy","reliability","fairness","evaluation dataset"],"classifications":["Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":34},{"id":"36d58d1312538c8427f22840271b5ebad11621a75a532e2ed197a7c1e65daaac7078395d13a5bd263d9093071626dbffa74b870f1a81493cfac2ba993894c1ec","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.687.pdf","title":"","llm_title":"EUROPA: A Legal Multilingual Keyphrase Generation Dataset","authors":["Olivier Salaün","Frédéric Piedboeuf","Guillaume Le Berre","David Alfonso Hermelo","Philippe Langlais"],"llm_authors":"Olivier Salaün, Frédéric Piedboeuf, Guillaume Le Berre, David Alfonso Hermelo, Philippe Langlais","author_string":"","year":2024,"abstract":"","llm_abstract":"Keyphrase generation has primarily been explored within the context of academic research articles, with a particular focus on scientific domains and the English language. In this work, we present EUROPA, a dataset for multilingual keyphrase generation in the legal domain. It is derived from legal judgments from the Court of Justice of the European Union (EU), and contains instances in all 24 EU official languages. We run multilingual models on our corpus and analyze the results, showing room for improvement on a domain-specific multilingual corpus such as the one we present.","llm_keywords":["keyphrase generation","multilingual keyphrase generation","legal domain","EUROPA dataset","multilingual models"],"classifications":["Text Generation"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":19},{"id":"19adc86ecf44e0afb74ca3f70e1c2cc9467565600d9d8cc3c94b5697c7e5dc2924a31e4c272e2524ec6e92b6b91e806af298bf9314c3c2562fe5f2c211df5ea6","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.acl-long.193.pdf","title":"","llm_title":"FEDLEGAL: The First Real-World Federated Learning Benchmark for Legal NLP","authors":["Zhuo Zhang","Xiangjing Hu","Jingyuan Zhang","Yating Zhang","Hui Wang","Lizhen Qu","Zenglin Xu"],"llm_authors":"Zhuo Zhang, Xiangjing Hu, Jingyuan Zhang, Yating Zhang, Hui Wang, Lizhen Qu, Zenglin Xu","author_string":"","year":2023,"abstract":"","llm_abstract":"The inevitable private information in legal data necessitates legal artificial intelligence to study privacy-preserving and decentralized learning methods. Federated learning (FL) has merged as a promising technique for multiple participants to collaboratively train a shared model while efficiently protecting the sensitive data of participants. However, to the best of our knowledge, there is no work on applying FL to legal NLP. To fill this gap, this paper presents the first real-world FL benchmark for legal NLP, coined FEDLEGAL, which comprises five legal NLP tasks and one privacy task based on the data from Chinese courts. Based on the extensive experiments on these datasets, our results show that FL faces new challenges in terms of real-world non-IID data. The benchmark also encourages researchers to investigate privacy protection using real-world data in the FL setting, as well as deploying models in resource-constrained scenarios.","llm_keywords":["Federated learning","Legal NLP","Privacy-preserving","Non-IID data","Chinese courts","Decentralized learning","Information utility","Privacy attacks"],"classifications":["Resources"],"num_cited_by":22,"num_cited_by_title_only":22,"num_pages":16},{"id":"758852584cfad3b8a9eccdda562226877fd624b52adf357080478ca4896833668bd70656f2d92b07efc36f6b6f71950d20b3229b7e46495898b8e8cd2f9cdef3","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.arabicnlp-1.20.pdf","title":"","llm_title":"ArabLegalEval: A Multitask Benchmark for Assessing Arabic Legal Knowledge in Large Language Models","authors":["Faris Hijazi","Somayah AlHarbi","Abdulaziz AlHussein","Harethah Abu Shairah","Reem AlZahrani","Hebah AlShamlan","Omar Knio","George Turkiyyah"],"llm_authors":"Faris Hijazi, Somayah AlHarbi, Abdulaziz AlHussein, Harethah Abu Shairah, Reem AlZahrani, Hebah AlShamlan, Omar Knio, George Turkiyyah","author_string":"","year":2024,"abstract":"","llm_abstract":"The rapid advancements in Large Language Models (LLMs) have led to significant improvements in various natural language processing tasks. However, the evaluation of LLMs’ legal knowledge, particularly in non-English languages such as Arabic, remains under-explored. To address this gap, we introduce ArabLegalEval, a multitask benchmark dataset for assessing the Arabic legal knowledge of LLMs. Inspired by the MMLU and LegalBench datasets, ArabLegalEval consists of multiple tasks sourced from Saudi legal documents and synthesized questions. In this work, we aim to analyze the capabilities required to solve legal problems in Arabic and benchmark the performance of state-of-the-art LLMs. We explore the impact of in-context learning and investigate various evaluation methods. Additionally, we explore workflows for generating questions with automatic validation to enhance the dataset’s quality. We benchmark multilingual and Arabic-centric LLMs, such as GPT-4 and Jais, respectively. We also share our methodology for creating the dataset and validation, which can be generalized to other domains. We hope to accelerate AI research in the Arabic Legal domain by releasing the ArabLegalEval dataset and code: https://github.com/Thiqah/ArabLegalEval","llm_keywords":["Arabic Legal Knowledge","Large Language Models","Benchmarking","Natural Language Processing","Legal Reasoning","In-Context Learning","Multitask Datasets","Arabic LLMs","Legal Evaluation","Automatic Validation"],"classifications":["Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":25},{"id":"f793596a8cb973c5542d9b53c22e8e932fe988126a93811d0d769cf9f98a49d43c2ebc0fe597f67b1437cb35120207b05dd810c21302eb7aff95525825065e6b","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.559.pdf","title":"","llm_title":"AGB-DE: A Corpus for the Automated Legal Assessment of Clauses in German Consumer Contracts","authors":["Daniel Braun","Florian Matthes"],"llm_authors":"Daniel Braun, Florian Matthes","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal tasks and datasets are often used as benchmarks for the capabilities of language models. However, openly available annotated datasets are rare. In this paper, we introduce AGB-DE, a corpus of 3,764 clauses from German consumer contracts that have been annotated and legally assessed by legal experts. Together with the data, we present a first baseline for the task of detecting potentially void clauses, comparing the performance of an SVM baseline with three fine-tuned open language models and the performance of GPT-3.5. Our results show the challenging nature of the task, with no approach exceeding an F1-score of 0.54. While the fine-tuned models often performed better with regard to precision, GPT-3.5 outperformed the other approaches with regard to recall. An analysis of the errors indicates that one of the main challenges could be the correct interpretation of complex clauses, rather than the decision boundaries of what is permissible and what is not.","llm_keywords":["legal assessment","consumer contracts","language models","German corpus","annotated dataset","baseline performance","SVM","GPT-3.5","complex clauses"],"classifications":["Resources","Classification","Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":17},{"id":"79932836a0ebb3a63a1ec10fde6eb275eeb0bcea4e6a2030ec755be45fcf2deffc9ba93043520707d2c771325ad57857c82d8a5a2a997ec2c992fe6af8770d75","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.findings-acl.360.pdf","title":"","llm_title":"An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text","authors":["Yova Kementchedjhieva","Ilias Chalkidis"],"llm_authors":"Yova Kementchedjhieva, Ilias Chalkidis","author_string":"","year":2023,"abstract":"","llm_abstract":"Standard methods for multi-label text classification largely rely on encoder-only pre-trained language models, whereas encoder-decoder models have proven more effective in other classification tasks. In this study, we compare four methods for multi-label classification, two based on an encoder only, and two based on an encoder-decoder. We carry out experiments on four datasets—two in the legal domain and two in the biomedical domain, each with two levels of label granularity— and always depart from the same pre-trained model, T5. Our results show that encoder-decoder methods outperform encoder-only methods, with a growing advantage on more complex datasets and labeling schemes of finer granularity. Using encoder-decoder models in a non-autoregressive fashion, in particular, yields the best performance overall, so we further study this approach through ablations to better understand its strengths.","llm_keywords":["multi-label classification","encoder-decoder models","T5 model","legal text","biomedical text","non-autoregressive approach","language models","classification tasks"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":22,"num_pages":16},{"id":"9fd608d0ac2849e349c345d1c5b9a36afb67403a590e396595ee6886766246b5487ec8105954997f07d1da5d0042edd931dbfd6e6960252b60e0e32a90a12129","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.166.pdf","title":"","llm_title":"ChronosLex: Time-aware Incremental Training for Temporal Generalization of Legal Classification Tasks","authors":["Santosh T.Y.S.S","Tuan-Quang Vuong","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Tuan-Quang Vuong, Matthias Grabmair","author_string":"","year":2024,"abstract":"","llm_abstract":"This study investigates the challenges posed by the dynamic nature of legal multi-label text classification tasks, where legal concepts evolve over time. Existing models often overlook the temporal dimension in their training process, leading to suboptimal performance of those models over time, as they treat training data as a single homogeneous block. To address this, we introduce ChronosLex, an incremental training paradigm that trains models on chronological splits, preserving the temporal order of the data. However, this incremental approach raises concerns about overfitting to recent data, prompting an assessment of mitigation strategies using continual learning and temporal invariant methods. Our experimental results over six legal multi-label text classification datasets reveal that continual learning methods prove effective in preventing overfitting thereby enhancing temporal generalizability, while temporal invariant methods struggle to capture these dynamics of temporal shifts.","llm_keywords":["legal classification","temporal generalization","incremental training","continual learning","temporal shifts","data drift","chronological splits","legal multi-label text classification"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":18},{"id":"4c8054db609138505897885381198dcbb3520e975be58c5929df3c581f0cbdb78030d8cfd3520b047ad6309b69d662dd03f307eef6fcdba90b53fee199c726fd","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.532.pdf","title":"","llm_title":"LePaRD: A Large-Scale Dataset of Judicial Citations to Precedent","authors":["Robert Mahari","Dominik Stammbach","Elliott Ash","Alex Sandy Pentland"],"llm_authors":"Robert Mahari, Dominik Stammbach, Elliott Ash, Alex ‘Sandy’ Pentland","author_string":"","year":2024,"abstract":"","llm_abstract":"We present the Legal Passage Retrieval Dataset, LePaRD. LePaRD contains millions of examples of U.S. federal judges citing precedent in context. The dataset aims to facilitate work on legal passage retrieval, a challenging practice-oriented legal retrieval and reasoning task. Legal passage retrieval seeks to predict relevant passages from precedential court decisions given the context of a legal argument. We extensively evaluate various approaches on LePaRD, and find that classification-based retrieval appears to work best. Our best models only achieve a recall of 59% when trained on data corresponding to the 10,000 most-cited passages, underscoring the difficulty of legal passage retrieval. By publishing LePaRD, we provide a large-scale and high quality resource to foster further research on legal passage retrieval. We hope that research on this practice-oriented NLP task will help expand access to justice by reducing the burden associated with legal research via computational assistance.","llm_keywords":["Legal Passage Retrieval","Judicial Citations","Precedent","NLP","Legal Dataset","Computational Assistance","Access to Justice"],"classifications":["Information Retrieval","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":15},{"id":"e3b392a1bd3f3ddfbe652c58c6fdb4050649e34ba3fc3a2fe82e5b1c4a06d841d807e04307917900f03f414873e0ba0d88bcb47affd5f61022d348e6cbef7193","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.618v2.pdf","title":"","llm_title":"IL-TUR: Benchmark for Indian Legal Text Understanding and Reasoning","authors":["Abhinav Joshi","Shounak Paul","Akshat Sharma","Pawan Goyal","Saptarshi Ghosh","Ashutosh Modi"],"llm_authors":"Abhinav Joshi, Shounak Paul, Akshat Sharma, Pawan Goyal, Saptarshi Ghosh, Ashutosh Modi","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal systems worldwide are inundated with exponential growth in cases and documents. There is an imminent need to develop NLP and ML techniques for automatically processing and understanding legal documents to streamline the legal system. However, evaluating and comparing various NLP models designed specifically for the legal domain is challenging. This paper addresses this challenge by proposing IL-TUR: Benchmark for Indian Legal Text Understanding and Reasoning. IL-TUR contains monolingual (English, Hindi) and multi-lingual (9 Indian languages) domain-specific tasks that address different aspects of the legal system from the point of view of understanding and reasoning over Indian legal documents. We present baseline models (including LLM-based) for each task, outlining the gap between models and the ground truth. To foster further research in the legal domain, we create a leaderboard (available at: https://exploration-lab.github.io/IL-TUR/) where the research community can upload and compare legal text understanding systems.","llm_keywords":["Indian legal text processing","Legal NLP","Benchmarking","Multilingual tasks","Legal reasoning","NLP in legal domain","Machine learning","Baseline models"],"classifications":["Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":40},{"id":"cfe9e2dccdc4948efd5908620c8dd548a944a779f8aadce87be151a460db2442005df68d393cf93c33449d2750079ac537f2ae2b76c604312c3f12052f8d6114","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.sustainlp-1.11.pdf","title":"","llm_title":"Can we Pretrain a SotA Legal Language Model on a Budget From Scratch?","authors":["Joel Niklaus","Daniele Giofré"],"llm_authors":"Joel Niklaus and Daniele Giofré","author_string":"","year":2023,"abstract":"","llm_abstract":"Even though many efficient transformers have been proposed, only few such models are available for specialized domains. Additionally, since the pretraining process is extremely costly in general – but even more so as the sequence length increases – it is often only in reach of large research labs. One way of making pretraining cheaper is the Replaced Token Detection (RTD) task, by providing more signal during training compared to MLM, since the loss can be computed over all tokens. In this work, we train Longformer models with the efficient RTD task on long-context legal data to showcase that pretraining efficient LMs is possible using less than 12 GPU days. We evaluate the trained models on challenging summarization tasks requiring the model to summarize complex long texts. We find that both the small and base models outperform their baselines on the in-domain BillSum and out-of-domain PubMed tasks in their respective parameter range. We publish our models as a resource for researchers and practitioners.","llm_keywords":["efficient transformers","specialized domains","pretraining cost","Replaced Token Detection","Longformer","legal language model","summarization tasks","BillSum dataset","PubMed dataset"],"classifications":["Resources","Machine Summarization"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":25},{"id":"7e657b3239b4492169427f9a2a4c8044b5f3c559c168559a00b31da6799f67065bcf4ede8780390b599be1d59c6eb544e420c0668eb8afd32573423681ab7a8a","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.acl-long.865.pdf","title":"","llm_title":"LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development","authors":["Ilias Chalkidis","Nicolas Garneau","Anders Søgaard","Cătălina Goantă","Daniel Martin Katz"],"llm_authors":"Ilias Chalkidis, Nicolas Garneau, Anders Søgaard, Cat˘ alina Goant ˘ ,a˘, Daniel Martin Katz","author_string":"","year":2023,"abstract":"","llm_abstract":"In this work, we conduct a detailed analy¬sis on the performance of legal-oriented pre¬trained language models (PLMs). We exam¬ine the interplay between their original ob¬jective, acquired knowledge, and legal lan¬guage understanding capacities which we de¬fine as the upstream, probing, and downstream performance, respectively. We consider not only the models’ size but also the pre-training corpora used as important dimensions in our study. To this end, we release a multinational English legal corpus (LeXFiles) and a legal knowledge probing benchmark (LegalLAMA) to facilitate training and detailed analysis of legal-oriented PLMs. We release two new legal PLMs trained on LeXFiles and evaluate them alongside others on LegalLAMA and LexGLUE. We find that probing performance strongly correlates with upstream performance in related legal topics. On the other hand, downstream performance is mainly driven by the model’s size and prior legal knowledge which can be estimated by upstream and prob¬ing performance. Based on these findings, we can conclude that both dimensions are im¬portant for those seeking the development of domain-specific PLMs.","llm_keywords":["Legal Language Models","LeXFiles","LegalLAMA","Pre-trained Language Models","Corpus Development","Domain-specific PLMs","Upstream Performance","Probing Performance","Downstream Tasks"],"classifications":["Pre-Processing","Resources"],"num_cited_by":57,"num_cited_by_title_only":57,"num_pages":23},{"id":"a7762326ea7adaee8f10f6e9a5b53b1b8c7927c10d94c9c316241fc3e6bf0b3282225c324a620dd770d5b1d7d25f64157788ac0690236ee56a2907e7e541d11b","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-demos.36.pdf","title":"","llm_title":"ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal Advice","authors":["Yutong Hu","Kangcheng Luo","Yansong Feng"],"llm_authors":"Yutong Hu, Kangcheng Luo, Yansong Feng","author_string":"","year":2024,"abstract":"","llm_abstract":"Despite remarkable performance in legal consultation exhibited by legal Large Language Models(LLMs) combined with legal article retrieval components, there are still cases when the advice given is incorrect or baseless. To alleviate these problems, we propose ELLA, a tool for Empowering LLMs for interpretable, accurate, and informative Legal Advice. ELLA visually presents the correlation between legal articles and LLM’s response by calculating their similarities, providing users with an intuitive legal basis for the responses. Besides, based on the users’ queries, ELLA retrieves relevant legal articles and displays them to users. Users can interactively select legal articles for LLM to generate more accurate responses. ELLA also retrieves relevant legal cases for user reference. Our user study shows that presenting the legal basis for the response helps users understand better. The accuracy of LLM’s responses also improves when users intervene in selecting legal articles for LLM. Providing relevant legal cases also aids individuals in obtaining comprehensive information. Our github repo is: https://github.com/Huyt00/ELLA1.","llm_keywords":["Legal Advice","Large Language Models","Legal Article Retrieval","Interpretable AI","Informative Responses","Legal Consultation"],"classifications":["Information Retrieval","Information Extraction","Text Generation","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":14},{"id":"10097cd1aaa04580ca716f5dcb2fa9054a984df0370c33d512f57bac2d79c3044a0e978fd9bba72a9b22c4c44bd5dca99614d368b0f57896a93a412af312e7ad","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.13.pdf","title":"","llm_title":"Through the Lens of Split Vote: Exploring Disagreement, Difficulty and Calibration in Legal Case Outcome Classification","authors":["Shanshan Xu","Santosh T.Y.S.S","Oana Ichim","Barbara Plank","Matthias Grabmair"],"llm_authors":"Shanshan Xu, Santosh T.Y.S.S, Oana Ichim, Barbara Plank, Matthias Grabmair","author_string":"","year":2024,"abstract":"","llm_abstract":"In legal decisions, split votes (SV) occur when judges cannot reach a unanimous decision, posing a difficulty for lawyers who must navigate diverse legal arguments and opinions. In high-stakes domains, understanding the alignment of perceived difficulty between humans and AI systems is crucial to build trust. However, existing NLP calibration methods focus on a classifier’s awareness of predictive performance, measured against the human majority class, overlooking inherent human label variation (HLV). This paper explores split votes as naturally observable human disagreement and value pluralism. We collect judges’ vote distributions from the European Court of Human Rights (ECHR), and present SV-ECHR a case outcome classification (COC) dataset with SV information. We build a taxonomy of disagreement with SV-specific subcategories. We further assess the alignment of perceived difficulty between models and humans, as well as confidence- and human-calibration of COC models. We observe limited alignment with the judge vote distribution. To our knowledge, this is the first systematic exploration of calibration to human judgments in legal NLP. Our study underscores the necessity for further research on measuring and enhancing model calibration considering HLV in legal decision tasks.","llm_keywords":["Split vote","Disagreement","Calibration","Legal case outcome classification","Human label variation","European Court of Human Rights","Predictive performance","Natural Language Processing","Case outcome classification dataset","Value pluralism"],"classifications":["Classification","Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":18},{"id":"0034dd86a2b6e62ce763030218cfce84366e63aeeabe5113365cce2d5cfde4a0ed5eaffd3707ce6444185f017f932b3321580d2dd1dc4ca807aa33f90692f3df","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.law-1.12.pdf","title":"","llm_title":"Annotators-in-the-loop: Testing a Novel Annotation Procedure on Italian Case Law","authors":["Emma Zanoli","Matilde Barbini","Davide Riva","Sergio Picascia","Emanuela Furiosi","Stefano D’Ancona","Cristiano Chesi"],"llm_authors":"Emma Zanoli, Matilde Barbini, Davide Riva, Sergio Picascia, Emanuela Furiosi, Stefano D’Ancona, Cristiano Chesi","author_string":"","year":2023,"abstract":"","llm_abstract":"The availability of annotated legal corpora is crucial for a number of tasks, such as legal search, legal information retrieval, and predictive justice. Annotation is mostly assumed to be a straightforward task: as long as the annotation scheme is well defined and the guidelines are clear, annotators are expected to agree on the labels. This is not always the case, especially in legal annotation, which can be extremely difficult even for expert annotators. We propose a legal annotation procedure that takes into account annotator certainty and improves it through negotiation. We also collect annotator feedback and show that our approach contributes to a positive annotation environment. Our work invites reflection on often neglected ethical concerns regarding legal annotation.","llm_keywords":["legal annotation","annotator certainty","negotiation","legal NLP","ethical concerns","Italian case law","annotation guidelines","legal corpora","legal information retrieval","predictive justice"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":11},{"id":"3e3beb3ca8fe77df4079d74057a10f15a0cf3f81b5aed92b78559124ad846f02435c6c5e39fc0e868e36a29d39b011634ea946e317d9a16f2caf6654994a5c65","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.acl-short.31.pdf","title":"","llm_title":"PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English","authors":["Jianfeng Chi","Wasi Uddin Ahmad","Yuan Tian","Kai-Wei Chang"],"llm_authors":"Jianfeng Chi, Wasi Uddin Ahmad, Yuan Tian, Kai-Wei Chang","author_string":"","year":2023,"abstract":"","llm_abstract":"Privacy policies provide individuals with information about their rights and how their personal information is handled. Natural language understanding (NLU) technologies can support individuals and practitioners to understand better privacy practices described in lengthy and complex documents. However, existing efforts that use NLU technologies are limited by processing the language in a way exclusive to a single task focusing on certain privacy practices. To this end, we introduce the Privacy Policy Language Understanding Evaluation (PLUE) benchmark, a multi-task benchmark for evaluating the privacy policy language understanding across various tasks. We also collect a large corpus of privacy policies to enable privacy policy domain-specific language model pre-training. We evaluate several generic pre-trained language models and continue pre-training them on the collected corpus. We demonstrate that domain-specific continual pre-training offers performance improvements across all tasks. The code and models are released at https://github.com/JFChi/PLUE.","llm_keywords":["privacy policies","natural language understanding","benchmark","multi-task evaluation","domain-specific pre-training","language models"],"classifications":[],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":14},{"id":"a29871b7761fb5d6fb5d9b0e6ab04ebdaffcd2691da60d86abcd0db5ab862997e5d0cef16c3416b2bcef87165bf77c8cc647b6909bea6eccc67bb4752fb4e37c","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2023.acl-long.777.pdf","title":"","llm_title":"U-CREAT: Unsupervised Case Retrieval using Events extraction","authors":["Abhinav Joshi","Akshat Sharma","Sai Kiran Tanikella","Ashutosh Modi"],"llm_authors":"Abhinav Joshi, Akshat Sharma, Sai Kiran Tanikella, Ashutosh Modi","author_string":"","year":2023,"abstract":"","llm_abstract":"The task of Prior Case Retrieval (PCR) in the legal domain is about automatically citing relevant (based on facts and precedence) prior legal cases in a given query case. To further promote research in PCR, in this paper, we propose a new large benchmark (in English) for the PCR task: IL-PCR (Indian Legal Prior Case Retrieval) corpus. Given the complex nature of case relevance and the long size of legal documents, BM25 remains a strong baseline for ranking the cited prior documents. In this work, we explore the role of events in legal case retrieval and propose an unsupervised retrieval method-based pipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction). We find that the proposed unsupervised retrieval method significantly increases performance compared to BM25 and makes retrieval faster by a considerable margin, making it applicable to real-time case retrieval systems. Our proposed system is generic, we show that it generalizes across two different legal systems (Indian and Canadian), and it shows state-of-the-art performance on the benchmarks for both the legal systems (IL-PCR and COLIEE corpora).","llm_keywords":["prior case retrieval","legal domain","IL-PCR","BM25","unsupervised retrieval","events extraction","legal documents","real-time case retrieval","Indian legal system","Canadian legal system"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":17},{"id":"8c0ee9c9fa14be05ff05f10db2174a01042bd975e0ef39b958ccec9a38a16b0a5ef9e8f61e047ed4d560c74b6e73589e19c91410637fab226b334b5975d62868","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.805.pdf","title":"","llm_title":"MultiLegalPile: A 689GB Multilingual Legal Corpus","authors":["Joel Niklaus","Veton Matoshi","Matthias Stürmer","Ilias Chalkidis","Daniel E. Ho"],"llm_authors":"Joel Niklaus, Veton Matoshi, Matthias Stürmer, Ilias Chalkidis, Daniel E. Ho","author_string":"","year":2024,"abstract":"","llm_abstract":"Large, high-quality datasets are crucial for training Large Language Models (LLMs). However, so far, few datasets are available for specialized critical domains such as law and the available ones are often small and only in English. To fill this gap, we curate and release MULTILEGALPILE, a 689GB corpus in 24 languages from 17 jurisdictions. MULTILEGALPILE includes diverse legal data sources and allows for pretraining NLP models under fair use, with most of the dataset licensed very permissively. We pretrain two RoBERTa models and one Longformer multilingually, and 24 monolingual models on each of the language-specific subsets and evaluate them on LEXTREME. Additionally, we evaluate the English and multilingual models on LexGLUE. Our multilingual models set a new SotA on LEXTREME and our English models on LexGLUE. We release the dataset, trained models, and all code under the most open licenses possible.","llm_keywords":["Multilingual Corpus","Legal Texts","Large Language Models","RoBERTa","Longformer","NLP","Open Science","Language-Specific Pretraining","LEXTREME","LexGLUE"],"classifications":["Resources"],"num_cited_by":43,"num_cited_by_title_only":43,"num_pages":18},{"id":"ee7557fe90a1ecef04b87343210c7a33964920816966ce68385df7e06326428fa49085e2ccfc5ce92fba38ebe0ebec62529c73128973dff60af3ee4f8aaac152","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.350.pdf","title":"","llm_title":"Legal Case Retrieval: A Survey of the State of the Art","authors":["Yi Feng","Chuanyi Li","Vincent Ng"],"llm_authors":"Yi Feng, Chuanyi Li, Vincent Ng","author_string":"","year":2024,"abstract":"","llm_abstract":"Recent years have seen increasing attention on Legal Case Retrieval (LCR), a key task in the area of Legal AI that concerns the retrieval of cases from a large legal database of historical cases that are similar to a given query. This paper presents a survey of the major milestones made in LCR research, targeting researchers who are finding their way into the field and seek a brief account of the relevant datasets and the recent neural models and their performances.","llm_keywords":["Legal Case Retrieval","Legal AI","Information Retrieval","Neural Models","Datasets","Legal System","Common Law","Civil Law","Precedent","Statute"],"classifications":["Information Retrieval","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":14},{"id":"3994ddec9f3582ffa33964c93c30bcf797ccc3362a6433dc32dae7dfa9272f10babb6cf921ee0c1a61057ee6d73d4a3162284db08623a0a7a07554927b2db7c6","file_path":"legal-nlp-survey-20250328-002/team 1/4 - ACL (Annual Meeting of the Association for Computational Linguistics)/2024.acl-long.388.pdf","title":"","llm_title":"Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling","authors":["Hang Jiang","Xiajie Zhang","Robert Mahari","Daniel Kessler","Eric Ma","Tal August","Irene Li","Alex Sandy Pentland","Yoon Kim","Deb Roy","Jad Kabbara"],"llm_authors":"Hang Jiang, Xiajie Zhang, Robert Mahari, Daniel Kessler, Eric Ma, Tal August, Irene Li, Alex ‘Sandy’ Pentland, Yoon Kim, Deb Roy, Jad Kabbara","author_string":"","year":2024,"abstract":"","llm_abstract":"Making legal knowledge accessible to non-experts is crucial for enhancing general legal literacy and encouraging civic participation in democracy. However, legal documents are often challenging to understand for people without legal backgrounds. In this paper, we present a novel application of large language models (LLMs) in legal education to help non-experts learn intricate legal concepts through storytelling, an effective pedagogical tool in conveying complex and abstract concepts. We also introduce a new dataset LEGALSTORIES, which consists of 294 complex legal doctrines, each accompanied by a story and a set of multiple-choice questions generated by LLMs. To construct the dataset, we experiment with various LLMs to generate legal stories explaining these concepts. Furthermore, we use an expert-in-the-loop approach to iteratively design multiple-choice questions. Then, we evaluate the effectiveness of storytelling with LLMs through randomized controlled trials (RCTs) with legal novices on 10 samples from the dataset. We find that LLM-generated stories enhance comprehension of legal concepts and interest in law among non-native speakers compared to only definitions. Moreover, stories consistently help participants relate legal concepts to their lives. Finally, we find that learning with stories shows a higher retention rate for non-native speakers in the follow-up assessment. Our work has strong implications for using LLMs in promoting teaching and learning in the legal field and beyond.","llm_keywords":["large language models","legal education","storytelling","legal literacy","LLMs","randomized controlled trials","legal concepts","education technology","natural language processing"],"classifications":["Text Generation","Resources"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":26},{"id":"da7d748a24c55f7a8564792bbde21f29b195155197e49b37a70391b5b76e85eecda4b486c3ade00ebf0d82ebfac67844bccc18b9b155b38ce030efcf5bf90d23","file_path":"legal-nlp-survey-20250328-002/team 1/7 - CoNLL Conference on Computational Natural Language Learning/2024.conll-1.13.pdf","title":"","llm_title":"AIStorySimilarity: Quantifying Story Similarity Using Narrative for Search, IP Infringement, and Guided Creativity","authors":["Jon Chun"],"llm_authors":"Jon Chun","author_string":"","year":2024,"abstract":"","llm_abstract":"Stories are central for interpreting experiences, communicating, and influencing each other via films, medical, media, and other narratives. Quantifying the similarity between stories has numerous applications including detecting IP infringement, detecting hallucinations, search/recommendation engines, and guiding human-AI collaborations. Despite this, traditional NLP text similarity metrics are limited to short text distance metrics like n-gram overlaps and embeddings. Larger texts require preprocessing with significant information loss through paraphrasing or multi-step decomposition. This paper introduces AIStorySimilarity, a novel benchmark to measure the semantic distance between long-text stories based on core structural elements drawn from narrative theory and script writing. Based on four narrative elements (characters, plot, setting, and themes) as well 31 sub-features within these, we use a SOTA LLM (gpt-3.5-turbo) to extract and evaluate the semantic similarity of a diverse set of major Hollywood movies. In addition, we compare human evaluation with story similarity scores computed three ways: extracting elements from film scripts before evaluation (Elements), directly evaluating entire scripts (Scripts), and extracting narrative elements from the parametric memory of SOTA LLMs without any provided scripts (GenAI). To the best of our knowledge, AIStorySimilarity is the first benchmark to measure long-text story similarity using a comprehensive approach to narrative theory. All code, data, and plot image files are available at https://github.com/jon-chun/AIStorySimiliarity.","llm_keywords":["story similarity","narrative theory","long-text analysis","AIStorySimilarity","semantic distance","LLM","narrative elements","Hollywood movies","story evaluation","benchmark"],"classifications":["Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":17},{"id":"a7cb173345d0e2ba83b30bad5074bf03cbe7a07c808241d1ce3d0baec32b2f85d29861609a2160c4665bffd19310206eac533005183eb95b15e99c91bd41cc20","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.28.pdf","title":"","llm_title":"Enhancing Legal Violation Identification with LLMs and Deep Learning Techniques: Achievements in the LegalLens 2024 Competition","authors":["Tan-Minh Nguyen","Ngoc-Duy Mai","Xuan-Bach Le","Huu-Dung Nguyen","Cong-Minh Pham","Ha-Thanh Nguyen","Thi-Hai-Yen Vuong"],"llm_authors":"Tan-Minh Nguyen, Ngoc-Duy Mai, Xuan-Bach Le, Huu-Dung Nguyen, Cong-Minh Pham, Ha-Thanh Nguyen, Thi-Hai-Yen Vuong","author_string":"","year":2024,"abstract":"","llm_abstract":"LegalLens is a competition organized to encourage advancements in automatically detecting legal violations. This paper presents our solutions for two tasks Legal Named Entity Recognition (L-NER) and Legal Natural Language Inference (L-NLI). Our approach involves fine-tuning BERT-based models, designing methods based on data characteristics, and a novel prompting template for data augmentation using LLMs. As a result, we secured first place in L-NER and third place in L-NLI among thirty-six participants. We also perform error analysis to provide valuable insights and pave the way for future enhancements in legal NLP. Our implementation is available at https://github.com/lxbach10012004/legal-lens/tree/main.","llm_keywords":["Legal violation identification","LLMs","Deep learning","Legal Named Entity Recognition","Legal Natural Language Inference","BERT models","Data augmentation","Legal NLP"],"classifications":["Information Extraction","Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"d5297da84dd30741030a563bb073554bd3e9b73c1f6ed274253c3d18c72faf3bea1f553d0a39ce648732ea923366b8df60322e4058d0a75d460058a0e6cde188","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.3.pdf","title":"","llm_title":"Enhancing Legal Expertise in Large Language Models through Composite Model Integration: The Development and Evaluation of Law-Neo","authors":["Zhihao Liu","Yanzhen Zhu","Mengyuan Lu"],"llm_authors":"Zhihao Liu, Yanzhen Zhu, Mengyuan Lu","author_string":"","year":2024,"abstract":"","llm_abstract":"Although large language models (LLMs) like ChatGPT (OpenAI et al., 2024) have demonstrated considerable capabilities in general domains, they often lack proficiency in specialized fields. Enhancing a model’s performance in a specific domain, such as law, while maintaining low costs, has been a significant challenge. Existing methods, such as fine-tuning or building mixture of experts (MoE) models, often struggle to balance model parameters, training costs, and domain-specific performance. Inspired by composition to augment language models (Bansal et al., 2024), we have developed Law-Neo, a novel model designed to enhance legal LLMs. This model significantly improves the model’s legal domain expertise at minimal training costs, while retaining the logical capabilities of a large-scale anchor model. Our Law-Neo model outperformed other models in comprehensive experiments on multiple legal task benchmarks, demonstrating the effectiveness of this approach.","llm_keywords":["Large Language Models","Law-Neo","Legal Domain","Model Integration","Composite Model","Low Cost Training","Legal Expertise"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":9},{"id":"bb1461bf8739bd3fe3dd9cd90320905769887c3e16168cec5712cfe5abc75afad96b4ea8650dc839d4c248c82a71b9d433262c337c1a37bf6fa45c2fee72f0cc","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.21.pdf","title":"","llm_title":"Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution","authors":["Shikha Bordia"],"llm_authors":"Shikha Bordia","author_string":"","year":2024,"abstract":"","llm_abstract":"In this work, we present two systems—Named Entity Resolution (NER) and Natural Language Inference (NLI)—for detecting legal violations within unstructured textual data and for associating these violations with potentially affected individuals, respectively. Both these systems are lightweight DeBERTa based encoders that outperform the LLM baselines. The proposed NER system achieved an F1 score of 60.01% on Subtask A of the LegalLens challenge, which focuses on identifying violations. The proposed NLI system achieved an F1 score of 84.73% on Subtask B of the LegalLens challenge, which focuses on resolving these violations by matching them with pre-existing legal complaints of class action cases. Our NER system ranked sixth and NLI system ranked fifth on the LegalLens leaderboard. We release the trained models and inference scripts.","llm_keywords":["Legal Violation Detection","Named Entity Resolution","Natural Language Inference","DeBERTa","LegalLens Challenge","Unstructured Text Data","LegalComplaints"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":8},{"id":"a6021c60a95021ff07c9eb414d06c362c7241e61f9f509662636b6498949fe1fa33f10c574d81362c28c097c1e474d1ebbb78c2e878792066c26ed21c3fda9d9","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.4.pdf","title":"","llm_title":"uOttawa at LegalLens-2024: Transformer-based Classification Experiments","authors":["Nima Meghdadi","Diana Inkpen"],"llm_authors":"Nima Meghdadi and Diana Inkpen","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper presents the methods used for LegalLens-2024 shared task, which focused on detecting legal violations within unstructured textual data and associating these violations with potentially affected individuals. The shared task included two subtasks: A) Legal Named Entity Recognition (L-NER) and B) Legal Natural Language Inference (L-NLI). For subtask A, we utilized the spaCy library, while for subtask B, we employed a combined model incorporating RoBERTa and CNN. Our results were 86.3% in the L-NER subtask and 88.25% in the L-NLI subtask. Overall, our paper demonstrates the effectiveness of transformer models in addressing complex tasks in the legal domain. The source code for our implementation is publicly available at https://github.com/NimaMeghdadi/uOttawa-at-LegalLens-2024-Transformer-based-Classification","llm_keywords":["LegalLens-2024","Legal Named Entity Recognition","Legal Natural Language Inference","Transformer models","spaCy","RoBERTa","CNN","Legal domain"],"classifications":["Information Extraction","Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"27baccd21a9b6dcbf04dfa969fda7b125ee389608a37e9916825957f99889587e564d02965db94a4a142ebadbf65f79037d88b5120129dcaad29656430c281a8","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.26.pdf","title":"","llm_title":"Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Kanwal Mehreen","Subhasya Tippareddy","Ashay Srivastava"],"llm_authors":"Ram Mohan Rao Kadiyala, Siddartha Pullakhandam, Kanwal Mehreen, Subhasya Tippareddy, Ashay Srivastava","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper presents our system description and error analysis of our entry for NLLP 2024 shared task on Legal Natural Language Inference (L-NLI) (Hagag et al., 2024). The task required classifying these relationships as entailed, contradicted, or neutral, indicating any association between the review and the complaint. Our system emerged as the winning submission, significantly outperforming other entries with a substantial margin and demonstrating the effectiveness of our approach in legal text analysis. We provide a detailed analysis of the strengths and limitations of each model and approach tested, along with a thorough error analysis and suggestions for future improvements. This paper aims to contribute to the growing field of legal NLP by offering insights into advanced techniques for natural language inference in legal contexts, making it accessible to both experts and newcomers in the field.","llm_keywords":["Legal NLP","Natural Language Inference","Social Media Evidence","LLM","Text Classification","Error Analysis","Legal Decision Support"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":8},{"id":"ff5844a61dc5b310618183118773fd229159c10da37676979c89f3042eb194b6927d1c387a8687ede6985e47d035b9f181608b30d9452dc94ae786a4f0cef82a","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.13.pdf","title":"","llm_title":"Algorithm for Automatic Legislative Text Consolidation","authors":["Matias Etcheverry","Thibaud Real","Pauline Chavallard"],"llm_authors":"Matias Etcheverry, Thibaud Real, Pauline Chavallard","author_string":"","year":2024,"abstract":"","llm_abstract":"This study introduces a method for automating the consolidation process in a legal context, a time-consuming task traditionally performed by legal professionals. We present a generative approach that processes legislative texts to automatically apply amendments. Our method employs light quantized generative model, fine-tuned with LoRA, to generate accurate and reliable amended texts. To the authors knowledge, this is the first time generative models are used on legislative text consolidation. Our dataset is publicly available on HuggingFace. Experimental results demonstrate a significant improvement in efficiency, offering faster updates to legal documents. A full automated pipeline of legislative text consolidation can be done in a few hours, with a success rate of more than 63% on a difficult bill.","llm_keywords":["legislative text consolidation","generative models","automation","legal amendments","text processing","LoRA","natural language processing","computational linguistics","legal document updates","information extraction"],"classifications":["Text Generation","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"23ee62018f435c41408b7a1629d047580c8b1e089bf4e4267634eedaa244f254f791f642f3a314bbda4708489633ca95cb43df8228f89062c9469ba5edaaa400","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.14.pdf","title":"","llm_title":"Measuring the Groundedness of Legal Question-Answering Systems","authors":["Dietrich Trautmann","Natalia Ostapuk","Quentin Grail","Adrian Alan Pol","Guglielmo Bonifazi","Shang Gao","Martin Gajek"],"llm_authors":"Dietrich Trautmann, Natalia Ostapuk, Quentin Grail, Adrian Alan Pol, Guglielmo Bonifazi, Shang Gao and Martin Gajek","author_string":"","year":2024,"abstract":"","llm_abstract":"In high-stakes domains like legal question-answering, the accuracy and trustworthiness of generative AI systems are of paramount importance. This work presents a comprehensive benchmark of various methods to assess the groundedness of AI-generated responses, aiming to significantly enhance their reliability. Our experiments include similarity-based metrics and natural language inference models to evaluate whether responses are well-founded in the given contexts. We also explore different prompting strategies for large language models to improve the detection of ungrounded responses. We validated the effectiveness of these methods using a newly created grounding classification corpus, designed specifically for legal queries and corresponding responses from retrieval-augmented prompting, focusing on their alignment with source material. Our results indicate potential in groundedness classification of generated responses, with the best method achieving a macro-F1 score of 0.8. Additionally, we evaluated the methods in terms of their latency to determine their suitability for real-world applications, as this step typically follows the generation process. This capability is essential for processes that may trigger additional manual verification or automated response regeneration. In summary, this study demonstrates the potential of various detection methods to improve the trustworthiness of generative AI in legal settings.","llm_keywords":["legal question-answering","generative AI","groundedness","factual consistency","large language models","similarity-based metrics","natural language inference","error analysis","trustworthiness","benchmarking"],"classifications":["Classification","Text Generation","Information Retrieval"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":11},{"id":"4c9a95d508584fdffd983d69df09c5a8d91a4365e408d29a7b84f991a617a5dcf3931e650a386ab8bfdc5adf6b1cddac2c5a8ed337c6522d00f0b1fdd0eac7c1","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.3.pdf","title":"","llm_title":"Long Text Classification using Transformers with Paragraph Selection Strategies","authors":["Mohit Tuteja","Daniel González Juclà"],"llm_authors":"Mohit Tuteja, Daniel González Juclà","author_string":"","year":2023,"abstract":"","llm_abstract":"In the legal domain, we often perform classification tasks on very long documents, for example court judgements. These documents often contain thousands of words, so the length of these documents poses a challenge for this modelling task. In this research paper, we present a comprehensive evaluation of various strategies to perform long text classification using Transformers in conjunction with strategies to select document chunks using traditional NLP models. We conduct our experiments on 6 benchmark datasets comprising lengthy documents, 4 of which are publicly available. Each dataset has a median word count exceeding 1,000. Our evaluation encompasses state-of-the-art Transformer models, such as RoBERTa, Longformer, HAT, MEGA and LegalBERT and compares them with a traditional baseline TF-IDF + Neural Network (NN) model. We investigate the effectiveness of pre-training on large corpora, fine-tuning strategies, and transfer learning techniques in the context of long text classification.","llm_keywords":["text classification","legal domain","transformers","paragraph selection","long documents","NLP","RoBERTa","Longformer","LegalBERT","attention mechanism"],"classifications":["Classification","Pre-Processing","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":8},{"id":"37f1bc875dd3145022eca85f44598a83f2e46c390487111c37d446218676774e607842552dabc06bf3af09784df82c0bea78b5c839434f7ad7bc74feafc4e234","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.12.pdf","title":"","llm_title":"Connecting Symbolic Statutory Reasoning with Legal Information Extraction","authors":["Nils Holzenberger","Benjamin Van Durme"],"llm_authors":"Nils Holzenberger, Benjamin Van Durme","author_string":"","year":2023,"abstract":"","llm_abstract":"Statutory reasoning is the task of determining whether a given law – a part of a statute – applies to a given legal case. Previous work has shown that structured, logical representations of laws and cases can be leveraged to solve statutory reasoning, including on the Statutory Reasoning Assessment dataset (SARA), but rely on costly human translation into structured representations. Here, we investigate a form of legal information extraction atop the SARA cases, illustrating how the task can be done with high performance. Further, we show how the performance of downstream symbolic reasoning directly correlates with the quality of the information extraction.","llm_keywords":["Statutory reasoning","legal information extraction","SARA","Prolog","knowledge base","information extraction models","legal NLP","large language models","legal domain"],"classifications":["Information Extraction"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":19},{"id":"971edfba4140f7164517586e8629c02d8a9862c7253425950128ee40720a77924bdef2651bcff6e83735e372d4a099e725e38b798e91a3114194a91384be7e4c","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.4.pdf","title":"","llm_title":"Do Language Models Learn about Legal Entity Types during Pretraining?","authors":["Claire Barale","Michael Rovatsos","Nehal Bhuta"],"llm_authors":"Claire Barale, Michael Rovatsos, Nehal Bhuta","author_string":"","year":2023,"abstract":"","llm_abstract":"Language Models (LMs) have proven their ability to acquire diverse linguistic knowledge during the pretraining phase, potentially serving as a valuable source of incidental supervision for downstream tasks. However, there has been limited research conducted on the retrieval of domain-specific knowledge, and specifically legal knowledge. We propose to explore the task of Entity Typing, serving as a proxy for evaluating legal knowledge as an essential aspect of text comprehension, and a foundational task to numerous downstream legal NLP applications. Through systematic evaluation and analysis and two types of prompting (cloze sentences and QA-based templates) and to clarify the nature of these acquired cues, we compare diverse types and lengths of entities both general and domain-specific entities, semantics or syntax signals, and different LM pretraining corpus (generic and legal-oriented) and architectures (encoder BERT-based and decoder-only with Llama2). We show that (1) Llama2 performs well on certain entities and exhibits potential for substantial improvement with optimized prompt templates, (2) law-oriented LMs show inconsistent performance, possibly due to variations in their training corpus, (3) LMs demonstrate the ability to type entities even in the case of multi-token entities, (4) all models struggle with entities belonging to sub-domains of the law (5) Llama2 appears to frequently overlook syntactic cues, a shortcoming less present in BERT-based architectures. The code of the experiments is available at https://github.com/clairebarale/probing_legal_entity_types.","llm_keywords":["Language Models","Legal Entity Types","Pretraining","NLP","Entity Typing","BERT","Llama2","Domain-specific Knowledge"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":13},{"id":"de11f11ae024ba9d94ba52faefe77ca345bb4e4baf05a68787668b173b39e3f6e0550ffc0069793f519b5ac1a3875dc82d75729f29b31c52c6b0ccec5e3fdd84","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.15.pdf","title":"","llm_title":"Low-Resource Deontic Modality Classification in EU Legislation","authors":["Kristina Minkova","Shashank M Chakravarthy","Gijs van Dijck"],"llm_authors":"Kristina Minkova, Shashank M Chakravarthy, Gijs van Dijck","author_string":"","year":2023,"abstract":"","llm_abstract":"In law, it is important to distinguish between obligations, permissions, prohibitions, rights, and powers. These categories are called deontic modalities. This paper evaluates the performance of two deontic modality classification models, LEGAL-BERT and a Fusion model, in a low-resource setting. To create a generalized dataset for multi-class classification, we extracted random provisions from European Union (EU) legislation. By fine-tuning previously researched and published models, we evaluate their performance on our dataset against fusion models designed for low-resource text classification. We incorporate focal loss as an alternative for cross-entropy to tackle issues of class imbalance. The experiments indicate that the fusion model performs better for both balanced and imbalanced data with a macro F1-score of 0.61 for imbalanced data, 0.62 for balanced data, and 0.55 with focal loss for imbalanced data. When focusing on accuracy, our experiments indicate that the fusion model performs better with scores of 0.91 for imbalanced data, 0.78 for balanced data, and 0.90 for imbalanced data with focal loss.","llm_keywords":["deontic modalities","legal classification","EU legislation","low-resource","LEGAL-BERT","fusion model","focal loss","machine learning","text classification","neural networks"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":10},{"id":"fac54a4e114c962cdf48c2e1acb1d79e4e555b539e821395ee9cf64d6e8dae382b8ce25bf8c525ad9d549ca95e76233107be496961df690a079793a314722205","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.20.pdf","title":"","llm_title":"Super-SCOTUS: A multi-sourced dataset for the Supreme Court of the US","authors":["Biaoyan Fang","Trevor Cohn","Timothy Baldwin","Lea Frermann"],"llm_authors":"Biaoyan Fang, Trevor Cohn, Timothy Baldwin, Lea Frermann","author_string":"","year":2023,"abstract":"","llm_abstract":"Given the complexity of the judiciary in the US Supreme Court, various procedures, along with various resources, contribute to the court system. However, most research focuses on a limited set of resources, e.g., court opinions or oral arguments, for analyzing a specific perspective in court, e.g., partisanship or voting. To gain a fuller understanding of these perspectives in the legal system of the US Supreme Court, a more comprehensive dataset, connecting different sources in different phases of the court procedure, is needed. To address this gap, we present a multi-sourced dataset for the Supreme Court, comprising court resources from different procedural phases, connecting language documents with extensive metadata. We showcase its utility through a case study on how different court documents reveal the decision direction (conservative vs. liberal) of the cases. We analyze performance differences across three protected attributes, indicating that different court resources encode different biases, and reinforcing that considering various resources provides a fuller picture of the court procedures. We further discuss how our dataset can contribute to future research directions.","llm_keywords":["Supreme Court","US judiciary","multi-sourced dataset","court opinions","oral arguments","legal system","partisanship","voting","decision direction"],"classifications":["Resources","Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":9,"num_pages":13},{"id":"7ccf6028b443ed603ea2fb654b216d6adad4e895b27ac5526172ca1b486ac5371cf58f5c1b39439bc6f09a16ef109e89d4b12e4d8e42163fced820a61297d1bd","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.30.pdf","title":"","llm_title":"LegalLens 2024 Shared Task: Masala-chai Group Submission","authors":["Khalid Rajan","Royal Sequiera"],"llm_authors":"Khalid Rajan, Royal Sequiera","author_string":"","year":2024,"abstract":"","llm_abstract":"In this paper, we describe masala-chai team’s participation in the LegalLens 2024 shared task, and outline our approach to predicting legal entities and performing natural language inference in the legal domain. We experimented with several transformer-based models including BERT, RoBERTa, Llama 3.1, and GPT-4o. Our experiments indicated that state-of-art models such as GPT-4o do not work well for NER and NLI tasks despite using techniques such as bootstrapping and prompt optimization. Our best evaluations on the NER task (F1 macro: 0.380) was obtained using a finetuned RoBERTa model and NLI (accuracy: 0.825, F1 macro: 0.833) using a finetuned Llama 3.1 8B model. However, RoBERTa, despite having a fraction of Llama 3.1 8B’s parameters, delivered comparable results. Key findings and insights from our experiments are discussed in detail. We make our results and code available for reproducibility and further analysis at https://github.com/rosequ/masala-chai.","llm_keywords":["Legal Named Entity Recognition","Natural Language Inference","Transformer Models","Legal NLP","Fine-tuning","RoBERTa","GPT-4o","BERT","Llama 3.1"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":9},{"id":"4b8f6179038ed13af518d037d7e8b9f9817e690202806f05de704c1b762df4bb2a33327135cd0f5cf3156b2545b27e10f5c8670c433a9c5c9f958b93b4e2b23e","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.15.pdf","title":"","llm_title":"Transductive Legal Judgment Prediction Combining BERT Embeddings with Delaunay-Based GNNs","authors":["Hugo Attali","Nadi Tomeh"],"llm_authors":"Hugo Attali and Nadi Tomeh","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper presents a novel approach to legal judgment prediction by combining BERT embeddings with a Delaunay-based Graph Neural Network (GNN). Unlike inductive methods that classify legal documents independently, our transductive approach models the entire document set as a graph, capturing both contextual and relational information. This method significantly improves classification accuracy by enabling effective label propagation across connected documents. Evaluated on the Swiss-Judgment-Prediction (SJP) dataset, our model outperforms established baselines, including larger models with cross-lingual training and data augmentation techniques, while maintaining efficiency with minimal computational overhead.","llm_keywords":["Transductive Learning","Legal Judgment Prediction","BERT Embeddings","Graph Neural Networks","Delaunay Triangulation","Swiss Judgment Prediction","Context-aware Classification","Domain-specific Knowledge"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":7},{"id":"1422c1e7e69abee88ce08a08b05326fb02c7117af680c63f009a1a2ec179823bf1acc4609654b7e75c315ebaa89828230724f06223662f1230e7df2253c365b1","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.12.pdf","title":"","llm_title":"Attributed Question Answering for Preconditions in the Dutch Law","authors":["Felicia Redelaar","Romy van Drie","Suzan Verberne","Maaike de Boer"],"llm_authors":"Felicia Redelaar, Romy van Drie, Suzan Verberne, Maaike de Boer","author_string":"","year":2024,"abstract":"","llm_abstract":"In this paper, we address the problem of answering questions about preconditions in the law, e.g. “When can the court terminate the guardianship of a natural person?”. When answering legal questions, it is important to attribute the relevant part of the law; we therefore not only generate answers but also references to law articles. We implement a retrieval augmented generation (RAG) pipeline for longform answers based on the Dutch law, using several state-of-the-art retrievers and generators. For evaluating our pipeline, we create a dataset containing 102 legal QA pairs with attributions. Our experiments show promising results on our extended version for the automatic evaluation metrics from the Automatic LLMs’ Citation Evaluation (ALCE) Framework and the G-EVAL Framework. Our findings indicate that RAG has significant potential in complex, citation-heavy domains like law, as it helps laymen understand legal preconditions and rights by generating high-quality answers with accurate attributions.","llm_keywords":["Attributed Question Answering","Dutch Law","Legal QA","Retrieval Augmented Generation","Preconditions","RAG","Legal Domain"],"classifications":["Information Retrieval","Text Generation","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":12},{"id":"ab2408aae658a5ce1986efb153df11534580df819ef31d035e0e978a47cd6f1fae1a00343f4aebe2911db86fdd8eb17393e853ee7b172c799d29fffda84a6be2","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.5.pdf","title":"","llm_title":"Quebec Automobile Insurance Question-Answering With Retrieval-Augmented Generation","authors":["David Beauchemin","Zachary Gagnon","Richard Khoury"],"llm_authors":"David Beauchemin, Zachary Gagnon, Richard Khoury","author_string":"","year":2024,"abstract":"","llm_abstract":"Large Language Models (LLMs) perform outstandingly in various downstream tasks, and the use of the Retrieval-Augmented Generation (RAG) architecture has been shown to improve performance for legal question answering (Nuruzzaman and Hussain, 2020; Louis et al., 2024). However, there are limited applications in insurance questions-answering, a specific type of legal document. This paper introduces two corpora: the Quebec Automobile Insurance Expertise Reference Corpus and a set of 82 Expert Answers to Layperson Automobile Insurance Questions. Our study leverages both corpora to automatically and manually assess a GPT4-o, a state-of-the-art LLM, to answer Quebec automobile insurance questions. Our results demonstrate that, on average, using our expertise reference corpus generates better responses on both automatic and manual evaluation metrics. However, they also highlight that LLM QA is unreliable enough for mass utilization in critical areas. Indeed, our results show that between 5% to 13% of answered questions include a false statement that could lead to customer misunderstanding.","llm_keywords":["Quebec automobile insurance","Retrieval-Augmented Generation","Large Language Models","insurance question-answering","legal documents","machine learning","text summarization","natural language processing"],"classifications":["Information Retrieval","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":13},{"id":"5d0234039dd2ad13afeca2de397ddeaca775b59abebcd5b494500121a394e5cf10c096024a734132d1b71da88f43e80b8078a569275f82cfb5d53084df5a3abe","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.27.pdf","title":"","llm_title":"Empowering Air Travelers: A Chatbot for Canadian Air Passenger Rights","authors":["Maksym Taranukhin","Sahithya Ravi","Gábor Lukács","Evangelos Milios","Vered Shwartz"],"llm_authors":"Maksym Taranukhin, Sahithya Ravi, Gábor Lukács, Evangelos Milios, Vered Shwartz","author_string":"","year":2024,"abstract":"","llm_abstract":"The Canadian air travel sector has seen a significant increase in flight delays, cancellations, and other issues concerning passenger rights. Recognizing this demand, we present a chatbot to assist passengers and educate them about their rights. Our system breaks a complex user input into simple queries which are used to retrieve information from a collection of documents detailing air travel regulations. The most relevant passages from these documents are presented along with links to the original documents and the generated queries, enabling users to dissect and leverage the information for their unique circumstances. The system successfully overcomes two predominant challenges: understanding complex user inputs, and delivering accurate answers, free of hallucinations, that passengers can rely on for making informed decisions. A user study comparing the chatbot to a Google search demonstrated the chatbot’s usefulness and ease of use. Beyond the primary goal of providing accurate and timely information to air passengers regarding their rights, we hope that this system will also enable further research exploring the tradeoff between the user-friendly conversational interface of chatbots and the accuracy of retrieval systems.","llm_keywords":["chatbot","air passenger rights","Canada","flight delays","information retrieval","user interface","accuracy","hallucinations","natural language processing"],"classifications":["Information Retrieval","Text Generation","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"1fbcbfcee87e2dca1b3d53451acf6ee4cd5d6b3c55a8edc09f125a9d16da1efd8cc5728fb515667fe43ebb49130c3a746186122de81c1d9fc1b24694b6fbc277","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.2.pdf","title":"","llm_title":"Summarizing Long Regulatory Documents with a Multi-Step Pipeline","authors":["Mika Sie","Ruby Beek","Michiel Bots","Sjaak Brinkkemper","Albert Gatt"],"llm_authors":"Mika Sie, Ruby Beek, Michiel Bots, Sjaak Brinkkemper, Albert Gatt","author_string":"","year":2024,"abstract":"","llm_abstract":"Due to their length and complexity, long regulatory texts are challenging to summarize. To address this, a multi-step extractive-abstractive architecture is proposed to handle lengthy regulatory documents more effectively. In this paper, we show that the effectiveness of a two-step architecture for summarizing long regulatory texts varies significantly depending on the model used. Specifically, the two-step architecture improves the performance of decoder-only models. For abstractive encoder-decoder models with short context lengths, the effectiveness of an extractive step varies, whereas for long-context encoder-decoder models, the extractive step worsens their performance. This research also highlights the challenges of evaluating generated texts, as evidenced by the differing results from human and automated evaluations. Most notably, human evaluations favoured language models pretrained on legal text, while automated metrics rank general-purpose language models higher. The results underscore the importance of selecting the appropriate summarization strategy based on model architecture and context length.","llm_keywords":["text summarization","regulatory documents","extractive-abstractive architecture","legal language models","context length"],"classifications":["Machine Summarization"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":15},{"id":"d13f6e738ad55876a087082b4f15c11f36b7ec49fd0e7684b57887f824f9fb90b1a6df1c7ec54356c881eb95f6ab74eb69440bf1b1d36bd4b5caf1226a9bd56e","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.20.pdf","title":"","llm_title":"Comparative Study of Explainability Methods for Legal Outcome Prediction","authors":["Ieva Raminta Staliunaitė","Josef Valvoda","Ken Satoh"],"llm_authors":"Ieva Raminta Staliunaitė, Josef Valvoda, Ken Satoh","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper investigates explainability in Natural Legal Language Processing (NLLP). We study the task of legal outcome prediction of the European Court of Human Rights cases in a ternary classification setup, where a language model is fine-tuned to predict whether an article has been claimed and violated (positive outcome), claimed but not violated (negative outcome) or not claimed at all (null outcome). Specifically, we experiment with three popular NLP explainability methods. Correlating the attribution scores of input-level methods (Integrated Gradients and Contrastive Explanations) with rationales from court rulings, we show that the correlations are very weak, with absolute values of Spearman and Kendall correlation coefficients ranging between 0.003 and 0.094. Furthermore, we use a concept-level interpretability method (Concept Erasure) with human expert annotations of legal reasoning, to show that obscuring legal concepts from the model representation has an insignificant effect on model performance (at most a decline of 0.26 F1). Therefore, our results indicate that automated legal outcome prediction models are not reliably grounded in legal reasoning.","llm_keywords":["Explainability","Legal Outcome Prediction","Natural Legal Language Processing","Interpretability Methods","Integrated Gradients","Contrastive Explanations","Concept Erasure","Machine Learning in Law"],"classifications":["Classification","Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":16},{"id":"744ecbd887d1dccdfc9ccc14cf927fa5102daf6101115a46040dbcd3a63165442038ff1f8046ad7cea600c9b9981579578044a7b4638d03db1095aa2010852f2","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.31.pdf","title":"","llm_title":"Semantists at LegalLens-2024: Data-efficient Training of LLM’s for Legal Violation Identification","authors":["Rajaraman Kanagasabai","Hariram Veeramani"],"llm_authors":"Rajaraman Kanagasabai, Hariram Veeramani","author_string":"","year":2024,"abstract":"","llm_abstract":"In this paper, we describe our system for LegalLens-2024 Shared Task on automatically identifying legal violations from unstructured text sources. We participate in Subtask B, called Legal Natural Language Inference (L-NLI), that aims to predict the relationship between a given premise summarizing a class action complaint and a hypothesis from an online media text, indicating any association between the review and the complaint. This task is challenging as it provides only limited labelled data. In our work, we adopt LLM based methods and explore various data-efficient learning approaches for maximizing performance. In the end, our best model employed an ensemble of LLM’s fine-tuned on the task-specific data, and achieved a Macro F1 score of 78.5% on test data, and ranked 2nd among all teams submissions.","llm_keywords":["Legal Violation Identification","Natural Language Inference","Large Language Models","Data-efficient Learning","LegalLens-2024"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"2ec6879026ef697ece36733b37f15af2915adcf77e68bee2d31d29b5be2919227eaa28470e04da3492e2e2793493f2126c9268a199ecdf74f35ee4f729997f65","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.26.pdf","title":"","llm_title":"Tracing Influence at Scale: A Contrastive Learning Approach to Linking Public Comments and Regulator Responses","authors":["Linzi Xing","Brad Hackinen","Giuseppe Carenini"],"llm_authors":"Linzi Xing, Brad Hackinen, and Giuseppe Carenini","author_string":"","year":2023,"abstract":"","llm_abstract":"U.S. Federal Regulators receive over one million comment letters each year from businesses, interest groups, and members of the public, all advocating for changes to proposed regulations. These comments are believed to have wide-ranging impacts on public policy. However, measuring the impact of specific comments is challenging because regulators are required to respond to comments but they do not have to specify which comments they are addressing. In this paper, we propose a simple yet effective solution to this problem by using an iterative contrastive method to train a neural model aiming for matching text from public comments to responses written by regulators. We demonstrate that our proposal substantially outperforms a set of selected text-matching baselines on a human-annotated test set. Furthermore, it delivers performance comparable to the most advanced gigantic language model (i.e., GPT-4), and is more cost-effective when handling comments and regulator responses matching in larger scale.","llm_keywords":["contrastive learning","text matching","public comments","regulator responses","neural model","natural language processing","policy influence","SBERT","unsupervised learning","U.S. federal regulations"],"classifications":["Classification","Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":9},{"id":"b0fbe7dda797b359d8f3221595215f19cd86dfebe5ceaae9ab8f0bb473a7f84cac9c4731193859eb8acf6d1e76a9eee4cf8c02e900324bfc62b990da127b0c9b","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.36.pdf","title":"","llm_title":"Towards Supporting Legal Argumentation with NLP: Is More Data Really All You Need?","authors":["Santosh T.Y.S.S.","Kevin D. Ashley","Katie Atkinson","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S., Kevin D. Ashley, Katie Atkinson, Matthias Grabmair","author_string":"","year":2024,"abstract":"","llm_abstract":"Modeling legal reasoning and argumentation justifying decisions in cases has always been central to AI & Law, yet contemporary developments in legal NLP have increasingly focused on statistically classifying legal conclusions from text. While conceptually “simpler”, these approaches often fall short in providing usable justifications connecting to appropriate legal concepts. This paper reviews both traditional symbolic works in AI & Law and recent advances in legal NLP, and distills possibilities of integrating expert-informed knowledge to strike a balance between scalability and explanation in symbolic vs. data-driven approaches. We identify open challenges and discuss the potential of modern NLP models and methods that integrate conceptual legal knowledge.","llm_keywords":["legal reasoning","NLP","AI & Law","legal argumentation","data-driven methods","symbolic representation","large language models","legal expertise","knowledge integration","explainability"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":18},{"id":"5eb6f55b17b8ba26e10a1cccbc71d281e251aeeac3d294b73703e1f3b72c0e76d93a0e630ef56b7c5d68cae30c0c7fd5b15ae851bf2754a5261f89ca84e351d6","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.21.pdf","title":"","llm_title":"Transferring Legal Natural Language Inference Model from a US State to Another: What Makes It So Hard?","authors":["Alice Saebom Kwak","Gaetano Vincent Forte","Derek E. Bambauer","Mihai Surdeanu"],"llm_authors":"Alice Saebom Kwak, Gaetano Vincent Forte, Derek E. Bambauer, Mihai Surdeanu","author_string":"","year":2023,"abstract":"","llm_abstract":"This study investigates whether a legal natural language inference (NLI) model trained on the data from one US state can be transferred to another state. We fine-tuned a pre-trained model on the task of evaluating the validity of legal will statements, once with the dataset containing the Tennessee wills and once with the dataset containing the Idaho wills. Each model’s performance on the in-domain setting and the out-of-domain setting are compared to see if the models can across the states. We found that the model trained on one US state can be mostly transferred to another state. However, it is clear that the model’s performance drops in the out-of-domain setting. The F1 scores of the Tennessee model and the Idaho model are 96.41 and 92.03 when predicting the data from the same state, but they drop to 66.32 and 81.60 when predicting the data from another state. Subsequent error analysis revealed that there are two major sources of errors. First, the model fails to recognize equivalent laws across states when there are stylistic differences between laws. Second, difference in statutory section numbering system between the states makes it difficult for the model to locate laws relevant to the cases being predicted on. This analysis provides insights on how the future NLI system can be improved. Also, our findings offer empirical support to legal experts advocating the standardization of legal documents.","llm_keywords":["Legal NLI","Model transfer","Will validity","Cross-state performance","Error analysis"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":8},{"id":"fdebef8601697f566d88c0e801fb07a30f651ee607edecbe1b78790c23291737b701f6c4401412d9a7c86cc24c0902c3eb742d5ca34c9948181ba42c0d9eda80","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.14.pdf","title":"","llm_title":"Legal NLP Meets MiCAR: Advancing the Analysis of Crypto White Papers","authors":["Carolina Camassa"],"llm_authors":"Carolina Camassa","author_string":"","year":2023,"abstract":"","llm_abstract":"In the rapidly evolving field of crypto assets, white papers are essential documents for investor guidance, and are now subject to unprecedented content requirements under the European Union’s Markets in Crypto-Assets Regulation (MiCAR). Natural Language Processing (NLP) can serve as a powerful tool for both analyzing these documents and assisting in regulatory compliance. This paper delivers two contributions to the topic. First, we survey existing applications of textual analysis to unregulated crypto asset white papers, uncovering a research gap that could be bridged with interdisciplinary collaboration. We then conduct an analysis of the changes introduced by MiCAR, highlighting the opportunities and challenges of integrating NLP within the new regulatory framework. The findings set the stage for further research, with the potential to benefit regulators, crypto asset issuers, and investors.","llm_keywords":["Natural Language Processing","crypto assets","white papers","MiCAR","regulation","ICO","market analysis","textual analysis","compliance","European Union"],"classifications":["Information Extraction","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":11},{"id":"4f1ccf8f4d34a678e6f13f5d5ea858d8345839a8f32d43dca1047895bf05899fbdee7fc6691a3bb1190f27a808995b8d061cce75a02760403a0a9e7f6988a2df","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.5.pdf","title":"","llm_title":"Pretrained Language Models v. Court Ruling Predictions: A Case Study on a Small Dataset of French Court of Appeal Rulings","authors":["Olivia Vaudaux","Caroline Bazzoli","Maximin Coavoux","Géraldine Vial","Étienne Vergès"],"llm_authors":"Olivia Vaudaux, Caroline Bazzoli, Maximin Coavoux, Géraldine Vial, Étienne Vergès","author_string":"","year":2023,"abstract":"","llm_abstract":"NLP systems are increasingly used in the law domain, either by legal institutions or by the industry. As a result there is a pressing need to characterize their strengths and weaknesses and understand their inner workings. This article presents a case study on the task of judicial decision prediction, on a small dataset from French Courts of Appeal. Specifically, our dataset of around 1000 decisions is about the habitual place of residency of children from divorced parents. The task consists in predicting, from the facts and reasons of the documents, whether the court rules that children should live with their mother or their father. Instead of feeding the whole document to a classifier, we carefully construct the dataset to make sure that the input to the classifier does not contain any ‘spoilers’ (it is often the case in court rulings that information all along the document mentions the final decision). Our results are mostly negative: even classifiers based on French pretrained language models (Flaubert, JuriBERT) do not classify the decisions with a reasonable accuracy. However, they can extract the decision when it is part of the input. With regards to these results, we argue that there is a strong caveat when constructing legal NLP datasets automatically.","llm_keywords":["Natural Language Processing","Judicial Decision Prediction","French Courts of Appeal","Pretrained Language Models","BERT","Legal NLP","Data Annotation","Dataset Construction"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"bcbf343f08865b8af109a2608e93def052ca37b65c625df6b2dd71fc0f52146beb8c7e9760b73c58be11a46e9c30632b5f615d382acb0643ec783683197ba025","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.13.pdf","title":"","llm_title":"Retrieval-based Evaluation for LLMs: A Case Study in Korean Legal QA","authors":["Cheol Ryu","Seolhwa Lee","Subeen Pang","Chanyeol Choi","Hojun Choi","Myeonggee Min","Jy-yong Sohn"],"llm_authors":"Cheol Ryu, Seolhwa Lee, Subeen Pang, Chanyeol Choi, Hojun Choi, Myeonggee Min, Jy-yong Sohn","author_string":"","year":2023,"abstract":"","llm_abstract":"While large language models (LLMs) have demonstrated significant capabilities in text generation, their utilization in areas requiring domain-specific expertise, such as law, must be approached cautiously. This caution is warranted due to the inherent challenges associated with LLM-generated texts, including the potential presence of factual errors. Motivated by this issue, we propose Eval-RAG, a new evaluation method for LLM-generated texts. Unlike existing methods, Eval-RAG evaluates the validity of generated texts based on the related document that are collected by the retriever. In other words, Eval-RAG adopts the idea of retrieval augmented generation (RAG) for the purpose of evaluation. Our experimental results on Korean Legal Question-Answering (QA) tasks show that conventional LLM-based evaluation methods can be better aligned with Lawyers’ evaluations, by combining with Eval-RAG. In addition, our qualitative analysis show that Eval-RAG successfully finds the factual errors in LLM-generated texts, while existing evaluation methods cannot.","llm_keywords":["LLMs","Legal QA","Evaluation methods","Retrieval-augmented generation","Factual errors","Korean legal tasks","Text generation","Document retrieval","Hallucinated text"],"classifications":["Information Retrieval","Information Extraction","Text Generation","Resources"],"num_cited_by":19,"num_cited_by_title_only":19,"num_pages":6},{"id":"ca1056796024c13d6a59f6097fd3cb31389a4259824e3cd5aa0ba8e1e7812c8e1d42448a37a125e2bf00e1a862f130d243e585178edaa649a81a5d668b9fb320","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.2.pdf","title":"","llm_title":"NOMOS: Navigating Obligation Mining in Official Statutes","authors":["Andrea Pennisi","Elvira González Hernández","Nina Koivula"],"llm_authors":"Andrea Pennisi, Elvira González Hernández, Nina Koivula","author_string":"","year":2023,"abstract":"","llm_abstract":"The process of identifying obligations in a legal text is not a straightforward task, because not only are the documents long, but the sentences therein are long as well. As a result of long elements in the text, law is more difficult to interpret (Coupette et al., 2021). Moreover, the identification of obligations relies not only on the clarity and precision of the language used but also on the unique perspectives, experiences, and knowledge of the reader. In particular, this paper addresses the problem of identifying obligations using machine and deep learning approaches showing a full comparison between both methodologies and proposing a new approach called NOMOS based on the combination of Positional Embeddings (PE) and Temporal Convolutional Networks (TCNs). Quantitative and qualitative experiments, conducted on legal regulations 1, demonstrate the effectiveness of the proposed approach.","llm_keywords":["obligations","legal text","machine learning","deep learning","Positional Embeddings","Temporal Convolutional Networks","NOMOS","legal regulations"],"classifications":["Classification","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":9},{"id":"7d9261dc26cef471f24000ed4c5c9022604198a6fd6f939648a63ad8e2ba8d57bf6b201ac55dfe4bab5d317f43a75b6cc8de06248b49d02d58b5d977a91210e7","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.10v2.pdf","title":"","llm_title":"Beyond The Text: Analysis of Privacy Statements through Syntactic and Semantic Role Labeling","authors":["Yan Shvartzshnaider","Ananth Balashankar","Thomas Wies","Lakshminarayanan Subramanian"],"llm_authors":"Yan Shvartzshnaider, Ananth Balashankar, Thomas Wies, Lakshminarayanan Subramanian","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper formulates a new task of extracting privacy parameters from a privacy policy, through the lens of Contextual Integrity (CI), an established social theory framework for reasoning about privacy norms. Through extensive experiments, we further show that incorporating CI-based domain-specific knowledge into a BERT-based SRL model results in the highest precision and recall, achieving an F1 score of 84%. With our work, we would like to motivate new research in building NLP applications for the privacy domain.","llm_keywords":["Contextual Integrity","Privacy Policies","Natural Language Processing","Semantic Role Labeling","BERT","Privacy Norms","Information Flow","Policy Analysis"],"classifications":["Information Extraction"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":14},{"id":"17e8fe1345505eb840a6cfa3a0cb3dc6b86359470d20781f26d9527c47cfa93924a047d58cd85977b6867bc3b3711cb88960fcc0d322393601a4f21a06010a1f","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.35.pdf","title":"","llm_title":"LexSumm and LexT5: Benchmarking and Modeling Legal Summarization Tasks in English","authors":["Santosh T.Y.S.S","Cornelius Weiss","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Cornelius Weiss, Matthias Grabmair","author_string":"","year":2024,"abstract":"","llm_abstract":"In the evolving NLP landscape, benchmarks serve as yardsticks for gauging progress. However, existing Legal NLP benchmarks only focus on predictive tasks, overlooking generative tasks. This work curates LexSumm, a benchmark designed for evaluating legal summarization tasks in English. It comprises eight English legal summarization datasets, from diverse jurisdictions, such as the US, UK, EU and India. Additionally, we release LexT5, legal oriented sequence-to-sequence model, addressing the limitation of the existing BERT-style encoder-only models in the legal domain. We assess its capabilities through zero-shot probing on LegalLAMA and fine-tuning on LexSumm. Our analysis reveals abstraction and faithfulness errors even in summaries generated by zero-shot LLMs, indicating opportunities for further improvements. LexSumm benchmark and LexT5 model are available at https://github.com/TUMLegalTech/LexSumm-LexT5.","llm_keywords":["NLP","legal summarization","LexSumm","LexT5","legal NLP","benchmark","legal dataset","sequence-to-sequence model","zero-shot LLM","legal documents"],"classifications":["Machine Summarization","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":23},{"id":"13eaf38ee6479640f067f21953f1a7df7a16094c208407d9f95aabac359638f8f1c48158bc04a59c09bb4001d6b81fbbabd5c77379e1bb37d588fff4ca390ab4","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.22.pdf","title":"","llm_title":"Large Language Models are legal but they are not: Making the case for a powerful LegalLLM","authors":["Thanmay Jayakumar","Fauzan Farooqui","Luqman Farooqui"],"llm_authors":"Thanmay Jayakumar, Fauzan Farooqui, Luqman Farooqui","author_string":"","year":2023,"abstract":"","llm_abstract":"Realizing the recent advances in Natural Language Processing (NLP) to the legal sector poses challenging problems such as extremely long sequence lengths, specialized vocabulary that is usually only understood by legal professionals, and high amounts of data imbalance. The recent surge of Large Language Models (LLM) has begun to provide new opportunities to apply NLP in the legal domain due to their ability to handle lengthy, complex sequences. Moreover, the emergence of domain-specific LLMs has displayed extremely promising results on various tasks. In this study, we aim to quantify how general LLMs perform in comparison to legal-domain models (be it an LLM or otherwise). Specifically, we compare the zero-shot performance of three general-purpose LLMs (ChatGPT-3.5, LLaMA-2-70b, and Falcon-180b) on the LEDGAR subset of the LexGLUE benchmark for contract provision classification. Although the LLMs were not explicitly trained on legal data, we observe that they are still able to classify the theme correctly in most cases. However, we find that their mic-F1/mac-F1 performance is upto 19.2/26.8% lesser than smaller models fine-tuned on the legal domain, thus underscoring the need for more powerful legal-domain LLMs.","llm_keywords":["Natural Language Processing","Legal domain","Large Language Models","Contract provision classification","LegalLLM","Transformer models","Zero-shot performance","Domain-specific models"],"classifications":["Classification","Resources"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":7},{"id":"0294a13bba9af4c38db23c40b180bced42b8df96915bbcde9e5baed3f1303a559bf7bdfc98fab0bf091086101efe34acd970dd4b860a2f021fdc8c8c26029b73","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.25.pdf","title":"","llm_title":"A Comparative Study of Prompting Strategies for Legal Text Classification","authors":["Ali Hakimi Parizi","Yuyang Liu","Prudhvi Nokku","Sina Gholamian","David B. Emerson"],"llm_authors":"Ali Hakimi Parizi, Yuyang Liu, Prudhvi Nokku, Sina Gholamian, David B. Emerson","author_string":"","year":2023,"abstract":"","llm_abstract":"In this study, we explore the performance of large language models (LLMs) using different prompt engineering approaches in the context of legal text classification. Prior research has demonstrated that various prompting techniques can improve the performance of a diverse array of tasks done by LLMs. However, in this research, we observe that professional documents, and in particular legal documents, pose unique challenges for LLMs. We experiment with several LLMs and various prompting techniques, including zero/few-shot prompting, prompt ensembling, chain-of-thought, and activation fine-tuning and compare the performance on legal datasets. Although the new generation of LLMs and prompt optimization techniques have been shown to improve generation and understanding of generic tasks, our findings suggest that such improvements may not readily transfer to other domains. Specifically, experiments indicate that not all prompting approaches and models are well-suited for the legal domain which involves complexities such as long documents and domain-specific language.","llm_keywords":["Legal text classification","Prompt engineering","Large language models","Zero-shot prompting","Few-shot prompting","Prompt ensembling","Chain-of-thought","Activation fine-tuning","Domain-specific challenges"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":8},{"id":"d97d067686cfe28ffd571be7067de2e386261c474ae9f70489b0917f679373b0075372ef1c8a657384f9737dfe8ee2ab9b25f2ffa4d9a5669a7808d4effd0711","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.1.pdf","title":"","llm_title":"Anthropomorphization of AI: Opportunities and Risks","authors":["Ameet Deshpande","Tanmay Rajpurohit","Karthik Narasimhan","Ashwin Kalyan"],"llm_authors":"Ameet Deshpande, Tanmay Rajpurohit, Karthik Narasimhan, Ashwin Kalyan","author_string":"","year":2023,"abstract":"","llm_abstract":"Anthropomorphization, which is the tendency to attribute human-like traits to non-human entities, is prevalent in many social contexts – children anthropomorphize toys and adults do so with brands. It is also a versatile tool in science, with behavioral psychology and evolutionary biology meticulously documenting its consequences. With widespread adoption of AI systems, and the push to make it human-like through alignment techniques, human voice, and avatars, the tendency for users to anthropomorphize it increases significantly. We take a dyadic approach to understanding this phenomenon with large language models (LLMs) by studying (1) the objective legal implications, as analyzed through the lens of the recent blueprint of AI bill of rights and the (2) subtle psychological aspects of customization and anthropomorphization. We find that anthropomorphized LLMs customized for different user bases violate multiple provisions in the legislative blueprint and raise corporate personhood confusions. In addition, we point out that anthropomorphization of LLMs affects the influence they can have on their users, thus establishing potential for manipulation and negative influence. With LLMs being hyper-personalized for vulnerable groups like children and patients among others, we propose a conservative strategy for the cautious use of anthropomorphization to improve trustworthiness of AI systems.","llm_keywords":["Anthropomorphization","AI","Large Language Models","Legal Implications","Psychological Effects","Customization","Trustworthiness","Corporate Personhood","Manipulation","AI Bill of Rights"],"classifications":[],"num_cited_by":36,"num_cited_by_title_only":36,"num_pages":7},{"id":"c5e67743df85ef280e30681b20cb9530dc02094fcdab2af6557961f72a2fac64792ef0af28b2bcc0a97c892f838e4f78d36ceac435692f8f643d529ed48199c2","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.6.pdf","title":"","llm_title":"Italian Legislative Text Classification for Gazzetta Ufficiale","authors":["Marco Rovera","Alessio Palmero Aprosio","Francesco Greco","Mariano Lucchese","Sara Tonelli","Antonio Antetomaso"],"llm_authors":"Marco Rovera, Alessio Palmero Aprosio, Francesco Greco, Mariano Lucchese, Sara Tonelli, Antonio Antetomaso","author_string":"","year":2023,"abstract":"","llm_abstract":"This work introduces a novel, extensive annotated corpus for multi-label legislative text classification in Italian, based on legal acts from the Gazzetta Ufficiale, the official source of legislative information of the Italian state. The annotated dataset, which we released to the community, comprises over 363,000 titles of legislative acts, spanning over 30 years from 1988 until 2022. Moreover, we evaluate four models for text classification on the dataset, demonstrating how using only the acts’ titles can achieve top-level classification performance, with a micro F1-score of 0.87. Also, our analysis shows how Italian domain-adapted legal models do not outperform general-purpose models on the task. Models’ performance can be checked by users via a demonstrator system provided in support of this work.","llm_keywords":["legislative text classification","Italian law","Gazzetta Ufficiale","annotated corpus","multi-label classification","transformer models","text classification models","legal domain","machine learning"],"classifications":["Classification","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":7},{"id":"6897a041a0825c62dd609206960965408255c9cb709394cd224155402ad8db7636a04232d634519976ee4097169e4b66dd7f514335465313e34d2b7d28bea070","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.17.pdf","title":"","llm_title":"Exploration of Open Large Language Models for eDiscovery","authors":["Sumit Pai","Sounak Lahiri","Ujjwal Kumar","Krishanu Das Baksi","Elijah Soba","Michael Suesserman","Nirmala Pudota","Jonathan Foster","Edward Bowen","Sanmitra Bhattacharya"],"llm_authors":"Sumit Pai, Sounak Lahiri, Ujjwal Kumar, Krishanu Das Baksi, Elijah Soba, Michael Suesserman, Nirmala Pudota, Jonathan Foster, Edward Bowen, Sanmitra Bhattacharya","author_string":"","year":2023,"abstract":"","llm_abstract":"The rapid advancement of Generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), has led to their widespread adoption for various natural language processing (NLP) tasks. One crucial domain ripe for innovation is the Technology-Assisted Review (TAR) process in Electronic discovery (eDiscovery). Traditionally, TAR involves manual review and classification of documents for relevance over large document collections for litigations and investigations. This process is aided by machine learning and NLP tools which require extensive training and fine-tuning. In this paper, we explore the application of LLMs to TAR, specifically for predictive coding. We experiment with out-of-the-box prompting and fine-tuning of LLMs using parameter-efficient techniques. We conduct experiments using open LLMs and compare them to commercially-licensed ones. Our experiments demonstrate that open LLMs lag behind commercially-licensed models in relevance classification using out-of-the-box prompting. However, topic-specific instruction tuning of open LLMs not only improve their effectiveness but can often outperform their commercially-licensed counterparts in performance evaluations. Additionally, we conduct a user study to gauge the preferences of our eDiscovery Subject Matter Specialists (SMS) regarding human-authored versus model-generated reasoning. We demonstrate that instruction-tuned open LLMs can generate high quality reasonings that are comparable to commercial LLMs.","llm_keywords":["Generative AI","Large Language Models","eDiscovery","Technology-Assisted Review","predictive coding","zero-shot learning","fine-tuning","instruction tuning","legal technology"],"classifications":["Classification","Text Generation"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":12},{"id":"4ab7b8a6192c09507e504a08aa6fcc879a69fd4dad5ca86f7fe1f11d692646633046ef09b6810e4baa9a42efc40285996f522a6da20bf4b25dda0c3d2f382357","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.19.pdf","title":"","llm_title":"Joint Learning for Legal Text Retrieval and Textual Entailment: Leveraging the Relationship between Relevancy and Affirmation","authors":["Hai-Long Nguyen","Thi-Hai-Yen Vuong","Ha-Thanh Nguyen","Xuan-Hieu Phan"],"llm_authors":"Hai-Long Nguyen, Thi-Hai-Yen Vuong, Ha-Thanh Nguyen, Xuan-Hieu Phan","author_string":"","year":2023,"abstract":"","llm_abstract":"In legal text processing and reasoning, one normally performs information retrieval to find relevant documents of an input question, and then performs textual entailment to answer the question. The former is about relevancy whereas the latter is about affirmation (or conclusion). While relevancy and affirmation are two different concepts, there is obviously a connection between them. That is why performing retrieval and textual entailment sequentially and independently may not make the most of this mutually supportive relationship. This paper, therefore, propose a multi–task learning model for these two tasks to improve their performance. Technically, in the COLIEE dataset, we use the information of Task 4 (conclusions) to improve the performance of Task 3 (searching for legal provisions related to the question). Our empirical findings indicate that this supportive relationship truly exists. This important insight sheds light on how leveraging relationship between tasks can significantly enhance the effectiveness of our multi-task learning approach for legal text processing.","llm_keywords":["legal text retrieval","textual entailment","multi-task learning","relevancy","affirmation","legal text processing","COLIEE","information retrieval","legal reasoning"],"classifications":["Information Retrieval"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"03c5dc9a2c66d24ee295dfd350bafc4d86ec0c4bfb0221372b1d284811c9916b3f9cee70c3bb103e7254b4e7e59dc8b72d13457590b8186c89fb9f27a5e6976d","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.8.pdf","title":"","llm_title":"Questions about Contracts: Prompt Templates for Structured Answer Generation","authors":["Adam Roegiest","Radha Chitta","Jonathan Donnelly","Maya Lash","Alexandra Vtyurina","François Longtin"],"llm_authors":"Adam Roegiest, Radha Chitta, Jonathan Donnelly, Maya Lash, Alexandra Vtyurina, François Longtin","author_string":"","year":2023,"abstract":"","llm_abstract":"Finding the answers to legal questions about specific clauses in contracts is an important analysis in many legal workflows (e.g., understanding market trends, due diligence, risk mitigation) but more important is being able to do this at scale. In this paper, we present an examination of using large language models to produce (partially) structured answers to legal questions; primarily in the form of multiple choice and multiple select. We first show that traditional semantic matching is unable to perform this task at acceptable accuracy and then show how question specific prompts can achieve reasonable accuracy across a range of generative models. Finally, we show that much of this effectiveness can be maintained when generalized prompt templates are used rather than question specific ones.","llm_keywords":["legal questions","contracts","large language models","structured answers","prompt templates"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"dd000c29d39f824ddbc8188da907b4f8258f6418f95312c095be4744c3e1852aabeea14b0503aaccf97792004ab56c7ce9a19dd54621502af0bc998165263020","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.18.pdf","title":"","llm_title":"BLT: Can Large Language Models Handle Basic Legal Text?","authors":["Andrew Blair-Stanek","Nils Holzenberger","Benjamin Van Durme"],"llm_authors":"Andrew Blair-Stanek, Nils Holzenberger, Benjamin Van Durme","author_string":"","year":2024,"abstract":"","llm_abstract":"We find that the best publicly available LLMs like GPT-4 and Claude currently perform poorly on basic legal text handling. This motivates the creation of a benchmark consisting of examples that lawyers and paralegals would expect LLMs to handle zero-shot, such as looking up the text at a line of a witness deposition or at a subsection of a contract. LLMs’ poor performance on this benchmark casts into doubt their reliability as-is for legal practice. However, fine-tuning on our training set brings even a small model to near-perfect performance. This benchmark will be useful for fine-tuning LLMs for downstream legal tasks, as well as for tracking LLMs’ reliability as-is for basic legal tasks.","llm_keywords":["Large Language Models","legal text handling","benchmark","GPT-4","fine-tuning","legal practice","zero-shot learning","LLM reliability","BLT dataset"],"classifications":["Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":17},{"id":"6f32e145322d07ecf82f07b1d909479ea8edd6691c6a77d0f474f909b8e38d81673ef7567d55a5cbad9f96000e67f1e32482029bedd38d0d1981c4379fc9ba7f","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.11.pdf","title":"","llm_title":"Enhancing Contract Negotiations with LLM-Based Legal Document Comparison","authors":["Savinay Narendra","Kaushal Shetty","Adwait Ratnaparkhi"],"llm_authors":"Savinay Narendra, Kaushal Shetty, Adwait Ratnaparkhi","author_string":"","year":2024,"abstract":"","llm_abstract":"We present a large language model (LLM) based approach for comparing legal contracts with their corresponding template documents. Legal professionals use commonly observed deviations between templates and contracts to help with contract negotiations, and also to refine the template documents. Our comparison approach, based on the well-studied natural language inference (NLI) task, first splits a template into key concepts and then uses LLMs to decide if the concepts are entailed by the contract document. We also repeat this procedure in the opposite direction — contract clauses are tested for entailment against the template clause to see if they contain additional information. The non-entailed concepts are labelled, organized and filtered by frequency, and placed into a clause library, which is used to suggest changes to the template documents. We first show that our LLM-based approach outperforms all previous work on a publicly available dataset designed for NLI in the legal domain. We then apply it to a private real-world legal dataset, achieve an accuracy of 96.46%. Our approach is the first in the literature to produce a natural language comparison between legal contracts and their template documents.","llm_keywords":["LLM","legal contracts","natural language inference","contract management","contract negotiation","clause variation analysis","template documents","contract classification","contract summarization"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":11},{"id":"3521a77d01a14ac307d1cc0d6a3b9b80e1ab411cf5878a873a162ee77995e58194bc403b45e99812bab2b227c5c1efbd3ce8feed9190a8f791f30a12f8a9c64e","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.16.pdf","title":"","llm_title":"Cross Examine: An Ensemble-based approach to leverage Large Language Models for Legal Text Analytics","authors":["Saurav Chowdhury","Suyog Joshi","Lipika Dey"],"llm_authors":"Saurav Chowdhury, Suyog Joshi, Lipika Dey","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal documents are complex in nature, describing a course of argumentative reasoning that is followed to settle a case. Churning through large volumes of legal documents is a daily requirement for a large number of professionals who need access to the information embedded in them. Natural Language Processing(NLP) methods that help in document summarization with key information components, insight extraction and question answering play a crucial role in legal text processing. Most of the existing document analysis systems use supervised machine learning, which require large volumes of annotated training data for every different application and are expensive to build. In this paper we propose a legal text analytics pipeline using Large Language Models (LLMs), which can work with little or no training data. For document summarization, we propose an iterative pipeline using retrieval augmented generation to ensure that the generated text remains contextually relevant. For question answering, we propose a novel ontology-driven ensemble approach similar to cross-examination that exploits questioning and verification principles. A knowledge graph, created with the extracted information, stores the key entities and relationships reflecting the repository content structure. A new dataset is created with Indian court documents related to bail applications for cases filed under POCSO Act. Analysis of insights extracted from the answers reveal patterns of crime and social conditions leading to those crimes, which are important inputs for social scientists as well as legal system.","llm_keywords":["Legal text analytics","Large Language Models","document summarization","question answering","knowledge graph","legal ontology","ensemble-based approach","Retrieval-Augmented Generation","POCSO Act"],"classifications":["Resources","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":11},{"id":"09e5ecf853bb0dbda36dec974ed7431557da1e2433c25028cb339ce1da96ea8c607e8a7aed08bf3b0453fb545d467a6e7a0314285d571035ff7c776fcb3f2770","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.1.pdf","title":"","llm_title":"LeGen: Complex Information Extraction from Legal Sentences using Generative Models","authors":["Chaitra C R","Sankalp Kulkarni","Sai Rama Akash Varma Sagi","Shashank Pandey","Rohit Yalavarthy","Dipanjan Chakraborty","Prajna Upadhyay"],"llm_authors":"Chaitra C R, Sankalp Kulkarni, Sai Rama Akash Varma Sagi, Shashank Pandey, Rohit Yalavarthy, Dipanjan Chakraborty, Prajna Upadhyay","author_string":"","year":2024,"abstract":"","llm_abstract":"Constructing legal knowledge graphs from unstructured legal texts is a complex challenge due to the intricate nature of legal language. While open information extraction (OIE) techniques can convert text into triples of the form ⟨subject, relation, object⟩, they often fall short of capturing the nuanced relationships within lengthy legal sentences, necessitating more sophisticated approaches known as complex information extraction. This paper proposes LeGen – an end-to-end approach leveraging pre-trained large language models (GPT-4o, T5, BART) to perform complex information extraction from legal sentences. LeGen learns and represents the discourse structure of legal sentences, capturing both their complexity and semantics. It minimizes error propagation typical in multi-step pipelines and achieves up to a 32.2% gain on the Indian Legal benchmark. Additionally, it demonstrates competitive performance on open information extraction benchmarks. A promising application of the resulting legal knowledge graphs is in developing question-answering systems for government schemes, tailored to the Next Billion Users who struggle with the complexity of legal language. Our code and data are available at https://github.com/prajnaupadhyay/LegalIE.","llm_keywords":["legal information extraction","knowledge graphs","generative models","complex legal sentences","law and AI","GPT-4o","T5","BART","question answering systems"],"classifications":["Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":17},{"id":"0a7223709d03330c8e9e15dc8d97473c6f0dca430bd08c03a2b5be8825d7ab97a362561a31847a8109cd27e7fc6e694a679b98eaa092b4cf8ed2ccd5bad9cc00","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.6.pdf","title":"","llm_title":"Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models","authors":["Shubham Kumar Nigam","Aniket Deroy","Subhankar Maity","Arnab Bhattacharya"],"llm_authors":"Shubham Kumar Nigam, Aniket Deroy, Subhankar Maity, Arnab Bhattacharya","author_string":"","year":2024,"abstract":"","llm_abstract":"This study investigates judgment prediction in a realistic scenario within the context of Indian judgments, utilizing a range of transformer-based models, including InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and GPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are predicted at the point when a case is presented for a decision in court, using only the information available at that time, such as the facts of the case, statutes, precedents, and arguments. This approach mimics real-world conditions, where decisions must be made without the benefit of hindsight, unlike retrospective analyses often found in previous studies. For transformer models, we experiment with hierarchical transformers and the summarization of judgment facts to optimize input for these models. Our experiments with LLMs reveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust performance in judgment prediction. Furthermore, incorporating additional legal information, such as statutes and precedents, significantly improves the outcome of the prediction task. The LLMs also provide explanations for their predictions. To evaluate the quality of these predictions and explanations, we introduce two human evaluation metrics: Clarity and Linking. Our findings from both automatic and human evaluations indicate that, despite advancements in LLMs, they are yet to achieve expert-level performance in judgment prediction and explanation tasks.","llm_keywords":["Legal judgment prediction","Large language models","Transformer-based models","Indian judgments","GPT-3.5 Turbo","Statutes and precedents","Hierarchical transformers","Clarity and Linking","Human evaluation metrics"],"classifications":["Classification","Machine Summarization","Information Extraction"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":20},{"id":"5d0d805d663f9b77a698419c3125a80425b7d556aee7a574f71bfc6141ed7cbc25c13841339b30aae4001cada0d3318423093232486a0efc8e47019ff83c25a4","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.24.pdf","title":"","llm_title":"Gaps or Hallucinations? Scrutinizing Machine-Generated Legal Analysis for Fine-grained Text Evaluations","authors":["Abe Bohan Hou","William Jurayj","Nils Holzenberger","Andrew Blair-Stanek","Benjamin Van Durme"],"llm_authors":"Abe Bohan Hou, William Jurayj, Nils Holzenberger, Andrew Blair-Stanek, Benjamin Van Durme","author_string":"","year":2024,"abstract":"","llm_abstract":"Large Language Models (LLMs) show promise as a writing aid for professionals performing legal analyses. However, LLMs can often hallucinate in this setting, in ways difficult to recognize by non-professionals and existing text evaluation metrics. In this work, we pose the question: when can machine-generated legal analysis be evaluated as acceptable? We introduce the neutral notion of gaps – as opposed to hallucinations in a strict erroneous sense – to refer to the difference between human-written and machine-generated legal analysis. Gaps do not always equate to invalid generation. Working with legal experts, we consider the CLERC generation task proposed in Hou et al. (2024b), leading to a taxonomy, a fine-grained detector for predicting gap categories, and an annotated dataset for automatic evaluation. Our best detector achieves 67% F1 score and 80% precision on the test set. Employing this detector as an automated metric on legal analysis generated by SOTA LLMs, we find around 80% contain hallucinations of different kinds.","llm_keywords":["Legal Analysis","Large Language Models","Hallucinations","Text Evaluation","Machine-Generated Analysis","Gaps","Legal Expertise","CLERC Generation Task","Automatic Evaluation"],"classifications":["Text Generation","Pre-Processing","Resources","Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":23},{"id":"b595300255981faeaac6d1bf5b294772d19d649845d1226ab28ded17b5072dedd1e12498d4a6b38cd134203488a441b630e45bf7aa6774a2a486b920080df79a","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.8.pdf","title":"","llm_title":"Information Extraction for Planning Court Cases","authors":["Drish Mali","Rubash Mali","Claire Barale"],"llm_authors":"Drish Mali, Rubash Mali, Claire Barale","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal documents are often long and unstructured, making them challenging and timeconsuming to apprehend. An automatic system that can identify relevant entities and labels within legal documents, would significantly reduce the legal research time. We developed a system to streamline legal case analysis from planning courts by extracting key information from XML files using Named Entity Recognition (NER) and multi-label classification models to convert them into structured form. This research contributes three novel datasets for the Planning Court cases: a NER dataset, a multi-label dataset fully annotated by humans, and newly re-annotated multi-label datasets partially annotated using LLMs. We experimented with various general-purpose and legal domain-specific models with different maximum sequence lengths. It was noted that incorporating paragraph position information improved the performance of models for the multi-label classification task. Our research highlighted the importance of domain-specific models, with LegalRoBERTa and LexLM demonstrating the best performance.","llm_keywords":["Information Extraction","Planning Court Cases","Named Entity Recognition","Multi-label Classification","Legal Documents","Natural Language Processing","Large Language Models","LegalRoBERTa","LexLM","Data Annotation"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":18},{"id":"c1e068ad2c240b21bf4cc817828e16a089d35bf5bdfc10f38ea2567521c46005c9f229b95b0d88cba5e1380668b01e9b4f8a29c28cd83eeaf5e871b6a56b40ca","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.9.pdf","title":"","llm_title":"Legal Judgment Prediction: If You Are Going to Do It, Do It Right","authors":["Masha Medvedeva","Pauline McBride"],"llm_authors":"Masha Medvedeva, Pauline McBride","author_string":"","year":2023,"abstract":"","llm_abstract":"The field of Legal Judgment Prediction (LJP) has witnessed significant growth in the past decade, with over 100 papers published in the past three years alone. Our comprehensive survey of over 150 papers reveals a stark reality: only ∼7% of published papers are doing what they set out to do - predict court decisions. We delve into the reasons behind the flawed and unreliable nature of the remaining experiments, emphasising their limited utility in the legal domain. We examine the distinctions between predicting court decisions and the practices of legal professionals in their daily work. We explore how a lack of attention to the identity and needs of end-users has fostered the misconception that LJP is a near-solved challenge suitable for practical application, and contributed to the surge in academic research in the field. To address these issues, we examine three different dimensions of ‘doing LJP right’: using data appropriate for the task; tackling explainability; and adopting an application-centric approach to model reporting and evaluation. We formulate a practical checklist of recommendations, delineating the characteristics that are required if a judgment prediction system is to be a valuable addition to the legal field.","llm_keywords":["Legal Judgment Prediction","Natural Language Processing","Machine Learning","Court Decisions","Data Reliability","Explainability","Model Evaluation","Legal Domain","Predictive Systems"],"classifications":["Classification"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":12},{"id":"3e095da72de6d68e1bb2d6a347ed8338d60d0c771cee1af6379f50fa4fbbaefe0c58a1f261711de68b5d5fb4d312eb407f04db4d45c9c82053ad2353df39c77f","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.18.pdf","title":"","llm_title":"Retrieval-Augmented Chain-of-Thought in Semi-structured Domains","authors":["Vaibhav Mavi","Abulhair Saparov","Chen Zhao"],"llm_authors":"Vaibhav Mavi, Abulhair Saparov, Chen Zhao","author_string":"","year":2023,"abstract":"","llm_abstract":"Applying existing question answering (QA) systems to specialized domains like law and finance presents challenges that necessitate domain expertise. Although large language models (LLMs) have shown impressive language comprehension and in-context learning capabilities, their inability to handle very long inputs/contexts is well known. Tasks specific to these domains need significant background knowledge, leading to contexts that can often exceed the maximum length that existing LLMs can process. This study explores leveraging the semi-structured nature of legal and financial data to efficiently retrieve relevant context, enabling the use of LLMs for domain-specialized QA. The resulting system outperforms contemporary models and also provides useful explanations for the answers, encouraging the integration of LLMs into legal and financial NLP systems for future research.","llm_keywords":["question answering","large language models","legal domain","financial domain","in-context learning","semi-structured data","information retrieval","chain-of-thought prompting","NLP","domain-specific AI"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":14},{"id":"d8405ff908c58359df795418fb795c3ddf10e163dd00c15ed37c25d220a7b636586d7fdce360b453b1225655c8550f85dcdf97ebde10f6b17f98a8b5e4773eb6","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.16.pdf","title":"","llm_title":"Automatic Anonymization of Swiss Federal Supreme Court Rulings","authors":["Joel Niklaus","Robin Mamié","Matthias Stürmer","Daniel Brunner","Marcel Gygli"],"llm_authors":"Joel Niklaus, Robin Mamié, Matthias Stürmer, Daniel Brunner, Marcel Gygli","author_string":"","year":2023,"abstract":"","llm_abstract":"Releasing court decisions to the public relies on proper anonymization to protect all involved parties, where necessary. The Swiss Federal Supreme Court relies on an existing system that combines different traditional computational methods with human experts. In this work, we enhance the existing anonymization software using a large dataset annotated with entities to be anonymized. We compared BERT-based models with models pre-trained on in-domain data. Our results show that using in-domain data to pre-train the models further improves the F1-score by more than 5% compared to existing models. Our work demonstrates that combining existing anonymization methods, such as regular expressions, with machine learning can further reduce manual labor and enhance automatic suggestions.","llm_keywords":["anonymization","Swiss Federal Supreme Court","machine learning","natural language processing","legal text processing","Named Entity Recognition","BERT-based models","in-domain data","court rulings"],"classifications":["Information Extraction","Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":7},{"id":"5dff3d63ff86b6e498139fa7f49b1d3e0ee137b84163411cdb358404ae837da298243cf53a926c4693211d9f21d80b0157ec965f4ebde64cf3da0634fcc7d417","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.7.pdf","title":"","llm_title":"Mixed-domain Language Modeling for Processing Long Legal Documents","authors":["Wenyue Hua","Yuchen Zhang","Zhe Chen","Josie Li","Melanie Weber"],"llm_authors":"Wenyue Hua, Yuchen Zhang, Zhe Chen, Josie Li, Melanie Weber","author_string":"","year":2023,"abstract":"","llm_abstract":"The application of Natural Language Processing (NLP) to specialized domains, such as the law, has recently received a surge of interest. As many legal services rely on processing and analyzing large collections of documents, automating such tasks with NLP tools such as language models emerges as a key challenge since legal documents may contain specialized vocabulary from other domains, such as medical terminology in personal injury text. However, most language models are general-purpose models, which either have limited reasoning capabilities on highly specialized legal terminology and syntax, such as BERT or ROBERTA, or are expensive to run and tune, such as GPT-3.5 and Claude. Thus, in this paper, we propose a specialized language model for personal injury text, LEGALRELECTRA, which is trained on mixed-domain legal and medical corpora. We show that as a small language model, our model improves over general-domain and single-domain medical and legal language models when processing mixed-domain (personal injury) text. Our training architecture implements the ELECTRA framework but utilizes REFORMER instead of BERT for its generator and discriminator. We show that this improves the model’s performance on processing long passages and results in better long-range text comprehension.","llm_keywords":["Natural Language Processing","legal domain","personal injury","language models","LEGALRELECTRA","ELECTRA","REFORMER","domain adaptation"],"classifications":["Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"3f646c9d341fb316d5db20957d9c24165eefc9c0959ddcb06e970fc365031a547003dd0f25d8998fae7b8955e4c9bbc2ef5ebef94954465a4e6f903cb6c1ce01","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.11.pdf","title":"","llm_title":"Towards Mitigating Perceived Unfairness in Contracts from a Non-Legal Stakeholder’s Perspective","authors":["Anmol Singhal","Preethu Rose Anish","Shirish Karande","Smita Ghaisas"],"llm_authors":"Anmol Singhal, Preethu Rose Anish, Shirish Karande, and Smita Ghaisas","author_string":"","year":2023,"abstract":"","llm_abstract":"Commercial contracts are known to be a valuable source for deriving project-specific requirements. However, contract negotiations mainly occur among the legal counsel of the parties involved. The participation of non-legal stakeholders, including requirement analysts, engineers, and solution architects, whose primary responsibility lies in ensuring the seamless implementation of contractual terms, is often indirect and inadequate. Consequently, a significant number of sentences in contractual clauses, though legally accurate, can appear unfair from an implementation perspective to non-legal stakeholders. This perception poses a problem since requirements indicated in the clauses are obligatory and can involve punitive measures and penalties if not implemented as committed in the contract. Therefore, the identification of potentially unfair clauses in contracts becomes crucial. In this work, we conduct an empirical study to analyze the perspectives of different stakeholders regarding contractual fairness. We then investigate the ability of Pre-trained Language Models (PLMs) to identify unfairness in contractual sentences by comparing chain of thought prompting and semi-supervised fine-tuning approaches. Using BERT-based fine-tuning, we achieved an accuracy of 84% on a dataset consisting of proprietary contracts. It outperformed chain of thought prompting using Vicuna-13B by a margin of 9%.","llm_keywords":["contracts","unfairness","non-legal stakeholders","pre-trained language models","contract negotiation","requirements analysis","contractual fairness","BERT-based fine-tuning","empirical study"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":14},{"id":"b943200f62debb87bee3ffb3de18ac21ecb439b97208257ffe6f7e9caaa01a869e4c544fba1ce05ebdc11565cffdcf586db2f50d851b84e6bc77a1b170e794ae","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.33.pdf","title":"","llm_title":"LegalLens Shared Task 2024: Legal Violation Identification in Unstructured Text","authors":["Ben Hagag","Liav Harpaz","Gil Semo","Dor Bernsohn","Rohit Saha","Pashootan Vaezipoor","Kyryl Truskovskyi","Gerasimos Spanakis"],"llm_authors":"Ben Hagag, Liav Harpaz, Gil Semo, Dor Bernsohn, Rohit Saha, Pashootan Vaezipoor, Kyryl Truskovskyi, Gerasimos Spanakis","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper presents the results of the LegalLens Shared Task, focusing on detecting legal violations within text in the wild across two sub-tasks: LegalLens-NER for identifying legal violation entities and LegalLens-NLI for associating these violations with relevant legal contexts and affected individuals. Using an enhanced LegalLens dataset covering labor, privacy, and consumer protection domains, 38 teams participated in the task. Our analysis reveals that while a mix of approaches was used, the top-performing teams in both tasks consistently relied on fine-tuning pre-trained language models, outperforming legal-specific models and few-shot methods. The top-performing team achieved a 7.11% improvement in NER over the baseline, while NLI saw a more marginal improvement of 5.7%. Despite these gains, the complexity of legal texts leaves room for further advancements.","llm_keywords":["LegalLens","legal violations","Named Entity Recognition","Natural Language Inference","AI","machine learning","natural language processing","law","data analysis"],"classifications":["Information Extraction","Classification","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"5af3ffe878389ea0a90a3e043196b196cf8ff1ea8138467eddc61da3463180cb8836f0ea1d66b65dc17e432d7b6b8994195b05973562be2c3adfb51502febaf2","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2023.nllp-1.24.pdf","title":"","llm_title":"AsyLex: A Dataset for Legal Language Processing of Refugee Claims","authors":["Claire Barale","Mark Klaisoongnoen","Pasquale Minervini","Michael Rovatsos","Nehal Bhuta"],"llm_authors":"Claire Barale, Mark Klaisoongnoen, Pasquale Minervini, Michael Rovatsos, Nehal Bhuta","author_string":"","year":2023,"abstract":"","llm_abstract":"Advancements in natural language processing (NLP) and language models have demonstrated immense potential in the legal domain, enabling automated analysis and comprehension of legal texts. However, developing robust models in Legal NLP is significantly challenged by the scarcity of resources. This paper presents AsyLex, the first dataset specifically designed for Refugee Law applications to address this gap. The dataset introduces 59,112 documents on refugee status determination in Canada from 1996 to 2022, providing researchers and practitioners with essential material for training and evaluating NLP models for legal research and case review. Case review is defined as entity extraction and outcome prediction tasks. The dataset includes 19,115 gold-standard human-labeled annotations for 20 legally relevant entity types curated with the help of legal experts and 1,682 gold-standard labeled documents for the case outcome. Furthermore, we supply the corresponding trained entity extraction models and the resulting labeled entities generated through the inference process on AsyLex. Four supplementary features are obtained through rule-based extraction. We demonstrate the usefulness of our dataset on the legal judgment prediction task to predict the binary outcome and test a set of baselines using the text of the documents and our annotations. We observe that models pretrained on similar legal documents reach better scores, suggesting that acquiring more datasets for specialized domains such as law is crucial. The dataset is available at https://huggingface.co/datasets/clairebarale/AsyLex.","llm_keywords":["Natural Language Processing","Legal Language Processing","Refugee Claims","AsyLex Dataset","Entity Extraction","Legal Judgement Prediction","Refugee Law","Text Analysis","Machine Learning","Data Annotation"],"classifications":["Information Extraction","Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":14},{"id":"e21f85d249680a2421ca2c4494568e38a5815bbc54757cbe6b6fc77c98616208425c1be89ddb77ec05fc26cbde9de086a1e46410b9e19221c450438e6f7b76c7","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.34.pdf","title":"","llm_title":"DeBERTa Beats Behemoths: A Comparative Analysis of Fine-Tuning, Prompting, and PEFT Approaches on LegalLensNER","authors":["Hanh Thi Hong Tran","Nishan Chatterjee","Senja Pollak","Antoine Doucet"],"llm_authors":"Hanh Thi Hong Tran, Nishan Chatterjee, Senja Pollak, Antoine Doucet","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper summarizes the participation of our team (Flawless Lawgic) in the legal named entity recognition (L-NER) task at LegalLens 2024: Detecting Legal Violations. Given possible unstructured texts (e.g., online media texts), we aim to identify legal violations by extracting legal entities such as “violation”, “violation by”, “violation on”, and “law”. This system-description paper discusses our approaches to address the task, empirically highlighting the performances of fine-tuning models from the Transformers family (e.g., RoBERTa and DeBERTa) against open-sourced LLMs (e.g., Llama, Mistral) with different tuning settings (e.g., LoRA, Supervised Fine-Tuning (SFT) and prompting strategies). Our best results, with a weighted F1 of 0.705 on the test set, show a 30 percentage points increase in F1 compared to the baseline and rank 2 on the leaderboard, leaving a marginal gap of only 0.4 percentage points lower than the top solution. Our solutions are available at @honghanhh/lner.","llm_keywords":["DeBERTa","fine-tuning","LegalLensNER","legal named entity recognition","transformers","PEFT","prompting strategies","LLMs","legal violations","L-NER"],"classifications":["Information Extraction","Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"2f57a84d7737755c06e24f0046ba975c07a4a90d8d15eff3d7a72800ad4eb23a84e8945061fde0a6e5ec9926caf0b38bd0b5d03b08e24ed8a8419e6eb2c9c179","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.9.pdf","title":"","llm_title":"Automated Anonymization of Parole Hearing Transcripts","authors":["Abed El Rahman Itani","Wassiliki Siskou","Annette Hautli-Janisz"],"llm_authors":"Abed El Rahman Itani, Wassiliki Siskou, Annette Hautli-Janisz","author_string":"","year":2024,"abstract":"","llm_abstract":"Responsible natural language processing is more and more concerned with preventing the violation of personal rights that language technology can entail (Weidinger et al., 2022). In this paper we illustrate the case of parole hearings in California, the verbatim transcripts of which are made available to the general public upon a request sent to the California Board of Parole Hearings. The parole hearing setting is highly sensitive: inmates face a board of legal representatives who discuss highly personal matters not only about the inmates themselves but also about victims and their relatives, such as spouses and children. Participants have no choice in contributing to the data collection process, since the disclosure of the transcripts is mandated by law. As researchers who are interested in understanding and modeling the communication in these hierarchy-driven settings, we face an ethical dilemma: publishing raw data as is for the community would compromise the privacy of all individuals affected, but manually cleaning the data requires a substantive effort. In this paper we present an automated anonymization process which reliably removes and pseudonymizes sensitive data in verbatim transcripts, while at the same time preserving the structure and content of the data. Our results show that the process exhibits little to no leakage of sensitive information when applied to more than 300 hearing transcripts.","llm_keywords":["anonymization","parole hearings","privacy","natural language processing","sensitive data","ethical dilemmas","data sharing","transcripts","automated processes","legal settings"],"classifications":["Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":14},{"id":"698bed651e4f27928c3f543e4715ed3f105f24d883de8af7335e0d03488f5e64e85c8ee6e2b30acb1fa6020a7e3ca5b507a3ca2e8750dbc8831c99ec2e3797eb","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.7.pdf","title":"","llm_title":"The CLC-UKET Dataset: Benchmarking Case Outcome Prediction for the UK Employment Tribunal","authors":["Huiyuan Xie","Felix Steffek","Joana Ribeiro de Faria","Christine Carter","Jonathan Rutherford"],"llm_authors":"Huiyuan Xie, Felix Steffek, Joana Ribeiro de Faria, Christine Carter, Jonathan Rutherford","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper explores the intersection of technological innovation and access to justice by developing a benchmark for predicting case outcomes in the UK Employment Tribunal (UKET). To address the challenge of extensive manual annotation, the study employs a large language model (LLM) for automatic annotation, resulting in the creation of the CLC-UKET dataset. The dataset consists of approximately 19,000 UKET cases and their metadata. Comprehensive legal annotations cover facts, claims, precedent references, statutory references, case outcomes, reasons and jurisdiction codes. Facilitated by the CLC-UKET data, we examine a multi-class case outcome prediction task in the UKET. Human predictions are collected to establish a performance reference for model comparison. Empirical results from baseline models indicate that finetuned transformer models outperform zero-shot and few-shot LLMs on the UKET prediction task. The performance of zero-shot LLMs can be enhanced by integrating task-related information into few-shot examples. We hope that the CLC-UKET dataset, along with human annotations and empirical findings, can serve as a valuable benchmark for employment-related dispute resolution.","llm_keywords":["UK Employment Tribunal","case outcome prediction","large language model","legal annotations","multi-class prediction","finetuned transformer models","zero-shot learning","few-shot learning","access to justice","employment disputes"],"classifications":["Resources","Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":16},{"id":"c4a82b979a87fa6722b07f6ec603d86ec179e9b8098b38b11b66de95dee192278b326dd4d3ec4b09ff827fa21c47c67a840817df8c191c4576057a3e2367406e","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.25.pdf","title":"","llm_title":"Classify First, and Then Extract: Prompt Chaining Technique for Information Extraction","authors":["Alice Saebom Kwak","Clayton T. Morrison","Derek E. Bambauer","Mihai Surdeanu"],"llm_authors":"Alice Saebom Kwak, Clayton T. Morrison, Derek E. Bambauer, Mihai Surdeanu","author_string":"","year":2024,"abstract":"","llm_abstract":"This work presents a new task-aware prompt design and example retrieval approach for information extraction (IE) using a prompt chaining technique. Our approach divides IE tasks into two steps: (1) text classification to understand what information (e.g., entity or event types) is contained in the underlying text and (2) information extraction for the identified types. Initially, we use a large language model (LLM) in a few-shot setting to classify the contained information. The classification output is used to select the relevant prompt and retrieve the examples relevant to the input text. Finally, we ask a LLM to do the information extraction with the generated prompt. By evaluating our approach on legal IE tasks with two different LLMs, we demonstrate that the prompt chaining technique improves the LLM’s overall performance in a few-shot setting when compared to the baseline in which examples from all possible classes are included in the prompt. Our approach can be used in a low-resource setting as it does not require a large amount of training data. Also, it can be easily adapted to many different IE tasks by simply adjusting the prompts. Lastly, it provides a cost benefit by reducing the number of tokens in the prompt.","llm_keywords":["Prompt Chaining","Information Extraction","Text Classification","Large Language Models","Few-Shot Learning","Example Retrieval","Low-Resource Setting","Semantic Similarity","Task-Aware Techniques"],"classifications":["Classification","Information Retrieval","Information Extraction","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":15},{"id":"d029da4a46bd9d35aef5211693e20f2de21d9f12a95e7e50775c3f22c9f4bfab087704dcd892281dcbd8d9611c7f34c07df510ba84b639553d2636041768657e","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.22.pdf","title":"","llm_title":"LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of the European Court of Human Rights","authors":["Odysseas Chlapanis","Dimitrios Galanis","Ion Androutsopoulos"],"llm_authors":"Odysseas S. Chlapanis, Dimitrios Galanis, Ion Androutsopoulos","author_string":"","year":2024,"abstract":"","llm_abstract":"We present Legal Argument Reasoning (LAR), a novel task designed to evaluate the legal reasoning capabilities of Large Language Models (LLMs). The task requires selecting the correct next statement (from multiple choice options) in a chain of legal arguments from court proceedings, given the facts of the case. We constructed a dataset (LAR-ECHR) for this task using cases from the European Court of Human Rights (ECHR). We evaluated seven general-purpose LLMs on LAR-ECHR and found that (a) the ranking of the models is aligned with that of LegalBench, an established US-based legal reasoning benchmark, even though LAR-ECHR is based on EU law, (b) LAR-ECHR distinguishes top models more clearly, compared to LegalBench, (c) even the best model (GPT-4o) obtains 75.8% accuracy on LAR-ECHR, indicating significant potential for further model improvement. The process followed to construct LAR-ECHR can be replicated with cases from other legal systems.","llm_keywords":["Legal Argument Reasoning","Large Language Models","European Court of Human Rights","LegalBench","Legal Dataset","EU Law","Model Evaluation","Legal Reasoning"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":13},{"id":"2244f478c1cde4351f427e116820b45043bac1b58ff7dc950102fa8373c38054f2141fe9c8ac16b212bfdf387887d79109b3f157c7284249f82488849d979e6c","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.17.pdf","title":"","llm_title":"LLMs to the Rescue: Explaining DSA Statements of Reason with Platform’s Terms of Services","authors":["Marco Aspromonte","Andrea Filippo Ferraris","Federico Galli","Giuseppe Contissa"],"llm_authors":"Marco Aspromonte, Andrea Filippo Ferraris, Federico Galli, Giuseppe Contissa","author_string":"","year":2024,"abstract":"","llm_abstract":"The Digital Services Act (DSA) requires online platforms in the EU to provide \"statements of reason\" (SoRs) when restricting user content, but their effectiveness in ensuring transparency is still debated due to vague and complex terms of service (ToS). This paper explores the use of NLP techniques, specifically multi-agent systems based on large language models (LLMs), to clarify SoRs by linking them to relevant ToS sections. Analysing SoRs from platforms like Booking.com, Reddit, and LinkedIn, our findings show that LLMs can enhance the interpretability of content moderation decisions, improving user understanding and engagement with DSA requirements.","llm_keywords":["Digital Services Act","statements of reason","terms of service","large language models","content moderation","transparency","natural language processing","multi-agent systems","user content","platform policies"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":11},{"id":"f74d5771242c6d3617c2a3bc18d3756a8c418f71c66a2b5a902304286978e7c34a30a2acc75e9c2bd3659bf33e63fe53fd193e30d31099ba60e663e4043e94fc","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.10.pdf","title":"","llm_title":"Towards an Automated Pointwise Evaluation Metric for Generated Long-Form Legal Summaries","authors":["Shao Min Tan","Quentin Grail","Lee Quartey"],"llm_authors":"Shao Min Tan, Quentin Grail, Lee Quartey","author_string":"","year":2024,"abstract":"","llm_abstract":"Long-form abstractive summarization is a task that has particular importance in the legal domain. Automated evaluation metrics are important for the development of text generation models, but existing research on the evaluation of generated summaries has focused mainly on short summaries. We introduce an automated evaluation methodology for generated long-form legal summaries, which involves breaking each summary into individual points, comparing the points in a human-written and machine-generated summary, and calculating a recall and precision score for the latter. The method is designed to be particularly suited for the complexities of legal text, and is also fully interpretable. We also create and release a small meta-dataset for the benchmarking of evaluation methods, focusing on long-form legal summarization. Our evaluation metric corresponds better with human evaluation compared to existing metrics which were not developed for legal data.","llm_keywords":["long-form summarization","legal text","automated evaluation","pointwise evaluation","natural language processing","large language models","meta-dataset"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":14},{"id":"b311de18164e953c6785c567b7ee3fb75b38939251fe1f5a77f6e21d6d5b18ce35598b48798a920b1916b6fa15f67a2e300ab400c893ed771f03c138179c9ed3","file_path":"legal-nlp-survey-20250328-002/team 2/10 NLLP Workshop/2024.nllp-1.19.pdf","title":"","llm_title":"Multi-Property Multi-Label Documents Metadata Recommendation based on Encoder Embeddings","authors":["Nasredine Cheniki","Vidas Daudaravicius","Abdelfettah Feliachi","Didier Hardy","Marc Wilhelm Küster"],"llm_authors":"Nasredine Cheniki, Vidas Daudaravicius, Abdelfettah Feliachi, Didier Hardy, Marc Wilhelm Küster","author_string":"","year":2024,"abstract":"","llm_abstract":"The task of document classification, particularly multi-label classification, presents a significant challenge due to the complexity of assigning multiple relevant labels to each document. This complexity is further amplified in multi-property multi-label classification tasks, where documents must be categorized across various sets of labels. In this research, we introduce an innovative encoder embedding-driven approach to multi-property multi-label document classification that leverages semantic-text similarity and the reuse of pre-existing annotated data to enhance the efficiency and accuracy of the document annotation process. Our method requires only a single model for text similarity, eliminating the need for multiple property-specific classifiers and thereby reducing computational demands and simplifying deployment. We evaluate our approach through a prototype deployed at the European Commission for daily operations, which demonstrates superior performance over existing classification systems. Our contributions include improved accuracy without additional training, increased efficiency, and demonstrated effectiveness in practical applications. The results of our study indicate the potential of our approach to be applied across various domains requiring multi-property multi-label document classification, offering a scalable and adaptable solution for metadata annotation tasks.","llm_keywords":["document classification","multi-label classification","encoder embeddings","semantic-text similarity","metadata annotation","pre-trained models","BERT","European Commission","efficiency","scalability"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"6c1f6a3fd2c5ed82d9f10e3d0844a21aa53745cd6a1b85a802b4e81996080f233000a154ba3459678945fc4dd2952b1c5559a9fcb43118d7b4c34910de2a48bf","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.575.pdf","title":"","llm_title":"Modeling Legal Reasoning: LM Annotation at the Edge of Human Agreement","authors":["Rosamond Thalken","Edward H. Stiglitz","David Mimno","Matthew Wilkens"],"llm_authors":"Rosamond Thalken, Edward H. Stiglitz, David Mimno, Matthew Wilkens","author_string":"","year":2023,"abstract":"","llm_abstract":"Generative language models (LMs) are increasingly used for document class-prediction tasks and promise enormous improvements in cost and efficiency. Existing research often examines simple classification tasks, but the capability of LMs to classify on complex or specialized tasks is less well understood. We consider a highly complex task that is challenging even for humans: the classification of legal reasoning according to jurisprudential philosophy. Using a novel dataset of historical United States Supreme Court opinions annotated by a team of domain experts, we systematically test the performance of a variety of LMs. We find that generative models perform poorly when given instructions (i.e. prompts) equal to the instructions presented to human annotators through our codebook. Our strongest results derive from fine-tuning models on the annotated dataset; the best performing model is an in-domain model, LEGAL-BERT. We apply predictions from this fine-tuned model to study historical trends in jurisprudence, an exercise that both aligns with prominent qualitative historical accounts and points to areas of possible refinement in those accounts. Our findings generally sound a note of caution in the use of generative LMs on complex tasks without fine-tuning and point to the continued relevance of human annotation-intensive classification methods.","llm_keywords":["generative language models","legal reasoning","jurisprudential philosophy","fine-tuning","LEGAL-BERT","document classification","Supreme Court opinions","annotation"],"classifications":["Classification"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":14},{"id":"2e7e3a69738792b78155cde90a0091727a35c6519677a99ee18f6ca28d020b300f382c115151e3d3a726b77be9d553aca533f56f717a34786a2d7c6dbcc6698d","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.458.pdf","title":"","llm_title":"Copyright Violations and Large Language Models","authors":["Antonia Karamolegkou","Jiaang Li","Li Zhou","Anders Søgaard"],"llm_authors":"Antonia Karamolegkou, Jiaang Li, Li Zhou, Anders Søgaard","author_string":"","year":2023,"abstract":"","llm_abstract":"Language models may memorize more than just facts, including entire chunks of texts seen during training. Fair use exemptions to copyright laws typically allow for limited use of copyrighted material without permission from the copyright holder, but typically for extraction of information from copyrighted materials, rather than verbatim reproduction. This work explores the issue of copyright violations and large language models through the lens of verbatim memorization, focusing on possible redistribution of copyrighted text. We present experiments with a range of language models over a collection of popular books and coding problems, providing a conservative characterization of the extent to which language models can redistribute these materials. Overall, this research highlights the need for further examination and the potential impact on future developments in natural language processing to ensure adherence to copyright regulations.","llm_keywords":["language models","memorization","copyright violations","verbatim reproduction","natural language processing"],"classifications":[],"num_cited_by":101,"num_cited_by_title_only":101,"num_pages":10},{"id":"a16146f1bce7fc8bed3303b8b934465503c65079b4d4b7b5b49ef692013949e5bae07a9e5d65e0a9ded46906535555bf023463e55dd68880c2d36ee30477339b","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.909.pdf","title":"","llm_title":"What to Read in a Contract? Party-Specific Summarization of Legal Obligations, Entitlements, and Prohibitions","authors":["Abhilasha Sancheti","Aparna Garimella","Balaji Vasan Srinivasan","Rachel Rudinger"],"llm_authors":"Abhilasha Sancheti, Aparna Garimella, Balaji Vasan Srinivasan, Rachel Rudinger","author_string":"","year":2023,"abstract":"","llm_abstract":"Reviewing and comprehending key obligations, entitlements, and prohibitions in legal contracts can be a tedious task due to their length and domain-specificity. Furthermore, the key rights and duties requiring review vary for each contracting party. In this work, we propose a new task of party-specific extractive summarization for legal contracts to facilitate faster reviewing and improved comprehension of rights and duties. To facilitate this, we curate a dataset comprising of party-specific pairwise importance comparisons annotated by legal experts, covering ∼293K sentence pairs that include obligations, entitlements, and prohibitions extracted from lease agreements. Using this dataset, we train a pairwise importance ranker and propose a pipeline-based extractive summarization system that generates a party-specific contract summary. We establish the need for incorporating domain-specific notion of importance during summarization by comparing our system against various baselines using both automatic and human evaluation methods.","llm_keywords":["legal contracts","party-specific summarization","obligations","entitlements","prohibitions","extractive summarization","lease agreements","importance ranking","natural language processing"],"classifications":["Machine Summarization","Information Extraction","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":18},{"id":"379e7f7bad0484fba1eac74b2c221db7bf5248b2513f8f536331bd83ce1ca77349714fd2bbd7c442fc7f1267d057988bf218d173fde6ac0ea4ac622d6cf347c3","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.864.pdf","title":"","llm_title":"Syllogistic Reasoning for Legal Judgment Analysis","authors":["Wentao Deng","Jiahuan Pei","Keyi Kong","Zhe Chen","Furu Wei","Yujun Li","Zhaochun Ren","Zhumin Chen","Pengjie Ren"],"llm_authors":"Wentao Deng, Jiahuan Pei, Keyi Kong, Zhe Chen, Furu Wei, Yujun Li, Zhaochun Ren, Zhumin Chen, Pengjie Ren","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal judgment assistants are developing fast due to impressive progress of large language models (LLMs). However, people can hardly trust the results generated by a model without reliable analysis of legal judgement. For legal practitioners, it is common practice to utilize syllogistic reasoning to select and evaluate the arguments of the parties as part of the legal decision-making process. But the development of syllogistic reasoning for legal judgment analysis is hindered by the lack of resources: (1) there is no large-scale syllogistic reasoning dataset for legal judgment analysis, and (2) there is no set of established benchmarks for legal judgment analysis. In this paper, we construct and manually correct a syllogistic reasoning dataset for legal judgment analysis. The dataset contains 11,239 criminal cases which cover 4 criminal elements, 80 charges and 124 articles. We also select a set of large language models as benchmarks, and conduct a in-depth analysis of the capacity of their legal judgment analysis.","llm_keywords":["Syllogistic Reasoning","Legal Judgment Analysis","Large Language Models","Dataset","Benchmarks"],"classifications":[],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":13},{"id":"97c7bad252b6e7259b9b202d858f8c438df2160f184a915cc24f0a6d1701719cc6684b2d0bbaf319a8d861c0c1fab04a8171368452ab2a9a891f36579569ce24","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.591.pdf","title":"","llm_title":"Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers","authors":["Dmitry Nikolaev","Tanise Ceron","Sebastian Padó"],"llm_authors":"Dmitry Nikolaev, Tanise Ceron, Sebastian Padó","author_string":"","year":2023,"abstract":"","llm_abstract":"Scaling analysis is a technique in computational political science that assigns a political actor (e.g. politician or party) a score on a predefined scale based on a (typically long) body of text (e.g. a parliamentary speech or an election manifesto). For example, political scientists have often used the left–right scale to systematically analyse political landscapes of different countries. NLP methods for automatic scaling analysis can find broad application provided they (i) are able to deal with long texts and (ii) work robustly across domains and languages. In this work, we implement and compare two approaches to automatic scaling analysis of political-party manifestos: label aggregation, a pipeline strategy relying on annotations of individual statements from the manifestos, and long-input-Transformer-based models, which compute scaling values directly from raw text. We carry out the analysis of the Comparative Manifestos Project dataset across 41 countries and 27 languages and find that the task can be efficiently solved by state-of-the-art models, with label aggregation producing the best results.","llm_keywords":["scaling analysis","political science","NLP","label aggregation","long-input Transformers","Comparative Manifestos Project","multilingual analysis","political-party manifestos","RILE score"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":15},{"id":"29f7cdcd4b57b946101b6737627a738f8784a69efc70f9fb969d39700887b5d22baf4b8d2352d22345584ab0999ca8e9e2f5b43acfbd93e00d308c084619cf4e","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.524.pdf","title":"","llm_title":"IDTraffickers: An Authorship Attribution Dataset to link and connect Potential Human-Trafficking Operations on Text Escort Advertisements","authors":["Vageesh Saxena","Benjamin Bashpole","Gijs Van Dijck","Gerasimos Spanakis"],"llm_authors":"Vageesh Saxena, Benjamin Bashpole, Gijs Van Dijck, Gerasimos Spanakis","author_string":"","year":2023,"abstract":"","llm_abstract":"Human trafficking (HT) is a pervasive global issue affecting vulnerable individuals, violating their fundamental human rights. Investigations reveal that many HT cases are associated with online advertisements (ads), particularly in escort markets. Consequently, identifying and connecting HT vendors has become increasingly challenging for Law Enforcement Agencies (LEAs). To address this issue, we introduce IDTraffickers, an extensive dataset consisting of 87,595 text ads and 5,244 vendor labels to enable the verification and identification of potential HT vendors on online escort markets. To establish a benchmark for authorship identification, we train a DeCLUTR-small model, achieving a macro-F1 score of 0.8656 in a closed-set classification environment. Next, we leverage the style representations extracted from the trained classifier to conduct authorship verification, resulting in a mean r-precision score of 0.8852 in an open-set ranking environment. Finally, to encourage further research and ensure responsible data sharing, we plan to release IDTraffickers for the authorship attribution task to researchers under specific conditions, considering the sensitive nature of the data. We believe that the availability of our dataset and benchmarks will empower future researchers to utilize our findings, thereby facilitating the effective linkage of escort ads and the development of more robust approaches for identifying HT indicators.","llm_keywords":["Human trafficking","Authorship Attribution","Online Escort Advertisements","Dataset","Vendor Identification","DeCLUTR-small model","Style Representations","Law Enforcement Agencies","Data Analysis","Linkage of Ads"],"classifications":["Classification","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":21},{"id":"29f5ff74f211bf6b26d7f6a08ec1d09fa458a3a853c3c25510ecb27fdefbeabd066d5be0030d54233e12a4e421e76a10192e25ac738f997d4d5f3a9562f9e67a","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2024.emnlp-main.312.pdf","title":"","llm_title":"Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024","authors":["Ilias Chalkidis"],"llm_authors":"Ilias Chalkidis","author_string":"","year":2024,"abstract":"","llm_abstract":"In light of the recent 2024 European Parliament elections, we are investigating if LLMs can be used as Voting Advice Applications (VAAs). We audit MISTRAL and MIXTRAL models and evaluate their accuracy in predicting the stance of political parties based on the latest “EU and I” voting assistance questionnaire. Furthermore, we explore alternatives to improve models’ performance by augmenting the input context via Retrieval-Augmented Generation (RAG) relying on web search, and Self-Reflection using staged conversations that aim to re-collect relevant content from the model’s internal memory. We find that MIXTRAL is highly accurate with an 82% accuracy on average with a significant performance disparity across different political groups (50-95%). Augmenting the input context with expert-curated information can lead to a significant boost of approx. 9%, which remains an open challenge for automated RAG approaches, even considering curated content.","llm_keywords":["Large Language Models","Voting Advice Applications","European Parliament Elections","MISTRAL and MIXTRAL models","Contextual Augmentation","Retrieval-Augmented Generation","Self-Reflection","Political Stance Prediction"],"classifications":["Classification","Information Retrieval","Information Extraction","Text Generation"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":13},{"id":"ccd9d3e895f9b912c86dc81a334117d9892270514a094ea02d55ca67947a41f3732f417e072ce0da07e9cee6aafe80c294ca600a247dd5bb2be8534538cb0ae5","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2024.emnlp-main.98.pdf","title":"","llm_title":"SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation","authors":["Xiaoze Liu","Ting Sun","Tianyang Xu","Feijie Wu","Cunxiang Wang","Xiaoqian Wang","Jing Gao"],"llm_authors":"Xiaoze Liu, Ting Sun, Tianyang Xu, Feijie Wu, Cunxiang Wang, Xiaoqian Wang, Jing Gao","author_string":"","year":2024,"abstract":"","llm_abstract":"Large Language Models (LLMs) have transformed machine learning but raised significant legal concerns due to their potential to produce text that infringes on copyrights, resulting in several high-profile lawsuits. The legal landscape is struggling to keep pace with these rapid advancements, with ongoing debates about whether generated text might plagiarize copyrighted materials. Current LLMs may infringe on copyrights or overly restrict non-copyrighted texts, leading to these challenges: (i) the need for a comprehensive evaluation benchmark to assess copyright compliance from multiple aspects; (ii) evaluating robustness against safeguard bypassing attacks; and (iii) developing effective defenses targeted against the generation of copyrighted text. To tackle these challenges, we introduce a curated dataset to evaluate methods, test attack strategies, and propose lightweight, a real-time defense mechanism to prevent the generation of copyrighted text, ensuring the safe and lawful use of LLMs. Our experiments demonstrate that current LLMs frequently output copyrighted text, and that jailbreaking attacks can significantly increase the volume of copyrighted output. Our proposed defense mechanism significantly reduce the volume of copyrighted text generated by LLMs by effectively refusing malicious requests.","llm_keywords":["Large Language Models","Copyright Compliance","Text Generation","Legal Concerns","Defense Mechanisms","Evaluation Benchmark","Jailbreaking Attacks","Public Domain","Intellectual Property"],"classifications":["Information Retrieval","Text Generation","Resources"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":31},{"id":"d5d33ab6ae58f9e9623838c5b2b3778fbcdef212b408952ac5318a85833d5ae64496f76369dadee74d0a719223263677b6b59291f116d6be294a0615737d6313","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-industry.18.pdf","title":"","llm_title":"TMID: A Comprehensive Real-world Dataset for Trademark Infringement Detection in E-Commerce","authors":["Tongxin Hu","Zhuang Li","Xin Jin","Lizhen Qu","Xin Zhang"],"llm_authors":"Tongxin Hu, Zhuang Li, Xin Jin, Lizhen Qu, Xin Zhang","author_string":"","year":2023,"abstract":"","llm_abstract":"Annually, e-commerce platforms incur substantial financial losses due to trademark infringements, making it crucial to identify and mitigate potential legal risks tied to merchant information registered to the platforms. However, the absence of high-quality datasets hampers research in this area. To address this gap, our study introduces TMID, a novel dataset to detect trademark infringement in merchant registrations. This is a real-world dataset sourced directly from Alipay, one of the world’s largest e-commerce and digital payment platforms. As infringement detection is a legal reasoning task requiring an understanding of the contexts and legal rules, we offer a thorough collection of legal rules and merchant and trademark-related contextual information with annotations from legal experts. We ensure the data quality by performing an extensive statistical analysis. Furthermore, we conduct an empirical study on this dataset to highlight its value and the key challenges. Through this study, we aim to contribute valuable resources to advance research into legal compliance related to trademark infringement within the e-commerce sphere.","llm_keywords":["trademark infringement","e-commerce","real-world dataset","legal compliance","natural language processing","TMID","Alipay","large language models","merchant registrations"],"classifications":["Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":9},{"id":"e8b20b697bb26e01086c4dd425ce6d9c74e6b7f12d5eeec2a9ba6a4cce818f8ad811f1e758202758da9e64b946cb3dea83eba899a2abfbe2bf871baf6349a67e","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.1019.pdf","title":"","llm_title":"MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding","authors":["Steven H. Wang","Antoine Scardigli","Leonard Tang","Wei Chen","Dimitry Levkin","Anya Chen","Spencer Ball","Thomas Woodside","Oliver Zhang","Dan Hendrycks"],"llm_authors":"Steven H. Wang, Antoine Scardigli, Leonard Tang, Wei Chen, Dimitry Levkin, Anya Chen, Spencer Ball, Thomas Woodside, Oliver Zhang, Dan Hendrycks","author_string":"","year":2023,"abstract":"","llm_abstract":"Reading comprehension of legal text can be a particularly challenging task due to the length and complexity of legal clauses and a shortage of expert-annotated datasets. To address this challenge, we introduce the Merger Agreement Understanding Dataset (MAUD), an expert-annotated reading comprehension dataset based on the American Bar Association’s 2021 Public Target Deal Points Study, with over 39,000 examples and over 47,000 total annotations. Our fine-tuned Transformer baselines show promising results, with models performing well above random on most questions. However, on a large subset of questions, there is still room for significant improvement. As the only expert-annotated merger agreement dataset, MAUD is valuable as a benchmark for both the legal profession and the NLP community.","llm_keywords":["legal NLP","merger agreements","reading comprehension","dataset","transformer models","expert-annotated","American Bar Association"],"classifications":["Resources"],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":14},{"id":"6b96fe558a5435a245905469c7f979873ddb5123a2e0c24b3363f1aa3b56a74826d1a018dfbfedadfdcb4265e79cfc546a8f380d209686bd4439dd6d86768321","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.321.pdf","title":"","llm_title":"MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments","authors":["Debtanu Datta","Shubham Soni","Rajdeep Mukherjee","Saptarshi Ghosh"],"llm_authors":"Debtanu Datta, Shubham Soni, Rajdeep Mukherjee, Saptarshi Ghosh","author_string":"","year":2023,"abstract":"","llm_abstract":"Automatic summarization of legal case judgments is a practically important problem that has attracted substantial research efforts in many countries. In the context of the Indian judiciary, there is an additional complexity – Indian legal case judgments are mostly written in complex English, but a significant portion of India’s population lacks command of the English language. Hence, it is crucial to summarize the legal documents in Indian languages to ensure equitable access to justice. While prior research primarily focuses on summarizing legal case judgments in their source languages, this study presents a pioneering effort toward cross-lingual summarization of English legal documents into Hindi, the most frequently spoken Indian language. We construct the first high-quality legal corpus comprising of 3,122 case judgments from prominent Indian courts in English, along with their summaries in both English and Hindi, drafted by legal practitioners. We benchmark the performance of several diverse summarization approaches on our corpus and demonstrate the need for further research in cross-lingual summarization in the legal domain.","llm_keywords":["multilingual summarization","legal case judgments","Indian languages","cross-lingual summarization","English to Hindi translation","legal domain","dataset"],"classifications":["Machine Summarization","Resources"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":12},{"id":"adcae8490510fb7516f04b53bda04e5dc8dea4a43909e872e9d2045b29f04dfd6f530beda43d7b92a386b6d70d19ca718679625acdf6ddf16f5d0703edee54e6","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.740.pdf","title":"","llm_title":"Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration","authors":["Yiquan Wu","Siying Zhou","Yifei Liu","Weiming Lu","Xiaozhong Liu","Yating Zhang","Changlong Sun","Fei Wu","Kun Kuang"],"llm_authors":"Yiquan Wu, Siying Zhou, Yifei Liu, Weiming Lu, Xiaozhong Liu, Yating Zhang, Changlong Sun, Fei Wu, Kun Kuang","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal Judgment Prediction (LJP) has become an increasingly crucial task in Legal AI, i.e., predicting the judgment of the case in terms of case fact description. Precedents are the previous legal cases with similar facts, which are the basis for the judgment of the subsequent case in national legal systems. Thus, it is worthwhile to explore the utilization of precedents in the LJP. Recent advances in deep learning have enabled a variety of techniques to be used to solve the LJP task. These can be broken down into two categories: large language models (LLMs) and domain-specific models. LLMs are capable of interpreting and generating complex natural language, while domain models are efficient in learning task-specific information. In this paper, we propose the precedent-enhanced LJP framework (PLJP) – a system that leverages the strength of both LLM and domain models in the context of precedents. Specifically, the domain models are designed to provide candidate labels and find the proper precedents efficiently, and the large models will make the final prediction with an in-context precedents comprehension. Experiments on the real-world dataset demonstrate the effectiveness of our PLJP. Moreover, our work shows a promising direction for LLM and domain-model collaboration that can be generalized to other vertical domains.","llm_keywords":["Legal Judgment Prediction","Precedents","Large Language Models","Domain-specific Models","Deep Learning"],"classifications":["Classification","Information Retrieval"],"num_cited_by":34,"num_cited_by_title_only":34,"num_pages":16},{"id":"74be14fb23e09893bf6dd48879d69b63a8ebe12ec5135691f19e6932aec7cbd2252bbdddab50229110188d75a9ca45aea50643b8b89404b49053f25c0f598db8","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2024.emnlp-main.195.pdf","title":"","llm_title":"GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory","authors":["Wei Fan","Haoran Li","Zheye Deng","Weiqi Wang","Yangqiu Song"],"llm_authors":"Wei Fan, Haoran Li, Zheye Deng, Weiqi Wang, Yangqiu Song","author_string":"","year":2024,"abstract":"","llm_abstract":"Privacy issues arise prominently during the inappropriate transmission of information between entities. Existing research primarily studies privacy by exploring various privacy attacks, defenses, and evaluations within narrowly predefined patterns, while neglecting that privacy is not an isolated, context-free concept limited to traditionally sensitive data (e.g., social security numbers), but intertwined with intricate social contexts that complicate the identification and analysis of potential privacy violations. The advent of Large Language Models (LLMs) offers unprecedented opportunities for incorporating the nuanced scenarios outlined in privacy laws to tackle these complex privacy issues. However, the scarcity of open-source relevant case studies restricts the efficiency of LLMs in aligning with specific legal statutes. To address this challenge, we introduce a novel framework, GOLDCOIN, designed to efficiently ground LLMs in privacy laws for judicial assessing privacy violations. Our framework leverages the theory of contextual integrity as a bridge, creating numerous synthetic scenarios grounded in relevant privacy statutes (e.g., HIPAA), to assist LLMs in comprehending the complex contexts for identifying privacy risks in the real world. Extensive experimental results demonstrate that GOLDCOIN markedly enhances LLMs’ capabilities in recognizing privacy risks across real court cases, surpassing the baselines on different judicial tasks.","llm_keywords":["privacy","large language models","contextual integrity","privacy laws","HIPAA","privacy violations"],"classifications":["Information Extraction","Resources"],"num_cited_by":5,"num_cited_by_title_only":7,"num_pages":23},{"id":"ced3083c4c2d083f2798fc737ef63646d6f3cc16bcb9870a0f108de81d6e1db6c1beb663bb02e9a66b56bb97fbc9e3a52f60141d003bc94f11a2694ba4f668bf","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-industry.47.pdf","title":"","llm_title":"Automatic Linking of Judgements to UK Supreme Court Hearings","authors":["Hadeel Saadany","Constantin Orasan","Catherine Breslin","Sophie Walker"],"llm_authors":"Hadeel Saadany, Constantin Orasan, Catherine Breslin, Sophie Walker","author_string":"","year":2023,"abstract":"","llm_abstract":"One the most important archived legal material in the UK is the Supreme Court published judgements and video recordings of court sittings for the decided cases. The impact of Supreme Court published material extends far beyond the parties involved in any given case as it provides landmark rulings on arguable points of law of the greatest public and constitutional importance. However, the recordings of a case are usually very long which makes it both time and effort consuming for legal professionals to study the critical arguments in the legal deliberations. In this research, we summarise the second part of a combined research-industrial project for building an automated tool designed specifically to link segments in the text judgement to semantically relevant timespans in the videos of the hearings. The tool is employed as a User-Interface (UI) platform that provides a better access to justice by bookmarking the timespans in the videos which contributed to the final judgement of the case. We explain how we employ AI generative technology to retrieve the relevant links and show that the customisation of the GPT text embeddings to our dataset achieves the best accuracy for our automatic linking system.","llm_keywords":["UK Supreme Court","legal material","video recordings","AI generative technology","text embeddings","judgement linking","information retrieval","legal research"],"classifications":["Machine Summarization","Information Retrieval","Information Extraction","Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":9},{"id":"1fac981fd4f927a14d718a7919759f7b55731a1ba5287cf9dda40bff39d215facfc9941e8caac6af9d7350273e7345036f5e2e631530bfce23f23c66c67bc6db","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.441.pdf","title":"","llm_title":"CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding","authors":["Yixiao Ma","Yueyue Wu","Weihang Su","Qingyao Ai","Yiqun Liu"],"llm_authors":"Yixiao Ma, Yueyue Wu, Weihang Su, Qingyao Ai, Yiqun Liu","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal case retrieval is a critical process for modern legal information systems. While recent studies have utilized pre-trained language models (PLMs) based on the general domain self-supervised pre-training paradigm to build models for legal case retrieval, there are limitations in using general domain PLMs as backbones. Specifically, these models may not fully capture the underlying legal features in legal case documents. To address this issue, we propose CaseEncoder, a legal document encoder that leverages fine-grained legal knowledge in both the data sampling and pre-training phases. In the data sampling phase, we enhance the quality of the training data by utilizing fine-grained law article information to guide the selection of positive and negative examples. In the pre-training phase, we design legal-specific pre-training tasks that align with the judging criteria of relevant legal cases. Based on these tasks, we introduce an innovative loss function called Biased Circle Loss to enhance the model’s ability to recognize case relevance in fine grains. Experimental results on multiple benchmarks demonstrate that CaseEncoder significantly outperforms both existing general pre-training models and legal-specific pre-training models in zero-shot legal case retrieval. The source code of CaseEncoder can be found at https://github.com/myx666/CaseEncoder.","llm_keywords":["legal case retrieval","pre-trained language models","CaseEncoder","legal document encoding","fine-grained legal knowledge","Biased Circle Loss","zero-shot retrieval","pre-training tasks"],"classifications":["Information Retrieval","Pre-Processing","Resources"],"num_cited_by":21,"num_cited_by_title_only":21,"num_pages":10},{"id":"4d650568ff34713e68615793c540a7ddd7c13ac1f896edeef36f07bdd0579e84d78225b1c850c2dce5ac39098ca2cbceb7c64fff873910d97cc5f2a04b7e63fc","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-industry.7.pdf","title":"","llm_title":"CDD: A Large Scale Dataset for Legal Intelligence Research","authors":["Changzhen Ji","Yating Zhang","Adam Jatowt","Haipang Wu"],"llm_authors":"Changzhen Ji, Yating Zhang, Adam Jatowt, Haipang Wu","author_string":"","year":2023,"abstract":"","llm_abstract":"As an important application of Artificial Intelligence, legal intelligence has recently attracted the attention of many researchers. Previous works investigated diverse issues like predicting crimes, predicting outcomes of judicial debates, or extracting information/knowledge from various kinds of legal documents. Although many advances have been made, the research on supporting prediction of court judgments remains relatively scarce, while the lack of large-scale data resources limits the development of this research. In this paper, we present a novel, large-size Court Debate Dataset (CDD), which includes 30,481 court cases, totaling 1,144,425 utterances. CDD contains real-world conversations involving judges, plaintiffs and defendants in court trials. To construct this dataset we have invited experienced judges to design appropriate labels for data records. We then asked law school students to provide annotations based on the defined labels. The dataset can be applied to several downstream tasks, such as text summarization, dialogue generation, text classification, etc. We introduce the details of the different tasks in the rapidly developing field of legal intelligence, the research of which can be fostered thanks to our dataset, and we provide the corresponding benchmark performance.","llm_keywords":["Legal intelligence","Artificial Intelligence","Court Debate Dataset","Judicial service","Dataset","Legal judgment prediction","Information extraction","Court trials"],"classifications":["Machine Summarization","Text Generation","Classification","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":8},{"id":"1c27e60adfe82628ffc13f2b388df3610003feb0a4e1070d8a151f5f4fa5ad47ead044dfaa08fa6f00ecfcb3d0b56a6af4d87042676d5879365a51af9ece0b8a","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2024.emnlp-main.73.pdf","title":"","llm_title":"Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation","authors":["Chenlong Deng","Kelong Mao","Zhicheng Dou"],"llm_authors":"Chenlong Deng, Kelong Mao, Zhicheng Dou","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal case retrieval for sourcing similar cases is critical in upholding judicial fairness. Different from general web search, legal case retrieval involves processing lengthy, complex, and highly specialized legal documents. Existing methods in this domain often overlook the incorporation of legal expert knowledge, which is crucial for accurately understanding and modeling legal cases, leading to unsatisfactory retrieval performance. This paper introduces KELLER, a legal knowledge-guided case reformulation approach based on large language models (LLMs) for effective and interpretable legal case retrieval. By incorporating professional legal knowledge about crimes and law articles, we enable large language models to accurately reformulate the original legal case into concise sub-facts of crimes, which contain the essential information of the case. Extensive experiments on two legal case retrieval benchmarks demonstrate superior retrieval performance and robustness on complex legal case queries of KELLER over existing methods.","llm_keywords":["legal case retrieval","large language models","knowledge-guided reformulation","judicial fairness","legal expert knowledge","interpretable retrieval","crimes and law articles"],"classifications":["Information Retrieval"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":13},{"id":"0a89eacadc148a108ffe9ffd8fd79319df02647feb1be865f63e82c3fd75ea33a658e4aef4e1f133bd1b93105d081d09a2dabc8190aef133f8857c08207c3721","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.718.pdf","title":"","llm_title":"VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights","authors":["Shanshan Xu","Leon Staufer","Santosh T.Y.S.S","Oana Ichim","Corina Heri","Matthias Grabmair"],"llm_authors":"Shanshan Xu, Leon Staufer, Santosh T.Y.S.S, Oana Ichim, Corina Heri, Matthias Grabmair","author_string":"","year":2023,"abstract":"","llm_abstract":"Recognizing vulnerability is crucial for understanding and implementing targeted support to empower individuals in need. This is especially important at the European Court of Human Rights (ECtHR), where the court adapts convention standards to meet actual individual needs and thus to ensure effective human rights protection. However, the concept of vulnerability remains elusive at the ECtHR and no prior NLP research has dealt with it. To enable future work in this area, we present VECHR, a novel expert-annotated multi-label dataset comprised of vulnerability type classification and explanation rationale. We benchmark the performance of state-of-the-art models on VECHR from both the prediction and explainability perspective. Our results demonstrate the challenging nature of the task with lower prediction performance and limited agreement between models and experts. We analyze the robustness of these models in dealing with out-of-domain (OOD) data and observe limited overall performance. Our dataset poses unique challenges offering a significant room for improvement regarding performance, explainability, and robustness.","llm_keywords":["vulnerability","European Court of Human Rights","machine learning","natural language processing","dataset","classification","explainability","legal technology"],"classifications":["Classification"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":15},{"id":"9542916487d2c7644f6663bdb2ca802d58bfd1dc02fc5592efcd677fadcaea7b991f10b6a35915c6b891de5d19a68756a2ddfaf9423c1edee10334a290a0eab2","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-industry.76.pdf","title":"","llm_title":"DELPHI: Data for Evaluating LLMs’ Performance in Handling Controversial Issues","authors":["David Q. Sun","Artem Abzaliev","Hadas Kotek","Christopher Klein","Zidi Xiu","Jason D. Williams"],"llm_authors":"David Q. Sun, Artem Abzaliev, Hadas Kotek, Christopher Klein, Zidi Xiu, Jason D. Williams","author_string":"","year":2023,"abstract":"","llm_abstract":"Controversy is a reflection of our zeitgeist, and an important aspect to any discourse. The rise of large language models (LLMs) as conversational systems has increased public reliance on these systems for answers to their various questions. Consequently, it is crucial to systematically examine how these models respond to questions that pertaining to ongoing debates. However, few such datasets exist in providing human-annotated labels reflecting the contemporary discussions. To foster research in this area, we propose a novel construction of a controversial questions dataset, expanding upon the publicly released Quora Question Pairs Dataset. This dataset presents challenges concerning knowledge recency, safety, fairness, and bias. We evaluate different LLMs using a subset of this dataset, illuminating how they handle controversial issues and the stances they adopt. This research ultimately contributes to our understanding of LLMs’ interaction with controversial issues, paving the way for improvements in their comprehension and handling of complex societal debates.","llm_keywords":["large language models","controversial issues","dataset","bias","fairness","LLM evaluation","contextual understanding"],"classifications":["Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":8},{"id":"5f221c892b9c9de926f391357354ebb2e8f51f4dc302401f0aafeb283e0373e358a16edcbacfee79652a5f0ec0b856c4fb78dd809ada32bd27744778c86ea3d3","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.528.pdf","title":"","llm_title":"DALE: Generative Data Augmentation for Low-Resource Legal NLP","authors":["Sreyan Ghosh","Chandra Kiran Evuru","Sonal Kumar","S Ramaneswaran","S Sakshi","Utkarsh Tyagi","Dinesh Manocha"],"llm_authors":"Sreyan Ghosh, Chandra Kiran Evuru, Sonal Kumar, S Ramaneswaran, S Sakshi, Utkarsh Tyagi, Dinesh Manocha","author_string":"","year":2023,"abstract":"","llm_abstract":"We present DALE, a novel and effective generative Data Augmentation framework for low-resource LEgal NLP. DALE addresses the challenges existing frameworks pose in generating effective data augmentations of legal documents - legal language, with its specialized vocabulary and complex semantics, morphology, and syntax, does not benefit from data augmentations that merely rephrase the source sentence. To address this, DALE, built on an Encoder-Decoder Language Model, is pre-trained on a novel unsupervised text denoising objective based on selective masking - our masking strategy exploits the domain-specific language characteristics of templatized legal documents to mask collocated spans of text. Denoising these spans help DALE acquire knowledge about legal concepts, principles, and language usage. Consequently, it develops the ability to generate coherent and diverse augmentations with novel contexts. Finally, DALE performs conditional generation to generate synthetic augmentations for low-resource Legal NLP tasks. We demonstrate the effectiveness of DALE on 13 datasets spanning 6 tasks and 4 low-resource settings. DALE outperforms all our baselines, including LLMs, qualitatively and quantitatively, with improvements of 1%-50%.","llm_keywords":["DALE","data augmentation","legal NLP","low-resource","encoder-decoder","text denoising","synthetic augmentations","legal documents","language models"],"classifications":[],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":55},{"id":"e1a603f43f880f72f26294c8d9ed1b81fa71e72885b395bb1b329e8f2b95b7187b6b18153f1c0ceafa9a4c16ed1510bed2f6e9544d247cb8afe0afce06c2e687","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.594.pdf","title":"","llm_title":"From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification","authors":["Shanshan Xu","Santosh T.Y.S.S","Oana Ichim","Isabella Risini","Barbara Plank","Matthias Grabmair"],"llm_authors":"Shanshan Xu, Santosh T.Y.S.S, Oana Ichim, Isabella Risini, Barbara Plank, Matthias Grabmair","author_string":"","year":2023,"abstract":"","llm_abstract":"In legal NLP, Case Outcome Classification (COC) must not only be accurate but also trustworthy and explainable. Existing work in explainable COC has been limited to annotations by a single expert. However, it is well-known that lawyers may disagree in their assessment of case facts. We hence collect a novel dataset RAVE: Rationale Variation in ECHR, which is obtained from two experts in the domain of international human rights law, for whom we observe weak agreement. We study their disagreements and build a two-level task-independent taxonomy, supplemented with COC-specific subcategories. We quantitatively assess different taxonomy categories and find that disagreements mainly stem from underspecification of the legal context, which poses challenges given the typically limited granularity and noise in COC metadata. To our knowledge, this is the first work in the legal NLP that focuses on building a taxonomy over human label variation. We further assess the explainablility of state-of-the-art COC models on RAVE and observe limited agreement between models and experts. Overall, our case study reveals hitherto underappreciated complexities in creating benchmark datasets in legal NLP that revolve around identifying aspects of a case’s facts supposedly relevant to its outcome.","llm_keywords":["Legal NLP","Case Outcome Classification","Rationale Construction","Dataset RAVE","Expert Disagreement","Taxonomy","Annotation","Human Label Variation","Explainability","Machine Learning"],"classifications":["Classification","Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":19},{"id":"c56e72cba801278dc18193da47f01af0d36784b1cbe03fcef91e866bc663edaa3727af64fef880fd6892f98fdb5a48f07eb4254f1b936942f5212fda7459e128","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.539.pdf","title":"","llm_title":"Regulation and NLP (RegNLP): Taming Large Language Models","authors":["Catalina Goanta","Nikolaos Aletras","Ilias Chalkidis","Sofia Ranchordas","Gerasimos Spanakis"],"llm_authors":"Catalina Goanta, Nikolaos Aletras, Ilias Chalkidis, Sofia Ranchordas, Gerasimos Spanakis","author_string":"","year":2023,"abstract":"","llm_abstract":"The scientific innovation in Natural Language Processing (NLP) and more broadly in artificial intelligence (AI) is at its fastest pace to date. As large language models (LLMs) unleash a new era of automation, important debates emerge regarding the benefits and risks of their development, deployment and use. Currently, these debates have been dominated by often polarized narratives mainly led by the AI Safety and AI Ethics movements. This polarization, often amplified by social media, is swaying political agendas on AI regulation and governance and posing issues of regulatory capture. Capture occurs when the regulator advances the interests of the industry it is supposed to regulate, or of special interest groups rather than pursuing the general public interest. Meanwhile in NLP research, attention has been increasingly paid to the discussion of regulating risks and harms. This often happens without systematic methodologies or sufficient rooting in the disciplines that inspire an extended scope of NLP research, jeopardizing the scientific integrity of these endeavors. Regulation studies are a rich source of knowledge on how to systematically deal with risk and uncertainty, as well as with scientific evidence, to evaluate and compare regulatory options. This resource has largely remained untapped so far. In this paper, we argue how NLP research on these topics can benefit from proximity to regulatory studies and adjacent fields. We do so by discussing basic tenets of regulation, and risk and uncertainty, and by highlighting the shortcomings of current NLP discussions dealing with risk assessment. Finally, we advocate for the development of a new multidisciplinary research space on regulation and NLP (RegNLP), focused on connecting scientific knowledge to regulatory processes based on systematic methodologies.","llm_keywords":["Large language models","AI regulation","AI ethics","AI safety","NLP research","Regulatory studies","Risk assessment","Multidisciplinary research"],"classifications":[],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":13},{"id":"a3208d93d6bc0b75c759bd8b626068f9becd06a8896a160c925a4bb33a566ceeba918371e94a19a7fe9f64525205db79aca9045d16209dac4fe035d40626c7bc","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2023.emnlp-main.703.pdf","title":"","llm_title":"Countering Misinformation via Emotional Response Generation","authors":["Daniel Russo","Shane Peter Kaszefski-Yaschuk","Jacopo Staiano","Marco Guerini"],"llm_authors":"Daniel Russo, Shane Peter Kaszefski-Yaschuk, Jacopo Staiano, Marco Guerini","author_string":"","year":2023,"abstract":"","llm_abstract":"The proliferation of misinformation on social media platforms (SMPs) poses a significant danger to public health, social cohesion and ultimately democracy. Previous research has shown how social correction can be an effective way to curb misinformation, by engaging directly in a constructive dialogue with users who spread – often in good faith – misleading messages. Although professional fact-checkers are crucial to debunking viral claims, they usually do not engage in conversations on social media. Thereby, significant effort has been made to automate the use of fact-checker material in social correction; however, no previous work has tried to integrate it with the style and pragmatics that are commonly employed in social media communication. To fill this gap, we present VerMouth, the first large-scale dataset comprising roughly 12 thousand claim-response pairs (linked to debunking articles), accounting for both SMP-style and basic emotions, two factors which have a significant role in misinformation credibility and spreading. To collect this dataset we used a technique based on an author-reviewer pipeline, which efficiently combines LLMs and human annotators to obtain high-quality data. We also provide comprehensive experiments showing how models trained on our proposed dataset have significant improvements in terms of output quality and generalization capabilities.","llm_keywords":["misinformation","social media","fact-checking","large-scale dataset","emotional response","LLMs","debunking","automated fact-checking"],"classifications":[],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":17},{"id":"cfe7fc30fbebe7105f1242a664be95ff30c3d4e79d9b57b9ed108fc5cb43c0620d7bce65451ac779c319b20961d3dabcd2a836f95cff082eeedc4b5d825ec48e","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2024.emnlp-main.402.pdf","title":"","llm_title":"Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs","authors":["Cheng Gao","Chaojun Xiao","Zhenghao Liu","Huimin Chen","Zhiyuan Liu","Maosong Sun"],"llm_authors":"Cheng Gao, Chaojun Xiao, Zhenghao Liu, Huimin Chen, Zhiyuan Liu, Maosong Sun","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal case retrieval (LCR) aims to provide similar cases as references for a given fact description. This task is crucial for promoting consistent judgments in similar cases, effectively enhancing judicial fairness and improving work efficiency for judges. However, existing works face two main challenges for real-world applications: existing works mainly focus on case-to-case retrieval using lengthy queries, which does not match real-world scenarios; and the limited data scale, with current datasets containing only hundreds of queries, is insufficient to satisfy the training requirements of existing data-hungry neural models. To address these issues, we introduce an automated method to construct synthetic query-candidate pairs and build the largest LCR dataset to date, LEAD, which is hundreds of times larger than existing datasets. This data construction method can provide ample training signals for LCR models. Experimental results demonstrate that model training with our constructed data can achieve state-of-the-art results on two widely-used LCR benchmarks. Besides, the construction method can also be applied to civil cases and achieve promising results. The data and codes can be found in https://github.com/thunlp/LEAD.","llm_keywords":["Legal Case Retrieval","Synthetic Data","Neural Models","Automated Dataset Construction","Judicial Fairness","Data Augmentation"],"classifications":["Information Retrieval","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":15},{"id":"34f3c3e86e8777fe09f64d863a3df2f80e954e1e2df33a95146dc1fe3f5a8d405b369be027cb82efd3cb4c68e2f161c043ebb4b2abeaf73d9b499fe3a171706c","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2024.emnlp-main.452.pdf","title":"","llm_title":"LawBench: Benchmarking Legal Knowledge of Large Language Models","authors":["Zhiwei Fei","Xiaoyu Shen","Dawei Zhu","Fengzhe Zhou","Zhuo Han","Alan Huang","Songyang Zhang","Kai Chen","Zhixin Yin","Zongwen Shen","Jidong Ge","Vincent Ng"],"llm_authors":"Zhiwei Fei, Xiaoyu Shen, Dawei Zhu, Fengzhe Zhou, Zhuo Han, Alan Huang, Songyang Zhang, Kai Chen, Zhixin Yin, Zongwen Shen, Jidong Ge, Vincent Ng","author_string":"","year":2024,"abstract":"","llm_abstract":"We present LawBench, the first evaluation benchmark composed of 20 tasks aimed to assess the ability of Large Language Models (LLMs) to perform Chinese legal-related tasks. LawBench is meticulously crafted to enable precise assessment of LLMs’ legal capabilities from three cognitive levels that correspond to the widely accepted Bloom’s cognitive taxonomy. Using LawBench, we present a comprehensive evaluation of 21 popular LLMs and the first comparative analysis of the empirical results in order to reveal their relative strengths and weaknesses. All data, model predictions and evaluation code are accessible from https://github.com/open-compass/LawBench.","llm_keywords":["LawBench","Large Language Models","Chinese Legal Tasks","Benchmark","Bloom's Cognitive Taxonomy","Legal Knowledge Assessment","Evaluation","Empirical Analysis","Open Source"],"classifications":["Resources","Pre-Processing"],"num_cited_by":3,"num_cited_by_title_only":95,"num_pages":30},{"id":"b340d9bef948b1fbf9cd66a9b2842da61f1cd204ca602a5062c409118784ca8b8139e2c51077aa0cf6274a7575a5a3fe885f8adadb62bdd102a91c93c6cb9c59","file_path":"legal-nlp-survey-20250328-002/team 2/8 Proceedings of the Conference on Empirical Methods in Natural Language Processing_/2024.emnlp-main.844.pdf","title":"","llm_title":"COPYBENCH: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation","authors":["Tong Chen","Akari Asai","Niloofar Mireshghallah","Sewon Min","James Grimmelmann","Yejin Choi","Hannaneh Hajishirzi","Luke Zettlemoyer","Pang Wei Koh"],"llm_authors":"Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh","author_string":"","year":2024,"abstract":"","llm_abstract":"Evaluating the degree of reproduction of copyright-protected content by language models (LMs) is of significant interest to the AI and legal communities. Although both literal and non-literal similarities are considered by courts when assessing the degree of reproduction, prior research has focused only on literal similarities. To bridge this gap, we introduce COPYBENCH, a benchmark designed to measure both literal and non-literal copying in LM generations. Using copyrighted fiction books as text sources, we provide automatic evaluation protocols to assess literal and non-literal copying, balanced against the model utility in terms of the ability to recall facts from the copyrighted works and generate fluent completions. We find that, although literal copying is relatively rare, two types of non-literal copying—event copying and character copying—occur even in models as small as 7B parameters. Larger models demonstrate significantly more copying, with literal copying rates increasing from 0.2% to 10.5% and non-literal copying from 2.3% to 5.9% when comparing Llama3-8B and 70B models, respectively. We further evaluate the effectiveness of current strategies for mitigating copying and show that (1) training-time alignment can reduce literal copying but may increase non-literal copying, and (2) current inference-time mitigation methods primarily reduce literal but not non-literal copying.","llm_keywords":["language models","copyright","literal copying","non-literal copying","COPYBENCH","event copying","character copying","model utility","fact recall","AI ethics"],"classifications":["Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":25},{"id":"be7b7bf4cf1f5b03b30f618160263ec5ed92af10f251ded88493583290c9813c5033c0eb9c2962a5ca839891ae8ea2aa8810ba713f414c3e7c2ced59008e488e","file_path":"legal-nlp-survey-20250328-002/team 2/9 North American Chapter of the Association for Computational Linguistics (NAACL)/2024.naacl-long.34.pdf","title":"","llm_title":"PILOT: Legal Case Outcome Prediction with Case Law","authors":["Lang Cao","Zifeng Wang","Cao Xiao","Jimeng Sun"],"llm_authors":"Lang Cao, Zifeng Wang, Cao Xiao, Jimeng Sun","author_string":"","year":2024,"abstract":"","llm_abstract":"Machine learning shows promise in predicting the outcome of legal cases, but most research has concentrated on civil law cases rather than case law systems. We identified two unique challenges in making legal case outcome predictions with case law. First, it is crucial to identify relevant precedent cases that serve as fundamental evidence for judges during decision-making. Second, it is necessary to consider the evolution of legal principles over time, as early cases may adhere to different legal contexts. In this paper, we proposed a new framework named PILOT (PredictIng Legal case OuTcome) for case outcome prediction. It comprises two modules for relevant case retrieval and temporal pattern handling, respectively. To benchmark the performance of existing legal case outcome prediction models, we curated a dataset from a large-scale case law database. We demonstrate the importance of accurately identifying precedent cases and mitigating the temporal shift when making predictions for case law, as our method shows a significant improvement over the prior methods that focus on civil law case outcome predictions.","llm_keywords":["legal case outcome prediction","case law","precedent cases","temporal pattern","machine learning","PILOT framework","ECHR2023 dataset"],"classifications":["Information Retrieval","Classification","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":13},{"id":"0b25ad9c3c80d5fb38f05423e81790ec86c078d500cab6641281a558826ebcef1d96a53a9738db4aa5c771cb0c9dfec6df61601b5275573fe59395fbdf46fc22","file_path":"legal-nlp-survey-20250328-002/team 2/9 North American Chapter of the Association for Computational Linguistics (NAACL)/2024.naacl-long.448.pdf","title":"","llm_title":"Discovering Lobby-Parliamentarian Alignments through NLP","authors":["Aswin Suresh","Lazar Radojevic","Francesco Salvi","Antoine Magron","Victor Kristof","Matthias Grossglauser"],"llm_authors":"Aswin Suresh, Lazar Radojevic*, Francesco Salvi*, Antoine Magron, Victor Kristof, Matthias Grossglauser","author_string":"","year":2024,"abstract":"","llm_abstract":"We discover alignments of views between interest groups (lobbies) and members of the European Parliament (MEPs) by automatically analyzing their texts. Specifically, we do so by collecting novel datasets of lobbies’ position papers and MEPs’ speeches, and comparing these texts on the basis of semantic similarity and entailment. In the absence of ground-truth, we perform an indirect validation by comparing the discovered alignments with a dataset, which we curate, of retweet links between MEPs and lobbies, and with the publicly disclosed meetings of MEPs. Our best method performs significantly better than several baselines. Moreover, an aggregate analysis of the discovered alignments, between groups of related lobbies and political groups of MEPs, correspond to the expectations from the ideology of the groups (e.g., groups on the political left are more aligned with humanitarian and environmental organisations). We believe that this work is a step towards enhancing the transparency of the intricate decision-making processes within democratic institutions.","llm_keywords":["lobbying","European Parliament","semantic similarity","policy alignment","NLP","text analysis","political transparency","retweet network","validation","interest groups"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":14},{"id":"035dab333fbd282f7ef903657b9f7995ed058e557f28a62c5489844dc9f67708eeb15f738e56cc4fe24afc4b868b22182ae85059730335e3f1fe1436a1fd4fe0","file_path":"legal-nlp-survey-20250328-002/team 2/9 North American Chapter of the Association for Computational Linguistics (NAACL)/2024.naacl-short.40.pdf","title":"","llm_title":"Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs","authors":["Ilias Chalkidis","Stephanie Brandl"],"llm_authors":"Ilias Chalkidis and Stephanie Brandl","author_string":"","year":2024,"abstract":"","llm_abstract":"Instruction-finetuned Large Language Models inherit clear political leanings that have been shown to influence downstream task performance. We expand this line of research beyond the two-party system in the US and audit Llama Chat in the context of EU politics in various settings to analyze the model’s political knowledge and its ability to reason in context. We adapt, i.e., further fine-tune, Llama Chat on speeches of individual euro-parties from debates in the European Parliament to reevaluate its political leaning based on the EUANDI questionnaire. Llama Chat shows considerable knowledge of national parties’ positions and is capable of reasoning in context. The adapted, party-specific, models are substantially re-aligned towards respective positions which we see as a starting point for using chat-based LLMs as data-driven conversational engines to assist research in political science.","llm_keywords":["Large Language Models","European Union","political leanings","political biases","EU politics","Llama Chat","political science","euro-parties","fine-tuning","conversational engines"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":18},{"id":"e985f87ef5694692c2dc144c3f259e3cb1d33ea9391db57307136f38714f995d1b65f062e57410464d1446c2d716fd985574f7510db62f941ab431ff524ec4b0","file_path":"legal-nlp-survey-20250328-002/team 2/9 North American Chapter of the Association for Computational Linguistics (NAACL)/2024.naacl-long.231.pdf","title":"","llm_title":"Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case Summarization","authors":["Santosh T.Y.S.S","Vatsal Venkatkrishna","Saptarshi Ghosh","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Vatsal Venkatkrishna, Saptarshi Ghosh, Matthias Grabmair","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal professionals face the challenge of managing an overwhelming volume of lengthy judgments, making automated legal case summarization crucial. However, prior approaches mainly focused on training and evaluating these models within the same jurisdiction. In this study, we explore the cross-jurisdictional generalizability of legal case summarization models. Specifically, we explore how to effectively summarize legal cases of a target jurisdiction where reference summaries are not available. In particular, we investigate whether supplementing models with unlabeled target jurisdiction corpus and extractive silver summaries obtained from unsupervised algorithms on target data enhances transfer performance. Our comprehensive study on three datasets from different jurisdictions highlights the role of pre-training in improving transfer performance. We shed light on the pivotal influence of jurisdictional similarity in selecting optimal source datasets for effective transfer. Furthermore, our findings underscore that incorporating unlabeled target data yields improvements in general pre-trained models, with additional gains when silver summaries are introduced. This augmentation is especially valuable when dealing with extractive datasets and scenarios featuring limited alignment between source and target jurisdictions. Our study provides key insights for developing adaptable legal case summarization systems, transcending jurisdictional boundaries.","llm_keywords":["legal case summarization","cross-jurisdictional generalizability","unsupervised algorithms","extractive summarization","abstractive summarization","pre-training","jurisdictional similarity","transfer learning","summarization models","legal technology"],"classifications":["Machine Summarization","Pre-Processing","Classification","Information Retrieval","Information Extraction","Text Generation","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":15},{"id":"7f9a4daa52b147313c83763308b3c551e59999f45adcf317fff915e69316dea8d03d5fd0e7c04ad26703db29ca2d2e479159966355f0a9f9a38e487f66b063c4","file_path":"legal-nlp-survey-20250328-002/team 2/9 North American Chapter of the Association for Computational Linguistics (NAACL)/2024.naacl-long.456.pdf","title":"","llm_title":"HumanRankEval: Automatic Evaluation of LMs as Conversational Assistants","authors":["Milan Gritta","Gerasimos Lampouras","Ignacio Iacobacci"],"llm_authors":"Milan Gritta, Gerasimos Lampouras, Ignacio Iacobacci","author_string":"","year":2024,"abstract":"","llm_abstract":"Language models (LMs) as conversational assistants recently became popular tools that help people accomplish a variety of tasks. These typically result from adapting LMs pretrained on general domain text sequences through further instruction-tuning and possibly preference optimisation methods. The evaluation of such LMs would ideally be performed using human judgement, however, this is not scalable. On the other hand, automatic evaluation featuring auxiliary LMs as judges and/or knowledge-based tasks is scalable but struggles with assessing conversational ability and adherence to instructions. To help accelerate the development of LMs as conversational assistants, we propose a novel automatic evaluation task: HumanRankEval (HRE). It consists of a large-scale, diverse and high-quality set of questions, each with several answers authored and scored by humans. To perform evaluation, HRE ranks these answers based on their log-likelihood under the LM’s distribution, and subsequently calculates their correlation with the corresponding human rankings. We support HRE’s efficacy by investigating how efficiently it separates pretrained and instruction-tuned LMs of various sizes. We show that HRE correlates well with human judgements and is particularly responsive to model changes following instruction-tuning.","llm_keywords":["Language Models","Conversational Assistants","Automatic Evaluation","Human Preferences","Instruction-tuning"],"classifications":["Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":13},{"id":"d44092c4ccc102edad599f95c8536d5c0e1f9e728dea5b8511eb7fd490f2857634354e5fe58916c5131a198a0697a4faed19e9aaaeb07bd120c2fef2db3f31ad","file_path":"legal-nlp-survey-20250328-002/team 2/9 North American Chapter of the Association for Computational Linguistics (NAACL)/2024.naacl-long.472.pdf","title":"","llm_title":"LegalDiscourse: Interpreting When Laws Apply and Who They Affect","authors":["Alexander Spangher","Te-Lin Wu","Zihan Xue","Mark Hansen","Jonathan May"],"llm_authors":"Alexander Spangher, Te-Lin Wu, Zihan Xue, Mark Hansen, Jonathan May","author_string":"","year":2024,"abstract":"","llm_abstract":"While legal AI has made strides in recent years, it still struggles with basic legal concepts: when does a law apply? Who does it apply to? What does it do? We take a discourse approach to addressing these problems and introduce a novel taxonomy for span-and-relation parsing of legal texts. We create a dataset, LegalDiscourse of 602 state-level law paragraphs consisting of 3,715 discourse spans and 1,671 relations. Our trained annotators have an agreement rate κ > .8, yet few-shot GPT3.5 performs poorly at span identification and relation classification. Although fine-tuning improves performance, GPT3.5 still lags far below human level. We demonstrate the usefulness of our schema by creating a web application with journalists. We collect over 100,000 laws for 52 U.S. states and territories using 20 scrapers we built, and apply our trained models to 6,000 laws using U.S. Census population numbers. We describe two journalistic outputs stemming from this application: (1) an investigation into the increase in liquor licenses following population growth and (2) a decrease in applicable laws under different under-count projections.","llm_keywords":["legal AI","discourse analysis","legal texts","GPT3.5","span-and-relation parsing","legal discourse schema","state-level laws","journalism","legal concepts","machine learning"],"classifications":["Classification","Resources","Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":24},{"id":"c6dcffbf4e314c9cc4efa242813b06e90890033babb1e42de5b23e1df5464545014ee141ccc2df1f3d4a88ce46da957f481e267078254cabc881d2a6e01ef881","file_path":"legal-nlp-survey-20250328-002/team 2/9 North American Chapter of the Association for Computational Linguistics (NAACL)/2024.naacl-long.404.pdf","title":"","llm_title":"Towards Explainability in Legal Outcome Prediction Models","authors":["Josef Valvoda","Ryan Cotterell"],"llm_authors":"Josef Valvoda, Ryan Cotterell","author_string":"","year":2024,"abstract":"","llm_abstract":"Current legal outcome prediction models—a staple of legal NLP—do not explain their reasoning. However, to employ these models in the real world, human legal actors need to be able to understand the model’s decisions. In the case of common law, legal practitioners reason towards the outcome of a case by referring to past case law, known as precedent. We contend that precedent is, therefore, a natural way of facilitating explainability for legal NLP models. In this paper, we contribute a novel method for identifying the precedent employed by legal outcome prediction models. Furthermore, by developing a taxonomy of legal precedent, we are able to compare human judges and neural models with respect to the different types of precedent they rely on. We find that while the models learn to predict outcomes reasonably well, their use of precedent is unlike that of human judges.","llm_keywords":["legal outcome prediction","explainability","NLP models","legal precedent","neural networks","legal reasoning","Anglo-American law","machine learning","case law"],"classifications":["Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":21},{"id":"279de12eea26689e444563231b571ded2c152de60e8fc7b37e00fd2f4638fa21e3ef74ed27d306b378c42763cdb658d774e01d85d0fe663525e690595c9a086c","file_path":"legal-nlp-survey-20250328-002/team 2/9 North American Chapter of the Association for Computational Linguistics (NAACL)/2024.naacl-industry.14.pdf","title":"","llm_title":"Leveraging Natural Language Processing and Large Language Models for Assisting Due Diligence in the Legal Domain","authors":["Myeongjun Erik Jang","Gábor Stikkel"],"llm_authors":"Myeongjun Erik Jang, Gábor Stikkel","author_string":"","year":2024,"abstract":"","llm_abstract":"Due diligence is a crucial legal process that mitigates potential risks of mergers and acquisitions (M&A). However, despite its prominent importance, there has been a lack of research regarding leveraging NLP techniques for due diligence. In this study, our aim is to explore the most efficient deep-learning model architecture for due diligence in terms of performance and latency, and evaluate the potential of large language models (LLMs) as an efficient due diligence assistant. To our knowledge, this is the first study that employs pre-trained language models (PLMs) and LLMs for the due diligence problem. Our experimental results suggest that methodologies that have demonstrated promising performance in the general domain encounter challenges when applied in due diligence due to the inherent lengthy nature of legal documents. We also ascertain that LLMs can be a useful tool for helping lawyers who perform due diligence.","llm_keywords":["NLP","due diligence","large language models","legal domain","pre-trained language models"],"classifications":["Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"3c2e884397862dff4fd45e0a2e939ad04ca90f3382cd63f3f7fb8e5666722f077ff3db12a1cda6921f6eb5c2d1fb3f3aac1c3f30fea716e4c0b3dee074326619","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.716.pdf","title":"LAiW: A Chinese Legal Large Language Models Benchmark","llm_title":"LAiW: A Chinese Legal Large Language Models Benchmark","authors":["Yongfu Dai","Duanyu Feng","Jimin Huang","Haochen Jia","Qianqian Xie","Yifang Zhang","Weiguang Han","Wei Tian","Hao Wang"],"llm_authors":"Yongfu Dai, Duanyu Feng, Jimin Huang, Haochen Jia, Qianqian Xie, Yifang Zhang, Weiguang Han, Wei Tian, Hao Wang","author_string":"Yongfu Dai ; Duanyu Feng ; Jimin Huang ; Haochen Jia ; Qianqian Xie ; Yifang Zhang ; Weiguang Han ; Wei Tian ; Hao Wang","year":2024,"abstract":"","llm_abstract":"General and legal domain LLMs have demonstrated strong performance in various tasks of LegalAI. However, their current evaluations lack alignment with the fundamental logic of legal reasoning, the legal syllogism. This hinders trust and understanding from legal experts. To bridge this gap, we introduce LAiW 1, the Chinese legal LLM benchmark structured around the legal syllogism. We evaluate legal LLMs across three levels of capability, each reflecting a progressively more complex stage of legal syllogism: fundamental information retrieval, legal principles inference, and advanced legal applications, and encompassing a wide range of tasks in different legal scenarios. Our automatic evaluation reveals that LLMs, despite their ability to answer complex legal questions, lack the inherent logical processes of the legal syllogism. This limitation poses a barrier to acceptance by legal professionals. Furthermore, manual evaluation with legal experts confirms this issue and highlights the importance of pretraining on legal text to enhance the legal syllogism of LLMs. Future research may prioritize addressing this gap to unlock the full potential of LLMs in legal applications.","llm_keywords":["LegalAI","large language models","legal syllogism","Chinese law","legal reasoning","benchmark","information retrieval","legal principles inference","advanced legal applications"],"classifications":[],"num_cited_by":69,"num_cited_by_title_only":34,"num_pages":29},{"id":"5f0915f204a0b50f0c7475336fc68c418be65569e29b0464ca696cf0b3b970281c424a500d1990ce2c4097315e8c52670110f4c67418b61079192692df9c14eb","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.178.pdf","title":"A Compliance Checking Framework Based on Retrieval Augmented Generation","llm_title":"A Compliance Checking Framework Based on Retrieval Augmented Generation","authors":["Jingyun Sun","Zhongze Luo","Yang Li"],"llm_authors":"Jingyun Sun, Zhongze Luo, Yang Li","author_string":"Jingyun Sun ; Zhongze Luo ; Yang Li","year":2024,"abstract":"","llm_abstract":"The text-based compliance checking aims to verify whether a company’s business processes comply with laws, regulations, and industry standards using NLP techniques. Existing methods can be divided into two categories: Logic-based methods offer the advantage of precise and reliable reasoning processes but lack flexibility. Semantic embedding methods are more generalizable; however, they may lose structured information and lack logical coherence. To combine the strengths of both approaches, we propose a compliance checking framework based on Retrieval-Augmented Generation (RAG). This framework includes a static layer for storing factual knowledge, a dynamic layer for storing regulatory and business process information, and a computational layer for retrieval and reasoning. We employ an eventic graph to structurally describe regulatory information as we recognize that the knowledge in regulatory documents is centered not on entities but on actions and states. We conducted experiments on Chinese and English compliance checking datasets. The results demonstrate that our framework consistently achieves state-of-the-art results across various scenarios, surpassing other baselines.","llm_keywords":["compliance checking","retrieval-augmented generation","NLP","logic-based methods","semantic embedding"],"classifications":["Information Retrieval","Text Generation"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":13},{"id":"ec20ed0d8e6d33b7ae386619cefbcd09b0531570203132b1cfd94fb52804664554885f5dc95e60ccc85f52292122e23c836821413319bc43493b7eb35354f5ef","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.738.pdf","title":"NYAYAANUMANA and INLEGALLLAMA: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis","llm_title":"NYAYAANUMANA and INLEGALLLAMA: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis","authors":["Shubham Kumar Nigam","Deepak Patnaik Balaramamahanthi","Shivam Mishra","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"llm_authors":"Shubham Kumar Nigam, Balaramamahanthi Deepak Patnaik, Shivam Mishra, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya","author_string":"Shubham Kumar Nigam ; Deepak Patnaik Balaramamahanthi ; Shivam Mishra ; Noel Shallum ; Kripabandhu Ghosh ; Arnab Bhattacharya","year":2024,"abstract":"","llm_abstract":"The integration of artificial intelligence (AI) in legal judgment prediction (LJP) has the potential to transform the legal landscape, particularly in jurisdictions like India, where a significant backlog of cases burdens the legal system. This paper introduces NyayaAnumana, the largest and most diverse corpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945 preprocessed cases. NyayaAnumana, which combines the words “Nyaya” and “Anumana” that means “judgment” and “inference” respectively for most major Indian languages, includes a wide range of cases from the Supreme Court, High Courts, Tribunal Courts, District Courts, and Daily Orders and, thus, provides unparalleled diversity and coverage. Our dataset surpasses existing datasets like PredEx and ILDC, offering a comprehensive foundation for advanced AI research in the legal domain. In addition to the dataset, we present INLegalLlama, a domain-specific generative large language model (LLM) tailored to the intricacies of the Indian legal system. It is developed through a two-phase training approach over a base LLaMa model. First, Indian legal documents are injected using continual pretraining. Second, task-specific supervised finetuning is done. This method allows the model to achieve a deeper understanding of legal contexts. Our experiments demonstrate that incorporating diverse court data significantly boosts model accuracy, achieving approximately 90% F1-score in prediction tasks. INLegalLlama not only improves prediction accuracy but also offers comprehensible explanations, addressing the need for explainability in AI-assisted legal decisions.","llm_keywords":["Artificial Intelligence","Legal Judgment Prediction","Indian Legal System","NyayaAnumana","INLegalLlama","Dataset","Language Model","Decision Analysis","Explainability","Machine Learning"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":26},{"id":"e1d7ee745b3180edfd51a4e75d0a1d5ac5874199733402ab563d312791d32cd2171124d5e8eac3e71dd6693be62e0031fae7ddbf4c0af9fdd20490d189712b03","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.629.pdf","title":"InternLM-Law: An Open-Sourced Chinese Legal Large Language Model","llm_title":"InternLM-Law: An Open-Sourced Chinese Legal Large Language Model","authors":["Zhiwei Fei","Songyang Zhang","Xiaoyu Shen","Dawei Zhu","Xiao Wang","Jidong Ge","Vincent Ng"],"llm_authors":"Zhiwei Fei, Songyang Zhang, Xiaoyu Shen, Dawei Zhu, Xiao Wang, Jidong Ge, Vincent Ng","author_string":"Zhiwei Fei ; Songyang Zhang ; Xiaoyu Shen ; Dawei Zhu ; Xiao Wang ; Jidong Ge ; Vincent Ng","year":2024,"abstract":"","llm_abstract":"We introduce InternLM-Law, a large language model (LLM) tailored for addressing diverse legal tasks related to Chinese laws. These tasks range from responding to standard legal questions (e.g., legal exercises in textbooks) to analyzing complex real-world legal situations. Our work contributes to Chinese Legal NLP research by (1) conducting one of the most extensive evaluations of state-of-the-art general-purpose and legal-specific LLMs to date that involves an automatic evaluation on the 20 legal NLP tasks in LawBench (Fei et al., 2024), a human evaluation on a challenging version of the Legal Consultation task, and an automatic evaluation of a model’s ability to handle very long legal texts; (2) presenting a methodology for training a Chinese legal LLM that offers superior performance to all of its counterparts in our extensive evaluation; and (3) facilitating future research in this area by making all of our code and model publicly available at https://github.com/InternLM/InternLM-Law.","llm_keywords":["Chinese Legal NLP","Large Language Model","LegalAI","Legal Judgment Prediction","Legal Consultation","LawBench","Model Evaluation","Open Source"],"classifications":["Resources","Text Generation"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":17},{"id":"69b2aeaf5aad0227e4397e483009fc52fdf4a5fe7918cf37b46112716512ba0396df795f445613c13b11475d007d806482987bf9b79e15443d7b45e28d4918a8","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-industry.50.pdf","title":"LAW: Legal Agentic Workflows for Custody and Fund Services Contracts","llm_title":"LAW: Legal Agentic Workflows for Custody and Fund Services Contracts","authors":["William Watson","Nicole Cho","Nishan Srishankar","Zhen Zeng","Lucas Cecchi","Daniel Scott","Suchetha Siddagangappa","Rachneet Kaur","Tucker Balch","Manuela Veloso"],"llm_authors":"William Watson, Nicole Cho, Nishan Srishankar, Zhen Zeng, Lucas Cecchi, Daniel Scott, Suchetha Siddagangappa, Rachneet Kaur, Tucker Balch, Manuela Veloso","author_string":"William Watson ; Nicole Cho ; Nishan Srishankar ; Zhen Zeng ; Lucas Cecchi ; Daniel Scott ; Suchetha Siddagangappa ; Rachneet Kaur ; Tucker Balch ; Manuela Veloso","year":2024,"abstract":"","llm_abstract":"Legal contracts in the custody and fund services domain govern critical aspects such as key provider responsibilities, fee schedules, and indemnification rights. However, it is challenging for an off-the-shelf Large Language Model (LLM) to ingest these contracts due to the lengthy unstructured streams of text, limited LLM context windows, and complex legal jargon. To address these challenges, we introduce LAW (Legal Agentic Workflows for Custody and Fund Services Contracts). LAW features a modular design that responds to user queries by orchestrating a suite of domain-specific tools and text agents. Our experiments demonstrate that LAW, by integrating multiple specialized agents and tools, significantly outperforms the baseline. LAW excels particularly in complex tasks such as calculating a contract’s termination date, surpassing the baseline by 92.9% points. Furthermore, LAW offers a cost-effective alternative to traditional fine-tuned legal LLMs by leveraging reusable, domain-specific tools.","llm_keywords":["legal contracts","custody and fund services","Large Language Models","text agents","domain-specific tools","contract termination","legal domain-specific LLM"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":12},{"id":"da522c592167f8bd50a02fbf63c10acbde4962fc2c9d46f158dcbde83b3e339fdace42cb4e0c64c6387b279305defb10c9421cd4507fb4468231d997c4de4524","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.290.pdf","title":"Know When to Fuse: Investigating Non-English Hybrid Retrieval in the Legal Domain","llm_title":"Know When to Fuse: Investigating Non-English Hybrid Retrieval in the Legal Domain","authors":["Antoine Louis","Gijs van Dijck","Gerasimos Spanakis"],"llm_authors":"Antoine Louis, Gijs van Dijck, Gerasimos Spanakis","author_string":"Antoine Louis ; Gijs van Dijck ; Gerasimos Spanakis","year":2024,"abstract":"","llm_abstract":"Hybrid search has emerged as an effective strategy to offset the limitations of different matching paradigms, especially in out-of-domain contexts where notable improvements in retrieval quality have been observed. However, existing research predominantly focuses on a limited set of retrieval methods, evaluated in pairs on domain-general datasets exclusively in English. In this work, we study the efficacy of hybrid search across a variety of prominent retrieval models within the unexplored field of law in the French language, assessing both zero-shot and in-domain scenarios. Our findings reveal that in a zero-shot context, fusing different domain-general models consistently enhances performance compared to using a standalone model, regardless of the fusion method. Surprisingly, when models are trained in-domain, we find that fusion generally diminishes performance relative to using the best single system, unless fusing scores with carefully tuned weights. These novel insights, among others, expand the applicability of prior findings across a new field and language, and contribute to a deeper understanding of hybrid search in non-English specialized domains.","llm_keywords":["hybrid search","information retrieval","legal domain","non-English retrieval","French language","zero-shot learning","in-domain learning","retrieval models","semantic matching","lexical matching"],"classifications":["Information Retrieval"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":20},{"id":"54d501b48ff82d8f3886c3336e70280c712d3c383edfad0390527c064e91980efc17eb7520bfa8bd6bb74c25354c2394babeedf1e2f4b851346bff108b550a75","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.50.pdf","title":"SLARD: A Chinese Superior Legal Article Retrieval Dataset","llm_title":"SLARD: A Chinese Superior Legal Article Retrieval Dataset","authors":["Zhe Chen","Pengjie Ren","Fuhui Sun","Xiaoyan Wang","Yunjun Li","Siwen Zhao","Tengyi Yang"],"llm_authors":"Zhe Chen, Pengjie Ren, Fuhui Sun, Xiaoyan Wang, Yunjun Li, Siwen Zhao, Tengyi Yang","author_string":"Zhe Chen ; Pengjie Ren ; Fuhui Sun ; Xiaoyan Wang ; Yujun Li ; Siwen Zhao ; Tengyi Yang","year":2025,"abstract":"","llm_abstract":"Retrieving superior legal articles involves identifying relevant legal articles that hold higher legal effectiveness. This process is crucial in legislative work because superior legal articles form the legal basis for drafting new laws. However, most existing legal information retrieval research focuses on retrieving legal documents, with limited research on retrieving superior legal articles. This gap restricts the digitization of legislative work. To advance research in this area, we propose SLARD: A Chinese Superior Legal Article Retrieval Dataset, which filters 2,627 queries and 9,184 candidates from over 4.3 million effective Chinese regulations, covering 32 categories, such as environment, agriculture, and water resources. Each query is manually annotated, and the candidates include superior articles at both the provincial and national levels. We conducted detailed experiments and analyses on the dataset and found that existing retrieval methods struggle to achieve ideal results. The best method achieved a R@1 of only 0.4719. Additionally, we found that existing large language models (LLMs) lack prior knowledge of the content of superior legal articles. This indicates the necessity for further exploration and research in this field.","llm_keywords":["legal article retrieval","dataset","Chinese regulations","superior legal articles","information retrieval","natural language processing","legislative work"],"classifications":["Information Retrieval"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":15},{"id":"becbc782f2d7ce16daad77dcd6ceec19ede9e3a02e137604e7e3f614173dcd38043e10a7979f8082052a4058b6d2707ecf90223aed057992c526d289865814bf","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.493.pdf","title":"Courtroom-LLM: A Legal-Inspired Multi-LLM Framework for Resolving Ambiguous Text Classifications","llm_title":"Courtroom-LLM: A Legal-Inspired Multi-LLM Framework for Resolving Ambiguous Text Classifications","authors":["Sangkeun Jung","Jeesu Jung"],"llm_authors":"Sangkeun Jung, Jeesu Jung","author_string":"Sangkeun Jung ; Jeesu Jung","year":2025,"abstract":"","llm_abstract":"In this research, we introduce the Courtroom-LLM framework, a novel multi-LLM structure inspired by legal courtroom processes, aiming to enhance decision-making in ambiguous text classification scenarios. Our approach simulates a courtroom setting within LLMs, assigning roles similar to those of prosecutors, defense attorneys, and judges, to facilitate comprehensive analysis of complex textual cases. We demonstrate that this structured multi-LLM setup can significantly improve decision-making accuracy, particularly in ambiguous situations, by harnessing the synergistic effects of diverse LLM arguments. Our evaluations across various text classification tasks show that the Courtroom-LLM framework outperforms both traditional single-LLM classifiers and simpler multi-LLM setups. These results highlight the advantages of our legal-inspired model in improving decision-making for text classification.","llm_keywords":["Courtroom-LLM","text classification","multi-LLM framework","ambiguous text","decision-making","natural language processing","large language models","legal-inspired approach"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":19},{"id":"ca79ba5d6e093e898acdbe1e7dffb33247d3c2b44af4775089cb2ca4649519f370f6ff83dfc2b3d075c80babe6e4e9337ce8167f53faf8f162245b6ab2fb2768","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.334.pdf","title":"Enhancing Criminal Investigation Analysis with Summarization and Memory-based Retrieval-Augmented Generation: A Comprehensive Evaluation of Real Case Data","llm_title":"Enhancing Criminal Investigation Analysis with Summarization and Memory-based Retrieval-Augmented Generation: A Comprehensive Evaluation of Real Case Data","authors":["Mads Skipanes","Tollef Emil Jørgensen","Kyle Porter","Gianluca Demartini","Sule Yildirim Yayilgan"],"llm_authors":"Mads Skipanes, Tollef Emil Jørgensen, Kyle Porter, Gianluca Demartini, Sule Yildirim Yayilgan","author_string":"Mads Skipanes ; rgensen, Tollef Emil JÃ ; Kyle Porter ; Gianluca Demartini ; Sule Yildirim Yayilgan","year":2024,"abstract":"","llm_abstract":"This study introduces KriRAG, a novel Retrieval-Augmented Generation (RAG) architecture designed to assist criminal investigators in analyzing information and overcoming the challenge of information overload. KriRAG structures and summarizes extensive document collections based on existing investigative queries, providing relevant document references and detailed answers for each query. Working with unstructured data from two homicide case files comprising approximately 3,700 documents and 13,000 pages, a comprehensive evaluation methodology is established, incorporating semantic retrieval, scoring, reasoning, and query response accuracy. The system’s outputs are evaluated against queries and answers provided by criminal investigators, demonstrating promising performance with 97.5% accuracy in relevance assessment and 77.5% accuracy for query responses. These findings provide a rigorous foundation for other query-oriented and open-ended retrieval applications. KriRAG is designed to run offline on limited hardware, ensuring sensitive data handling and on-device availability.","llm_keywords":["Retrieval-Augmented Generation","criminal investigation","summarization","information overload","thematization","large language models","semantic retrieval"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":18},{"id":"8e9d79f29fdec408201398da5f634df2ead17747c1e7f1abedbcee24db22245f2b9d8cd8191c7ab0110b0e830ae9fe354cacae73a8e28cd713acac7cd08a1614","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.298.pdf","title":"Fine-tuning Large Language Models for Improving Factuality in Legal Question Answering","llm_title":"Fine-tuning Large Language Models for Improving Factuality in Legal Question Answering","authors":["Yinghao Hu","Leilei Gan","Wenyi Xiao","Kun Kuang","Fei Wu"],"llm_authors":"Yinghao Hu, Leilei Gan, Wenyi Xiao, Kun Kuang, Fei Wu","author_string":"Yinghao Hu ; Leilei Gan ; Wenyi Xiao ; Kun Kuang ; Fei Wu","year":2024,"abstract":"","llm_abstract":"Hallucination, or the generation of incorrect or fabricated information, remains a critical challenge in large language models (LLMs), particularly in high-stake domains such as legal question answering (QA). In order to mitigate the hallucination rate in legal QA, we first introduce a benchmark called LegalHalBench and three automatic metrics to evaluate the common hallucinations when LLMs answer legal questions. We then propose a hallucination mitigation method that integrates behavior cloning and a novel Hard Sample-aware Iterative Direct Preference Optimization (HIPO). We conduct extensive real-data experiments to validate the effectiveness of our approach. Our results demonstrate remarkable improvements in various metrics, including the newly proposed Non-Hallucinated Statute Rate, Statute Relevance Rate, Legal Claim Truthfulness, as well as traditional metrics such as METEOR, BERTScore, ROUGE-L, and win rates. Our benchmark and model are available at https://github.com/YinghaoHu/LegalHalBench.","llm_keywords":["large language models","hallucination","legal question answering","factuality","LegalHalBench","behavior cloning","preference optimization","legal domain","hallucination mitigation","natural language processing"],"classifications":["Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":18},{"id":"198c2e705d1e2523aa66f404bfbae6c50b22b115aca1768ff3ac26dd09006015f805678fbd86dd7bd6fadf7fe1ec10207aaa2165d925b475f5bc910f90f38747","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.398.pdf","title":"CHIFRAUD: A Long-term Web Text Dataset for Chinese Fraud Detection","llm_title":"CHIFRAUD: A Long-term Web Text Benchmark for Chinese Fraud Detection","authors":["Min Tang","Lixin Zou","Zhe Jin","Shujie Cui","Shiuan Ni Liang","Weiqing Wang"],"llm_authors":"Min Tang, Lixin Zou, Shiuan-ni Liang, Zhe Jin, Weiqing Wang, Shujie Cui","author_string":"Min Tang ; Lixin Zou ; Zhe Jin ; ShuJie Cui ; Shiuan Ni Liang ; Weiqing Wang","year":2024,"abstract":"","llm_abstract":"Detecting fraudulent online text is essential, as these manipulative messages exploit human greed, deceive individuals, and endanger societal security. Currently, this task remains under-explored on the Chinese web due to the lack of a comprehensive dataset of Chinese fraudulent texts. However, creating such a dataset is challenging because it requires exclusive annotation within a vast collection of normal texts. Additionally, the creators of fraudulent webpages continuously update their tactics to evade detection by downstream platforms and promote fraudulent messages. To this end, this work firstly presents the comprehensive long-term dataset of Chinese fraudulent texts collected over 12 months, consisting of 59,106 entries extracted from billions of web pages. Furthermore, we design and provide a wide range of baselines, including large language model-based detectors, and pretrained language model approaches. The necessary dataset and benchmark codes for further research are available via https://github.com/xuemingxxx/ChiFraud.","llm_keywords":["Chinese fraud detection","dataset","fraudulent texts","web platforms","detection methods"],"classifications":["Pre-Processing","Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":13},{"id":"beab1978b0193a3a5931e8b415c7aefb478d0afe5336c4656b7e00dcbf54f2e3818705272272e14c894f2e57a0e3d8d4e1df8d29865c786a32b75131a59c959d","file_path":"legal-nlp-survey-20250328-002/team 2/14 International Conference on Computational Linguistics (COLING)/2025.coling-main.216.pdf","title":"TermDiffuSum: A Term-guided Diffusion Model for Extractive Summarization of Legal Documents","llm_title":"TermDiffuSum: A Term-guided Diffusion Model for Extractive Summarization of Legal Documents","authors":["Xiangyun Dong","Wei Li","Yuquan Le","Zhangyue Jiang","Junxi Zhong","Zhong Wang"],"llm_authors":"Xiangyun Dong, Wei Li, Yuquan Le, Zhangyue Jiang, Junxi Zhong, Zhong Wang","author_string":"Xiangyun Dong ; Wei Li ; Yuquan Le ; Zhangyue Jiang ; Junxi Zhong ; Zhong Wang","year":2024,"abstract":"","llm_abstract":"Extractive summarization for legal documents aims to automatically extract key sentences from legal texts to form concise summaries. Recent studies have explored diffusion models for extractive summarization task, showcasing their remarkable capabilities. Despite these advancements, these models often fall short in effectively capturing and leveraging the specialized legal terminology crucial for accurate legal summarization. To address the limitation, this paper presents a novel term-guided diffusion model for extractive summarization of legal documents, named TermDiffuSum. It incorporates legal terminology into the diffusion model via a well-designed multifactor fusion noise weighting schedule, which allocates higher attention weight to sentences containing a higher concentration of legal terms during the diffusion process. Additionally, TermDiffuSum utilizes a re-ranking loss function to refine the model’s selection of more relevant summaries by leveraging the relationship between the candidate summaries generated by the diffusion process and the reference summaries. Experimental results on a self-constructed legal summarization dataset reveal that TermDiffuSum outperforms existing diffusion-based summarization models, achieving improvements of 3.10 in ROUGE-1, 2.84 in ROUGE-2, and 2.89 in ROUGE-L. To further validate the generalizability of TermDiffuSum, we conduct experiments on three public datasets from news and social media domains, with results affirming the scalability of our approach.","llm_keywords":["extractive summarization","legal documents","diffusion models","legal terminology","TermDiffuSum","noise weighting schedule","re-ranking loss function","ROUGE scores"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":14},{"id":"e2950330de5ab42978bbd66ac2b6630151cc411436ac3a176ed8da5463116529f1e23c9ecaedb8e655177084f519cbb3a071dbd4046a0e5ee8cb350b8630677d","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.927.pdf","title":"Linking Judgement Text to Court Hearing Videos: UK Supreme Court as a Case Study","llm_title":"Linking Judgement Text to Court Hearing Videos: UK Supreme Court as a Case Study","authors":["Hadeel Saadany","Constantin Orăsan","Sophie Walker","Catherine Breslin","Mikolaj Barczentewicz"],"llm_authors":"Hadeel Saadany, Constantin Orăsan, Mikolaj Barczentewicz, Catherine Breslin, Sophie Walker","author_string":"Hadeel Saadany ; Constantin Orasan ; Sophie Walker ; Catherine Breslin","year":2024,"abstract":"","llm_abstract":"One the most important archived legal material in the UK is the video recordings of Supreme Court hearings and their corresponding judgements. The impact of Supreme Court published material extends far beyond the parties involved in any given case as it provides landmark rulings on points of law of the greatest public and constitutional importance. Typically, transcripts of legal hearings are lengthy, making it time-consuming for legal professionals to analyse crucial arguments. This study focuses on summarising the second phase of a collaborative research-industrial project aimed at creating an automatic tool designed to connect sections of written judgements with relevant moments in Supreme Court hearing videos, streamlining access to critical information. Acting as a User-Interface (UI) platform, the tool enhances access to justice by pinpointing significant moments in the videos, aiding in comprehension of the final judgement. We make available the initial dataset of judgement-hearing pairs for legal Information Retrieval research, and elucidate our use of AI generative technology to enhance it. Additionally, we demonstrate how fine-tuning GPT text embeddings to our dataset optimises accuracy for an automated linking system tailored to the legal domain.","llm_keywords":["Information Retrieval","Legal Information Retrieval","Embedding Customisation","UK Supreme Court","Judgement Text","Court Hearing Videos","Semantic Linking","Natural Language Processing"],"classifications":["Machine Summarization","Information Retrieval","Resources","Text Generation"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":12},{"id":"4d5b3881c665e8f4954222e499205399c574e0b818e957447afc233d8bd9f7bd7d12f277324c46f83b6de3f085769aa98e9e4fb54de93e3ced737e97a00a00e6","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.108.pdf","title":"Annotation and Classification of Relevant Clauses in Terms-and-Conditions Contracts","llm_title":"Annotation and Classification of Relevant Clauses in Terms-and-Conditions Contracts","authors":["Pietro Giovanni Bizzaro","Elena Della Valentina","Nadia Mana","Maurizio Napolitano","Massimo Zancanaro"],"llm_authors":"Pietro Giovanni Bizzaro, Elena Della Valentina, Nadia Mana, Maurizio Napolitano, Massimo Zancanaro","author_string":"Pietro Giovanni Bizzaro ; Elena Della Valentina ; Maurizio Napolitano ; Nadia Mana ; Massimo Zancanaro","year":2024,"abstract":"","llm_abstract":"In this paper, we propose a new annotation scheme to classify different types of clauses in Terms-and-Conditions contracts with the ultimate goal of supporting legal experts to quickly identify and assess problematic issues in this type of legal documents. To this end, we built a small corpus of Terms-and-Conditions contracts and finalized an annotation scheme of 14 categories, reaching an inter-annotator agreement of 0.92. Then, for 11 of them, we experimented with binary classification tasks using few-shot prompting with a multilingual T5 and two fine-tuned versions of two BERT-based LLMs for Italian. Our experiments showed the feasibility of automatic classification of our categories by reaching accuracies ranging from .79 to .95 on validation tasks.","llm_keywords":["annotation","legal document analysis","language modeling","machine learning","Terms-and-Conditions contracts","clause classification","Italian language","large language models"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"54bfe285269c5e873e9e5990c97f7510d9fd3dc4313a3a717426e6cbbdafe32c04751b4790460d20fdbca2d82d53383d6f3687632ceaabfe9bb77bee36108c6b","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.827.pdf","title":"Jargon: A Suite of Language Models and Evaluation Tasks for French Specialized Domains","llm_title":"Jargon: A Suite of Language Models and Evaluation Tasks for French Specialized Domains","authors":["Vincent Segonne","Aidan Mannion","Laura Cristina Alonzo Canul","Alexandre Daniel Audibert","Xingyu Liu","Cécile Macaire","Adrien Pupier","Yongxin Zhou","Mathilde Aguiar","Felix E. Herron","Magali Norré","Massih R. Amini","Pierrette Bouillon","Iris Eshkol-Taravella","Emmanuelle Esperança-Rodier","Thomas François","Lorraine Goeuriot","Jérôme Goulian","Mathieu Lafourcade","Benjamin Lecouteux","François Portet","Fabien Ringeval","Vincent Vandeghinste","Maximin Coavoux","Marco Dinarelli","Didier Schwab"],"llm_authors":"Vincent Segonne, Aidan Mannion, Laura Cristina Alonzo Canul, Alexandre Audibert, Xingyu Liu, Cécile Macaire, Adrien Pupier, Yongxin Zhou, Mathilde Aguiar, Felix Herron, Magali Norré, Massih-Reza Amini, Pierrette Bouillon, Iris Eshkol-Taravella, Emmanuelle Esperança-Rodier, Thomas François, Lorraine Goeuriot, Jérôme Goulian, Mathieu Lafourcade, Benjamin Lecouteux, François Portet, Fabien Ringeval, Vincent Vandeghinste, Maximin Coavoux, Marco Dinarelli, Didier Schwab","author_string":"Vincent Segonne ; Aidan Mannion ; Laura Cristina Alonzo Canul ; Alexandre Daniel Audibert ; Xingyu Liu ; Cécile Macaire ; Adrien Pupier ; Yongxin Zhou ; Mathilde Aguiar ; Felix E. Herron ; Magali Norré ; Massih R Amini ; Pierrette Bouillon ; Iris Eshkol-Taravella ; Emmanuelle Esperança-Rodier ; Thomas François ; Lorraine Goeuriot ; Jérôme Goulian ; Mathieu Lafourcade ; Benjamin Lecouteux ; François Portet ; Fabien Ringeval ; Vincent Vandeghinste ; Maximin Coavoux ; Marco Dinarelli ; Didier Schwab","year":2024,"abstract":"","llm_abstract":"Pretrained Language Models (PLMs) are the de facto backbone of most state-of-the-art NLP systems. In this paper, we introduce a family of domain-specific pretrained PLMs for French, focusing on three important domains: transcribed speech, medicine, and law. We use a transformer architecture based on efficient methods (LinFormer) to maximise their utility, since these domains often involve processing long documents. We evaluate and compare our models to state-of-the-art models on a diverse set of tasks and datasets, some of which are introduced in this paper. We gather the datasets into a new French-language evaluation benchmark for these three domains. We also compare various training configurations: continued pretraining, pretraining from scratch, as well as single- and multi-domain pretraining. Extensive domain-specific experiments show that it is possible to attain competitive downstream performance even when pre-training with the approximative LinFormer attention mechanism. For full reproducibility, we release the models and pretraining data, as well as contributed datasets.","llm_keywords":["Self-supervised learning","pretrained language models","evaluation benchmark","biomedical document processing","legal document processing","speech transcription"],"classifications":["Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":14},{"id":"98fc9dd9152a08eed1479e133b0820ceae9ce99a7637550b63b6955b05c66bc89af9e9693f9bf68fa1714d9234ca6196c1d1017e7def995a4f293db881402012","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.913.pdf","title":"LexDrafter: Terminology Drafting for Legislative Documents Using Retrieval Augmented Generation","llm_title":"LexDrafter: Terminology Drafting for Legislative Documents using Retrieval Augmented Generation","authors":["Ashish Chouhan","Michael Gertz"],"llm_authors":"Ashish Chouhan and Michael Gertz","author_string":"Ashish Chouhan ; Michael Gertz","year":2024,"abstract":"","llm_abstract":"With the increase in legislative documents at the EU, the number of new terms and their definitions is increasing as well. As per the Joint Practical Guide of the European Parliament, the Council and the Commission, terms used in legal documents shall be consistent, and identical concepts shall be expressed without departing from their meaning in ordinary, legal, or technical language. Thus, while drafting a new legislative document, having a framework that provides insights about existing definitions and helps define new terms based on a document’s context will support such harmonized legal definitions across different regulations and thus avoid ambiguities. In this paper, we present LexDrafter, a framework that assists in drafting Definitions articles for legislative documents using retrieval augmented generation (RAG) and existing term definitions present in different legislative documents. For this, definition elements are built by extracting definitions from existing documents. Using definition elements and RAG, a Definitions article can be suggested on demand for a legislative document that is being drafted. We demonstrate and evaluate the functionality of LexDrafter using a collection of EU documents from the energy domain. The code for LexDrafter framework is available at https://github.com/achouhan93/LexDrafter.","llm_keywords":["legal","EU legislative documents","EUR-Lex","retrieval-augmented generation","large language models","text generation"],"classifications":["Information Retrieval","Information Extraction","Text Generation"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":11},{"id":"2e5118e03a16d8d3c4d4a0044ec92f0f32c8dba928717b43245dd0ca9e7fe849b99c41fdae40232b7ca995009257e1e27dae5eba63a874ecb4a8974e5bc7d66f","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.644.pdf","title":"Fine-Grained Legal Argument-Pair Extraction via Coarse-Grained Pre-training","llm_title":"Fine-Grained Legal Argument-Pair Extraction via Coarse-Grained Pre-training","authors":["Chaojun Xiao","Yutao Sun","Yuan Yao","Xu Han","Wenbin Zhang","Zhiyuan Liu","Maosong Sun"],"llm_authors":"Chaojun Xiao, Yutao Sun, Yuan Yao, Xu Han, Wenbin Zhang, Zhiyuan Liu, Maosong Sun","author_string":"Chaojun Xiao ; Yutao Sun ; Yuan Yao ; Xu Han ; Wenbin Zhang ; Zhiyuan Liu ; Maosong Sun","year":2024,"abstract":"","llm_abstract":"Legal Argument-Pair Extraction (LAE) is dedicated to the identification of interactive arguments targeting the same subject matter within legal complaints and corresponding defenses. This process serves as a foundation for automatically recognizing the focal points of disputes. Current methodologies predominantly conceptualize LAE as a supervised sentence-pair classification problem and usually necessitate extensive manual annotations, thereby constraining their scalability and general applicability. To this end, we present an innovative approach to LAE that focuses on fine-grained alignment of argument pairs, building upon coarse-grained complaint-defense pairs. This strategy stems from two key observations: 1) In general, every argument presented in a legal complaint is likely to be addressed by at least one corresponding argument in the defense. 2) It’s rare for multiple complaint arguments to be addressed by a single defense argument; rather, each complaint argument usually corresponds to a unique defense argument. Motivated by these insights, we develop a specialized pre-training framework. Our model employs pre-training objectives designed to exploit the coarse-grained supervision signals. This enables expressive representations of legal arguments for LAE, even when working with a limited amount of labeled data. To verify the effectiveness of our model, we construct the largest LAE datasets from two representative causes, private lending, and contract dispute. The experimental results demonstrate that our model can effectively capture informative argument knowledge from unlabeled complaint-defense pairs and outperform the unsupervised and supervised baselines by 3.7 and 2.4 points on average respectively. Besides, our model can reach superior accuracy with only half manually annotated data. The datasets and code can be found in https://github.com/thunlp/LAE.","llm_keywords":["Legal Argument-Pair Extraction","Coarse-Grained Pre-training","Interactive Arguments","Supervised Classification","Pre-training Framework","Legal Complaints","Argument Alignment","Unlabeled Data"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":12},{"id":"f63041424f135cf1c37b0e2a67f168c3e391203b6a392ddd9490c667bea51efb1064ca7eaaa60693f9e6674a44112ff34cf88c9220458345ab71810b22c19d1b","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.939.pdf","title":"Logic Rules as Explanations for Legal Case Retrieval","llm_title":"Logic Rules as Explanations for Legal Case Retrieval","authors":["Zhongxiang Sun","Kepu Zhang","Weijie Yu","Haoyu Wang","Jun Xu"],"llm_authors":"Zhongxiang Sun, Kepu Zhang, Weijie Yu, Haoyu Wang, Jun Xu","author_string":"ZhongXiang Sun ; Kepu Zhang ; Weijie Yu ; Haoyu Wang ; Jun Xu","year":2024,"abstract":"","llm_abstract":"In this paper, we address the issue of using logic rules to explain the results from legal case retrieval. The task is critical to legal case retrieval because the users (e.g., lawyers or judges) are highly specialized and require the system to provide logical, faithful, and interpretable explanations before making legal decisions. Recently, research efforts have been made to learn explainable legal case retrieval models. However, these methods usually select rationales (key sentences) from the legal cases as explanations, failing to provide faithful and logically correct explanations. In this paper, we propose Neural-Symbolic enhanced Legal Case Retrieval (NS-LCR), a framework that explicitly conducts reasoning on the matching of legal cases through learning case-level and law-level logic rules. The learned rules are then integrated into the retrieval process in a neuro-symbolic manner. Benefiting from the logic and interpretable nature of the logic rules, NS-LCR is equipped with built-in faithful explainability. We also show that NS-LCR is a model-agnostic framework that can be plugged in for multiple legal retrieval models. To showcase NS-LCR’s superiority, we enhance existing benchmarks by adding manually annotated logic rules and introducing a novel explainability metric using Large Language Models (LLMs). Our comprehensive experiments reveal NS-LCR’s effectiveness for ranking, alongside its proficiency in delivering reliable explanations for legal case retrieval.","llm_keywords":["Legal Applications","Information Retrieval","Explainability","Neural-Symbolic","Logic Rules","Legal Case Retrieval","Model-Agnostic Framework","Benchmark Enhancement","Large Language Models"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":13},{"id":"09a85e42b352ac069c3424265a2c8c3b1420b6c53fdc7b7fdee64586868ee19a7413e70550659b31b89af7fb04223f725916903da6a5256747c97334ceef7762","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.365.pdf","title":"Creation and Analysis of an International Corpus of Privacy Laws","llm_title":"Creation and Analysis of an International Corpus of Privacy Laws","authors":["Sonu Gupta","Geetika Gopi","Harish Balaji","Ellen Poplavska","Nora O'Toole","Siddhant Arora","Thomas Norton","Norman Sadeh","Shomir Wilson"],"llm_authors":"Sonu Gupta, Geetika Gopi, Harish Balaji, Ellen Poplavska, Nora O’Toole, Siddhant Arora, Thomas Norton, Norman Sadeh, Shomir Wilson","author_string":"Sonu Gupta ; Geetika Gopi ; Harish Balaji ; Ellen Poplavska ; Nora O'Toole ; Siddhant Arora ; Thomas Norton ; Norman Sadeh ; Shomir Wilson","year":2024,"abstract":"","llm_abstract":"The landscape of privacy laws and regulations around the world is complex and ever-changing. National and super-national laws, agreements, decrees, and other government-issued rules form a patchwork that companies must follow to operate internationally. To examine the status and evolution of this patchwork, we introduce the Privacy Law Corpus, of 1,043 privacy laws, regulations, and guidelines, covering 183 jurisdictions. This corpus enables a large-scale quantitative and qualitative examination of legal focus on privacy. We examine the temporal distribution of when privacy laws were created and illustrate the dramatic increase in privacy legislation over the past 50 years, although a finer-grained examination reveals that the rate of increase varies depending on the personal data types that privacy laws address. Our exploration also demonstrates that most privacy laws respectively address relatively few personal data types. Additionally, topic modeling results show the prevalence of common themes in privacy laws, such as finance, healthcare, and telecommunications. Finally, we release the corpus to the research community to promote further study.","llm_keywords":["Privacy Law","Privacy Law Corpus","Personal Data","Regulations","Legal Text Analysis","Topic Modeling","International Jurisdictions","Privacy Legislation"],"classifications":["Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":14},{"id":"fa9a2b5dc73cf08d95f9daee6eb7ac8d6243275bb4f2a390d0884ff28dcd4e9d2f4049acd41c584bbd864f8890b29d452df2acb12321035bd36072346d6a542a","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.826.pdf","title":"JaParaPat: A Large-Scale Japanese-English Parallel Patent Application Corpus","llm_title":"JaParaPat: A Large-Scale Japanese-English Parallel Patent Application Corpus","authors":["Masaaki Nagata","Makoto Morishita","Katsuki Chousa","Norihito Yasuda"],"llm_authors":"Masaaki Nagata, Makoto Morishita, Katsuki Chousa, Norihito Yasuda","author_string":"Masaaki Nagata ; Makoto Morishita ; Katsuki Chousa ; Norihito Yasuda","year":2024,"abstract":"","llm_abstract":"We constructed JaParaPat (Japanese-English Parallel Patent Application Corpus), a bilingual corpus of more than 300 million Japanese-English sentence pairs from patent applications published in Japan and the United States from 2000 to 2021. We obtained the publication of unexamined patent applications from the Japan Patent Office (JPO) and the United States Patent and Trademark Office (USPTO). We also obtained patent family information from the DOCDB, that is a bibliographic database maintained by the European Patent Office (EPO). We extracted approximately 1.4M Japanese-English document pairs, which are translations of each other based on the patent families, and extracted about 350M sentence pairs from the document pairs using a translation-based sentence alignment method whose initial translation model is bootstrapped from a dictionary-based sentence alignment method. We experimentally improved the accuracy of the patent translations by 20 bleu points by adding more than 300M sentence pairs obtained from patent applications to 22M sentence pairs obtained from the web.","llm_keywords":["Patent application","Parallel corpus","Japanese-English","Translation accuracy","Sentence alignment","Machine translation","Patent families","Linguistics","Patent corpora"],"classifications":["Information Extraction","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":11},{"id":"aea675df3f6cb942f49ae9306dd0a12fcfb5c1bde29ea289afbf1609e0f3c1daf4c029d4b191c72a45b8318a3709372c0f6875ce016391ed455812bf4b036dc1","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.1164.pdf","title":"Pseudonymization Categories across Domain Boundaries","llm_title":"Pseudonymization Categories across Domain Boundaries","authors":["Maria Irena Szawerna","Simon Dobnik","Therese Lindström Tiedemann","Ricardo Muñoz Sánchez","Xuan-Son Vu","Elena Volodina"],"llm_authors":"Maria Irena Szawerna, Simon Dobnik, Therese Lindström Tiedemann, Ricardo Muñoz Sánchez, Xuan-Son Vu, Elena Volodina","author_string":"Maria Irena Szawerna ; Simon Dobnik ; Therese Lindström Tiedemann ; Ricardo Muñoz Sánchez ; Xuan-Son Vu ; Elena Volodina","year":2024,"abstract":"","llm_abstract":"Linguistic data, a component critical not only for research in a variety of fields but also for the development of various Natural Language Processing (NLP) applications, can contain personal information. As a result, its accessibility is limited, both from a legal and an ethical standpoint. One of the solutions is the pseudonymization of the data. Key stages of this process include the identification of sensitive elements and the generation of suitable surrogates in a way that the data is still useful for the intended task. Within this paper, we conduct an analysis of tagsets that have previously been utilized in anonymization and pseudonymization. We also investigate what kinds of Personally Identifiable Information (PII) appear in various domains. These reveal that none of the analyzed tagsets account for all of the PII types present cross-domain at the level of detailedness seemingly required for pseudonymization. We advocate for a universal system of tags for categorizing PIIs leading up to their replacement. Such categorization could facilitate the generation of grammatically, semantically, and sociolinguistically appropriate surrogates for the kinds of information that are considered sensitive in a given domain, resulting in a system that would enable dynamic pseudonymization while keeping the texts readable and useful for future research in various fields.","llm_keywords":["pseudonymization","anonymization","privacy","deidentification","universal tagset"],"classifications":["Information Extraction","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":12},{"id":"4ab5934a1c4ef3ba54cf3108f10255b58824cf8b0e3166d5d3d5e65aa07bfd8963c5be8223e8987d69609fe4e64f0ca46b49164ce22975d417c5ad549e6116a5","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.486.pdf","title":"ECtHR-PCR: A Dataset for Precedent Understanding and Prior Case Retrieval in the European Court of Human Rights","llm_title":"ECtHR-PCR: A Dataset for Precedent Understanding and Prior Case Retrieval in the European Court of Human Rights","authors":["Santosh T.Y.S.S.","Rashid Gustav Haddad","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Rashid Gustav Haddad, Matthias Grabmair","author_string":"Santosh T.Y.S.S. ; Rashid Haddad ; Matthias Grabmair","year":2024,"abstract":"","llm_abstract":"In common law jurisdictions, legal practitioners rely on precedents to construct arguments, in line with the doctrine of stare decisis. As the number of cases grow over the years, prior case retrieval (PCR) has garnered significant attention. Besides lacking real-world scale, existing PCR datasets do not simulate a realistic setting, because their queries use complete case documents while only masking references to prior cases. The query is thereby exposed to legal reasoning not yet available when constructing an argument for an undecided case as well as spurious patterns left behind by citation masks, potentially short-circuiting a comprehensive understanding of case facts and legal principles. To address these limitations, we introduce a PCR dataset based on judgements from the European Court of Human Rights (ECtHR), which explicitly separate facts from arguments and exhibit precedential practices, aiding us to develop this PCR dataset to foster systems’ comprehensive understanding. We benchmark different lexical and dense retrieval approaches with various negative sampling strategies, adapting them to deal with long text sequences using hierarchical variants. We found that difficulty-based negative sampling strategies were not effective for the PCR task, highlighting the need for investigation into domain-specific difficulty criteria. Furthermore, we observe performance of the dense models degrade with time and calls for further research into temporal adaptation of retrieval models. Additionally, we assess the influence of different views , Halsbury’s and Goodhart’s, in practice in ECtHR jurisdiction using PCR task.","llm_keywords":["Prior Case Retrieval","Temporal Robustness","Common Law","European Court of Human Rights","Legal Dataset"],"classifications":["Information Retrieval"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":11},{"id":"bce373cf9f907443a9ab4c90a227e6ac2d835272f16685baea59cd86f08097e7c0850b3140533e671c8f4e861eddb92977be1b33705fbc30d9ae7bef177c5177","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.422.pdf","title":"Detecting Cybercrimes in Accordance with Pakistani Law: Dataset and Evaluation Using PLMs","llm_title":"Detecting Cybercrimes in Accordance with Pakistani Law: Dataset and Evaluation using PLMs","authors":["Faizad Ullah","Ali Faheem","Ubaid Azam","Muhammad Sohaib Ayub","Faisal Kamiran","Asim Karim"],"llm_authors":"Faizad Ullah, Ali Faheem, Ubaid Azam, Muhammad Sohaib Ayub, Faisal Kamiran, and Asim Karim","author_string":"Faizad Ullah ; Ali Faheem ; Ubaid Azam ; Muhammad Sohaib Ayub ; Faisal Kamiran ; Asim Karim","year":2024,"abstract":"","llm_abstract":"Cybercrime is a serious and growing threat affecting millions of people worldwide. Detecting cybercrimes from text messages is challenging, as it requires understanding the linguistic and cultural nuances of different languages and regions. Roman Urdu is a widely used language in Pakistan and other South Asian countries, however, it lacks sufficient resources and tools for natural language processing and cybercrime detection. To address this problem, we make three main contributions in this paper. (1) We create and release CRU, a benchmark dataset for text-based cybercrime detection in Roman Urdu, which covers a number of cybercrimes as defined by the Prevention of Electronic Crimes Act (PECA) of Pakistan. This dataset is annotated by experts following a standardized procedure based on Pakistan’s legal framework. (2) We perform experiments on four pre-trained language models (PLMs) for cybercrime text classification in Roman Urdu. Our results show that xlm-roberta-base is the best model for this task, achieving the highest performance on all metrics. (3) We explore the utility of prompt engineering techniques, namely prefix and cloze prompts, for enhancing the performance of PLMs for low-resource languages such as Roman Urdu. We analyze the impact of different prompt shapes and k-shot settings on the performance of xlm-roberta-base and bert-base-multilingual-cased. We find that prefix prompts are more effective than cloze prompts for Roman Urdu classification tasks, as they provide more contextually relevant completions for the models. Our work provides useful insights and resources for future research on cybercrime detection and text classification in low-resource languages.","llm_keywords":["Cybercrime Detection","Roman Urdu","Pakistani Cybercrimes Law","Prevention of Electronic Crimes Act","Prompt Engineering","Low-Resource Languages","Natural Language Processing","Pre-trained Language Models","Text Classification"],"classifications":[],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":12},{"id":"59aa8a62be34562d4e8820344700139f6ccaf37a99b11ba7ac9fa199705855b95df971f3b80dc0ddbf4507eb8dd53a1fa7da4b6955dbfbdc93b625312e80c20a","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.1394.pdf","title":"There's Something New about the Italian Parliament: The IPSA Corpus","llm_title":"There’s Something New about the Italian Parliament: the IPSA Corpus","authors":["Valentino Frasnelli","Alessio Palmero Aprosio"],"llm_authors":"Valentino Frasnelli, Alessio Palmero Aprosio","author_string":"Valentino Frasnelli ; Alessio Palmero Aprosio","year":2024,"abstract":"","llm_abstract":"Parliamentary debates constitute a substantial and somewhat underutilized reservoir of publicly available written content. Despite their potential, the Italian parliamentary documents remain largely unexplored and most importantly inaccessible in their original paper-based form. In this paper we attempt to transform these valuable historical documents into IPSA, a digitally readable structured corpus containing speeches, reports of the Standing Committees, and law proposals spanning 175 years of Italian history, from the issuing of the Statuto Albertino in 1848, up to the present day. At first, the PDF documents, available on the official websites of Senato della Repubblica and Camera dei Deputati, the two chambers that form the Italian Parliament, are digitized using Optical Character Recognition (OCR) techniques. Then, the speeches are tagged with the corresponding speakers. The final dataset is released both in textual and structured format.","llm_keywords":["Parliamentary Debates","Linked Data","Optical Character Recognition","Italian History","Digitization","Structured Corpus","Italian Parliament"],"classifications":["Information Extraction","Resources","Pre-Processing"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"4cde5c23e371663d797b3d97f65cf5db7ac80461afc417c223f84dfc39dac4e8da824ac11a3a6d14602de728f51215e97ca9195147f7cc99840c2452db172084","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.1393.pdf","title":"The ParlaSent Multilingual Training Dataset for Sentiment Identification in Parliamentary Proceedings","llm_title":"The ParlaSent Multilingual Training Dataset for Sentiment Identification in Parliamentary Proceedings","authors":["Michal Mochtak","Peter Rupnik","Nikola Ljubešić"],"llm_authors":"Michal Mochtak, Peter Rupnik, Nikola Ljubešić","author_string":"Michal Mochtak ; Peter Rupnik ; Nikola Ljubešić","year":2024,"abstract":"","llm_abstract":"The paper presents a new training dataset of sentences in 7 languages, manually annotated for sentiment, which are used in a series of experiments focused on training a robust sentiment identifier for parliamentary proceedings. The paper additionally introduces the first domain-specific multilingual transformer language model for political science applications, which was additionally pre-trained on 1.72 billion words from parliamentary proceedings of 27 European parliaments. We present experiments demonstrating how the additional pre-training on parliamentary data can significantly improve the model downstream performance, in our case, sentiment identification in parliamentary proceedings. We further show that our multilingual model performs very well on languages not seen during fine-tuning, and that additional fine-tuning data from other languages significantly improves the target parliament’s results. The paper makes an important contribution to multiple disciplines inside the social sciences, and bridges them with computer science and computational linguistics. Lastly, the resulting fine-tuned language model sets up a more robust approach to sentiment analysis of political texts across languages, which allows scholars to study political sentiment from a comparative perspective using standardized tools and techniques.","llm_keywords":["sentiment","parliament","multilingual model","political discourse","transformer language model","sentiment analysis","comparative perspective","computational linguistics"],"classifications":["Resources"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":13},{"id":"07804e63cef03e25d64df163764c5f05f5d183bae95224a3b8744e19374f2b5ea19344c9d7cf251a0e0917f0c04479094b62ded4a481497c2c725ed571550fc7","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.1434.pdf","title":"Towards Explainability and Fairness in Swiss Judgement Prediction: Benchmarking on a Multilingual Dataset","llm_title":"Towards Explainability and Fairness in Swiss Judgement Prediction: Benchmarking on a Multilingual Dataset","authors":["Santosh T.Y.S.S.","Nina Baumgartner","Matthias Stürmer","Matthias Grabmair","Joel Niklaus"],"llm_authors":"Santosh T.Y.S.S, Nina Baumgartner, Matthias Stürmer, Matthias Grabmair, Joel Niklaus","author_string":"Santosh T.Y.S.S. ; Nina Baumgartner ; Matthias Stürmer ; Matthias Grabmair ; Joel Niklaus","year":2024,"abstract":"","llm_abstract":"The assessment of explainability in Legal Judgement Prediction (LJP) systems is of paramount importance in building trustworthy and transparent systems, particularly considering the reliance of these systems on factors that may lack legal relevance or involve sensitive attributes. This study delves into the realm of explainability and fairness in LJP models, utilizing Swiss Judgement Prediction (SJP), the only available multilingual LJP dataset. We curate a comprehensive collection of rationales that ‘support’ and ‘oppose’ judgement from legal experts for 108 cases in German, French, and Italian. By employing an occlusion-based explainability approach, we evaluate the explainability performance of state-of-the-art monolingual and multilingual BERT-based LJP models, as well as models developed with techniques such as data augmentation and cross-lingual transfer, which demonstrated prediction performance improvement. Notably, our findings reveal that improved prediction performance does not necessarily correspond to enhanced explainability performance, underscoring the significance of evaluating models from an explainability perspective. Additionally, we introduce a novel evaluation framework, Lower Court Insertion (LCI), which allows us to quantify the influence of lower court information on model predictions, exposing current models’ biases.","llm_keywords":["Fairness","Explainability","Multilingual","Legal Judgement Prediction","Swiss Judgement Prediction","Occlusion-based explainability","BERT-based LJP models","Data augmentation","Cross-lingual transfer","Lower Court Insertion"],"classifications":["Information Extraction","Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":14},{"id":"32c36a6287a9fb6dc9f4d6aa9b9eb6ec6e79eb4f67816b09f8eb6935e893f51b5e091fd989e54a956d45150d4b9489f901cf3493a6812fb37b2787b90e73d421","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.379.pdf","title":"CuRIAM: Corpus Re Interpretation and Metalanguage in U.S. Supreme Court Opinions","llm_title":"CuRIAM: Corpus re Interpretation and Metalanguage in U.S. Supreme Court Opinions","authors":["Michael Kranzlein","Nathan Schneider","Kevin Tobia"],"llm_authors":"Michael Kranzlein, Nathan Schneider, Kevin Tobia","author_string":"Michael Kranzlein ; Nathan Schneider ; Kevin Tobia","year":2024,"abstract":"","llm_abstract":"Most judicial decisions involve the interpretation of legal texts. As such, judicial opinions use language as the medium to comment on or draw attention to other language (for example, through definitions and hypotheticals about the meaning of a term from a statute). Language used in this way is called metalanguage. Focusing on the U.S. Supreme Court, we view metalanguage as reflective of justices’ interpretive processes, bearing on current debates and theories about textualism in law and political science. As a step towards large-scale metalinguistic analysis with NLP, we identify 9 categories prominent in metalinguistic discussions, including key terms, definitions, and different kinds of sources. We annotate these concepts in a corpus of U.S. Supreme Court opinions. Our analysis of the corpus reveals high interannotator agreement, frequent use of quotes and sources, and several notable frequency differences between majority, concurring, and dissenting opinions. We observe fewer instances than expected of several legal interpretive categories. We discuss some of the challenges in developing the annotation schema and applying it and provide recommendations for how this corpus can be used for broader analyses.","llm_keywords":["Legal Corpus","Corpus Analysis","Legal Interpretation","U.S. Supreme Court","Metalanguage","NLP","Statutory Interpretation"],"classifications":["Information Extraction","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":12},{"id":"c9c80428e194932037eb9d4383ea72d9d882f0537f30b9c24f6ee3f9e5a8a3a76435a7f4dc22450e5d729cefe7af8def4149b5f58558fd4dbbe69c53195f0046","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.987.pdf","title":"Mind Your Neighbours: Leveraging Analogous Instances for Rhetorical Role Labeling for Legal Documents","llm_title":"Mind Your Neighbours: Leveraging Analogous Instances for Rhetorical Role Labeling for Legal Documents","authors":["Santosh T.Y.S.S","Hassan Sarwat","Ahmed Mohamed Abdelaal Abdou","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Hassan Sarwat, Ahmed Abdou, Matthias Grabmair","author_string":"Santosh T.Y.S.S. ; Hassan Sarwat ; Ahmed Mohamed Abdelaal Abdou ; Matthias Grabmair","year":2024,"abstract":"","llm_abstract":"Rhetorical Role Labeling (RRL) of legal judgments is essential for various tasks, such as case summarization, semantic search and argument mining. However, it presents challenges such as inferring sentence roles from context, interrelated roles, limited annotated data, and label imbalance. This study introduces novel techniques to enhance RRL performance by leveraging knowledge from semantically similar instances (neighbours). We explore inference-based and training-based approaches, achieving remarkable improvements in challenging macro-F1 scores. For inference-based methods, we explore interpolation techniques that bolster label predictions without re-training. While in training-based methods, we integrate prototypical learning with our novel discourse-aware contrastive method that work directly on embedding spaces. Additionally, we assess the cross-domain applicability of our methods, demonstrating their effectiveness in transferring knowledge across diverse legal domains.","llm_keywords":["Rhetorical Role Labeling","Prototypical Learning","Contrastive Learning","Interpolation","Legal Documents","Sentence Classification","Data Scarcity","Semantic Search","Argument Mining","Label Imbalance"],"classifications":["Classification","Pre-Processing"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":11},{"id":"a6f7af784c8b1d2d00d755830ed753658040b3af0bc2d6edf137f093300267e2d16e2fc1ff943a6ca8b44a24d499e4e223ae841b33b3ed8cc346ba99b515431c","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.1400.pdf","title":"The Swedish Parliament Corpus 1867 – 2022","llm_title":"The Swedish Parliament Corpus 1867–2022","authors":["Väinö Aleksi Yrjänäinen","Fredrik Mohammadi Norén","Robert Borges","Johan Jarlbrink","Lotta Åberg Brorsson","Anders P. Olsson","Pelle Snickars","Måns Magnusson"],"llm_authors":"Väinö Yrjänäinen, Fredrik Mohammadi Norén, Robert Borges, Johan Jarlbrink, Lotta Åberg Brorsson, Anders P. Olsson, Pelle Snickars, Måns Magnusson","author_string":"Väinö Aleksi Yrjänäinen ; Fredrik Mohammadi Norén ; Robert Borges ; Johan Jarlbrink ; Lotta Åberg Brorsson ; Anders P. Olsson ; Pelle Snickars ; Måns Magnusson","year":2024,"abstract":"","llm_abstract":"The Swedish parliamentary records are an important source material for social science and humanities researchers. We introduce a new research corpus, the Swedish Parliament Corpus, which is larger and more developed than previously available research corpora for the Swedish parliament. The corpus contains annotated and structured parliamentary records over more than 150 years, through the bicameral parliament (1867–1970) and the unicameral parliament (1971–). In addition to the records, which contain all speeches in the parliament, we also provide a database of all members of parliament over the same period. Along with the corpus, we describe procedures to ensure data quality. The corpus facilitates detailed analysis of parliamentary speeches in several research fields.","llm_keywords":["parliamentary data","Sweden","political debate","language resource","politics","data curation"],"classifications":["Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":13},{"id":"015e854bf04807a1c17ff87f9e59bb4c6a5bd64b40d8cb0bc5d986223815972213d4503b79447101fcda8c2775ec4f4ad31dbc546f02969842c181773054b863","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.1220.pdf","title":"Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents","llm_title":"Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents","authors":["Ramona Christen","Anastassia Shaitarova","Matthias Stürmer","Joel Niklaus"],"llm_authors":"Ramona Christen, Anastassia Shaitarova, Matthias Stürmer, Joel Niklaus","author_string":"Ramona Christen ; Anastassia Shaitarova ; Matthias Stürmer ; Joel Niklaus","year":2024,"abstract":"","llm_abstract":"Resolving the scope of a negation within a sentence is a challenging NLP task. The complexity of legal texts and the lack of annotated in-domain negation corpora pose challenges for state-of-the-art (SotA) models when performing negation scope resolution on multilingual legal data. Our experiments demonstrate that models pre-trained without legal data underperform in the task of negation scope resolution. We release a new set of annotated court decisions in German, French, and Italian and use it to improve negation scope resolution in both zero-shot and multilingual settings. We achieve word-level F1-scores of up to 86.7% in our zero-shot cross-lingual experiments, where the models are trained on two languages of our legal datasets and evaluated on the third. Our multilingual experiments, where the models were trained on all available negation data and evaluated on our legal datasets, resulted in F1-scores of up to 91.1%.","llm_keywords":["Negation Scope Resolution","Legal","Multilingual","Dataset","Transformers"],"classifications":["Resources","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":13},{"id":"0b1eb8190400d72ceaa2a4700045457de0a2a07f328daed475439ab79bf5618d7f255273eb7a0a6284a171d2982c5c385151195b1f3c997fd5cad77e28c8fe85","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.911.pdf","title":"LexAbSumm: Aspect-based Summarization of Legal Decisions","llm_title":"LexAbSumm: Aspect-based Summarization of Legal Decisions","authors":["Santosh T.Y.S.S","Mahmoud Aly","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Mahmoud Aly, Matthias Grabmair","author_string":"Santosh T.Y.S.S. ; Mahmoud Aly ; Matthias Grabmair","year":2024,"abstract":"","llm_abstract":"Legal professionals frequently encounter long legal judgments that hold critical insights for their work. While recent advances have led to automated summarization solutions for legal documents, they typically provide generic summaries, which may not meet the diverse information needs of users. To address this gap, we introduce LexAbSumm, a novel dataset designed for aspect-based summarization of legal case decisions, sourced from the European Court of Human Rights jurisdiction. We evaluate several abstractive summarization models tailored for longer documents on LexAbSumm, revealing a challenge in conditioning these models to produce aspect-specific summaries. We release LexAbSum to facilitate research in aspect-based summarization for legal domain.","llm_keywords":["Aspect-based Summarization","Legal Judgements","European Court of Human Rights","Abstractive Summarization","Legal Documents"],"classifications":[],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"e0bcde2c967ebb78a44f3a91f6f8b5b71af5373f36ba54aa8eb75a4593c80073049261247cb26c96c13c197cd6a3527c6c93014c5f08962d04ab62678d82364c","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.49.pdf","title":"Agenda-Driven Question Generation: A Case Study in the Courtroom Domain","llm_title":"Agenda-Driven Question Generation: A Case Study in the Courtroom Domain","authors":["Yi Fung","Anoop Kumar","Aram Galstyan","Heng Ji","Prem Natarajan"],"llm_authors":"Yi Fung, Aram Galstyan, Heng Ji, Anoop Kumar, Prem Natarajan","author_string":"Yi Fung ; Anoop Kumar ; Aram Galstyan ; Heng Ji ; Prem Natarajan","year":2024,"abstract":"","llm_abstract":"This paper introduces a novel problem of automated question generation for courtroom examinations, CourtQG. While question generation has been studied in domains such as educational testing, product description and situation report generation, CourtQG poses several unique challenges owing to its non-cooperative and agenda-driven nature. Specifically, not only the generated questions need to be relevant to the case and underlying context, they also have to achieve certain objectives such as challenging the opponent’s arguments and/or revealing potential inconsistencies in their answers. We propose to leverage large language models (LLM) for CourtQG by fine-tuning them on two auxiliary tasks, agenda explanation (i.e., uncovering the underlying intents) and question type prediction. We additionally propose cold-start generation of questions from background documents without relying on examination history. Finally, we evaluate our proposed method on a constructed dataset, and show that it generates better questions according to standard metrics when compared to several baselines.","llm_keywords":["Courtroom Examination QG","Agenda-Aware Reasoning","NLP for Social Good","Large Language Models","Automated Question Generation","Legal Domain","Cold-start Generation","Natural Language Processing"],"classifications":["Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":12},{"id":"f7037d94d548595dcfd0ec3013294b33053e9b50e9738e18460cac2612fd8acf752efe75fece02e3f77d3485ecf708b6653ebc367aad4ae4a30473fb3cc83711","file_path":"legal-nlp-survey-20250328-002/team 2/13 International Conference on Language Resources and Evaluation (LREC)/2024.lrec-main.1177.pdf","title":"Query-driven Relevant Paragraph Extraction from Legal Judgments","llm_title":"Query-driven Relevant Paragraph Extraction from Legal Judgments","authors":["Santosh T.Y.S.S","Elvin A. Quero Hernandez","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Elvin Quero Hernandez, Matthias Grabmair","author_string":"Santosh T.Y.S.S. ; Elvin A. Quero Hernandez ; Matthias Grabmair","year":2024,"abstract":"","llm_abstract":"Legal professionals often grapple with navigating lengthy legal judgements to pinpoint information that directly address their queries. This paper focus on this task of extracting relevant paragraphs from legal judgements based on the query. We construct a specialized dataset for this task from the European Court of Human Rights (ECtHR) using the case law guides. We assess the performance of current retrieval models in a zero-shot way and also establish fine-tuning benchmarks using various models. The results highlight the significant gap between fine-tuned and zero-shot performance, emphasizing the challenge of handling distribution shift in the legal domain. We notice that the legal pre-training handles distribution shift on the corpus side but still struggles on query side distribution shift, with unseen legal queries. We also explore various Parameter Efficient Fine-Tuning (PEFT) methods to evaluate their practicality within the context of information retrieval, shedding light on the effectiveness of different PEFT methods across diverse configurations with pre-training and model architectures influencing the choice of PEFT method.","llm_keywords":["Relevant Paragraph Identification","Parameter Efficient Retrieval","Legal Retrieval"],"classifications":["Information Retrieval","Information Extraction","Resources","Pre-Processing"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":13},{"id":"4ee11e9d6dabbb0cde6db7a3bb531d9f2d70befedd058f446b541d12ff5f6ebb955e70d661a9a4539f02032a55db1325dbcc52562f87bf51ac274f7411c27621","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.116.pdf","title":"","llm_title":"LTRC at SemEval-2023 Task 6: Experiments with Ensemble Embeddings","authors":["Pavan Baswani","Hiranmai Sri Adibhatla","Manish Shrivastava"],"llm_authors":"Pavan Baswani, Hiranmai Sri Adibhatla, Manish Shrivastava","author_string":"","year":2023,"abstract":"","llm_abstract":"In this paper, we present our team’s involvement in SemEval-2023 Task 6: LegalEval: Understanding Legal Texts. The task comprised three subtasks, and we focus on subtask A: Rhetorical Roles prediction. Our approach included experimenting with pre-trained embeddings and refining them with statistical and neural classifiers. We provide a thorough examination of our experiments, solutions, and analysis, culminating in our best-performing model and current progress. We achieved a micro F1 score of 0.6133 on the test data using fine-tuned LegalBERT embeddings.","llm_keywords":["Legal Texts","Rhetorical Roles","LegalBERT","NLP","Semantic Evaluation","Legal Document Analysis","Machine Learning","Statistical Classifiers","Neural Classifiers","Legal AI"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"0c897e3c93f4d11ff29e35ba74e5e3fd6f7348a762ec7c82480c7317e545308fd541c8f8eb88aef2bf98270b1ac9aee6fb821ed65b8940b856614d7336734c0f","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.60.pdf","title":"","llm_title":"0x.Yuan at SemEval-2024 Task 5: Enhancing Legal Argument Reasoning with Structured Prompts","authors":["Yu-An Lu","Hung-Yu Kao"],"llm_authors":"Yu-An Lu, Hung-Yu Kao","author_string":"","year":2024,"abstract":"","llm_abstract":"The intersection of legal reasoning and Natural Language Processing (NLP) technologies, particularly Large Language Models (LLMs), offers groundbreaking potential for augmenting human capabilities in the legal domain. This paper presents our approach and findings from participating in SemEval-2024 Task 5, focusing on the effect of argument reasoning in civil procedures using legal reasoning prompts. We investigated the impact of structured legal reasoning methodologies, including TREACC, IRAC, IRAAC, and MIRAC, on guiding LLMs to analyze and evaluate legal arguments systematically. Our experimental setup involved crafting specific prompts based on these methodologies to instruct the LLM to dissect and scrutinize legal cases, aiming to discern the cogency of argumentative solutions within a zero-shot learning framework. The performance of our approach, as measured by F1 score and accuracy, demonstrated the efficacy of integrating structured legal reasoning into LLMs for legal analysis. The findings underscore the promise of LLMs, when equipped with legal reasoning prompts, in enhancing their ability to process and reason through complex legal texts, thus contributing to the broader application of AI in legal studies and practice.","llm_keywords":["Legal Reasoning","Natural Language Processing","Large Language Models","Structured Prompts","Civil Procedure","Semantic Evaluation","AI in Law"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"52fa11155ec1af72ec0958feee3bb714c051758525f3717a360deb96db9329fc97a1921b1723ec35aa5582cef382d19c7e2c3b5913c680a037f49f8fc1c9fba9","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.79.pdf","title":"","llm_title":"uOttawa at SemEval-2023 Task 6: Deep Learning for Legal Text Understanding","authors":["Intisar Almuslim","Sean Stilwell","Surya Kiran Suresh","Diana Inkpen"],"llm_authors":"Intisar Almuslim, Sean Stilwell, Surya Kiran Suresh, Diana Inkpen","author_string":"","year":2023,"abstract":"","llm_abstract":"We describe the methods we used for legal text understanding, specifically Task 6 Legal-Eval at SemEval 2023. The outcomes could assist law practitioners and help automate the working process of judicial systems. The shared task defined three main sub-tasks: sub-task A, Rhetorical Roles Prediction (RR); sub-task B, Legal Named Entities Extraction (L-NER); and sub-task C, Court Judgement Prediction with Explanation (CJPE). Our team addressed all three sub-tasks by exploring various Deep Learning (DL) based models. Overall, our team’s approaches achieved promising results on all three sub-tasks, demonstrating the potential of deep learning-based models in the judicial domain.","llm_keywords":["legal text understanding","deep learning","rhetorical roles prediction","legal named entities extraction","court judgement prediction","semantic evaluation","automated legal processing","judicial domain"],"classifications":["Classification","Information Extraction","Information Retrieval"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":9},{"id":"42a08a717b3d2c3048fd20d1b6eabe6815d23a1c4baba2a128abba8b0ce447df59c12e71d979a9052f68164b66dd67b55db285fa92738fbbb48150107c82fdec","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.133.pdf","title":"","llm_title":"eagerlearners at SemEval2024 Task 5: The Legal Argument Reasoning Task in Civil Procedure","authors":["Hoorieh Sabzevari","Mohammadmostafa Rostamkhani","Sauleh Eetemadi"],"llm_authors":"Hoorieh Sabzevari, Mohammadmostafa Rostamkhani, Sauleh Eetemadi","author_string":"","year":2024,"abstract":"","llm_abstract":"This study investigates the performance of the zero-shot method in classifying data using three large language models, alongside two models with large input token sizes and the two pre-trained models on legal data. Our main dataset comes from the domain of U.S. civil procedure. It includes summaries of legal cases, specific questions, potential answers, and detailed explanations for why each solution is relevant, all sourced from a book aimed at law students. By comparing different methods, we aimed to understand how effectively they handle the complexities found in legal datasets. Our findings show how well the zero-shot method of large language models can understand complicated data. We achieved our highest F1 score of 64% in these experiments.","llm_keywords":["zero-shot method","large language models","legal data","U.S. civil procedure","natural language processing","argumentation","legal reasoning"],"classifications":["Classification","Machine Summarization"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"c8bc3382f479a2dd0897d62f0d110df898ff2f0ab131b62ffeebeef9ce74a4393b801df67ac989211ee30ef347e6fac8a15cc5b844336f07ff683f2e2564b6c2","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.94.pdf","title":"","llm_title":"IRIT_IRIS_C at SemEval-2023 Task 6: A Multi-level Encoder-based Architecture for Judgement Prediction of Legal Cases and their Explanation","authors":["Nishchal Prasad","Mohand Boughanem","Taoufiq Dkaki"],"llm_authors":"Nishchal Prasad, Mohand Boughanem, Taoufiq Dkaki","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper describes our system used for sub-task C (1 & 2) in Task 6: LegalEval: Understanding Legal Texts. We propose a three-level encoder-based classification architecture that works by fine-tuning a BERT-based pre-trained encoder, and post-processing the embeddings extracted from its last layers, using transformer encoder layers and RNNs. We run ablation studies on the same and analyze its performance. To extract the explanations for the predicted class we develop an explanation extraction algorithm, exploiting the idea of a model’s occlusion sensitivity. We explored some training strategies with a detailed analysis of the dataset. Our system ranked 2nd (macro-F1 metric) for its sub-task C-1 and 7th (ROUGE-2 metric) for sub-task C-2.","llm_keywords":["Semantic Evaluation","Judgement Prediction","Legal Cases","BERT","Transformer","RNN","Legal Texts","Explanation Extraction","Machine Learning"],"classifications":["Classification","Information Extraction","Pre-Processing"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":7},{"id":"d92051bac990bba971a17cd9d5fbb78111919287ce655f2de584ba32bb3b6f89015aa4cbe150c4c4d3a2ae717a5d86a8deae73370f2eb237d8db37f0c97377e7","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.37.pdf","title":"","llm_title":"TeamUnibo at SemEval-2023 Task 6: A transformer based approach to Rhetorical Roles prediction and NER in Legal Texts","authors":["Yuri Noviello","Enrico Pallotta","Flavio Pinzarrone","Giuseppe Tanzi"],"llm_authors":"Yuri Noviello, Enrico Pallotta, Flavio Pinzarrone, Giuseppe Tanzi","author_string":"","year":2023,"abstract":"","llm_abstract":"This study aims to tackle some challenges posed by legal texts in the field of NLP. The LegalEval challenge (Modi et al., 2023) proposes three tasks, based on Indial Legal documents: Rhetorical Roles Prediction, Legal Named Entity Recognition, and Court Judgement Prediction with Explanation. Our work focuses on the first two tasks. For the first task we present a context-aware approach to enhance sentence information. With the help of this approach, the classification model utilizing InLegalBert as a transformer achieved 81.12% Micro-F1. For the second task we present a NER approach to extract and classify entities like names of petitioner, respondent, court or statute of a given document. The model utilizing XLNet as transformer and a dependency parser on top achieved 87.43% Macro-F1.","llm_keywords":["Rhetorical Roles Prediction","Legal Named Entity Recognition","Legal Texts","Transformers","InLegalBERT","XLNet","Natural Language Processing","Context-aware models","Legal documents"],"classifications":["Classification","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"d4b056a098fb0b1cee54c913d7c46c3a973913a85afe572f685841d20f04f21dda756d81ae4608123cb5d5255b0f64a9a487496ffcecb38c31559937178aedc4","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.108.pdf","title":"","llm_title":"YNU-HPCC at SemEval-2024 Task 5: Regularized Legal-BERT for Legal Argument Reasoning Task in Civil Procedure","authors":["Peng Shi","Jin Wang","Xuejie Zhang"],"llm_authors":"Peng Shi, Jin Wang and Xuejie Zhang","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper describes the submission of team YNU-HPCC to SemEval-2024 for Task 5: The Legal Argument Reasoning Task in Civil Procedure. The task asks candidates the topic, questions, and answers, classifying whether a given candidate’s answer is correct (True) or incorrect (False). To make a sound judgment, we propose a system. This system is based on fine-tuning the Legal-BERT model that specializes in solving legal problems. Meanwhile, Regularized Dropout (R-Drop) and focal Loss were used in the model. R-Drop is used for data augmentation, and focal loss addresses data imbalances. Our system achieved relatively good results on the competition’s official leaderboard. The code of this paper is available at https://github.com/YNU-PengShi/SemEval-2024-Task5.","llm_keywords":["Legal-BERT","Semantic Evaluation","Legal Argument","Data Augmentation","Focal Loss","Machine Learning","Natural Language Processing","Civil Procedure"],"classifications":["Classification","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"3afe054668385d2228cd58d0f0a691a8854836abcd6898ce22a6202104fdec5343c3419b3e7883d9ad960502e241e9517334c7bc62a78e64488d4b5c05d7c7c2","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.54.pdf","title":"","llm_title":"AntContentTech at SemEval-2023 Task 6: Domain-adaptive Pretraining and Auxiliary-task Learning for Understanding Indian Legal Texts","authors":["Jingjing Huo","Kezun Zhang","Zhengyong Liu","Xuan Lin","Wenqiang Xu","Maozong Zheng","Zhaoguo Wang","Song Li"],"llm_authors":"Jingjing Huo, Kezun Zhang, Zhengyong Liu, Xuan Lin, Wenqiang Xu, Maozong Zheng, Zhaoguo Wang, Song Li","author_string":"","year":2023,"abstract":"","llm_abstract":"The objective of this shared task is to gain an understanding of legal texts, and it is beset with difficulties such as the comprehension of lengthy noisy legal documents, domain specificity as well as the scarcity of annotated data. To address these challenges, we propose a system that employs a hierarchical model and integrates domain-adaptive pretraining, data augmentation, and auxiliary-task learning techniques. Moreover, to enhance generalization and robustness, we ensemble the models that utilize these diverse techniques. Our system ranked first on the RR sub-task and in the middle for the other two sub-tasks. Our code is publicly available here1.","llm_keywords":["Semantic Evaluation","Legal Texts","Domain-adaptive Pretraining","Auxiliary-task Learning","Legal AI Applications","Rhetorical Roles Prediction","Named Entities Extraction","Court Judgment Prediction"],"classifications":["Pre-Processing","Classification","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":7},{"id":"536fc5837e332ae4ecf8229bfe6e6ac54e96a5ea3ed15def3888e9d9f1d74c7d49ca8919086c42984c33d726913e0a398e4780e3fca61c9ee9a0cac7a5bc4c94","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.235.pdf","title":"","llm_title":"SU-FMI at SemEval-2024 Task 5: From BERT Fine-Tuning to LLM Prompt Engineering - Approaches in Legal Argument Reasoning","authors":["Kristiyan Krumov","Svetla Boytcheva","Ivan Koytchev"],"llm_authors":"Kristiyan Krumov, Svetla Boytcheva, Ivan Koytchev","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper presents our approach and findings for SemEval-2024 Task 5, focusing on legal argument reasoning. We explored the effectiveness of fine-tuning pre-trained BERT models and the innovative application of large language models (LLMs) through prompt engineering in the context of legal texts. Our methodology involved a combination of techniques to address the challenges posed by legal language processing, including handling long texts and optimizing natural language understanding (NLU) capabilities for the legal domain. Our contributions were validated by achieving a third-place ranking on the SemEval 2024 Task 5 Leaderboard. The results underscore the potential of LLMs and prompt engineering in enhancing legal reasoning tasks, offering insights into the evolving landscape of NLU technologies within the legal field.","llm_keywords":["BERT fine-tuning","large language models","prompt engineering","legal argument reasoning","natural language understanding","legal texts","SemEval-2024","text classification","handling long texts"],"classifications":["Pre-Processing","Classification","Text Generation"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":7},{"id":"69dda1df7a67a77d2073fec38b63ccac3713f1f7eadc061cd767e02c9b18c9937863b66e1a2bea7849c9d8c3cc30c0ae2db0c07bbf2055da9c9144cbe10b8c39","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.36.pdf","title":"","llm_title":"nclu_team at SemEval-2023 Task 6: Attention-based Approaches for Large Court Judgement Prediction with Explanation","authors":["Nicolay Rusnachenko","Thanet Markchom","Huizhi Liang"],"llm_authors":"Nicolay Rusnachenko, Thanet Markchom, Huizhi Liang","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal documents tend to be large in size. In this paper, we provide an experiment with attention-based approaches complemented by certain document processing techniques for judgment prediction. For the prediction of explanation, we consider this as an extractive text summarization problem based on an output of (1) CNN with attention mechanism and (2) self-attention of language models. Our extensive experiments show that treating document endings at first results in a 2.1% improvement in judgment prediction across all the models. Additional content peeling from non-informative sentences allows an improvement of explanation prediction performance by 4% in the case of attention-based CNN models. The best submissions achieved 8th and 3rd ranks on judgment prediction (C1) and prediction with explanation (C2) tasks respectively among 11 participating teams. The results of our experiments are published.","llm_keywords":["Court Judgement Prediction","Attention-based Approaches","CNN with Attention","Self-Attention","Legal Documents","Text Summarization","Transformer Models","Natural Language Processing","Deep Learning"],"classifications":["Classification","Machine Summarization","Pre-Processing","Information Extraction","Information Retrieval","Text Generation","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":5},{"id":"de77553b15a5c3fc1c7e378f618c4aa4b583dbd1921741f9a137949354a413b3a70da3d0f9c0e38043f251f573f3e4de73921302cdbcfc032bc504d14269e4f6","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.125.pdf","title":"","llm_title":"IRIT_IRIS_A at SemEval-2023 Task 6: Legal Rhetorical Role Labeling Supported by Dynamic-Filled Contextualized Sentence Chunks","authors":["Alexandre G. de Lima","Jose G. Moreno","Eduardo H. da S. Aranha"],"llm_authors":"Alexandre G. de Lima, Jose G. Moreno, Eduardo H. da S. Aranha","author_string":"","year":2023,"abstract":"","llm_abstract":"This work presents and evaluates an approach to efficiently leverage the context exploitation ability of pre-trained Transformer models as a way of boosting the performance of models tackling the Legal Rhetorical Role Labeling task. The core idea is to feed the model with sentence chunks that are assembled in a way that avoids the insertion of padding tokens and the truncation of sentences and, hence, obtain better sentence embeddings. The achieved results show that our proposal is efficient, despite its simplicity, since models based on it overcome strong baselines by 3.76% in the worst case and by 8.71% in the best case.","llm_keywords":["Legal Rhetorical Role Labeling","Transformer models","sentence chunks","context exploitation","legal documents","semantic roles","RoBERTa","Longformer","sentence embeddings","pre-trained models"],"classifications":["Classification","Pre-Processing"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":8},{"id":"dedcb9defdb4a28e888b25b69c320dd1930564298bc05923f8bedbeea8f364e6891de8d69b206ff792d940470ffb921e18d8f44e03fc647e01182619834efc8a","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.119.pdf","title":"","llm_title":"Viettel-AI at SemEval-2023 Task 6: Legal Document Understanding with Longformer for Court Judgment Prediction with Explanation","authors":["Thanh Dat Hoang","Chi Minh Bui","Khac-Hoai Nam Bui"],"llm_authors":"Thanh Dat Hoang, Chi Minh Bui, and Khac-Hoai Nam Bui","author_string":"","year":2023,"abstract":"","llm_abstract":"Court Judgement Prediction with Explanation (CJPE) is a task in the field of legal analysis and evaluation, which involves predicting the outcome of a court case based on the available legal text and providing a detailed explanation of the prediction. This is an important task in the legal system as it can aid in decision-making and improve the efficiency of the court process. In this paper, we present a new approach to understanding legal texts, which are normally long documents, based on data-oriented methods. Specifically, we first try to exploit the characteristic of data to understand the legal texts. The output is then used to train the model using the Longformer architecture. Regarding the experiment, the proposed method is evaluated on the sub-task CJPE of the SemEval-2023 Task 6. Accordingly, our method achieves top 1 and top 2 on the classification task and explanation task, respectively. Furthermore, we present several open research issues for further investigations in order to improve the performance in this research field.","llm_keywords":["Court Judgment Prediction","Legal Document Understanding","Longformer","Transformer Models","Natural Language Processing","Explanation Generation","Machine Learning","Text Classification"],"classifications":["Classification","Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":7},{"id":"e61b56f7097b70ac103f4651c64bbf77129c8215878ac1c18c1f2cfbdcf61f7970c42b0f4072d7c1661d23bc4564321e0887f225815aac11d94187c28b839746","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.140.pdf","title":"","llm_title":"Transformers at SemEval-2024 Task 5: Legal Argument Reasoning Task in Civil Procedure using RoBERTa","authors":["Kriti Singhal","Jatin Bedi"],"llm_authors":"Kriti Singhal, Jatin Bedi","author_string":"","year":2024,"abstract":"","llm_abstract":"Legal argument reasoning task in civil procedure is a new NLP task utilizing a dataset from the domain of the U.S. civil procedure. The task aims at identifying whether the solution to a question in the legal domain is correct or not. This paper describes the team \"Transformers\" submission to the Legal Argument Reasoning Task in Civil Procedure shared task at SemEval-2024 Task 5. We use a BERT-based architecture for the shared task. The highest F1-score score and accuracy achieved was 0.6172 and 0.6531 respectively. We secured the 13th rank in the Legal Argument Reasoning Task in Civil Procedure shared task.","llm_keywords":["NLP","Legal Argument Reasoning","RoBERTa","Civil Procedure","SemEval-2024","BERT-based architecture","Legal NLP tasks","Data imbalance","Domain-specific adaptation","Transformer models"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":4},{"id":"b39d3f7468f6bfd2d2118b6e0ee2f1de3d62e2d6b8722aa72b15b38e3c731d65bd4b793649d0e5d2800e093b51a490f0559205cde202e1e6277cb5591b722f69","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.187.pdf","title":"","llm_title":"Team UTSA-NLP at SemEval 2024 Task 5: Prompt Ensembling for Argument Reasoning in Civil Procedures with GPT4","authors":["Dan Schumacher","Anthony Rios"],"llm_authors":"Dan Schumacher1and Anthony Rios2","author_string":"","year":2024,"abstract":"","llm_abstract":"In this paper, we present our system for the SemEval Task 5, The Legal Argument Reasoning Task in Civil Procedure Challenge. Legal argument reasoning is an essential skill that all law students must master. Moreover, it is important to develop natural language processing solutions that can reason about a question given terse domain-specific contextual information. Our system explores a prompt-based solution using GPT4 to reason over legal arguments. We also evaluate an ensemble of prompting strategies, including chain-of-thought reasoning and in-context learning. Overall, our system results in a Macro F1 of .8095 on the validation dataset and .7315 (5th out of 21 teams) on the final test set. Code for this project is available at https://github.com/danschumac1/CivilPromptReasoningGPT4.","llm_keywords":["legal argument reasoning","NLP","prompt-based solution","GPT4","in-context learning","chain-of-thought reasoning","SemEval Task 5","ensemble strategies"],"classifications":["Text Generation"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":9},{"id":"6b1f1853222e1a7fabdfb3fab0fb2f59c929177b5c5df9063d54e52110aad7eab4eb66a2dd9c62cc6fddb183e3d9e031fa612a27eb5e8e02c15949d75a888f63","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.189.pdf","title":"","llm_title":"NLP at UC Santa Cruz at SemEval-2024 Task 5: Legal Answer Validation using Few-Shot Multi-Choice QA","authors":["Anish Pahilajani","Samyak R Jain","Devasha Trivedi"],"llm_authors":"Anish Pahilajani, Samyak R Jain, Devasha Trivedi","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper presents our submission to the SemEval 2024 Task 5: The Legal Argument Reasoning Task in Civil Procedure. We present two approaches to solving the task of legal answer validation, given an introduction to the case, a question and an answer candidate. Firstly, we fine-tuned pre-trained BERT-based models and found that models trained on domain knowledge perform better. Secondly, we performed few-shot prompting on GPT models and found that reformulating the answer validation task to be a multiple-choice QA task remarkably improves the performance of the model. Our best submission is a BERT-based model that achieved the 7th place out of 20.","llm_keywords":["Legal NLP","Semantic Evaluation","Few-Shot Learning","Multi-Choice Question Answering","BERT","GPT Models","Legal Reasoning","Civil Procedure","NLP Systems"],"classifications":["Classification","Pre-Processing"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"54f9e55c83422647155faf470fed56dac482043469d862a23537e667191d3b88877e256fb6469f72af222eb53fb36e73bae4775dd74f261e0a85cf2090ad0207","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.173.pdf","title":"","llm_title":"ResearchTeam_HCN at SemEval-2023 Task 6: A knowledge enhanced transformers based legal NLP system","authors":["Dhanachandra Ningthoujam","Pinal Patel","Rajkamal Kareddula","Ramanand Vangipuram"],"llm_authors":"Dhanachandra Ningthoujam, Pinal Patel, Rajkamal Kareddula, Ramanand Vangipuram","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper presents our work on LegalEval (understanding legal text), one of the tasks in SemEval-2023. It comprises of three sub-tasks namely Rhetorical Roles (RR), Legal Named Entity Recognition (L-NER), and Court Judgement Prediction with Explanation (CJPE). We developed different deep-learning models for each sub-tasks. For RR, we developed a multi-task learning model with contextual sequential sentence classification as the main task and non-contextual single sentence prediction as the secondary task. Our model achieved an F1-score of 76.50% on the unseen test set, and we attained the 14th position on the leaderboard. For the L-NER problem, we have designed a hybrid model, consisting of a multi-stage knowledge transfer learning framework and a rule-based system. This model achieved an F1-score of 91.20% on the blind test set and attained the top position on the final leaderboard. Finally, for the CJPE task, we used a hierarchical approach and could get around 66.67% F1-score on judgment prediction and 45.83% F1-score on the explainability of the CJPE task, and we attained 8th position on the leaderboard for this sub-task.","llm_keywords":["Legal NLP","Semantic Evaluation","Rhetorical Roles","Legal Named Entity Recognition","Court Judgement Prediction","Deep Learning","Transformer Models","Legal Document Processing"],"classifications":["Classification","Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":9},{"id":"8dc6abc008c91d079c3a8b2849613bed8e52ddb198cfe869ca8741e1a8640fee534e3e86f8ec6456d882586753fdce9ae3cfbba0ad7df5b4d462caf985449ffb","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.20.pdf","title":"","llm_title":"LRL_NC at SemEval-2023 Task 6: Sequential Sentence Classification for Legal Documents using Topic Modeling Features","authors":["Kushagri Tandon","Niladri Chatterjee"],"llm_authors":"Kushagri Tandon, Niladri Chatterjee","author_string":"","year":2023,"abstract":"","llm_abstract":"Natural Language Processing techniques can be leveraged to process legal proceedings for various downstream applications, such as summarization of a given judgement, prediction of the judgement for a given legal case, precedent search, among others. These applications will benefit from legal judgement documents already segmented into topically coherent units. The current task, namely, Rhetorical Role Prediction, aims at categorising each sentence in the sequence of sentences in a judgement document into different labels. The system proposed in this work combines topic modeling and RoBERTa to encode sentences in each document. A BiLSTM layer has been utilised to get contextualised sentence representations. The Rhetorical Role predictions for each sentence in each document are generated by a final CRF layer of the proposed neuro-computing system. This system secured the rank 12 in the official task ranking, achieving the micro-F1 score 0.7980. The code for the proposed systems has been made available at https://github.com/KushagriT/SemEval23_LegalEval_TeamLRL_NC","llm_keywords":["legal documents","NLP","rhetorical role prediction","sequential sentence classification","topic modeling","RoBERTa","BiLSTM","CRF","judgment summarization","precedent search"],"classifications":["Classification","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":7},{"id":"df2b60d2214b32f3a2699c6478f7ffcdc673900fdd5a6dc2377c2ffd59dc40da0d379673835f144e66950ea44412b54349c474dea2c536a00bcbddc923793ec5","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.152.pdf","title":"","llm_title":"DUTh at SemEval 2024 Task 5: A multi-task learning approach for the Legal Argument Reasoning Task in Civil Procedure","authors":["Ioannis Maslaris","Avi Arampatzis"],"llm_authors":"Ioannis Maslaris, Avi Arampatzis","author_string":"","year":2024,"abstract":"","llm_abstract":"Text-generative models have proven to be good reasoners. Although reasoning abilities are mostly observed in larger language models, a number of strategies try to transfer this skill to smaller language models. This paper presents our approach to SemEval 2024 Task-5: The Legal Argument Reasoning Task in Civil Procedure. This shared task aims to develop a system that efficiently handles a multiple-choice question-answering task in the context of the US civil procedure domain. The dataset provides a human-generated rationale for each answer. Given the complexity of legal issues, this task certainly challenges the reasoning abilities of LLMs and AI systems in general. Our work explores fine-tuning an LLM as a correct/incorrect answer classifier. In this context, we are making use of multi-task learning to incorporate the rationales into the fine-tuning process.","llm_keywords":["Large Language Models","Legal Argument Reasoning","Multi-task Learning","Question Answering","Fine-tuning","Rationales","Civil Procedure","LegalBERT"],"classifications":["Text Generation","Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"5c38c0482f06b8f76ef27e732985ff8731960253a575b27d7522b05f6812b845df8eca0e3a53091ef6912382f3e20373f894240b9580e0c38ee7c715df877088","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.56.pdf","title":"","llm_title":"VTCC-NER at SemEval-2023 Task 6: An Ensemble Pre-trained Language Models for Named Entity Recognition","authors":["Quang-Minh Tran","Xuan-Dung Doan"],"llm_authors":"Quang-Minh Tran, Xuan-Dung Doan","author_string":"","year":2023,"abstract":"","llm_abstract":"We propose an ensemble method that combines several pre-trained language models to enhance entity recognition in legal text. Our approach achieved a 90.9873% F1 score on the private test set, ranking 2nd on the leaderboard for SemEval 2023 Task 6, Subtask B - Legal Named Entities Extraction. Our code is available for further exploitation at: https://github.com/tqgminh/SemEval2023_LegalNER_VTCC.","llm_keywords":["Named Entity Recognition","pre-trained language models","legal text","SemEval 2023","ensemble method","F1 score","legal domain","CRF","dependency parsing"],"classifications":["Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":5},{"id":"fb53c3ceaf4764c306f5e533c6c1dd20664c15ff5e0dfe3e4c55bb38445a958f7d12f4daf1877cd26743ae4985c3d96205d7c41192223c27c5d39893e31c3b10","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.35.pdf","title":"","llm_title":"TüReuth Legal at SemEval-2023 Task 6: Modelling Local and Global Structure of Judgements for Rhetorical Role Prediction","authors":["Henrik Manegold","Leander Girrbach"],"llm_authors":"Henrik Manegold, Leander Girrbach","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper describes our system for SemEval-2023 Task 6: LegalEval: Understanding Legal Texts. We only participate in Sub-Task (A), Predicting Rhetorical Roles. Our final submission achieves 73.35 test set F1 score, ranking 17th of 27 participants. The proposed method combines global and local models of label distributions and transitions between labels. Through our analyses, we show that especially modelling the temporal distribution of labels contributes positively to performance.","llm_keywords":["Semantic Evaluation","Legal Texts","Rhetorical Role Prediction","Natural Language Processing","Machine Learning","Language Models","Document Structure","Law","Text Analysis"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":8},{"id":"0121f31c555a9866d8ed5abbe0c5de3c0ebfe5c14d84fe82e7496547d8050a8bee4a5aa75fe125d8fdfb949e02739b12667b3a1fba10bd4aa4611d987b7faf60","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.72.pdf","title":"","llm_title":"TeamShakespeare at SemEval-2023 Task 6: Understand Legal Documents with Contextualized Large Language Models","authors":["Xin Jin","Yuchen Wang"],"llm_authors":"Xin Jin, Yuchen Wang","author_string":"","year":2023,"abstract":"","llm_abstract":"The growth of pending legal cases in populous countries, such as India, has become a major issue. Developing effective techniques to process and understand legal documents is extremely useful in resolving this problem. In this paper, we present our systems for SemEval-2023 Task 6: understanding legal texts (Modi et al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that considers the comprehensive context information in both intra- and inter-sentence levels to predict rhetorical roles (subtask A) and then train a Legal-LUKE model, which is legal-contextualized and entity-aware, to recognize legal entities (subtask B). Our evaluations demonstrate that our designed models are more accurate than baselines, e.g., with an up to 15.0% better F1 score in subtask B. We achieved notable performance in the task leaderboard, e.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.","llm_keywords":["Legal documents","Natural Language Processing","Semantic Evaluation","Large Language Models","Rhetorical Role Prediction","Named Entity Recognition","Legal-BERT-HSLN","Legal-LUKE"],"classifications":["Classification","Information Extraction"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":9},{"id":"9757edd8ff3a6709fd2148b02ff8220ac8059e0cbbfe4876dd4abed1a685694217e07a8655d658857c8cecfb811f10334abcc7ee131ab4470aa2c4f1c123530c","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.144.pdf","title":"","llm_title":"MAINDZ at SemEval-2024 Task 5: CLUEDO - Choosing Legal oUtcome by Explaining Decision through Oversight","authors":["Irene Benedetto","Alkis Koudounas","Lorenzo Vaiani","Eliana Pastor","Luca Cagliero","Francesco Tarasconi"],"llm_authors":"Irene Benedetto, Alkis Koudounas, Lorenzo Vaiani, Eliana Pastor, Luca Cagliero, Francesco Tarasconi","author_string":"","year":2024,"abstract":"","llm_abstract":"Large language models (LLMs) have recently obtained strong performance on complex reasoning tasks. However, their capabilities in specialized domains like law remain relatively unexplored. We present CLUEDO, a system to tackle a novel legal reasoning task that involves determining if a provided answer correctly addresses a legal question derived from U.S. civil procedure cases. CLUEDO utilizes multiple collaborator models that are trained using multiple-choice prompting to choose the right label and generate explanations. These collaborators are overseen by a final \"detective\" model that identifies the most accurate answer in a zero-shot manner. Our approach achieves an F1 macro score of 0.74 on the development set and 0.76 on the test set, outperforming individual models. Unlike the powerful GPT-4, CLUEDO provides more stable predictions thanks to the ensemble approach. Our results showcase the promise of tailored frameworks to enhance legal reasoning capabilities in LLMs.","llm_keywords":["legal reasoning","large language models","multiple-choice prompting","ensemble models","U.S. civil procedure","semantic evaluation","zero-shot learning","machine learning","natural language processing","legal applications"],"classifications":["Classification","Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":9},{"id":"d4a767f839ea0e964373d6312012fdf6dba61e5ac6b53c6357788946f5ff97e6a0e1fa2b31c3d37329c037f2d5fcca98b1972837560996ff9c9db6d9c7be377e","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.276.pdf","title":"","llm_title":"SemEval-2024 Task 5: Argument Reasoning in Civil Procedure","authors":["Lena Held","Ivan Habernal"],"llm_authors":"Lena Held and Ivan Habernal","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper describes the results of SemEval\u0002-2024 Task 5: Argument Reasoning in Civil Pro\u0002cedure, consisting of a single task on judging and reasoning about the answers to questions in U.S. civil procedure. The dataset for this task contains question, answer and explanation pairs taken from The Glannon Guide To Civil Procedure (Glannon, 2018). The task was to classify in a binary manner if the answer is a correct choice for the question or not. Twenty participants submitted their solutions, with the best results achieving a remarkable 82.31% F1- score. We summarize and analyze the results from all participating systems and provide an overview over the systems of 14 participants.","llm_keywords":["argument reasoning","civil procedure","legal question answering","SemEval-2024","dataset analysis","U.S. law","machine learning"],"classifications":["Classification"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":12},{"id":"4175fa8528f329102d25c88bfc1da6b052adb64ce20bc5b580c0c9455d51009d1afa35ae812ec9145b1e6c74b7d546e3eba1b81ddb8683a1c674338d0764a666","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.57.pdf","title":"","llm_title":"Ginn-Khamov at SemEval-2023 Task 6, Subtask B: Legal Named Entities Extraction for Heterogenous Documents","authors":["Michael Ginn","Roman Khamov"],"llm_authors":"Michael Ginn and Roman Khamov","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper describes our submission to SemEval-2023 Task 6, Subtask B, a shared task on performing Named Entity Recognition in legal documents for specific legal entity types. Documents are divided into the preamble and judgement texts, and certain entity types should only be tagged in one of the two text sections. To address this challenge, our team proposes a token classification model that is augmented with information about the document type, which achieves greater performance than the non-augmented system.","llm_keywords":["Named Entity Recognition","Legal documents","Token classification","Augmentation","Legal domain","Pretrained language model","LegalBERT","RoBERTa"],"classifications":["Classification","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"8f5fe41f2c9655ab4fdbc686746cd361c3d63c7230af146fc7516ef3e95a8abb3b7fcb0926185029178d3eccc7d4a470bbb3d61d7400b854d1ce964762d7a400","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.103.pdf","title":"","llm_title":"NITS_Legal at SemEval-2023 Task 6: Rhetorical Roles Prediction of Indian Legal Documents via Sentence Sequence Labeling Approach","authors":["Deepali Jain","Malaya Dutta Borah","Anupam Biswas"],"llm_authors":"Deepali Jain, Malaya Dutta Borah, Anupam Biswas","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal documents are notorious for their complexity and domain-specific language, making them challenging for legal practitioners as well as non-experts to comprehend. To address this issue, the LegalEval 2023 track proposed several shared tasks, including the task of Rhetorical Roles Prediction (Task A). We participated as NITS_Legal team in Task A and conducted exploratory experiments to improve our understanding of the task. Our results suggest that sequence context is crucial in performing rhetorical roles prediction. Given the lengthy nature of legal documents, we propose a BiLSTM-based sentence sequence labeling approach that uses a local context-incorporated dataset created from the original dataset. To better represent the sentences during training, we extract legal domain-specific sentence embeddings from a Legal BERT model. Our experimental findings emphasize the importance of considering local context instead of treating each sentence independently to achieve better performance in this task. Our approach has the potential to improve the accessibility and usability of legal documents.","llm_keywords":["Rhetorical roles","Legal documents","Sentence sequence labeling","Legal BERT","BiLSTM","Contextual embeddings","LegalEval 2023","Document comprehension"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":7},{"id":"41aca800b6cfabbda7b8c371bd5b69d574020f9520eff2c3a2d9274261195a79fe3d87ac969ccbe6311b42e55248a0684c03060c6909b035b198e291fc04b838","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.255.pdf","title":"","llm_title":"HW-TSC at SemEval-2024 Task 5: Self-Eval? A Confident LLM System for Auto Prediction and Evaluation for the Legal Argument Reasoning Task","authors":["Xiaofeng Zhao","Xiaosong Qiao","Min Zhang","Chang Su","Yuang Li","Yinglu Li","Yilun Liu","Feiyu Yao","Xiaowei Liang","Shimin Tao","Hao Yang","Yanfei Jiang","Yunfei Lu","Dandan Tu"],"llm_authors":"Xiaofeng Zhao, Xiaosong Qiao, Min Zhang, Chang Su, Yuang Li, Yinglu Li, Yilun Liu, Feiyu Yao, Xiaowei Liang, Shimin Tao, Hao Yang, Yanfei Jiang, Yunfei Lu, Dandan Tu","author_string":"","year":2024,"abstract":"","llm_abstract":"In this article, we present an effective system for semeval-2024 task 5. The task involves assessing the feasibility of a given solution in civil litigation cases based on relevant legal provisions, issues, solutions, and analysis. This task demands a high level of proficiency in U.S. law and natural language reasoning. In this task, we designed a self-eval LLM system that simultaneously performs reasoning and self-assessment tasks. We created a confidence interval and a prompt instructing the LLM to output the answer to a question along with its confidence level. We designed a series of experiments to prove the effectiveness of the self-eval mechanism. In order to avoid the randomness of the results, the final result is obtained by voting on three results generated by the GPT-4. Our submission was conducted under zero-resource setting, and we achieved first place in the task with an F1-score of 0.8231 and an accuracy of 0.8673.","llm_keywords":["SemEval-2024","legal argument reasoning","GPT-4","zero-resource setting","self-evaluation","confidence interval","U.S. law","natural language processing","large language models"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":5},{"id":"656da50dc15a900dc7808a2f8599aad318c663ddf11c72130a445f6223549275916b54f8678dcc6df49ea9b8ec5a72217e509d24b7056ffc581e3b9ec80fa8ee","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.229.pdf","title":"","llm_title":"Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure","authors":["Odysseas Chlapanis","Ion Androutsopoulos","Dimitrios Galanis"],"llm_authors":"Odysseas S. Chlapanis, Ion Androutsopoulos, Dimitrios Galanis","author_string":"","year":2024,"abstract":"","llm_abstract":"The SemEval task on Argument Reasoning in Civil Procedure is challenging in that it requires understanding legal concepts and inferring complex arguments. Currently, most Large Language Models (LLM) excelling in the legal realm are principally purposed for classification tasks, hence their reasoning rationale is subject to contention. The approach we advocate involves using a powerful teacher-LLM (ChatGPT) to extend the training dataset with explanations and generate synthetic data. The resulting data are then leveraged to fine-tune a small student-LLM. Contrary to previous work, our explanations are not directly derived from the teacher’s internal knowledge. Instead they are grounded in authentic human analyses, therefore delivering a superior reasoning signal. Additionally, a new ‘mutation’ method generates artificial data instances inspired from existing ones. We are publicly releasing the explanations as an extension to the original dataset, along with the synthetic dataset and the prompts that were used to generate both. Our system ranked 15th in the SemEval competition. It outperforms its own teacher and can produce explanations aligned with the original human analyses, as verified by legal experts.","llm_keywords":["Semantic Evaluation","Large Language Models","Civil Procedure","Data Augmentation","Legal Reasoning","Teacher-Student Framework","Synthetic Data","Klaxon Rule","Chain-of-Thought Explanations"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":16},{"id":"005845e55d7808eed1d40e7b3ad05a9b9dc3b6062b011ccbc7347c018d9c2d30cbf08b2a8f650c4bb97141581c26852a9778c6d824982cdf479c835032e10fbf","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.160.pdf","title":"","llm_title":"NITK_LEGAL at SemEval-2023 Task 6: A Hierarchical based system for identification of Rhetorical Roles in legal judgements","authors":["Patchipulusu Sindhu","Diya Gupta","Sanjeevi Meghana","Anand Kumar M"],"llm_authors":"Patchipulusu Sindhu and Diya Gupta and Sanjeevi Meghana and Anand Kumar M","author_string":"","year":2023,"abstract":"","llm_abstract":"The ability to automatically recognise the rhetorical roles of sentences in a legal case judgement is a crucial challenge to tackle since it can be useful for a number of activities that come later, such as summarising legal judgements and doing legal searches. The task is exigent since legal case documents typically lack structure, and their rhetorical roles could be subjective. This paper describes SemEval-2023 Task 6: LegalEval: Understanding Legal Texts, Sub-task A: Rhetorical Roles Prediction (RR). We propose a system to automatically generate rhetorical roles of all the sentences in a legal case document using Hierarchical Bi-LSTM CRF model and RoBERTa transformer. We also showcase different techniques used to manipulate dataset to generate a set of varying embeddings and train the Hierarchical Bi-LSTM CRF model to achieve better performance. Among all, model trained with the sent2vec embeddings concatenated with the handcrafted features perform better with the micro f1-score of 0.74 on test data. The dataset utilised in our task is available at 1.","llm_keywords":["Rhetorical roles","Legal documents","Semantic evaluation","Hierarchical Bi-LSTM CRF","RoBERTa","Sent2vec","Micro F1-score","Indian court judgements","LegalEval","Text summarization"],"classifications":["Classification","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":7},{"id":"22a25c286e85ef5ad3f389bf46abf504d655da3b370181a28f03731b2a710009bb2d2c12c20af21a245c0ccf50b14652001541710f3686c2dcfc4201c3c0f4f0","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2023.semeval-1.155.pdf","title":"","llm_title":"VTCC-NLP at SemEval-2023 Task 6: Long-Text Representation Based on Graph Neural Network for Rhetorical Roles Prediction","authors":["Huu Hiep Nguyen","Hoang Ngo","Khac-Hoai Nam Bui"],"llm_authors":"Huu Hiep Nguyen, Hoang Ngo, Khac-Hoai Nam Bui","author_string":"","year":2023,"abstract":"","llm_abstract":"Rhetorical Roles (RR) prediction is to predict the label of each sentence in legal documents, which is regarded as an emergent task for legal document understanding. In this study, we present a novel method for the RR task by exploiting the long context representation. Specifically, legal documents are known as long texts, in which previous works have no ability to consider the inherent dependencies among sentences. In this paper, we propose GNNRR (Graph Neural Network for Rhetorical Roles Prediction), which is able to model the cross-information for long texts. Furthermore, we develop multitask learning by incorporating label shift prediction (LSP) for segmenting a legal document. The proposed model is evaluated on the SemEval 2023 Task 6 - Legal Eval Understanding Legal Texts for RR sub-task. Accordingly, our method achieves the top 4 in the public leaderboard of the sub-task. Our source code is available for further investigation.","llm_keywords":["Rhetorical Roles","Graph Neural Network","Legal Document Understanding","Multitask Learning","Semantic Evaluation"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"ee915c09f8dc49eb55649e051349c27f06dcdbced9feb534bcc7d7a79b2136e253c502556f4bc85775dae26293dbf37780408d149331d574158f385326b52531","file_path":"legal-nlp-survey-20250328-002/team 2/12 Lexical and Computational Semantics and Semantic Evaluation (formerly Workshop on Sense Evaluation) (SemEval)/2024.semeval-1.80.pdf","title":"","llm_title":"ignore at SemEval-2024 Task 5: A Legal Classification Model with Summary Generation and Contrastive Learning","authors":["Binjie Sun","Xiaobing Zhou"],"llm_authors":"Binjie Sun and Xiaobing Zhou","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper describes our work for SemEval-2024 Task 5: The Legal Argument Reasoning Task in Civil Procedure. After analyzing the task requirements and the training dataset, we used data augmentation, adopted the large model GPT for summary generation, and added supervised contrastive learning to the basic BERT model. Our system achieved an F1 score of 0.551, ranking 14th in the competition leaderboard. Our system achieves an F1 score improvement of 0.1241 over the official baseline model.","llm_keywords":["Legal Classification","Summary Generation","Contrastive Learning","Legal-BERT","NLP","Data Augmentation","Semantic Evaluation","Legal Argumentation","Civil Procedure"],"classifications":["Machine Summarization","Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"9d5da034ac206fdbccfc7baf9bc8fd28938197e6304248902f5a24fdb2cee54a7f60e86dbdf673c0bdf104ac60a4d740ca11c67fc3e1f840da7d8aae45a69df0","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper13.pdf","title":"Case\\protect \\discretionary {\\char \\hyphenchar \\font }{}{}Scope: An Enhanced Search Tool for European Court Cases","llm_title":"CaseScope: An Enhanced Search Tool for European Court Cases","authors":["Alexandre Correia","Pedro Evangelista","Nádia Soares","Eugénio Rocha","Cláudio Teixeira"],"llm_authors":"Alexandre Correia, Pedro Evangelista, Nádia Soares, Eugénio Rocha, Cláudio Teixeira","author_string":"","year":2023,"abstract":"","llm_abstract":"Natural Language Processing (NLP) is a rapidly growing field of research, enabled by advances in computer power and deep learning models. As a subfield of Artificial Intelligence, NLP can help with tasks such as Named Entity Recognition and Sentiment Analyses by extracting meaningful connections between words from a text. New architectures for neural networks like transformers have been responsible for a great increase in performance at these tasks. These improvements motivated this work, where we look into the extraction of information from legal documents in the CURIA database to develop CaseScope, a search tool that presents users with filters that are machine-generated for court cases from the European Union. Besides enhancing CaseScope’s search space with NLP techniques, we also provide a faster way to understand if a case is relevant to the user’s search by presenting generated summaries of documents produced with recent models. Main differences between CaseScope and currently available legal search tools are also compared. Features described in this work were developed with a multidisciplinary team, with expertise in many fields, including legal. Throughout our work, we present how CaseScope is built, from data collection to the search interface, to give a better insight into our approach to each step of creating CaseScope.","llm_keywords":["Natural language processing","artificial intelligence","legal search assistance","information extraction","keywords extraction","summarization"],"classifications":["Information Extraction","Information Retrieval","Machine Summarization"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":7},{"id":"264bc4cf451ceb5de49717d82efd14a9c05c42aa6283d44bb4ad81642cf10dfe766969b2135238f245be4920cb0356949ed873928d25b290501c6c2b3739119f","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper14.pdf","title":"Toward Implementation Science: A Case Study Using LA-MPS to Research Argument Elements at Scale","llm_title":"Toward Implementation Science: A Case Study Using LA-MPS to Research Argument Elements at Scale","authors":["Vern Walker","Stephen Strong"],"llm_authors":"Vern R. Walker, Stephen R. Strong","author_string":"","year":2023,"abstract":"","llm_abstract":"Access to justice can increase only if AI tools developed in laboratory settings are implemented at scale to address real-world problems. This paper urges the development of implementation science for AI and law—a set of principles and methods to facilitate and study the transfer of AI techniques and tools to real-world use cases. The paper contributes to this development by reporting a case study using LA-MPS, an innovative software application (Legal Apprentice, or “LA”) for reading, searching, and annotating legal decisions, which currently consists of three integrated web applications: Marker, Pad, and Search. LA-MPS is open-source, free, and adaptable to different legal domains, and it is deployable both locally (edge-centric) and through cloud servers. The case study uses decisions issued by the U.S. Board of Veterans’ Appeals (BVA) that adjudicate disability benefits. The case study simulates the workflow of standard legal research, conducted on a large dataset of unread but automatically annotated legal decisions (10,003 BVA decisions, containing 1,360,230 sentences). Two primary experiments were conducted. First, we used semantic auto-labeling to filter out a subset of 449 decisions (100,514 sentences) that deal with post-traumatic stress disorder (PTSD), and we evaluated auto-labeling accuracy using a stratified random sample (25 decisions, containing 5,529 sentences). Second, we conducted semantic searches on the set of 449 decisions to identify scenarios in which non-VA evidence prevailed over conflicting VA evidence. The case study is designed to demonstrate the feasibility of implementing currently available machine learning (ML) models at scale, to employ scientific methods to compare results at scale with laboratory results, and to evaluate the real-world results based on practical usefulness. The paper discusses the generalizability of these methods for implementation science. The software code and case study datasets are made available to the public.","llm_keywords":["implementation","dissemination","argument mining","legal decision annotation","sentence rhetorical role","automated semantic analysis"],"classifications":["Classification","Information Retrieval","Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":12},{"id":"7fccfd66b612e060a93894f26ea19670269ce7ee291eb276d0ed9da1261100fd5e3a108b1a5944b3e1b517305a063e6ee22066156814ab44917b75acee708179","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper3.pdf","title":"Enhancing Pre-Trained Language Models with Sentence Position Embeddings for Rhetorical Roles Recognition in Legal Opinions","llm_title":"Enhancing Pre-Trained Language Models with Sentence Position Embeddings for Rhetorical Roles Recognition in Legal Opinions","authors":["Anas Belfathi","Nicolas Hernandez","Laura Monceaux"],"llm_authors":"Anas Belfathi, Nicolas Hernandez, Laura Monceaux","author_string":"","year":2023,"abstract":"","llm_abstract":"The legal domain is a vast and complex field that involves a considerable amount of text analysis, including laws, legal arguments, and legal opinions. Legal practitioners must analyze these texts to understand legal cases, research legal precedents, and prepare legal documents. The size of legal opinions continues to grow, making it increasingly challenging to develop a model that can accurately predict the rhetorical roles of legal opinions given their complexity and diversity. In this research paper, we propose a novel model architecture for automatically predicting rhetorical roles using pre-trained language models (PLMs) enhanced with knowledge of sentence position information within a document. Based on an annotated corpus from the LegalEval@SemEval2023 competition, we demonstrate that our approach requires fewer parameters, resulting in lower computational costs when compared to complex architectures employing a hierarchical model in a global-context, yet it achieves great performance. Moreover, we show that adding more attention to a hierarchical model based only on BERT in the local-context, along with incorporating sentence position information, enhances the results.","llm_keywords":["Pre-trained language models","Discourse structure modeling","Legal Opinions","Sentence Positional Embeddings","Rhetorical Role","Sequence Labelling"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":9},{"id":"b122665c05067ec920a1e6cbd0b3951030e90fac4d33976c393fcf053e238b17a1047be467a999d7e5b2f4ce56981e92e1b6b879b449446c883dbc446bf51f40","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper4.pdf","title":"Automatic Rhetorical Roles Classification for Legal Documents using LEGAL-TransformerOverBERT","llm_title":"Automatic Rhetorical Roles Classification for Legal Documents using LEGAL-TransformerOverBERT","authors":["Gabriele Marino","Daniele Licari","Praveen Bushipaka","Giovanni Comandé","Tommaso Cucinotta"],"llm_authors":"Gabriele Marino, Daniele Licari, Praveen Bushipaka, Giovanni Comandé, Tommaso Cucinotta","author_string":"","year":2023,"abstract":"","llm_abstract":"Automatic identification of rhetorical roles can help in many downstream applications of legal documents analysis, such as legal decisions summarization and legal search. This is usually a complex task, even for humans, due to its inherent subjectivity and to the difficulty of capturing sentence context in very long legal documents. We propose a novel approach, based on Hierarchical Transformers, which overcomes these problems and achieves promising results on two different datasets of Italian and English legal judgments. Specifically, we introduce LEGAL-TransformerOverBERT (LEGAL-ToBERT), a model based on the stacking of a transformer encoder over a legal-domain-specific BERT model, and show that our approach is able to significantly improve the baselines set by the stand-alone LEGAL-BERT models, by capturing the relationships between different sentences of the same document. We make our models available and ready-to-use for downstream applications of rhetorical roles classification in the legal context both for the Italian and English language.","llm_keywords":["Rhetorical Roles Classification","LEGAL-BERT","Hierarchical Transformers","LEGAL-ToBERT","legal NLP","machine learning","transformer models","BERT","sentence classification"],"classifications":["Classification","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":9},{"id":"60b6a262774acb8017d79d306c536c82c4d9a4e38c4dd6102b2cf448a5b2e59b2d1e93c4e78225bd046b5984cbfba337613d20092b315165cded2522c2fc21a6","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper15.pdf","title":"Argumentative Segmentation Enhancement for Legal Summarization","llm_title":"Argumentative Segmentation Enhancement for Legal Summarization","authors":["Huihui Xu","Kevin Ashley"],"llm_authors":"Huihui Xu, Kevin Ashley","author_string":"","year":2023,"abstract":"","llm_abstract":"We use the combination of argumentative zoning [1] and a legal argumentative scheme to create legal argumentative segments. Based on the argumentative segmentation, we propose a novel task of classifying argumentative segments of legal case decisions. GPT-3.5 is used to generate summaries based on argumentative segments. In terms of automatic evaluation metrics, our method generates higher quality argumentative summaries while leaving out less relevant context as compared to GPT-4 and non-GPT models.","llm_keywords":["legal summarization","natural language processing","neural networks","argument mining","GPT-3.5","argumentative zoning","legal argumentative segments"],"classifications":["Classification","Machine Summarization"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":10},{"id":"7c58e3cb80223777a64d8b2b386579d7953ddeea35d87d7666c381996504042fdfd0d463641db48d338c20b238e56675877a766d97a7e2bbcc63843876d7e537","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper12.pdf","title":"LexKey: A Keyword Generator for Legal Documents","llm_title":"LexKey: A Keyword Generator for Legal Documents","authors":["Benjamin Cérat","Olivier Salaün","Noreddine Ben Jillali","Marc-André Morissette","Isabela Pocovnicu","Emma Elliott","François Harvey"],"llm_authors":"Benjamin Cérat, Olivier Salaün, Noreddine Ben Jillali, Marc-André Morissette, Isabela Pocovnicu, Emma Elliott, François Harvey","author_string":"","year":2023,"abstract":"","llm_abstract":"Recent advances in natural language processing like large pre-trained transformer models have opened up a host of previously out-of-reach automation even to small businesses. The LexKey project is one such initiative, assembling a large dataset of annotated decisions from various sources and training an abstractive generative model that produces useful and well-formatted keywords from legal texts. We present the challenges involved and the steps taken to achieve this goal, from data cleaning to modifying an existing model architecture to handle long legal documents to the evaluation, both quantitative and qualitative, of the output.","llm_keywords":["legal dataset","generative neural networks","keywords generation","long documents"],"classifications":["Resources","Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":12},{"id":"c612fca78430525bb1214a964603f576f540b231acffcd6c1b112d85e91f54afa2afa04c36ea208869c210bdced8e7410c3b2209f1af6ba4241aa9b0f403afdc","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper5.pdf","title":"Bridging the Gap: Mapping Layperson Narratives to Legal Issues with Language Models","llm_title":"Bridging the Gap: Mapping Layperson Narratives to Legal Issues with Language Models","authors":["Hannes Westermann","Sébastien Meeùs","Mia Godet","Aurore Troussel","Jinzhe Tan","Jaromir Savelka","Karim Benyekhlef"],"llm_authors":"Hannes Westermann, Sébastien Meeùs, Mia Godet, Aurore Troussel, Jinzhe Tan, Jaromir Savelka, Karim Benyekhlef","author_string":"","year":2023,"abstract":"","llm_abstract":"Individuals without legal training (i.e., laypeople) typically tend to perceive their situation through facts, i.e., events that occur. Understanding which legal opportunities or remedies are available to them requires an analysis of which legal issues are raised by these facts, which may be difficult for laypeople to assess. This “gap” can cause laypeople to miss out on benefits or be unable to resolve their disputes. In this paper, we propose an approach to automatically analyze a factual description provided by a layperson in order to map it to potentially relevant legal issues. The system then suggests the issues to the user who may decide if and how to explore them. We demonstrate how this approach could be integrated in legal decision support tools, such as the JusticeBot, to guide users to the relevant guided pathways, while giving the user the possibility to verify the results. This has the potential to further increase the impact on access to justice of such tools. We evaluated the approach on real-world data collected in the JusticeBot project, and found that the system was able to identify the relevant legal issue in 93.5% of selected cases. Our findings can be leveraged by legal professionals and developers of legal decision support systems to alleviate the challenges related to bridging the gap between layperson language and legal issues.","llm_keywords":["JusticeBot","Access to Justice","Augmented Intelligence","Language Models","Sentence Embeddings","Human-computer interaction"],"classifications":["Classification","Pre-Processing"],"num_cited_by":15,"num_cited_by_title_only":16,"num_pages":12},{"id":"81cd6ce7bcd5458cc0e6d61237b12be61917ea5109787556663fcf69de73734eaf1388e12cb26f5d9b677f47a142053bf785809722cf9abb08fec851cbd276ed","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper2.pdf","title":"Towards Meaningful Paragraph Embeddings for Data-Scarce Domains: A Case Study in the Legal Domain","llm_title":"Towards Meaningful Paragraph Embeddings for Data-Scarce Domains: A Case Study in the Legal Domain","authors":["Elize Herrewijnen","Dennis F W Craandijk"],"llm_authors":"Elize Herrewijnen, Dennis F W Craandijk","author_string":"","year":2023,"abstract":"","llm_abstract":"Creating meaningful text embeddings using BERT-based language models involves pre-training on large amounts of data. For domain-specific use cases where data is scarce (e.g., the law enforcement domain) it might not be feasible to pre-train a whole new language model. In this paper, we examine how extending BERT-based tokenizers and further pre-training BERT-based models can benefit downstream classification tasks. As a proxy for domain-specific data, we use the European Convention of Human Rights (ECtHR) dataset. We find that for down-stream tasks, further pre-training a language model on a small domain dataset can rival models that are completely retrained on large domain datasets. This indicates that completely retraining a language model may not be necessary to improve down-stream task performance. Instead, small adaptions to existing state-of-the-art language models like BERT may suffice.","llm_keywords":["Transformers","BERT","Language Models","Legal Text Classification","ECtHR dataset","Text Embeddings"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"569cc6e5577a5d7fdf195394a0478e69a866f84032e8642e87ebadae12173049c58ebf35b27eb17798e3e968e01967e5782a6ce7140171ee6c2a2eb164ea7470","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper1.pdf","title":"Can GPT-4 Support Analysis of Textual Data in Tasks Requiring Highly Specialized Domain Expertise?","llm_title":"Can GPT-4 Support Analysis of Textual Data in Tasks Requiring Highly Specialized Domain Expertise?","authors":["Jaromir Savelka","Kevin D. Ashley","Morgan A. Gray","Hannes Westermann","Huihui Xu"],"llm_authors":"Jaromir Savelka, Kevin D. Ashley, Morgan A. Gray, Hannes Westermann, Huihui Xu","author_string":"","year":2023,"abstract":"","llm_abstract":"We evaluated the capability of generative pre-trained transformers (GPT-4) in analysis of textual data in tasks that require highly specialized domain expertise. Specifically, we focused on the task of analyzing court opinions to interpret legal concepts. We found that GPT-4, prompted with annotation guidelines, performs on par with well-trained law student annotators. We observed that, with a relatively minor decrease in performance, GPT-4 can perform batch predictions leading to significant cost reductions. However, employing chain-of-thought prompting did not lead to noticeably improved performance on this task. Further, we demonstrated how to analyze GPT-4’s predictions to identify and mitigate deficiencies in annotation guidelines, and subsequently improve the performance of the model. Finally, we observed that the model is quite brittle, as small formatting related changes in the prompt had a high impact on the predictions. These findings can be leveraged by researchers and practitioners who engage in semantic/pragmatic annotations of texts in the context of the tasks requiring highly specialized domain expertise.","llm_keywords":["GPT-4","legal analysis","court opinions","annotation guidelines","chain-of-thought prompting","batch predictions","model brittleness","semantic annotation","generative pre-trained transformers"],"classifications":["Information Retrieval","Information Extraction","Text Generation","Resources","Classification"],"num_cited_by":61,"num_cited_by_title_only":61,"num_pages":12},{"id":"abc7cb8cd8163abdd4adb1d9ef375269040f227a65d4ac5bc86b6e3ce155b97de181cabf5d397602d1394b32b44a7cf8d1720e6536701d3cf085c8f75f2869d9","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper6.pdf","title":"Taking the Law More Seriously by Investigating Design Choices in Machine Learning Prediction Research","llm_title":"Taking the Law More Seriously by Investigating Design Choices in Machine Learning Prediction Research","authors":["Cor Steging","Silja Renooij","Bart Verheij"],"llm_authors":"Cor Steging, Silja Renooij, Bart Verheij","author_string":"","year":2023,"abstract":"","llm_abstract":"Approaches to court case prediction using machine learning differ widely with varying levels of success and legal reasonableness. In part this is due to some aspects of law, such as justification, being inherently difficult for machine learning approaches. Another aspect is the effect of design choices and the extent to which these are legally reasonable, which has not yet been extensively studied. We create four machine learning models tasked with predicting cases from the European Court of Human Rights and we perform experiments in order to measure the role of the following four design choices and effects: the choice of performance metric; the effect of including different parts of the legal case; the effect of a more or less specialized legal focus; and the temporal effects of the available past legal decisions. Through this research, we aim to study design decisions and their limitations and how they affect the performance of machine learning models.","llm_keywords":["court case prediction","design choices","machine learning","legal domain","European Court of Human Rights","performance metrics","BERT model","SVM","Naive Bayes","Random Forest"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"846398b278e2feb94d5619149114ed874aad0bcf78e73a452b4e6b51eb20470cd2820c1bbe50b2c9fc1e8cbb19189c8a3ddf1359f5a23968f2a225f5a68c9a45","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper8.pdf","title":"Contrast Is All You Need","llm_title":"Contrast Is All You Need","authors":["Burak Kilic","Floris Bex","Albert Gatt"],"llm_authors":"Burak Kilic, Floris Bex, Albert Gatt","author_string":"","year":2023,"abstract":"","llm_abstract":"In this study, we analyze data-scarce classification scenarios, where available labeled legal data is small and imbalanced, potentially hurting the quality of the results. We focused on two finetuning objectives; SetFit (Sentence Transformer Finetuning), a contrastive learning setup, and a vanilla finetuning setup on a legal provision classification task. Additionally, we compare the features that are extracted with LIME (Local Interpretable Model-agnostic Explanations) to see which particular features contributed to the model’s classification decisions. The results show that a contrastive setup with SetFit performed better than vanilla finetuning while using a fraction of the training samples. LIME results show that the contrastive learning approach helps boost both positive and negative features which are legally informative and contribute to the classification results. Thus a model finetuned with a contrastive objective seems to base its decisions more confidently on legally informative features.","llm_keywords":["LegalNLP","Contrastive Learning","NLP","Explainable AI","SetFit","Legal Text Classification","Data Scarcity","Few-shot Learning"],"classifications":["Classification","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":11},{"id":"c995cc4be57d5f65755593fccb5dc7c9bdac9321276c561f1fcf3cf5d5c19dd917193c3fce3223893401e72fc283b9e479438d9370d14f0d83ddde59579702b2","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper11.pdf","title":"Applying NLP to Support Legal Decision-making in Administrative Appeal Boards in the EU","llm_title":"Applying NLP to Support Legal Decision-making in Administrative Appeal Boards in the EU","authors":["Henrik Palmer Olsen","Malte Højmark-Bertelsen","Sebastian Felix Schwemer"],"llm_authors":"Henrik Palmer Olsen, Malte Højmark-Bertelsen, Sebastian Felix Schwemer","author_string":"","year":2023,"abstract":"","llm_abstract":"While Natural Language Processing (NLP) is being applied in an increasing number of contexts, including law, it remains a difficult task to leverage NLP for the purpose of real-life support of legal decision-making. This is because 1) legal-decision making must be made in a way that is sensitive not only to legislation but also to evolving case practice (prior decision-making that functions as precedent), 2) legal-decision making is sensitive to open-ended legislative language and shifting factual contexts, 3) traditional methods of NLP are capable of processing long texts, but they are suboptimal compared to novel methods, i.e., transformer-based models, e.g., BERT, etc. 4) however the transformer-based models are limited by maximum input lengths, which makes it difficult to apply in real-life scenarios, where legal documents exceed the maximum input length. In this paper, we show how we tackle the problem of providing NLP-based intelligence support to legal decision-makers in a real-world setting using transformer-based NLP.","llm_keywords":["Legal information retrieval","NLP","public administration","automation bias","decision support","legal decision-making"],"classifications":["Pre-Processing","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":8},{"id":"8085ba2dcae9125044f28adca68bbd7513adcb17b572a1e5b3cc54b62a3b8894e1a783ee3991d3d230545c98b09c6f15bf17ef092506a00d24a93012a47d6f63","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper16.pdf","title":"Extracting ODRL Digital Right Representations from License Texts using AMR","llm_title":"Extracting ODRL Digital Right Representations from License Texts using AMR","authors":["Malo Revel","Aurélien Lamercerie","Annie Foret","Zoltan Miklos"],"llm_authors":"Malo Revel, Aurélien Lamercerie, Annie Foret, Zoltan Miklos","author_string":"","year":2023,"abstract":"","llm_abstract":"Licenses of digital resources describe rights and duties for users. If the licenses are expressed in natural language, as it is frequently the case, it is hard to reason and verify the license compatibility to specific uses. We propose an automatic end-to-end workflow for extracting Open Digital Rights Language (ODRL) representations from textual license documents. This process uses AMR semantic representations as an intermediate; it adapts a tool that performs a semantic transduction analysis, using formal rules. This work focuses on deontic modalities expressing the permissions and obligations of the user. We provide a proof of concept and discuss experiments.","llm_keywords":["Content Extraction","Automated Semantic Analysis","Semantic Graph","AMR","License Rights","ODRL"],"classifications":["Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":7},{"id":"f3b0cc95e9a5cf16d2aa61ed8cebac7cd3041d389bd4ff44470ca2c2a3087c190b7eeaae5620731a0b7a13af79977e3d575a437c023f8c7c1cb30e048b19c554","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper9.pdf","title":"Organizing the Unorganized: A Novel Approach for Transferring a Taxonomy of Labels into Flat-Labeled Document Collections","llm_title":"Organizing the Unorganized: A Novel Approach for Transferring a Taxonomy of Labels into Flat-Labeled Document Collections","authors":["Michele Colombino","Laurentiu Jr Marius Zaharia","Giorgia Iacobellis","Rachele Mignone","Ivan Spada","Chiara Bonfanti","Emilio Sulis","Luigi Di Caro","Guido Boella"],"llm_authors":"Michele Colombino, Laurentiu Jr Marius Zaharia, Giorgia Iacobellis, Rachele Mignone, Ivan Spada, Chiara Bonfanti, Emilio Sulis, Luigi Di Caro, Guido Boella","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper presents a novel pipeline for transforming flat-labeled text collections into a hierarchical structure, which involves leveraging simple yet effective similarity methods that account for both lexical and semantic criteria to associate labels from disparate sources. Our approach employs a custom similarity measure, the Reinforced Edit Similarity, to identify probable correspondences based on lexical similarities. A subsequent semantic alignment and validation phase is then performed using an automatic classification mechanism. Preliminary results attest to the effectiveness of our proposal. These results are obtained from the research group of the University of Torino in the NGUPP project.","llm_keywords":["Legal informatics","Legal document classification","Legal taxonomies","Taxonomy alignment","Text embeddings"],"classifications":["Classification","Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"0762666c162c8d8aaf68691e28c7cd6f6a1481e344d8b51a1c0b883b5b8cf19415b5a3028df9616fe1281b1342ae0b7b09f85b9956871de3f8118e785fb1db9e","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper7.pdf","title":"Semantic Extraction of Key Figures and Their Properties From Tax Legal Texts Using Neural Models","llm_title":"Semantic Extraction of Key Figures and Their Properties From Tax Legal Texts Using Neural Models","authors":["Daniel Steinigen","Marcin Namysl","Markus Hepperle","Jan Krekeler","Susanne Landgraf"],"llm_authors":"Daniel Steinigen, Marcin Namysl, Markus Hepperle, Jan Krekeler, Susanne Landgraf","author_string":"","year":2023,"abstract":"","llm_abstract":"Applying information extraction to legislative texts is a challenging task that requires a specification to distinguish the relevant parts from the less relevant parts of the text. Moreover, there is still a lack of appropriate language- and domain-specific data in the field of information extraction. This work investigates the extraction and modeling of key figures from legal texts. We introduce a universally applicable annotation scheme together with a semantic model for key figures and their logically connected properties in legal texts. Moreover, we release KeyFiTax, a dataset with key figures based on paragraphs of German tax acts manually annotated by tax experts together with a knowledge graph populated from these paragraphs based on our semantic model. Using our dataset, we also evaluate and compare state-of-the-art entity extraction models in terms of long entity spans and low-resource data. Furthermore, we present a transformer-based approach for relation extraction using entity markers to obtain a logical formulation of the key figures. Finally, we introduce task triggers for training a combined resource-efficient entity and relation extraction model. We make our dataset together with the semantic model and the knowledge graph, as well as the implementation of the entity and relation extraction approaches investigated in this work public.","llm_keywords":["information extraction","entity extraction","relation extraction","ontologies","knowledge graphs","transformers","language models","German datasets","legal texts","tax key figures"],"classifications":["Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":12},{"id":"d80a604d5f586db9ff65558c04a6ede7afbe1bfa1475266892b1e5889a2951dd6ebf2df79dd3b577b206877746a36fad7438abe15adf3b5c0118829e64de1292","file_path":"legal-nlp-survey-20250328-002/team 3/20-ASAIL/paper17.pdf","title":"Induction of Narrative Models for Legal Case Elicitation","llm_title":"Induction of Narrative Models for Legal Case Elicitation","authors":["Karl Branting","Sarah McLeod","Bryant Park","Karine Megerdoomian"],"llm_authors":"Karl Branting, Sarah McLeod, Bryant Park, Karine Megerdoomian","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper proposes a new computational architecture for narrative-driven case elicitation, describes six new legal narrative corpora, and evaluates two different approaches to creating legal narrative schemas, the first using language models, and the second using event sequence alignment. An experimental evaluation suggests that the sequence alignment approach may be more appropriate for legal corpora that are small, sparse, and heterogeneous.","llm_keywords":["narrative schema induction","law","computational linguistics","machine-learning","human-computer interface","event sequence alignment"],"classifications":["Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":10},{"id":"b79565dadb5d2bd8059118c9f75c728c510576a719211bff4d04efb33826009b6a08e5c4524b076b4dd9df124e02a48a0956bc55599f3d30d43329105a74b2a0","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230961.pdf","title":"","llm_title":"Can GPT Alleviate the Burden of Annotation?","authors":["Morgan Gray","Jaromir Savelka","Wesley Oliver","Kevin Ashley"],"llm_authors":"Morgan GRAY, Jaromir SAVELKA, Wesley OLIVER, Kevin ASHLEY","author_string":"","year":2023,"abstract":"","llm_abstract":"Manual annotation is just as burdensome as it is necessary for some legal text analytic tasks. Given the promising performance of Generative Pretrained Transformers (GPT) on a number of different tasks in the legal domain, it is natural to ask if it can help with text annotation. Here we report a series of experiments using GPT-4 and GPT 3.5 as a pre-annotation tool to determine whether a sentence in a legal opinion describes a legal factor. These GPT models assign labels that human annotators subsequently confirm or reject. To assess the utility of pre-annotating sentences at scale, we examine the agreement among gold-standard annotations, GPT’s pre-annotations, and law students’ annotations. The agreements among these groups support that using GPT-4 as a pre-annotation tool is a useful starting point for large-scale annotation of factors.","llm_keywords":["GPT-4","Annotation","Interrater Agreement","Generative LLMs","Legal Text Analysis","Legal Factors","Law Students","Drug-Interdiction Auto-Stop (DIAS)","Pre-Annotation","Manual Annotation"],"classifications":["Pre-Processing","Classification"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":10},{"id":"3c8186607c81416484eed4ec0bef5765e663a381012d8bad20efa7e7899a2de51e45676f073d59b6d4e32e813c198b49b87195129825b7332c85c6fe62d0fc8a","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230953.pdf","title":"","llm_title":"Permission in a Kelsenian Perspective","authors":["Agata Ciabattoni","Xavier Parent","Giovanni Sartor"],"llm_authors":"Agata CIABATTONI, Xavier PARENT, Giovanni SARTOR","author_string":"","year":2023,"abstract":"","llm_abstract":"Although permissions are of crucial importance in several settings, they have garnered less attention within the deontic logic community than obligations. In previous work we showed how to reconstruct deontic logic using Kelsen’s quasi-causal conception of norms, restricting ourselves to the notion of obligation. Here we extend the account to permission, and show how to analyse the notion of strong permission through a Kelsenian lens. In our framework various forms of conflicts between obligation and permission are disentangled.","llm_keywords":["Kelsenian perspective","deontic logic","permission","obligation","legal norms","strong permission","sanctions","I/O logic","normative systems"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"e5b9279392dacfca55e3b8c678e291e1b59f02cf49701ebd15fa96d33b3c7b64a7b15c1088c184958aa6bc76c9445fa288aa3116fb5956603de79c81c3b8f757","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230954.pdf","title":"","llm_title":"Deontics and Time in Contracts","authors":["Seng Joe Watt","Oliver Goodenough","Meng Weng Wong"],"llm_authors":"Seng Joe WATT, Oliver GOODENOUGH, Meng Weng WONG","author_string":"","year":2023,"abstract":"","llm_abstract":"Existing approaches to modelling contracts often rely on deontic logic to reason about norms, and only treat time qualitatively. Using L4, a textual domain specific language (DSL) for the law, we offer a more operational interpretation of norms, based on states and transitions, that also accounts for the granular timing of events. In this paper, we present a higher-level rendering of the loan agreement from Flood & Goodenough in L4, and an accompanying operational semantics amenable to execution and static analysis. We also implement this semantics in Maude and show how this lets us visualize the execution of the loan agreement.","llm_keywords":["formal specification","contract automation","norm operationalization","deontic logic","L4 language","operational semantics","finite automata","legal DSL","contract execution","legal informatics"],"classifications":["Classification","Text Generation","Pre-Processing"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"d7a394f7ec9a0dbfe887a8dc913439e589c8b9eb0940324ce6cfde7b64838bc9a3a79f812c11beb568c3fdac8bf383651ddfd2f337a925c11b03b7c93ea03c0f","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230945.pdf","title":"","llm_title":"Improving Rationales with Small, Inconsistent and Incomplete Data","authors":["Cor Steging","Silja Renooij","Bart Verheij"],"llm_authors":"Cor Steging, Silja Renooij, Bart Verheij","author_string":"","year":2023,"abstract":"","llm_abstract":"Data-driven AI systems can make the right decisions for the wrong reasons, which can lead to irresponsible behavior. The rationale of such machine learning models can be evaluated and improved using a previously introduced hybrid method. This method, however, was tested using synthetic data under ideal circumstances, whereas labelled datasets in the legal domain are usually relatively small and often contain missing facts or inconsistencies. In this paper, we therefore investigate rationales under such imperfect conditions. We apply the hybrid method to machine learning models that are trained on court cases, generated from a structured representation of Article 6 of the ECHR, as designed by legal experts. We first evaluate the rationale of our models, and then improve it by creating tailored training datasets. We show that applying the rationale evaluation and improvement method can yield relevant improvements in terms of both performance and soundness of rationale, even under imperfect conditions.","llm_keywords":["Machine Learning","Responsible AI","Explainable AI","Knowledge","Data"],"classifications":["Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"63637f5ab51c85e9009d511e3d18f19c22b6774b242fcd5e9ba8b920d526f4032564e7ccda185e383326c989854b328fb3e581fac185c5b5583c63a8305db355","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230942.pdf","title":"","llm_title":"Inferring New Classifications in Legal Case-Based Reasoning","authors":["Cecilia Di Florio","Xinghan Liu","Emiliano Lorini","Antonino Rotolo","Giovanni Sartor"],"llm_authors":"Cecilia DI FLORIO, Xinghan LIU, Emiliano LORINI, Antonino ROTOLO, Giovanni SARTOR","author_string":"","year":2023,"abstract":"","llm_abstract":"This article continues the research initiated in [1,2], which established a connection between Boolean classifiers and legal case-based reasoning. We relax the assumption that case bases are such that all situations have been decided in favour of the defendant or the plaintiff and we introduce an inductive strategy for assigning plausible outcomes to undecided cases. Using counterfactual reasoning, we propose a method to determine whether, at each step of the induction, a feature is a factor, i.e., it consistently favours a single outcome, or is irrelevant, i.e., it does not favour any outcome, or is ambiguous, i.e., it favours opposite outcomes.","llm_keywords":["Case-based reasoning","Modal Logic for classifiers","Explainable AI","Defeasible reasoning","Inductive strategy","Counterfactual reasoning","Legal CBR","Incomplete knowledge"],"classifications":["Classification","Information Retrieval"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"14522c769d126d8d35dde2c4aa31bcb4dd5ef0f77e1dff5f5d1cc449faff7e61fbcc4b2787e3ef126144ddc00e735b4e73896ec8bb4f29769b20684d8e0eaf89","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230955.pdf","title":"","llm_title":"Automating Business Process Compliance for the EU AI Act","authors":["Claudio Novelli","Guido Governatori","Antonino Rotolo"],"llm_authors":"Claudio NOVELLI, Guido GOVERNATORI, Antonino ROTOLO","author_string":"","year":2023,"abstract":"","llm_abstract":"The EU AI Act is the first step toward a comprehensive legal framework for AI. It introduces provisions for AI systems based on their risk levels in relation to fundamental rights. Providers of AI systems must conduct Conformity Assessments before market placement. Recent amendments added Fundamental Rights Impact Assessments for high-risk AI system users, focusing on compliance with EU and national laws, fundamental rights, and potential impacts on EU values. The paper suggests that automating business process compliance can help standardize these assessments and outlines some methodological guidelines.","llm_keywords":["Risk Assessment","AI Act","Business Process Compliance","Conformity Assessment","Fundamental Rights Impact Assessment","High-risk AI systems","Transparency","Legal framework","Automation","Compliance"],"classifications":[],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":6},{"id":"c9e8d976baca649dd4d99dec66b7d0e191c71e698dbc08034dd981ec0d87ea016e356ddb07d689e83f9dc72bd4aa294ee6a08a398c7335cdcad3d4dd466db7eb","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230952.pdf","title":"","llm_title":"Conceptual Structures in Statutory Interpretation","authors":["Michał Araszkiewicz"],"llm_authors":"Michał Araszkiewicz","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper introduces a framework of conceptual structures allocated to statutory expressions during interpretive heuresis. Drawing from cognitive science research on conceptual structures, the study seeks to enhance existing computational models of legal reasoning across various domains. A comprehensive set of conceptual structures applicable in statutory interpretation is reconstructed. This framework increases awareness of potential interpretive options and contributes to the transparency of legal reasoning.","llm_keywords":["Cognitive science","conceptual structures","heuresis","reasoning","statutory interpretation"],"classifications":[],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":6},{"id":"8e47a6b08bcb860b60cfc2f8ca44aca4b5ac75f350de01a1d77d27d445a643df4f2bd1552e3ad384862cf9d7380dc739be4ca25831e8259b3905361866d77b25","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230943.pdf","title":"","llm_title":"Precedent-Based Reasoning with Incomplete Cases","authors":["Daphne Odekerken","Floris Bex","Henry Prakken"],"llm_authors":"Daphne ODEKERKEN, Floris BEX, Henry PRAKKEN","author_string":"","year":2023,"abstract":"","llm_abstract":"We extend the result model for precedent-based reasoning with incomplete case bases. In contrast to regular case bases, these consist of incomplete cases for which not all dimension values need to be specified, but rather each dimension is assigned a set of possible values. The outcome of cases then applies for each (combination of) the possible dimension values. Building on earlier proposed notions of justification and stability for incomplete focus cases, we introduce the notion of possible justification statuses, which are required to maintain consistency of the incomplete case base. We demonstrate how these theoretic notions can be applied in practice for human-in-the-loop decision support, discuss their computational complexity and provide efficient algorithms.","llm_keywords":["precedent-based reasoning","incomplete cases","legal argument","justification","stability","human-in-the-loop decision support","computational complexity","algorithms"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":10},{"id":"ccb2ca510f2170ef31876fca80beb0603625d403e1deb48bfddb284f3b8979e7480dffc9c13e56d0b2546704b705ac6ecc6d56345828a39d63c9c0b3253178c4","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230944.pdf","title":"","llm_title":"Hierarchical a Fortiori Reasoning with Dimensions","authors":["Wijnand van Woerkom","Davide Grossi","Henry Prakken","Bart Verheij"],"llm_authors":"Wijnand VAN WOERKOM, Davide GROSSI, Henry PRAKKEN, Bart VERHEIJ","author_string":"","year":2023,"abstract":"","llm_abstract":"In recent years, a model of a fortiori argumentation, developed to describe legal reasoning based on precedent, has been successfully applied in the field of artificial intelligence to improve interpretability of data-driven decision systems. In order to make this model more broadly applicable for this purpose, work has been done to expand the knowledge representation on the basis of which it functions, as the original model accommodates only binary propositional information. In particular, two separate expansions of the original model emerged; one which accounts for non-binary input information, and a second which accommodates hierarchically structured reasoning. In the present work we unify these expansions to a single model, incorporating both dimensional and hierarchical information.","llm_keywords":["a fortiori reasoning","explainable artificial intelligence","precedential constraint","dimensions","hierarchy"],"classifications":[],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"ab5fe2b60d309018219e625fbe4abe055cf7039273488dc4a5ba5c5a2c2f5793145dbca62d6a7f40f301ff46818ddad3525b4f020bf738e3760ce51781840316","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230949.pdf","title":"","llm_title":"Assisted Normative Reasoning with Aristotelian Diagrams","authors":["Kathrin Hanauer","Tereza Novotná","Matteo Pascucci"],"llm_authors":"Kathrin HANAUER, Tereza NOVOTNA´, Matteo PASCUCCI","author_string":"","year":2023,"abstract":"","llm_abstract":"We design a framework for assisted normative reasoning based on Aristotelian diagrams and algorithmic graph theory which can be employed to address heterogeneous tasks of deductive reasoning. Here we focus on two problems of normative determination: we show that the algorithms used to address these problems are computationally efficient and their operations are traceable by humans. Finally, we discuss an application of our framework to a scenario regulated by the GDPR.","llm_keywords":["Algorithmic graph theory","Aristotelian diagrams","assisted reasoning","automated deduction","normative reasoning"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"a08ed92f780e5918734387bd4e182aa0c4375f8e3ecf8356f15f6bd08d2b3039619ec2df9f00914f9f6e4f5482ac487a7683d78d9391a5071782aabec0253f40","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230947.pdf","title":"","llm_title":"Arguing About Choosing a Normative System: Conflict of Laws","authors":["Kees van Berkel","Reka Markovich","Christian Strasser","Leendert van der Torre"],"llm_authors":"Kees van Berkel, Reka Markovich, Christian Strasser, Leendert van der Torre","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper presents a formal model of specific reasoning patterns in conflict of laws (CoL). CoL arises when multiple countries have jurisdiction due to the diverse nationalities of the involved factors. When initiating legal action in one country, the question of which country’s substantial law to apply emerges, possibly involving the CoL regulations of other countries (in cases of transmission and renvoi). Moreover, parties contemplating legal action in a case falling under CoL often engage in a deliberation process known as forum shopping: determining which country’s CoL regulations would result in the most favorable outcome for them. Our model integrates deontic logic (specifically Input/Output logic) with proof theory and formal argumentation techniques to model both types of reasoning.","llm_keywords":["conflict of laws","forum shopping","renvoi","deontic logic","formal argumentation","input/output logic","proof theory"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"252230a25d8726c0fb280413f97ad0728e11f9e9dd8d767e5848860c9e6439af66587df62ef69b34bd5100df891f5902d1550cace521efee6b332f837d996fb0","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230940.pdf","title":"","llm_title":"A Note on Hierarchical Constraints","authors":["Trevor Bench-Capon"],"llm_authors":"Trevor Bench-Capon","author_string":"","year":2023,"abstract":"","llm_abstract":"In recent years a considerable amount of research has been devoted to formal theories of precedential constraint. In this note I consider a recent paper which explores the use of factor hierarchies in this connection. In that work it was shown both that cases constrained with the use of a hierarchy may be unconstrained if the hierarchy is flattened, and that cases unconstrained with a hierarchy may be constrained when the hierarchy is flattened. I discuss the nature of factor hierarchies and attempt to explain these results.","llm_keywords":["Precedential Constraint","Factors","Issues","Dimensions","Hierarchies"],"classifications":[],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"a099520ad44de5b4a94dd2a8cee0662b4bf24a9f92dace9f8ccbc8e7db135dd5035f00dced350cdf8e85a4b72bba0f43ea528ad7780125ee14c5840908e9ff22","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230951.pdf","title":"","llm_title":"Dimensions and Precedential Constraint: Factors Deriving from Multiple Dimensions","authors":["Trevor Bench-Capon","Katie Atkinson"],"llm_authors":"Trevor Bench-Capon and Katie Atkinson","author_string":"","year":2023,"abstract":"","llm_abstract":"Current theories of precedential constraint attempt to incorporate dimensions into the reasons for decisions. We argue that this is an unnecessary complication, and precedential constraint can be handled using only factors. In our account the role of dimensions is to organise facts, and their effect operates at the factor ascription level, prior to precedential constraint being applied.","llm_keywords":["Precedential Constraint","Factors","Dimensions","Reason Model","AI and Law","Legal Decision Making","Case-Based Reasoning","HYPO","CATO"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"65b37806502c717e775242b4b9b4febc6b31b342101a67278a0f170513e5a3e115866bdfdfd39141ad5865a793b646bb6da8029338c21b859d809fd129248213","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230956.pdf","title":"","llm_title":"Towards a Semantic Specification for GDPR Data Breach Reporting","authors":["Harshvardhan J. Pandit","Paul Ryan","Georg Philip Krog","Martin Crane","Rob Brennan"],"llm_authors":"Harshvardhan J. Pandit, Paul Ryan, Georg Philip Krog, Martin Crane, Rob Brennan","author_string":"","year":2023,"abstract":"","llm_abstract":"Data breaches and other security incidents are an emerging challenge in the digital era. The General Data Protection Regulation (GDPR) requires conducting an impact assessment to understand the effects of the breach, and to then notify authorities and affected individuals in certain cases. Communication of this information typically takes place via conventional mediums such as emails and forms on the websites of authorities, and is a manual process. To assist in developing tools to support data breach investigations, and to enable automated systems for assisting with breach assessments and GDPR compliance, we present a machine-readable specification for the representation and documentation of information related to data breaches and their communications. The specification uses current requirements from the GDPR obligations and authoritative guidelines. To represent information, it extends the Data Privacy Vocabulary (DPV) by introducing new concepts required for data breach relevant information.","llm_keywords":["GDPR","data breach","cybersecurity","semantics","data privacy","compliance","risk assessment","impact assessment","machine-readable specification","Data Privacy Vocabulary"],"classifications":["Information Extraction","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":6},{"id":"4d8c5a8b4494e94d1948560649a9cc89ea00561d652f602fbac49ba01dc68cb3d60a8951038a77a83ac1e8a1807fe04f85e51c62926f75ec8ab7abb609f6fd9c","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230941.pdf","title":"","llm_title":"The Importance of Intermediate Factors","authors":["Ilaria Canavotto","John Horty"],"llm_authors":"Ilaria CANAVOTTO and John HORTY","author_string":"","year":2023,"abstract":"","llm_abstract":"Bench-Capon argues that intermediate factors have no role to play in precedential constraint. We offer a contrasting perspective.","llm_keywords":["Reason model","hierarchies","issues","intermediate factors"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"f96a58e39cbf2a7c8bbfeb403047563a05d19a9e484d10757c4891b904f769d0ee7a5e0e37a6d8780d439e1703fe1c4e42a8e94047646699350bb474c97fb6fd","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230946.pdf","title":"","llm_title":"Evaluating Methods for Setting a Prior Probability of Guilt","authors":["Ludi van Leeuwen","Bart Verheij","Rineke Verbrugge","Silja Renooij"],"llm_authors":"Ludi van Leeuwen, Bart Verheij, Rineke Verbrugge, Silja Renooij","author_string":"","year":2023,"abstract":"","llm_abstract":"One way of reasoning with uncertainties in the context of law is to use probabilities. However, methods for reasoning about the probability of guilt in a court case requires us to specify a prior probability of guilt, which is the probability of guilt before any evidence is known. There is no accepted approach for specifying the prior probability of guilt but multiple solutions have been proposed. In this paper, we consider three approaches: a prior that is based on the population, a prior based on the number of agents that have similar opportunity as the suspect and a prior that represents a legal norm. For comparing and evaluating the approaches, we use an agent-based model as a ground truth in which all probabilities are known. With the data generated in the ground truth model, we investigate how the choice of prior influences the posterior probability of guilt for both guilty and innocent agents. Using a decision threshold, we can determine the effect of the three approaches on the rates of correct and incorrect convictions and acquittals. We find that the opportunity prior results in higher rates of both correct convictions and false convictions and requires more assumptions and access to data and knowledge than the legal prior and population prior.","llm_keywords":["Probability of Guilt","Prior Probability","Bayesian Networks","Agent-based Modelling","Legal Probabilism"],"classifications":["Classification","Information Extraction","Information Retrieval","Machine Summarization","Pre-Processing","Resources","Text Generation"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"6246b268a622d89cd65b38b469b4d108671deb09f609b9368ab5195d2ceccd75733d36837a3f34719a33053172c121a7ed83b987e16457426c2f35ecc369739f","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230962.pdf","title":"","llm_title":"From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems","authors":["Samyar Janatian","Hannes Westermann","Jinzhe Tan","Jaromir Savelka","Karim Benyekhlef"],"llm_authors":"Samyar JANATIAN, Hannes WESTERMANN, Jinzhe TAN, Jaromir SAVELKA, Karim BENYEKHLEF","author_string":"","year":2023,"abstract":"","llm_abstract":"Encoding legislative text in a formal representation is an important pre-requisite to different tasks in the field of AI & Law. For example, rule-based expert systems focused on legislation can support laypeople in understanding how legislation applies to them and provide them with helpful context and information. However, the process of analyzing legislation and other sources to encode it in the desired formal representation can be time-consuming and represents a bottleneck in the development of such systems. Here, we investigate to what degree large language models (LLMs), such as GPT-4, are able to automatically extract structured representations from legislation. We use LLMs to create pathways from legislation, according to the JusticeBot methodology for legal decision support systems, evaluate the pathways and compare them to manually created pathways. The results are promising, with 60% of generated pathways being rated as equivalent or better than manually created ones in a blind comparison. The approach suggests a promising path to leverage the capabilities of LLMs to ease the costly development of systems based on symbolic approaches that are transparent and explainable.","llm_keywords":["large language models","legal technology","artificial intelligence","semantic legislation analysis","augmented intelligence","legal decision support tools"],"classifications":["Information Extraction","Text Generation"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":10},{"id":"eb73f0cbe9755d4058fbe8050e39b975286bfe8198042397757985a57c000cb10dc9318be8dc4e1970630ef3436cd58821a3636ddc29c6e49192524d1e8d18f0","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230959.pdf","title":"","llm_title":"Connecting Rule-Based and Case-Based Representations of Soft-Constraint Norms","authors":["Wachara Fungwacharakorn","Kanae Tsushima","Hiroshi Hosobe","Hideaki Takeda","Ken Satoh"],"llm_authors":"Wachara Fungwacharakorn, Kanae Tsushima, Hiroshi Hosobe, Hideaki Takeda, Ken Satoh","author_string":"","year":2023,"abstract":"","llm_abstract":"To exhaustively understand the impact of rule amendments and unforeseen cases on existing norms, it requires connecting their rule-based and case-based representations. However, those connections have not been explored in depth, especially for norms that are represented as soft constraints. This paper aims to explore the connection between constraint hierarchies and case models as representative formalisms of rule-based and case-based representations of soft-constraint norms respectively. To explore the connection, we express norm scopes and preferences in both formalisms as diagrams. Based on tightening and arranging diagrams, we found the translation of constraint hierarchies with one constraint per level into case models. This provides new insights into understanding prototypical cases made by rule-based soft-constraint norms.","llm_keywords":["constraint hierarchies","soft constraints","case models","rule-based representation","case-based representation"],"classifications":["Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"499fc56b5576ab43412bad83e00cb2dd86cd177ba60ae5311da25bf1d7ce4ee11357bb79ef4c0950b93e741655618127f3eb862d7303ba30e59621880ec2aba8","file_path":"legal-nlp-survey-20250328-002/team 3/19-JURIX/FAIA-379-FAIA230950.pdf","title":"","llm_title":"Learning Case Relevance in Case-Based Reasoning with Abstract Argumentation","authors":["Guilherme Paulino-Passos","Francesca Toni"],"llm_authors":"Guilherme PAULINO-PASSOS and Francesca TONI","author_string":"","year":2023,"abstract":"","llm_abstract":"Case-based reasoning is known to play an important role in several legal settings. We focus on a recent approach to case-based reasoning, supported by an instantiation of abstract argumentation whereby arguments represent cases and attack between arguments results from outcome disagreement between cases and a notion of relevance. We explore how relevance can be learnt automatically with the help of decision trees, and explore the combination of case-based reasoning with abstract argumentation (AA-CBR) and learning of case relevance for prediction in legal settings. Specifically, we show that, for two legal datasets, AA-CBR with decision-tree-based learning of case relevance performs competitively in comparison with decision trees, and that AA-CBR with decision-tree-based learning of case relevance results in a more compact representation than their decision tree counterparts, which could facilitate cognitively tractable explanations.","llm_keywords":["case-based reasoning","argumentation","machine learning","explainable AI","legal reasoning","decision trees","abstract argumentation","case relevance learning"],"classifications":["Classification","Information Retrieval"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":6},{"id":"a8a5e3750ccea30ba66635de658c2dc6b09497f792aa089a85096fe8a4b7040883662bacb1a363b7422946043f40abb25790c961a130ef9b9963f4470c09879b","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/demonstration session/3594536.3595119.pdf","title":"Applying NLLP and ML to Predict Damages as a Remedy for Contract Breach","llm_title":"Applying NLLP and ML to Predict Damages as a Remedy for Contract Breach","authors":["Frank Giaoui","Luv Aggarwal","Diego Lobo","Joan Gondolo","Philippe Lachkeur","Satvik Jain"],"llm_authors":"Frank Giaoui, Luv Aggarwal, Diego Lobo, Joan Gondolo, Philippe Lachkeur, Satvik Jain","author_string":"","year":2023,"abstract":"","llm_abstract":"Motivated by the subjective decision making and lack of strict protocols in damages as a remedy for contract breach, this project uses natural legal language processing (NLLP) and artificial intelligence (AI) techniques to analyze patterns in contract law cases and reduce uncertainty in their outcome.\nA ‘hybrid’ model combining heuristics, NLLP & the results of an LSTM based model into an XGBoost regressor along with contextual information had the best performance for the classification of entity types from unstructured proceedings text. Linear regressors were developed to approximate the Recovery Rate and the Win Rate using a set of 6 engineered features likely to affect the outcome.","llm_keywords":["NLLP","artificial intelligence","contract breach","predictive modeling","damages","contract law","LSTM model","XGBoost regressor","heuristics"],"classifications":["Classification","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":2},{"id":"1780d792119e4aa0fe5ee435e12ab2e8aa9e6529e28dce72deb8582dbd9e2117ed3a1826b54aae2f98c7eee876d12303c1cd58f539cbd214fe9591a07be0694b","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595121.pdf","title":"Analogical Reasoning, Generalization, and Rule Learning for Common Law Reasoning","llm_title":"Analogical Reasoning, Generalization, and Rule Learning for Common Law Reasoning","authors":["Joseph Blass","Kenneth D. Forbus"],"llm_authors":"Joseph Blass and Kenneth D. Forbus","author_string":"FirstName Surname†, FirstName Surname, FirstName Surname","year":2023,"abstract":"","llm_abstract":"Research in AI & Law has sought to model common-law case-based reasoning by creating analogies from cases, extracting and applying rules from cases, or both. This paper presents a new approach to extracting legal information from cases and several methods to apply it to new cases, including by analogy and by conversion to logical rules. It evaluates the approaches on a dataset of real-world cases and compares the results to off-the-shelf machine-learning techniques. We conclude that abstract legal information can be extracted from similar cases through analogical generalization, and that the extracted legal schemas can be used to reason about and solve other cases both by analogy and by rules.","llm_keywords":["Analogy","Precedential Reasoning","Rule Learning","Legal Schemas","AI & Law","Common Law Reasoning"],"classifications":["Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"e291c5b24b4677beb0259acfe05f5cdf81570b5eb42a8b81e8f2a2c2b9fe99372c234549a50c2589d83ac8749cc7844261c4c0cde645aa135636db3a80533bce","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595153.pdf","title":"Do agents dream of abiding by the rules?","llm_title":"Do agents dream of abiding by the rules? Learning norms via behavioral exploration and sparse human supervision","authors":["Peter Fratrič","Mostafa Mohajeri Parizi","Giovanni Sileno","Tom van Engers","Sander Klous"],"llm_authors":"Peter Fratrič, Mostafa Mohajeri Parizi, Giovanni Sileno, Tom van Engers, Sander Klous","author_string":"Peter Fratrič","year":2023,"abstract":"","llm_abstract":"In recent years, several normative systems have been presented in the literature. Relying on formal methods, these systems support the encoding of legal rules into machine-readable formats, enabling, e.g. to check whether a certain workflow satisfies or agents abide by these rules. However, not all rules can be easily expressed (see for instance the unclear boundaries between tax planning and tax avoidance). The paper introduces a framework for norm identification and norm induction that automates the formalization of norms about non-compliant behavior by exploring the behavioral space via simulation, and integrating inputs from humans via active learning. The proposed problem formulation sets also a bridge between AI & law and more general branches of AI concerned by the adaptation of artificial agents to human directives.","llm_keywords":["Norm identification","Norm induction","Normative systems","Compliance checking","Non-compliance"],"classifications":[],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"3a24e9aa399ec2b74efb7ba27c39fcc413a6dfaacd23cc04191b1ce67011251b455afd3108bfdb258d0de97849aca040fe63f3061a68e01737861142ab15a0ae","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595154.pdf","title":"Hierarchical Precedential Constraint","llm_title":"Hierarchical Precedential Constraint","authors":["Wijnand van Woerkom","Davide Grossi","Henry Prakken","Bart Verheij"],"llm_authors":"Wijnand van Woerkom, Davide Grossi, Henry Prakken, Bart Verheij","author_string":"","year":2023,"abstract":"","llm_abstract":"In recent work, theories of case-based legal reasoning have been applied to the development of explainable artificial intelligence methods, through the analogy of training examples as previously decided cases. One such theory is that of precedential constraint. A downside of this theory with respect to this application is that it performs single-step reasoning, moving directly from the case base to an outcome. For this reason we propose a generalization of the theory of precedential constraint which allows multi-step reasoning, moving from the case base through a series of intermediate legal concepts before arriving at an outcome. Our generalization revolves around the notion of factor hierarchy, so we call this hierarchical precedential constraint. We present the theory, demonstrate its applicability to case-based legal reasoning, and perform a preliminary analysis of its theoretical properties.","llm_keywords":["case-based reasoning","precedential constraint","factors","factor hierarchy","explainable artificial intelligence"],"classifications":[],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":10},{"id":"1b9fa28250b8351875be7163eb507dc2406ba3274ae8224dae7515595029aa3c286857a42b4763ea50ab296c13a928ebec556eaf962064b770f7c671f9200a2a","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595177.pdf","title":"Legal Holding Extraction from Italian Case Documents using Italian-LEGAL-BERT Text Summarization","llm_title":"Legal Holding Extraction from Italian Case Documents using Italian-LEGAL-BERT Text Summarization","authors":["Daniele Licari","Praveen Bushipaka","Gabriele Marino","Giovanni Comandé","Tommaso Cucinotta"],"llm_authors":"Daniele Licari, Praveen Bushipaka, Gabriele Marino, Giovanni Comandé, Tommaso Cucinotta","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal holdings are used in Italy as a critical component of the legal system, serving to establish legal precedents, provide guidance for future legal decisions, and ensure consistency and predictability in the interpretation and application of the law. They are written by domain experts who describe in a clear and concise manner the principle of law applied in the judgments. We introduce a legal holding extraction method based on Italian LEGAL-BERT to automatically extract legal holdings from Italian cases. In addition, we present ITA-CaseHold, a benchmark dataset for Italian legal summarization. We conducted several experiments using this dataset, as a valuable baseline for future research on this topic.","llm_keywords":["Holding Extraction","Italian-LEGAL-BERT","Extractive Text Summarization","Benchmark Dataset","Italian Case Documents","Legal Summarization","Text Summarization","Legal Holdings"],"classifications":["Information Extraction","Machine Summarization","Resources"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":9},{"id":"31c7abbfca03f50c07cd6ae9f5d15f95911ea19ed7881e1862c5f273a0192962819d65e1331b6e192eed9be701b503526d073b6a3ab1683fe997213633cd7a74","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595130.pdf","title":"Argumentation Schemes for Legal Presumption of Causality","llm_title":"Argumentation Schemes for Legal Presumption of Causality","authors":["Ruta Liepin","Adam Wyner","Giovanni Sartor","Francesca Lagioia"],"llm_authors":"Ruta Liepin ¯ a, Adam Wyner, Giovanni Sartor, Francesca Lagioia","author_string":"","year":2023,"abstract":"","llm_abstract":"Causal reasoning is a challenging topic not only in philosophy, science and in theories of human mind, but also in legal reasoning. Causality is indeed a key precondition for civil and criminal liability, in all cases dealing with the connection between human actions or omissions and harmful events. Only a partial overlap exists between natural causality (cause-in-fact) and legal causality: there are instances in which what appears to be a natural cause is not recognised as a legal one, as well as instances in which causality may be presumptively ascribed by the law in the absence of decisive evidence for natural causality. Legal policy considerations may explain these puzzling divergences, as we will discuss in the following. In this paper, we use argumentation schemes to provide simple and intuitive patterns for assessing causality in the legal domain. The analysis of these argument schemes will enable us to clarify some connections between natural and legal causation. Our schemes will include the necessary condition (but-for), overdetermination (NESS), preemption, presumptions based on the increase of risks or presumption based on statutory obligations, and interruption of causality due to unexpected events (Actus Novus). These approaches are tested on the basis of real legal cases in different domains.","llm_keywords":["causation","legal causation","argumentation","legal reasoning"],"classifications":["Information Retrieval","Text Generation","Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"10efbfe5840bc1f28e9e788d4328b781c3838d596bdbe3bb8407a4b7813a75c8dcfcf679cc14c68de0af27dfa24178f564b4ffd4d31dca652db038650527ece0","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595137.pdf","title":"ANGELIC II: An Improved Methodology for Representing Legal Domain Knowledge","llm_title":"ANGELIC II: An Improved Methodology for Representing Legal Domain Knowledge","authors":["Katie Atkinson","Trevor Bench-Capon"],"llm_authors":"Katie Atkinson and Trevor Bench-Capon","author_string":"","year":2023,"abstract":"","llm_abstract":"The purpose of this paper is to provide a definitive, up-to-date account of a methodology has that been proven successful for representing and reasoning about legal domains. The ANGELIC (ADF for kNowledGe Encapsulation of Legal Information for Cases) methodology was originally developed to exploit then recent developments in knowledge representation techniques that lend themselves well to capturing factor-based reasoning about legal cases. The methodology is situated firmly within the tradition of research in AI and Law that aims to build systems that are knowledge rich in terms of the domain expertise that is emulated within the systems. When the methodology was first introduced, it was demonstrated on academic examples, but it was subsequently used in and evaluated on a variety of real world domains for external clients. This set of evaluation exercises yielded a variety of learning points as the methodology was applied to different legal domains with their own particular features. These learning points, and the extensions to the methodology that follow from them, urge a consolidation exercise to provide an updated version of the methodology that reflects how it has matured over time. This paper represents a milestone in the development of the methodology in that it presents the ANGELIC II Domain Model, along with a description of its constituent parts, and demonstrates its application through a case study in a key evaluation domain.","llm_keywords":["Legal Knowledge Representation","Methodology","Design","Artificial Intelligence","Law","Knowledge Encapsulation","Factor-Based Reasoning","Domain Expertise"],"classifications":[],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":10},{"id":"ab50a978dba7a7b068982eda3ab4b113e7d854de10b4ab4786abd88796e0bc8a0c31cadb5b57bd10d2964f8bfc04da182add315c315c2401485f64c3f7d31b0d","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595167.pdf","title":"Confidence Sequences for Evaluating One-Phase Technology-Assisted Review","llm_title":"Confidence Sequences for Evaluating One-Phase Technology-Assisted Review","authors":["David D. Lewis","Lenora Gray","Mark Noel"],"llm_authors":"David D. Lewis, Lenora Gray, Mark Noel","author_string":"David D. Lewis","year":2023,"abstract":"","llm_abstract":"Technology-assisted review (TAR) workflows are central to electronic discovery (eDiscovery). Researchers have proposed many methods for evaluating TAR workflows, but this research has had little impact on eDiscovery practice. We examine the operational constraints faced by eDiscovery reviewers and managers, and show how past evaluation proposals are inconsistent with their needs. We then present a new evaluation approach for one-phase TAR workflows based on confidence sequences. Our approach provides a review manager with complete control over the design and duration of the TAR workflow, as well as the amount and timing of review of evaluation documents. Evaluation documents can be reused for supervised learning while preserving valid frequentist confidence intervals on recall at all points during review. The method is expensive in terms of sample size but plausible for large scale reviews, and has many opportunities for improvement.","llm_keywords":["e-discovery","eDisclosure","effectiveness metrics","safe anytime-valid inference","conformal prediction","martingales"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"e9dc8f0cbbca18cac4793e936a0b4bb66f6b20fbb8a9516b2e3cf06fe1b3c824aa5fbbcd92537529e92e44c0e06e2e7bf54c2b9ae3414c8753d1a8cada0d571e","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595129.pdf","title":"A Formal Framework for Combining Legal Reasoning Methods","llm_title":"A Formal Framework for Combining Legal Reasoning Methods","authors":["Henry Prakken","Giovanni Sartor"],"llm_authors":"Henry Prakken and Giovanni Sartor","author_string":"Henry Prakken, Giovanni Sartor","year":2023,"abstract":"","llm_abstract":"This paper proposes a novel argumentation-based approach to combine legal-reasoning methods that each solve a subproblem of an overall legal problem. The methods can be of any nature (for instance, logical, case-based or probabilistic), as long as their input-output behaviour can be described at the metalevel with deductive or defeasible rules. The model is formulated in the ASPIC+ framework, to profit from its metatheory and explanation methods, and to allow for disagreement about how to solve a subproblem. The model is not meant to be directly implementable but to serve as a semantics for architectures and implementations.","llm_keywords":["Legal argumentation","legal problem solving methods","ASPIC+","defeasible reasoning","deductive reasoning","case-based reasoning","subsumption","metalevel formalism","burden of proof"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":10},{"id":"c7c15957009805ee6dbd4bc3d4784058ea3543edec01aaa6cfa2425fc1dc2eb8c57a30f742cf7d7865475cbe1b0c6cbb2381018853c562b8add5c08e285b27f8","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595152.pdf","title":"Argument Mining with Graph Representation Learning","llm_title":"Argument Mining with Graph Representation Learning","authors":["Gechuan Zhang","Paul Nulty","David Lillis"],"llm_authors":"Gechuan Zhang, Paul Nulty, David Lillis","author_string":"Gechuan Zhang","year":2023,"abstract":"","llm_abstract":"Argument Mining (AM) is a unique task in Natural Language Processing (NLP) that targets arguments: a meaningful logical structure in human language. Since the argument plays a significant role in the legal field, the interdisciplinary study of AM on legal texts has significant promise. For years, a pipeline architecture has been used as the standard paradigm in this area. Although this simplifies the development and management of AM systems, the connection between different parts of the pipeline causes inevitable shortcomings such as cascading error propagation. This paper presents an alternative perspective of the AM task, whereby legal documents are represented as graph structures and the AM task is undertaken as a hybrid approach incorporating Graph Neural Networks (GNNs), graph augmentation and collective classification. GNNs have been demonstrated to be an effective method for representation learning on graphs, and they have been successfully applied to many other NLP tasks. In contrast to previous pipeline-based architecture, our approach results in a single end-to-end classifier for the identification and classification of argumentative text segments. Experiments based on corpora from both the European Court of Human Rights (ECHR) and the Court of Justice of the European Union (CJEU) show that our approach achieves strong results compared to state-of-the-art baselines. Both the graph augmentation and collective classification steps are shown to improve performance on both datasets when compared to using GNNs alone.","llm_keywords":["Argument Mining","Graph Neural Networks","Legal Text","Natural Language Processing","Graph Representation Learning"],"classifications":["Classification","Information Extraction"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":10},{"id":"7bbc411c143b2d3f529648086bfcd0d4a4369874fd7e3c252a69cb4c72990f8c34101efdfc02a1ca74e9ebb0eff1a4e409fe15d8dd655cbe9d2160d28855132c","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595136.pdf","title":"Justification, stability and relevance for case-based reasoning with incomplete focus cases","llm_title":"Justification, stability and relevance for case-based reasoning with incomplete focus cases","authors":["Daphne Odekerken","Floris Bex","Henry Prakken"],"llm_authors":"Daphne Odekerken, Floris Bex, Henry Prakken","author_string":"","year":2023,"abstract":"","llm_abstract":"We define and study the notions of stability and relevance for precedent-based reasoning, focusing on Horty’s result model of precedential constraint. According to this model, precedents constrain the possible outcomes for a focus case, which is a yet undecided case, where precedents and the focus case are compared on their characteristics (called dimensions). In this paper, we refer to the enforced outcome for the focus case as its justification status. In contrast to earlier work, we do not assume that all dimension values of the focus case have been established with certainty: rather, each dimension is assigned a set of possible values. We define a focus case as stable if its justification status is the same for every choice of the possible values. For focus cases that are not stable, we study the task of identifying relevance: which possible values should be excluded to make the focus case stable? We show how the tasks of identifying justification, stability and relevance can be exploited for human-in-the-loop decision support. Finally, we discuss the computational complexity of these tasks and provide efficient algorithms.","llm_keywords":["case-based reasoning","stability","relevance","complexity","algorithms","human-in-the-loop","decision support"],"classifications":["Classification"],"num_cited_by":8,"num_cited_by_title_only":14,"num_pages":10},{"id":"eb4947f00184a637a8966045aabf91ea3dc1fe2bf8f924cb78d85066d5eb71b981603cbe3f94e16e901110751d776c68a778f19d7df19a6cf40667ba1aee3449","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595171.pdf","title":"No Labels? No Problem! Experiments with active learning strategies for multi-class classification in imbalanced low-resource settings","llm_title":"No Labels? No Problem! Experiments with active learning strategies for multi-class classification in imbalanced low-resource settings","authors":["Emiel Steegh","Giovanni Sileno"],"llm_authors":"Emiel Steegh, Giovanni Sileno","author_string":"","year":2023,"abstract":"","llm_abstract":"Labeling textual corpora in their entirety is infeasible in most practical situations, yet it is a very common need today in public and private organizations. In contexts with large unlabeled datasets, active learning methods may reduce the manual labeling effort by selecting samples deemed more informative for the learning process. The paper elaborates on a method for multi-class classification based on state-of-the-art NLP active learning techniques, performing various experiments in low-resource and imbalanced settings. In particular, we refer to a dataset of Dutch legal documents constructed with two levels of imbalance; we study the performance of task-adapting a pre-trained Dutch language model, BERTje, and of using active learning to fine-tune the model to the task, testing several selection strategies. We find that, on the constructed datasets, an entropy-based strategy slightly improves the F1, precision, and recall convergence rates; and that the improvements are most pronounced in the severely imbalanced dataset. These results show promise for active learning in low-resource imbalanced domains but also leave space for further improvement.","llm_keywords":["Active Learning","Transfer Learning","Semi-supervised classification","Dutch Legal Domain","Task Adaption","Learning Convergence"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"cf6aff8e8f651772fb1826f6da319b60771bb295993cf7a2301dbce904a7ab1fe00e779d94d282173ebb4bb1453009af7b64403664a445ce785fde35c1fce2b6","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595132.pdf","title":"MultiLegalSBD: A Multilingual Legal Sentence Boundary Detection Dataset","llm_title":"MultiLegalSBD: A Multilingual Legal Sentence Boundary Detection Dataset","authors":["Tobias Brugger","Matthias Stürmer","Joel Niklaus"],"llm_authors":"Tobias Brugger, Matthias Stürmer, Joel Niklaus","author_string":"Tobias Brugger","year":2023,"abstract":"","llm_abstract":"Sentence Boundary Detection (SBD) is one of the foundational building blocks of Natural Language Processing (NLP), with incorrectly split sentences heavily influencing the output quality of downstream tasks. It is a challenging task for algorithms, especially in the legal domain, considering the complex and different sentence structures used. In this work, we curated a diverse multilingual legal dataset consisting of over 130,000 annotated sentences in 6 languages. Our experimental results indicate that the performance of existing SBD models is subpar on multilingual legal data. We trained and tested monolingual and multilingual models based on CRF, BiLSTM-CRF, and transformers, demonstrating state-of-the-art performance. We also show that our multilingual models outperform all baselines in the zero-shot setting on a Portuguese test set. To encourage further research and development by the community, we have made our dataset, models, and code publicly available.","llm_keywords":["Sentence Boundary Detection","Natural Language Processing","Legal Document Analysis","Text Annotation","Multilingual"],"classifications":["Information Extraction","Resources","Pre-Processing"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":10},{"id":"a85fdcc70107c6ff40bdc8216d0b802a889061710be5c03075722d8b903940b70920838888af1baeb1e8254ef6d4672037ddac7c6b258d88335087e399005605","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595149.pdf","title":"A Quantitative Evaluation of Trademark Search Engines' Performances through Large-Scale Statistical Analysis","llm_title":"A Quantitative Evaluation of Trademark Search Engines’ Performances through Large-Scale Statistical Analysis","authors":["Thomas Vandamme","Julien Cabay","Olivier Debeir"],"llm_authors":"Thomas Vandamme, Julien Cabay, Olivier Debeir","author_string":"Thomas Vandamme","year":2023,"abstract":"","llm_abstract":"Intellectual Property Offices now offer their users trademark search engines to help them identify earlier trademarks in their register. Such tools have proven to be extremely useful given the growing number of trademarks registered but have never been subjected to thorough evaluation, despite the necessity for openness and accountability in justice systems. Additionally, their performance is unknown, in particular the reliability of their results pertaining to applicable legal rules. In fact, their \"black box nature\" makes automatic and at-scale evaluation hard to perform directly, which is why we propose a novel method for evaluating their performance using settled case-law for ground truth, and at-scale analysis. Based on this methodology, we evidence the performance for two such systems, the Benelux Office of Intellectual Property (BOIP) and European Union Intellectual Property Office (EUIPO), using 8 126 opposition division decisions from the EUIPO. We show important disparities between the two systems, along with surprisingly good results for EUIPO’s system.","llm_keywords":["Intellectual Property","Trademark","EUIPO","BOIP","Search Engine","Likelihood of Confusion"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":8},{"id":"454f95f8d40366999f7028ba7601fa3240e9e52de072f92316688d20944a8ac33ce4d51b8a79af7d72f266542cb90b84f7366871c4aab1bde5678cdb6567038e","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595172.pdf","title":"Identification of Legislative Errors","llm_title":"Identification of Legislative Errors","authors":["Michał Araszkiewicz","Enrico Francesconi","Tomasz Zurek"],"llm_authors":"Michał Araszkiewicz, Enrico Francesconi, Tomasz Zurek","author_string":"","year":2023,"abstract":"","llm_abstract":"We present an approach designed to support the process of legislative drafting by helping to detect errors in a normative text. It is based on a framework allowing for representation and comparison of structure and semantic content of legal provisions. Such comparison serves as a starting point for detection of (potential) legislative errors. The approach provides in particular criteria to select provisions to be compared, related to the phenomenon of provisions overlapping. We show that specific cases of such an overlap may amount to legislative errors. The presented framework enables a precise and transparent account of these errors. We also acknowledge that textual provisions enable various interpretations, while the error methodology detection assumes that the semantic representation of provisions is a result of a specific interpretation. We introduce the notion of Constraining Interpretive Rules which are used to evaluate the acceptability of specific interpretations of legal provisions. We discuss the features of the model on a real example and we present an implementation of the approach by using semantic technologies.","llm_keywords":["Legislative errors","Legal knowledge representation","Semantic technologies","Legislative drafting support","Interpretation of statutory law"],"classifications":["Text Generation","Resources","Pre-Processing"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"8c9a22d3020c61e7d195ed26d3bac2641c373eb68e2a047734b935a98524528d7dc4449678f1ea8b47a3565ccd964dd8a65df61bc0b1154a466957d3c79edccc","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595163.pdf","title":"Can GPT-3 Perform Statutory Reasoning?","llm_title":"Can GPT-3 Perform Statutory Reasoning?","authors":["Andrew Blair-Stanek","Nils Holzenberger","Benjamin Van Durme"],"llm_authors":"Andrew Blair-Stanek, Nils Holzenberger, Benjamin Van Durme","author_string":"","year":2023,"abstract":"","llm_abstract":"Statutory reasoning is the task of reasoning with facts and statutes, which are rules written in natural language by a legislature. It is a basic legal skill. In this paper we explore the capabilities of the most capable GPT-3 model, text-davinci-003, on an established statutory-reasoning dataset called SARA. We consider a variety of approaches, including dynamic few-shot prompting, chain-of-thought prompting, and zero-shot prompting. While we achieve results with GPT-3 that are better than the previous best published results, we also identify several types of clear errors it makes. We investigate why these errors happen. We discover that GPT-3 has imperfect prior knowledge of the actual U.S. statutes on which SARA is based. More importantly, we create simple synthetic statutes, which GPT-3 is guaranteed not to have seen during training. We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.","llm_keywords":["statutory reasoning","GPT-3","natural language processing","law","statutes","reasoning","AI research"],"classifications":[],"num_cited_by":108,"num_cited_by_title_only":108,"num_pages":10},{"id":"922c7a915119e9228a0195323d0ce3587e08ffcafb4ae30b4669cab140412e444f1c2169a5d83cba1928b5fa1d1f6c784a9bd1cdc1bebd45f12d58a9c4fdfd14","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595118.pdf","title":"Who really wrote Martin v. Hunter's Lessee?","llm_title":"Who really wrote Martin v. Hunter’s Lessee?: Applying a machine learning ensemble to uncover a Chief Justice’s unethical behavior","authors":["Seth Chandler","Emily Muenster","Daniel Lichtblau"],"llm_authors":"Seth J. Chandler, Emily A. Muenster, Daniel Lichtblau","author_string":"","year":2023,"abstract":"","llm_abstract":"This article applies multiple machine learning methods to strongly suggest that Chief Justice John Marshall behaved unethically in an important 19th Century case of American constitutional law: Martin v. Hunter’s Lessee. He wrote large swathes of the opinion even though he had a large financial stake in the outcome of the case and even though he had formally recused himself. We establish this through multiple machine learning methods, including a character-sequence-to-image method known as the frequency chaos game representation (FCGR), sentence embeddings using BERT, and the renowned Delta method involving bags of words. All these methods of stylometry reach the same conclusions.","llm_keywords":["law","stylometry","United States Supreme Court","FCGR","Burrow’s Delta","sentence embedding","BERT","singular value decomposition","neural networks","spurious clues"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":9},{"id":"dbd697495acc51ec737c593857ae1deb9464224d04e5dbabbb781360e14d0c4035802e79b05ba157eb20f4548b89d74316aeb8e269a2ca82f2150a6d9961ee29","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595164.pdf","title":"Model- and data-agnostic justifications with A Fortiori Case-Based Argumentation","llm_title":"Model- and data-agnostic justifications with A Fortiori Case-Based Argumentation","authors":["Joeri Peters","Floris Bex","Henry Prakken"],"llm_authors":"Joeri G.T. Peters, Floris J. Bex, and Henry Prakken","author_string":"","year":2023,"abstract":"","llm_abstract":"AF-CBA is an example-based approach to XAI that draws on the case-based argumentation tradition in AI & Law. It means to explain binary classifications made by an opaque machine-learning model by presenting an argument graph to the user, which represents an argument game about the classification of a case on the basis of precedents derived from labelled data used in the training phase of the classifier. We improve the robustness of this method by modifying it to better handle inconsistent labelling and evaluate an alternative setup that does not require access to the labelled data by using earlier predictions instead.","llm_keywords":["XAI","CBR","argumentation","precedential constraint","machine learning","transparency","black-box models","explanation","case-based argumentation","AF-CBA"],"classifications":["Classification"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":10},{"id":"8b2f73fbb0b4c3172a8ba3d3efba7c907545315d36f193884e36bdc5a38898e75bb6d77c9226dcee59e70fb86edd80bac2a6c437faa78386695750c836cc94d9","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595151.pdf","title":"Insert Your Title Here","llm_title":"Automated Anonymization of Court Decisions: Facilitating the Publication of Court Decisions through Algorithmic Systems","authors":["Kalliopi Terzidou"],"llm_authors":"Kalliopi Terzidou","author_string":"FirstName Surname†, FirstName Surname, FirstName Surname","year":2023,"abstract":"","llm_abstract":"The practice of anonymization of court decisions has been further systematized by EU Member States’ courts, after the entry into force of the General Data Protection Regulation and its transposition into national laws. Anonymization of the parties’ personal information protects their privacy during the publication of judgments, which is necessary for the scrutiny of the judiciary’s reasoning in a given case and the filing of an appeal whenever a party disagrees with the court’s reasoning and/or order. European courts have recently resorted to algorithmic approaches to automate the process of anonymization, which can bestow prompt and consistent application of anonymization rules for court administrations to comply with the applicable personal data protection legislation. These automated solutions can also encompass technical and administrative challenges, ranging from re-identification risks that compromise the protection of the parties’ personal data to the lack of acceptance of the algorithmic system by court staff during their daily work routine. The present paper reviews current anonymization practices conducted through algorithmic techniques by, first, explaining the legal framework underlying the publication and anonymization of court decisions, second, examining three algorithmic solutions for the anonymization of court decisions by different EU Member States, and third, reflecting on their efficiencies and challenges for court administrations.","llm_keywords":["Anonymization","Court Decisions","Data Protection","Algorithmic Systems","European Union","GDPR","Natural Language Processing","Privacy","AI-based Solutions"],"classifications":["Pre-Processing"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":9},{"id":"554f7b3d5672b65a945b2fb8624efd4759930161a96f1b1b828eb3c6c8e9afc694461e3ac8583e31624b86dab767bd0bc11ce566930cb277bdbc60dc800248f8","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595158.pdf","title":"Combining a Legal Knowledge Model with Machine Learning for Reasoning with Legal Cases","llm_title":"Combining a Legal Knowledge Model with Machine Learning for Reasoning with Legal Cases","authors":["Jack Mumford","Katie Atkinson","Trevor Bench-Capon"],"llm_authors":"Jack Mumford, Katie Atkinson, Trevor Bench-Capon","author_string":"Jack Mumford","year":2023,"abstract":"","llm_abstract":"Recent years have witnessed significant progress in the deployment of advanced Natural Language Processing (NLP) techniques based on transformer technology, across many domains and applications. However, in legal domains, due to the complexity, length, and sparsity of legal case documents, the use of these advanced NLP techniques has offered comparatively slight returns. Perhaps even more importantly, such methods are critically lacking in explainability and justification of outputs, which are essential for many legal applications. We propose that the direction of these NLP techniques should be aimed at ascription to a legal knowledge model, which can then provide the necessary and auditable justifications for the rationale of any case outcome. In this paper we investigate the effectiveness of using Hierarchical Bidirectional Encoder Representations from Transformers (H-BERT) models to ascribe to an Angelic Domain Model (ADM) that is able to represent the legal knowledge of a domain in a structured way, enabling justifications and improving performance. Our study involved an annotation task on a popular domain, cases from the European Court of Human Rights, to gain an understanding of the balance of complaints in the domain. The data set produced from this study enabled training of models for factor ascription using the classification targets derived from the annotations. We present results of experiments conducted to evaluate the performance of the ascription task at three different levels of abstraction within the structured model.","llm_keywords":["Transformers","domain model","factor ascription","case annotation","legal knowledge","Natural Language Processing","Hierarchical Bidirectional Encoder Representations","European Court of Human Rights","legal cases","explainability"],"classifications":["Classification","Resources"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":10},{"id":"ffafe584a90d6428b88afb7abec45b395c867848d3c7ae17dcd01f5619dc11da5ebce2e5255fe7bcc5760ae31b9a129353031df7d78be12dff483093a0f97552","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595124.pdf","title":"The Dutch Law as a Semantic Role Labeling Dataset","llm_title":"The Dutch Law as a Semantic Role Labeling Dataset","authors":["Romy van Drie","Maaike de Boer","Roos Bakker","Ioannis Tolios","Daan Vos"],"llm_authors":"Romy A. N. van Drie, Maaike H. T. de Boer, Roos M. Bakker, Ioannis Tolios, Daan Vos","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal documents, and specifically law texts, are not easy to understand by humans. The specific terminology and sentence constructions are particular, which also makes it a difficult machine understanding task. In this paper, we present a publicly available benchmark dataset containing Dutch law texts which can be used to train AI models that assist humans equipped with the task of interpreting legal texts. However, the dataset can be used in a broader context, such as semantic role labeling of Dutch (legal) texts. Our dataset contains 4463 annotated sentences from 55 different Dutch laws, in which four roles are annotated by human annotators: action, actor, object and recipient. The inter-annotator agreement is substantial (𝜅=0.75). In experiments with a rule-based and a transformer-based method, results show that the transformer-based method performs quite well on the dataset (accuracy > 0.8). These results indicate that we can reliably predict actions, actors, objects and recipients in legal texts. This can help people equipped with the task of formal interpretation of legal texts.","llm_keywords":["semantic role labeling","Dutch law","natural language processing","legal text","interpretation","datasets","machine understanding"],"classifications":["Information Extraction","Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":7},{"id":"51e0049705e40c5ed4f46112812d16811339042f1e8b00e6e384bfc0e3626ddda1c81e687e1875bb641f0a523d7e06adb6385f3f17051a31de8a041a9682cc2e","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595174.pdf","title":"Argumentation Structure Prediction in CJEU Decisions on Fiscal State Aid","llm_title":"Argumentation Structure Prediction in CJEU Decisions on Fiscal State Aid","authors":["Piera Santin","Giulia Grundler","Andrea Galassi","Federico Galli","Francesca Lagioia","Elena Palmieri","Federico Ruggeri","Giovanni Sartor","Paolo Torroni"],"llm_authors":"Piera Santin, Giulia Grundler, Andrea Galassi, Federico Galli, Francesca Lagioia, Elena Palmieri, Federico Ruggeri, Giovanni Sartor, Paolo Torroni","author_string":"","year":2023,"abstract":"","llm_abstract":"Argument structure prediction aims to identify the relations between arguments or between parts of arguments. It is a crucial task in legal argument mining, where it could help identifying motivations behind judgments or even fallacies or inconsistencies. It is also a very challenging task, which is relatively underdeveloped compared to other argument mining tasks, owing to a number of reasons including a low availability of datasets and a high complexity of the reasoning involved. In this work, we address argumentative link prediction in decisions by Court of Justice of the European Union on fiscal state aid. We study how propositions are combined in higher-level structures and how the relations between propositions can be predicted by NLP models. To this end, we present a novel annotation scheme and use it to extend a dataset from literature with an additional annotation layer. We use our new dataset to run an empirical study, where we compare two architectures and explore different combinations of hyperparameters and training regimes. Our results indicate that an ensemble of residual networks yields the best results.","llm_keywords":["Argument Mining","Legal Argument","Link Prediction","CJEU decisions","Natural Language Processing","Machine Learning","Automated Legal Analysis","Annotation Scheme","Residual Networks","Argumentative Link Prediction"],"classifications":["Pre-Processing","Resources","Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"38eadc25eeaaa4beb8298fd5b96b18ca25184a795eee56ec0dd485fa31b47d5ba88133e2539970d5edb842b0256979c719b551ea7fe67736671ed2ff7c2ccf17","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595146.pdf","title":"Camera_Ready_-_Steenhuis,_Colarusso_and_Willey_-_RateMyPDF_ICAIL_2023 (mgedit)","llm_title":"Beyond Readability with RateMyPDF: A Combined Rule-based and Machine Learning Approach to Improving Court Forms","authors":["Matthias Grabmair","Quinten Steenhuis","Bryce Willey","David Colarusso"],"llm_authors":"Quinten Steenhuis, Bryce Willey, David Colarusso","author_string":"Matthias Grabmair","year":2023,"abstract":"","llm_abstract":"In this paper, we describe RateMyPDF, a web application that helps authors measure and improve the usability of court forms. It offers a score together with automated suggestions to improve the form drawn from both traditional machine learning approaches and the general purpose GPT-3 large language model. We worked with form authors and usability experts to determine the set of features we measure and validated them by gathering a dataset of approximately 24,000 PDF forms from 46 U.S. States and the District of Columbia. Our tool and automated measures allow a form author or court tasked with improving a large library of forms to work at scale. This paper describes the features that we find improve form usability, the results from our analysis of the large form dataset, details of the tool, and the implications of our tool on access to justice for self-represented litigants. We found that the RateMyPDF score significantly correlates to the score of expert reviewers. While the current version of the tool allows automated analysis of Microsoft Word and PDF court forms, the findings of our research apply equally to the growing number of automated wizard-driven interactive legal applications that replace paper forms with interactive websites.","llm_keywords":["Accessibility","Law","Administrative Burden","Readability","Court Forms","Automated Analysis"],"classifications":["Pre-Processing","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"645ef6b11fe2b5757e18989d1288eda28fc1e3214447899b512111cb6d92a8b1d75160d534c808d9999955679dfc337f423b8effbf5832e520fb131cb1b52c96","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595148.pdf","title":"Reasoning with hierarchies of open-textured predicates","llm_title":"Reasoning with hierarchies of open-textured predicates","authors":["Ilaria Canavotto","John Horty"],"llm_authors":"Ilaria Canavotto and John Horty","author_string":"Ilaria Canavotto","year":2023,"abstract":"","llm_abstract":"We develop the reason model of precedential constraint in the context of a hierarchy of intermediate legal concepts, based on the idea that constraint depends, not just on the ultimate decision reached in a case, but on the variety of intermediate decisions that may constitute judicial opinions. After developing this model, we study the relation between constraint in a full hierarchical setting and constraint in a setting in which hierarchies, cases, and case bases are flattened into structures corresponding to those at work in the standard reason model. We show that constraint in the full hierarchical setting may be lost in the flattened setting, but also, and more surprisingly, that new patterns of constraint might appear in the flattened setting that were not present in the full hierarchical setting.","llm_keywords":["Reason model","legal argument","precedential constraint","hierarchies","abstract factors"],"classifications":[],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":10},{"id":"d27dafa6f25ecbcfbbd87a1713a27b18e30f2e459e2a7cdf2a1be2278e43139eaa11a3ce687b3ccc19a266dc08e0dea067347793f076c8a80dc192476ec0e7c6","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595159.pdf","title":"EQUALS: A Real-world Dataset for Legal Question Answering via Reading Chinese Laws","llm_title":"EQUALS: A Real-world Dataset for Legal Question Answering via Reading Chinese Laws","authors":["Andong Chen","Feng Yao","Xinyan Zhao","Yating Zhang","Changlong Sun","Yun Liu","Weixing Shen"],"llm_authors":"Andong Chen, Feng Yao, Xinyan Zhao, Yating Zhang, Changlong Sun, Yun Liu, Weixing Shen","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal Question Answering (LQA) is a promising artificial intelligence application with high practical value. A professional and effective legal question answering (QA) agent can assist in reducing the workload of lawyers and judges, and help to achieve judicial accessibility. However, the NLP community lacks a large-scale LQA dataset with high quality, making it difficult to develop practical data-driven LQA agents. To tackle this bottleneck, this work presents EQUALS, a well-annotated real-world dataset for Legal Question Answering via reading Chinese Laws. EQUALS contains 6,914 {question, article, answer} triplets as well as a pool of articles of laws that covers 10 different collections of Chinese Laws. Questions and the corresponding answers in EQUALS are collected from a professional law consultation forum. More importantly, the exact spans of law articles are annotated by senior law students as the answers. In this way, we could assure the quality and professionalism of EQUALS. Furthermore, this work proposes a QA framework that encompasses a law article retrieval module and a machine reading comprehension module for extracting accurate answers from the law article. We conduct thorough experiments with representative baselines on EQUALS, and the results indicate that EQUALS is a challenging question answering task. To the best of our knowledge, EQUALS is the largest real-world LQA dataset which shall significantly promote the research of LQA tasks. The work has been open-sourced and is available at: https://github.com/andongBlue/EQUALS.","llm_keywords":["Legal Dataset","Legal Question Answering","Question Answering Framework"],"classifications":["Resources","Information Retrieval","Information Extraction"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":10},{"id":"70969f62866812fbc02cb32acf8833b188f37d81eb243036911ed4b3938c0654fcba0db88504ca95deb47c562d1ba0dd49c477cd6fe6d6bd241438299e616c99","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595125.pdf","title":"Using Agent-Based Simulations to Evaluate Bayesian Networks for Criminal Scenarios","llm_title":"Using Agent-Based Simulations to Evaluate Bayesian Networks for Criminal Scenarios","authors":["Ludi van Leeuwen","Bart Verheij","Rineke Verbrugge","Silja Renooij"],"llm_authors":"Ludi van Leeuwen, Bart Verheij, Rineke Verbrugge, Silja Renooij","author_string":"Ludi van Leeuwen, Bart VerheijRineke Verbrugge and Silja Renooij","year":2023,"abstract":"","llm_abstract":"Scenario-based Bayesian networks (BNs) have been proposed as a tool for the rational handling of evidence. The proper evaluation of existing methods requires access to a ground truth that can be used to test the quality and usefulness of a BN model of a crime. However, that would require a full probability distribution over all relevant variables used in the model, which is in practice not available. In this paper, we use an agent-based simulation as a proxy for the ground truth for the evaluation of BN models as tools for the rational handling of evidence. We use fictional crime scenarios as a background. First, we design manually constructed BNs using existing design methods in order to model example crime scenarios. Second, we build an agent-based simulation covering the scenarios of criminal and non-criminal behavior. Third, we algorithmically determine BNs using statistics collected experimentally from the agent-based simulation that represents the ground truth. Finally, we compare the manual, scenario-based BNs to the algorithmic BNs by comparing the posterior probability distribution over outcomes of the network to the ground-truth frequency distribution over those outcomes in the simulation, across all evidence valuations. We find that both manual BNs and algorithmic BNs perform similarly well: they are good reflections of the ground truth in most of the evidence valuations. Using ABMs as a ground truth can be a tool to investigate Bayesian Networks and their design methods, especially under circumstances that are implausible in real-life criminal cases, such as full probabilistic information.","llm_keywords":["Bayesian Networks","evidential reasoning","agent-based simulation","scenarios"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":10},{"id":"aeb94287e59afa349524f1efa32a7a45327b2c06f265831c047410d9922eba8cd7184edb6a56814e2ec2bd2c72b3de6335d63c1392e0d082d3dc8e8295498d4b","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595157.pdf","title":"Automatic Identification and Empirical Analysis of Legally Relevant Factors","llm_title":"Automatic Identification and Empirical Analysis of Legally Relevant Factors","authors":["Morgan Gray","Jaromir Savelka","Wesley Oliver","Kevin Ashley"],"llm_authors":"Morgan Gray, Jaromir Savelka, Wesley Oliver, Kevin Ashley","author_string":"","year":2023,"abstract":"","llm_abstract":"This research addresses how to automatically identify certain factors in the texts of legal decisions and analyze their role in courts’ decisions. It focuses on drug interdiction auto stop cases in which courts decide whether police officers have reasonable suspicion to detain a motorist. It illustrates how the methods to identify factors automatically can support empirical legal research in the domain and how machine learning methods of different accuracy and interpretability can be harnessed to explain case outcomes in terms legal professionals can understand.","llm_keywords":["text classification","factors","empirical legal analysis","legal text analysis","machine learning"],"classifications":["Information Extraction","Classification"],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":10},{"id":"fba68fad1e52a9889d45d6277a2b6f356c68e8a6cd8a55e18abb31361f1521a94e070185578add6d5332228362d495520c97819420897cecaf15321b8d9843b2","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595165.pdf","title":"Pre-trained Language Models for the Legal Domain: A Case Study on Indian Law","llm_title":"Pre-trained Language Models for the Legal Domain: A Case Study on Indian Law","authors":["Shounak Paul","Arpan Mandal","Pawan Goyal","Saptarshi Ghosh"],"llm_authors":"Shounak Paul, Arpan Mandal, Pawan Goyal, Saptarshi Ghosh","author_string":"","year":2023,"abstract":"","llm_abstract":"NLP in the legal domain has seen increasing success with the emergence of Transformer-based Pre-trained Language Models (PLMs) pre-trained on legal text. PLMs trained over European and US legal text are available publicly; however, legal text from other domains (countries), such as India, have a lot of distinguishing characteristics. With the rapidly increasing volume of Legal NLP applications in various countries, it has become necessary to pre-train such LMs over legal text of other countries as well. In this work, we attempt to investigate pre-training in the Indian legal domain. We re-train (continue pre-training) two popular legal PLMs, LegalBERT and CaseLawBERT, on Indian legal data, as well as train a model from scratch with a vocabulary based on Indian legal text. We apply these PLMs over three benchmark legal NLP tasks – Legal Statute Identification from facts, Semantic Segmentation of Court Judgment Documents, and Court Appeal Judgment Prediction – over both Indian and non-Indian (EU, UK) datasets. We observe that our approach not only enhances performance on the new domain (Indian texts) but also over the original domain (European and UK texts). We also conduct explainability experiments for a qualitative comparison of all these different PLMs.","llm_keywords":["pre-trained language models","legal domain","Indian law","NLP","Transformer-based models","LegalBERT","CaseLawBERT","domain-specific pre-training","legal NLP tasks","explainability experiments"],"classifications":["Pre-Processing","Classification","Resources"],"num_cited_by":49,"num_cited_by_title_only":49,"num_pages":10},{"id":"bdeb509caf00759fadc6f53859a6b009c699c20e414f0c0ca4869b5856094ba76538a3a2d66f1b952c052b3c898a51e35c9c25a44dbb9ed8724f8ec305fd1176","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/full papers/3594536.3595162.pdf","title":"Computable Contracts by Extracting Obligation Logic Graphs","llm_title":"Computable Contracts by Extracting Obligation Logic Graphs","authors":["Sergio Servantez","Nedim Lipka","Alexa Siu","Milan Aggarwal","Balaji Krishnamurthy","Aparna Garimella","Kristian Hammond","Rajiv Jain"],"llm_authors":"Sergio Servantez, Nedim Lipka, Alexa Siu, Milan Aggarwal, Balaji Krishnamurthy, Aparna Garimella, Kristian Hammond, Rajiv Jain","author_string":"","year":2023,"abstract":"","llm_abstract":"The emergence of contract specific programming languages has struggled to translate into widespread adoption of computable contracts due largely to high conversion costs. In this work, we present the first system for converting natural language contracts into code through the extraction of key entities, relationships, and formulas into a graph representation called the Obligation Logic Graph (OLG). This approach allows the semantic meaning of contract obligations, including dependencies between obligations, to be captured through the OLG and mapped to code downstream. We also introduce OLG extraction as a new joint entity and relation prediction task for legal contracts, and present the Contract-OLG dataset, consisting of 1,876 contract provisions, 18,597 entities and 18,170 relationships. We perform detailed experiments to understand the capabilities of state-of-the-art Transformer and graph-based models at completing these tasks, and identify where there is currently a significant gap between human expert and machine performance, particularly for relation extraction.","llm_keywords":["natural language processing","information extraction","computable contracts","obligation logic graph","legal contracts","entity extraction","relation prediction","domain-specific languages"],"classifications":[],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"91a2c106e7ea1d3de036ad2fc53e9c9e86a260bf7806ed3fc83abafb5f21368844bb74356f0711bd161d6b68ec3b1a7610044fd4ea61e1a01ecee6d111c80c6a","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595150.pdf","title":"On evaluating legal summaries with ROUGE","llm_title":"On evaluating legal summaries with ROUGE","authors":["Bianca Steffes","Piotr Rataj","Luise Burger","Lukas Roth"],"llm_authors":"Bianca Steffes, Piotr Rataj, Luise Burger, Lukas Roth","author_string":"Bianca Steffes","year":2023,"abstract":"","llm_abstract":"ROUGE is the most commonly used measure for evaluating summarization algorithms in practice. However, it is questionable whether ROUGE scores adequately reflect the quality of summaries in terms of content. We introduce a metric to measure (legal) content of summaries based on exhaustiveness and concreteness and compare ROUGE scores with values generated by legal experts according to our metric on two tasks. Our results show that ROUGE does not reliably gauge legal content and thus should not be used as a single indicator for the quality of summarization algorithms. For our particular use case we furthermore show one way to increase the reliability of ROUGE by pre-selecting sentences.","llm_keywords":["legal text summarization","ROUGE","German texts","German Federal Court of Justice","summarization evaluation","content quality","automated measures","legal content coverage"],"classifications":["Machine Summarization"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":5},{"id":"e62a0a3338cf89f5d01f9ab25da3a34a5f9e551d76a749c4ce4dd4810689340500a76184dc2d904534f7d4e3ee27a1a83804f16bb2df58bddfc8023d3f5f87a5","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595141.pdf","title":"Insert Your Title Here","llm_title":"Improving Translation of Case Descriptions into Logical Fact Formulas using LegalCaseNER","authors":["May Myo Zin","Ha Thanh Nguyen","Ken Satoh","Saku Sugawara","Fumihito Nishino"],"llm_authors":"May Myo Zin, Ha Thanh Nguyen, Ken Satoh, Saku Sugawara, Fumihito Nishino","author_string":"FirstName Surname†, FirstName Surname, FirstName Surname","year":2023,"abstract":"","llm_abstract":"The automated translation of natural language text into structured logical representations is a critical task in various applications, including legal reasoning and decision-making. This paper presents a Name Entity Recognition (NER) based approach for translating the legal case descriptions written in natural language into PROLEG fact formulas. The approach comprises (1) extracting legal entities from the case description using a specialized NER model, namely LegalCaseNER and (2) transforming the extracted entities into PROLEG fact formulas using PROLEG rules. The experimental results demonstrate the efficacy of our proposed approach in accurately extracting relevant entities from legal case descriptions and translating them into the appropriate PROLEG fact formulas. Our approach provides a promising solution for handling complex and diverse case descriptions, enabling their representation in a structured format. This work provides a foundation for future research in the application of logical fact formulas in legal reasoning and decision-making.","llm_keywords":["entity extraction","translation","natural language","logical reasoning","legal case descriptions","PROLEG","named entity recognition"],"classifications":["Information Extraction"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":5},{"id":"78981dc3c8cd266e8e23f9f0060fb5e3e8737ea25a58deb1ab61b1ccb13ffc52bd58c5bfb8ed8bc8319ff3b82dd1a68c443b0fb4ca7f2f997c5bcd92c0f20f38","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595170.pdf","title":"Legal Syllogism Prompting: Teaching Large Language Models for Legal Judgment Prediction","llm_title":"Legal Syllogism Prompting: Teaching Large Language Models for Legal Judgment Prediction","authors":["Cong Jiang","Xiaolei Yang"],"llm_authors":"Cong Jiang, Xiaolei Yang","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal syllogism is a form of deductive reasoning commonly used by legal professionals to analyze cases. In this paper, we propose legal syllogism prompting (LoT), a simple prompting method to teach large language models (LLMs) for legal judgment prediction. LoT teaches only that in the legal syllogism the major premise is law, the minor premise is the fact, and the conclusion is judgment. Then the models can produce a syllogism reasoning of the case and give the judgment without any learning, fine-tuning, or examples. On CAIL2018, a Chinese criminal case dataset, we performed zero-shot judgment prediction experiments with GPT-3 models. Our results show that LLMs with LoT achieve better performance than the baseline and chain of thought prompting, the state-of-art prompting method on diverse reasoning tasks. LoT enables the model to concentrate on the key information relevant to the judgment and to correctly understand the legal meaning of acts, as compared to other methods. Our method enables LLMs to predict judgment along with law articles and justification, which significantly enhances the explainability of models.","llm_keywords":["large language models","legal syllogism","legal judgment prediction","chain of thought","explainability","deductive reasoning","zero-shot learning","artificial intelligence","law"],"classifications":["Classification"],"num_cited_by":45,"num_cited_by_title_only":45,"num_pages":5},{"id":"a66c287b47037b783e3c836906fcacf6b31aaeae97629460d37e71a7e252820beeabd0255dd8cd371f88808263cd44f344f19c2b960778cfa9f8aeb44aaed1aa","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595126.pdf","title":"Image Analysis Approach to Trademark Congestion and Depletion","llm_title":"Image Analysis Approach to Trademark Congestion and Depletion","authors":["Amit Haim","Aniket Kesari"],"llm_authors":"Amit Haim, Aniket Kesari","author_string":"Amit Haim","year":2023,"abstract":"","llm_abstract":"Is there a limited supply of good image trademarks? Trademark law long rested on the assumption that there is an inexhaustible supply of good marks that provide businesses with sufficient economic advantages to engage in effective branding. However, this conventional wisdom has recently come under scrutiny as evidence has mounted that the number of effective word marks suffers from both depletion of good marks and congestion of similar marks within certain areas. Leveraging new advances in computational social science, we extend this analysis to the study of image marks. We find that there is little evidence for either congestion or depletion in image marks across the most popular areas, but do see some evidence for registered marks being more complex than unregistered marks.","llm_keywords":["trademark depletion","trademark congestion","image trademarks","empirical legal studies","computational social science","big data","computer vision","trademark law"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"0d0f0c8775c6eddc06d093d4d2856b029820d9614c558621db71c0f404dff5e89d2cfc925c8bcca09e57e4e9b576cf5808f05af9e5193944571f0bd6479f2c7c","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595128.pdf","title":"Effects of XAI on Legal Process","llm_title":"Effects of XAI on Legal Process","authors":["Aileen Nielsen","Stavroula Skylaki","Milda Norkute","Alexander Stremitzer"],"llm_authors":"Aileen Nielsen, Stavroula Skylaki, Milda Norkute, Alexander Stremitzer","author_string":"","year":2023,"abstract":"","llm_abstract":"Despite strong scholarly interest in explainable features in AI (XAI), there is little experimental work to gauge the effect of XAI on human-AI cooperation in legal tasks. We study the effect of textual highlighting as an XAI feature used in tandem with a machine learning (ML) generated summary of a legal complaint. In a randomized controlled study we find that the XAI has no effect on the proportion of time participants devote to different sections of a legal document, but we identify potential signs of XAI’s influence on the reading process. XAI attention-based highlighting may change the spatio-temporal distribution of attention allocation, a result not anticipated by previous studies. Future work on the effect of XAI in legal tasks should measure process as well as outcomes to better gauge the effects of XAI in legal applications.","llm_keywords":["explainable AI","legal process","user attention allocation","human-computer interaction","experimental study"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":5},{"id":"60abdbabf77d57e04c5f70736d791c24b398582c4e1c48dff11b9dba2f6babee968c166971a1384a05f9d205124f850872f8c6c595eff2f82edbf0fcf526216b","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595161.pdf","title":"Unlocking Practical Applications in Legal Domain: Evaluation of GPT for Zero-Shot Semantic Annotation of Legal Texts","llm_title":"Unlocking Practical Applications in Legal Domain: Evaluation of GPT for Zero-Shot Semantic Annotation of Legal Texts","authors":["Jaromir Savelka"],"llm_authors":"Jaromir Savelka","author_string":"Jaromir Savelka","year":2023,"abstract":"","llm_abstract":"We evaluated the capability of a state-of-the-art generative pre-trained transformer (GPT) model to perform semantic annotation of short text snippets (one to few sentences) coming from legal documents of various types. Discussions of potential uses (e.g., document drafting, summarization) of this emerging technology in legal domain have intensified, but to date there has not been a rigorous analysis of these large language models’ (LLM) capacity in sentence-level semantic annotation of legal texts in zero-shot learning settings. Yet, this particular type of use could unlock many practical applications (e.g., in contract review) and research opportunities (e.g., in empirical legal studies). We fill the gap with this study. We examined if and how successfully the model can semantically annotate small batches of short text snippets (10–50) based exclusively on concise definitions of the semantic types. We found that the GPT model performs surprisingly well in zero-shot settings on diverse types of documents (F1 = .73 on a task involving court opinions, .86 for contracts, and .54 for statutes and regulations). These findings can be leveraged by legal scholars and practicing lawyers alike to guide their decisions in integrating LLMs in wide range of workflows involving semantic annotation of legal texts.","llm_keywords":["Semantic legal annotation","generative pre-trained transformers","GPT","transfer learning","zero-shot","adjudicatory decisions","contracts","statutory and regulatory provisions"],"classifications":["Classification","Information Extraction"],"num_cited_by":58,"num_cited_by_title_only":58,"num_pages":5},{"id":"99e86ab83d2d2c237dc84d2f3df3e3e6ff5dbeeb6bdde1ef6a53debe4ece7df1d71e25ab4f6a46cac1210645ea1c9d7b5e692a0123ba5c01ebcd66eaa6588637","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595144.pdf","title":"Edited_31_05_2023LeArNER_fin_v4  (mgedit)","llm_title":"LeArNER: Few-shot Legal Argument Named Entity Recognition","authors":["Matthias Grabmair","Shao-Man Lee","Yu-Hsiang Tan","Han-Ting Yu"],"llm_authors":"Shao-Man Lee, Yu-Hsiang Tan, Han-Ting Yu","author_string":"Matthias Grabmair","year":2023,"abstract":"","llm_abstract":"Our proposed NER model for legal texts, LeArNER, utilizes minimal annotated data for model training to reduce expenses associated with corpus collection and training. We evaluated our model on a dataset of constitutional legal cases from Taiwan, written in traditional Chinese, and achieved an impressive F1 score of 94.88% for 13 entity types. LeArNER's performance was best achieved with a training sample of only 2000 sentences, highlighting its efficiency and potential for further legal NER research.","llm_keywords":["named entity recognition","few-shot learning","Taiwan Constitutional Court","traditional Chinese legal NER","legal texts","machine learning","deep learning","information extraction","natural language processing"],"classifications":["Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":5},{"id":"bfbfcea4eb7d9cb0f5862df808fb42f251e605fab6a1e97b4816a83bc9b39bde88e34125ad69b82f92c4acf45bf8fd8e234896a9bc9b39b0940ee7d5d17b73b2","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595169.pdf","title":"Analysing the Resourcefulness of the Paragraph for Precedence Retrieval","llm_title":"Analysing the Resourcefulness of the Paragraph for Precedence Retrieval","authors":["Bhoomeendra Singh Sisodiya","Narendra Babu Unnam","P. Krishna Reddy","Apala Das","K.V.K. Santhy","V. Balakista Reddy"],"llm_authors":"Bhoomeendra Singh Sisodiya, Narendra Babu Unnam, P. Krishna Reddy, Apala Das, K.V.K. Santhy, V. Balakista Reddy","author_string":"","year":2023,"abstract":"","llm_abstract":"Developing methods for extracting relevant legal information to aid legal practitioners is an active research area. In this regard, research efforts are being made by leveraging different kinds of information, such as meta-data, citations, keywords, sentences, paragraphs, etc. Similar to any text document, legal documents are composed of paragraphs. In this paper, we have analyzed the resourcefulness of paragraph-level information in capturing similarity among judgments for improving the performance of precedence retrieval. We found that the paragraph-level methods could capture the similarity among the judgments with only a few paragraph interactions and exhibit more discriminating power over the baseline document-level method. Moreover, the comparison results on two benchmark datasets for the precedence retrieval on the Indian supreme court judgments task show that the paragraph-level methods exhibit comparable performance with the state-of-the-art methods.","llm_keywords":["Judgment similarity","Legal Search","Common Law","Precedence retrieval","Paragraph-level information","Precedence retrieval systems","Legal documents","Information extraction"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":5},{"id":"b1a4736c525406b1e45ce36b025a432ba9fd22b41f13adf4758723e4ba36731759f7122d4113606926b7fb274c5e1e5fdc3df852d3e5ab83c904d5c66b24fdfb","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595160.pdf","title":"On Normative Arrows and Comparing Tax Automation Systems","llm_title":"On Normative Arrows and Comparing Tax Automation Systems","authors":[],"llm_authors":"P.N. Meessen","author_string":"P.N. Meessen","year":2023,"abstract":"","llm_abstract":"Automation of legal norms can only exist because of compromises made in translating laws in natural languages to code (executables) in formal languages. Tax and benefits law is canonically considered one of the least compromising domains of law in terms of this nuance. In this paper, I compare two domain-specific languages used in the automation of tax and benefits law: Catala, which is proposed for use by the French Tax Authority, and Regelspraak, which the Dutch Tax Authority uses. The comparison is based on a top-down modeling approach, which does not try to go all the way down to the technical differences but aims to identify the points at which the two approaches diverge in the way the norm is shaped. It becomes evident that a lot of decisions that affect normativity are made inside the technical components of these systems. Safeguarding legal protection at the creation of automation of norms will likely require cross-domain efforts.","llm_keywords":["legal automation","domain-specific languages","norm engineering","tax automation","tax law","Catala","Regelspraak","legal norms","French Tax Authority","Dutch Tax Authority"],"classifications":["Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":5},{"id":"d88d6d40e4d62a0975cbd82f909076ca94e4e434746a6bd1426c1355a34b758b459289997b737aab288c461563e17d842474de3b6aef33b64e23632ce7ebde60","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595120.pdf","title":"Keyword-based Augmentation Method to Enhance Abstractive Summarization for Legal Documents","llm_title":"Keyword-based Augmentation Method to Enhance Abstractive Summarization for Legal Documents","authors":["Huyen Nguyen","Junhua Ding"],"llm_authors":"Huyen Nguyen, Junhua Ding","author_string":"","year":2023,"abstract":"","llm_abstract":"Since state-of-the-art machine learning models like Transformers can not handle long text well, the quality of the summarization of legal documents is still not desirable. In order to improve the ability of machine learning models to understand the context of a long document, we introduce the keywords into the models to guide the summarization to locate and capture key information from long documents such as legal cases. Different from other works leveraging keywords to enhance the model, we further investigate how keyword quality impacts summarization. To improve the performance of the summarization, we also explore different methods for effectively encoding exceptionally lengthy documents and models for keyword extraction. The experiment results demonstrated that the keywords-based augmentation method is effective for summarization and higher-quality keywords can enhance the summarization models.","llm_keywords":["abstractive summarization","legal case summarization","keyword extraction","Transformers","natural language processing","information retrieval","text mining","NLP"],"classifications":["Machine Summarization","Information Extraction","Pre-Processing","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":5},{"id":"a6c5c26d171aa96d40722d853b69ca4910c6c13c3bf9f1703d49e605957e5730c4d28786d84af66a0591413da957cf361450e407551a89456650b550f7c07e37","file_path":"legal-nlp-survey-20250328-002/team 3/18-ICAIL/short papers/3594536.3595127.pdf","title":"Binding Language in Administrative Guidance Documents","llm_title":"Binding Language in Administrative Guidance Documents","authors":["Amit Haim"],"llm_authors":"Amit Haim","author_string":"Amit Haim","year":2023,"abstract":"","llm_abstract":"Do regulatory guidance documents use binding language despite being purportedly non-binding? Regulatory agencies play a crucial role in modern societies by issuing regulations. While most regulations are promulgated as rules with public notice and comment procedures, administrative guidance documents are as abundant but less studied. They have less formal requirements and are meant as non-binding guidelines, yet skeptics argue they are often used to evade judicial review, and courts turn to their text to inquire whether they are effectively binding. Recent advancements in text analysis methods have allowed scholars to analyze regulatory text, including the measurement of binding language. However, guidance documents have not been part of this trend, largely due to their inaccessibility. This article contributes to the field of empirical legal studies and administrative law by constructing a novel dataset of guidance documents, leveraging a unique policy change. It uses text analysis methods with qualitative insights from doctrinal court decisions, and finds that guidance documents are in fact less binding than rules, but that binding language increased over time and that substantial portions of available documents score higher than a document struck down by a court.","llm_keywords":["natural language processing","administrative law","guidance","rules","regulation"],"classifications":["Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":5},{"id":"ea5ffda4741b0509da9b395e607cb6b538a5227533b54907799fa79d3f7befafd4bbdacf1d109d54652ba0f3ef6fd5325bfcbfa3bbec0c004cba3b6197e4c6c9","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-12-21.pdf","title":"","llm_title":"CAPTAIN at COLIEE 2023: Efficient Methods for Legal Information Retrieval and Entailment Tasks","authors":["Chau Nguyen","Phuong Nguyen","Thanh Tran","Dat Nguyen","An Trieu","Tin Pham","Anh Dang","Le-Minh Nguyen"],"llm_authors":"Chau Nguyen, Phuong Nguyen, Thanh Tran, Dat Nguyen, An Trieu, Tin Pham, Anh Dang, Le-Minh Nguyen","author_string":"","year":2023,"abstract":"","llm_abstract":"The Competition on Legal Information Extraction/Entailment (COLIEE) is held annually to encourage advancements in the automatic processing of legal texts. Processing legal documents is challenging due to the intricate structure and meaning of legal language. In this paper, we outline our strategies for tackling Task 2, Task 3, and Task 4 in the COLIEE 2023 competition. Our approach involved utilizing appropriate state-of-the-art deep learning methods, designing methods based on domain characteristics observation, and applying meticulous engineering practices and methodologies to the competition. As a result, our performance in these tasks has been outstanding, with first places in Task 2 and Task 3, and promising results in Task 4.","llm_keywords":["COLIEE competition","Legal Text Processing","Legal Information Retrieval","Legal Information Entailment","Deep Learning","MonoT5 model"],"classifications":["Information Extraction","Classification","Information Retrieval"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":10},{"id":"07a65ba902beadc722a152a1beb5d3b814de56b6c477ba1b926965e0ea3ca58d92915a3eefc3846f95d08a7b8d1dce6a887841e261702b83ec41e519d2a3986f","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-37-44.pdf","title":"","llm_title":"NOWJ at COLIEE 2023 - Multi-Task and Ensemble Approaches in Legal Information Processing","authors":["Thi-Hai-Yen Vuong","Hai-Long Nguyen","Tan-Minh Nguyen","Hoang-Trung Nguyen","Thai-Binh Nguyen","Ha-Thanh Nguyen"],"llm_authors":"Thi-Hai-Yen Vuong, Hai-Long Nguyen, Tan-Minh Nguyen, Hoang-Trung Nguyen, Thai-Binh Nguyen, Ha-Thanh Nguyen","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper presents the NOWJ team’s approach to the COLIEE 2023 Competition, which focuses on advancing legal information processing techniques and applying them to real-world legal scenarios. Our team tackles the four tasks in the competition, which involve legal case retrieval, legal case entailment, statute law retrieval, and legal textual entailment. We employ state-of-the-art machine learning models and innovative approaches, such as BERT, Longformer, BM25-ranking algorithm, and multi-task learning models. Although our team did not achieve state-of-the-art results, our findings provide valuable insights and pave the way for future improvements in legal information processing.","llm_keywords":["Legal information processing","COLIEE","NOWJ","Multi-task learning","Ensemble approaches","BERT","Longformer","BM25-ranking","Legal case retrieval","Legal textual entailment"],"classifications":["Information Retrieval"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":8},{"id":"9e72b78c7c6b8d5678945046005a9aa66dbbe218c19ed5e12d14b41f1d70abeb4508747f5d2f52f8796ac8458ad5b95c0e6c1385a55443558bcb9eea89194a3a","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-53-57.pdf","title":"","llm_title":"Transformer-based Legal Information Extraction","authors":["Mi-Young Kim","Juliano Rabelo","Housam Babiker","Randy Goebel"],"llm_authors":"Mi-Young Kim, Juliano Rabelo, Housam Babiker, and Randy Goebel","author_string":"","year":2023,"abstract":"","llm_abstract":"The challenge of information overload in the legal domain increases every day. The COLIEE competition has created four challenge tasks which are intended to encourage the development of systems and methods to alleviate some of that pressure: a case law retrieval (Task 1) and entailment (Task 2), and a statute law retrieval (Task 3) and entailment (Task 4). In this paper, we describe our methods for Task 1 and Task 4. In Task 1 we used a sentence-transformer model to create a numeric representation for each case paragraph, then create a histogram of the similarities between a query case and a candidate case. The histogram is then submitted to a binary classifier which decides whether that candidate case should be noticed or not. Some postprocessing heuristics are also applied. Our method for Task 4 was ranked third among eight participating teams in the COLIEE 2023 competition. Our approach relies on fine-tuning a pre-trained DeBERTa large language model trained on SNLI and MultiNLI datasets.","llm_keywords":["legal information extraction","transformer-based model","case law retrieval","statute law entailment","binary classification","textual entailment","natural language inference","semantic similarity"],"classifications":["Information Retrieval","Classification"],"num_cited_by":7,"num_cited_by_title_only":4,"num_pages":5},{"id":"a26fee80ac4d3de44ba5567f2adadf6bdc44b05d0c012d8fdeeea55a3e2290fc2d21e980665ff090a7fe2ac93df5cd9728110ea54cdd847a06f3431dafb5a04d","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-63-67.pdf","title":"","llm_title":"Performance of Individual Models vs. Agreement-Based Ensembles for Case Entailment","authors":["Michel Custeau","Diana Inkpen"],"llm_authors":"Michel Custeau, Diana Inkpen","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper investigates the performance of an agreement-based ensemble approach in Task 2 of the COLIEE 2023 competition, which aims to assess entailment relationships between queries and candidate paragraphs in legal language. The experiments utilized agreement-based RoBERTa ensembles that combined differently pretrained RoBERTa models, which had the goal of improving overall performance by evaluating their agreement on entailment decisions. This method was designed based on its success on the previous year’s competition dataset. The findings show that while the RoBERTa agreement-based ensembles achieved a higher score compared to individual models on the COLIEE 2022 dataset, it failed to outperform the individual models on the 2023 competition data, indicating that the ensemble approach in its current state may not be the most effective for this task. These results emphasize the necessity for further investigation of the suggested ensemble methodology, while concurrently identifying specific components within the ensembles that warrant enhancement.","llm_keywords":["Legal NLP","Case Entailment","RoBERTa","SNLI","Agreement-based Ensemble"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":5},{"id":"79d7a3d9cc5eeb58f49aa198e13d82ea28965785cd53b0b396be0717969439695c28de06d39cbaee23db487dfbbe10f4ead222340d2004193d4648701a5dd00c","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-58-62.pdf","title":"","llm_title":"THUIR@COLIEE 2023: More Parameters and Legal Knowledge for Legal Case Entailment","authors":["Haitao Li","Changyue Wang","Weihang Su","Yueyue Wu","Qingyao Ai","Yiqun Liu"],"llm_authors":"Haitao Li, Changyue Wang, Weihang Su, Yueyue Wu, Qingyao Ai, Yiqun Liu","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper describes the approach of the THUIR team at the COLIEE 2023 Legal Case Entailment task. This task requires the participant to identify a specific paragraph from a given supporting case that entails the decision for the query case. We try traditional lexical matching methods and pre-trained language models with different sizes. Furthermore, learning-to-rank methods are employed to further improve performance. However, learning-to-rank is not very robust on this task. which suggests that answer passages cannot simply be determined with information retrieval techniques. Experimental results show that more parameters and legal knowledge contribute to the legal case entailment task. Finally, we get the third place in COLIEE 2023. The implementation of our method can be found at https://github.com/CSHaitao/THUIR-COLIEE2023.","llm_keywords":["legal case entailment","language model","legal NLP","information retrieval","learning-to-rank"],"classifications":["Classification","Information Retrieval"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":5},{"id":"8e4ffdd23df9267d652b5528b60046c94524b2f0dc23b0ad6ea80e09ef796b47905460bf70975ff65e9f64ab7ad7400fd2ebc6c8efd7b46c6ed83ff267d9dd48","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-6-11.pdf","title":"","llm_title":"THUIR@COLIEE 2023: Incorporating Structural Knowledge into Pre-trained Language Models for Legal Case Retrieval","authors":["Haitao Li","Weihang Su","Changyue Wang","Yueyue Wu","Qingyao Ai","Yiqun Liu"],"llm_authors":"Haitao Li, Weihang Su, Changyue Wang, Yueyue Wu, Qingyao Ai, Yiqun Liu","author_string":"","year":2023,"abstract":"","llm_abstract":"Legal case retrieval techniques play an essential role in modern intelligent legal systems. As an annually well-known international competition, COLIEE is aiming to achieve the state-of-the-art retrieval model for legal texts. This paper summarizes the approach of the championship team THUIR in COLIEE 2023. To be specific, we design structure-aware pre-trained language models to enhance the understanding of legal cases. Furthermore, we propose heuristic pre-processing and post-processing approaches to reduce the influence of irrelevant messages. In the end, learning-to-rank methods are employed to merge features with different dimensions. Experimental results demonstrate the superiority of our proposal. Official results show that our run has the best performance among all submissions. The implementation of our method can be found at https://github.com/CSHaitao/THUIR-COLIEE2023.","llm_keywords":["legal case retrieval","dense retrieval","pre-trained language models","structural knowledge","legal texts","COLIEE","learning-to-rank"],"classifications":["Pre-Processing","Information Retrieval"],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":6},{"id":"8eaa548b764c565b1fca0c711f7f802fa2419995a754945a861a8c06029fdc5d1d8d486e5774f5e0406e8d3562af29242b2f49c1e186903749e340a21aacd5a9","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-68-76.pdf","title":"","llm_title":"Japanese Legal Bar Problem Solver Focusing on Person Names","authors":["Takaaki Onaga","Masaki Fujita","Yoshinobu Kano"],"llm_authors":"Takaaki Onaga, Masaki Fujita, Yoshinobu Kano","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper describes our system for COLIEE 2023 Task 4, which automatically answers Japanese legal bar exam problems. We propose an extension to our previous system in COLIEE 2022, which achieved the highest accuracy among all submissions by using data augmentation. In this paper, we present three main contributions. First, we incorporate LUKE as our deep learning component, a named entity recognition model trained on RoBERTa. Second, we ensemble the given training datasets in a manner similar to cross-validation, to utilize the training data to the fullest extent possible. Third, we fine-tune the pretrained LUKE model in multiple ways, comparing fine-tuning on training datasets that include alphabetical person names and ensembling different fine-tuning models. Our formal run results show that LUKE and our fine-tuning approach using alphabetical person names were effective, achieving an accuracy of 0.69 in the COLIEE 2023 Task 4 formal run.","llm_keywords":["COLIEE","legal textual entailment","Legal Bar Exam","LUKE","Predicate Argument Structure Analysis"],"classifications":["Classification","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":9},{"id":"1b5541d23f4d515933c4849c9ce70781c2aaf8a961449cad45bcd4fa029abe728b2226d2adf5f794c7fbec74df11a397b4fd669445ab6926a16308c39b503286","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-45-52.pdf","title":"","llm_title":"IITDLI : Legal Case Retrieval Based on Lexical Models","authors":["Rohan Debbarma","Pratik Prawar","Abhijnan Chakraborty","Srikanta Bedathur"],"llm_authors":"Rohan Debbarma, Pratik Prawar, Abhijnan Chakraborty, Srikanta Bedathur","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper describes in detail the methods used by IITDLI as a part of its submission to Competition of Legal Information Extraction and Entailment (COLIEE) 2023 for Task 1 (Legal Case Retrieval) and Task 2 (Legal Case Entailment). For Task 1, a retrieval pipeline consisting of term extraction, ranking using lexical model (BM25), year filter and post-processing of results produced excellent results. For Task 2, it was observed that zero shot Mono-T5 trained out of domain still outperforms other traditional and neural retrieval models. For Task 1, we have also explored how the different components of the pipeline incrementally contribute to the performance of the model. It is observed that year filter and term extraction are extremely crucial components of the pipeline sans which the Micro F1 dropped by more than 3% in validation set. Our submission ranked 2nd among all teams for Task 1 and 4th among all teams for Task 2.","llm_keywords":["legal information retrieval","natural language processing","textual entailment","case law retrieval","case law entailment"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":8},{"id":"c6592fe9a0ea2a7e3f3f434598b249ec2c28baee55c41024b7ef4cc9e51db85b70c1928d7f459f3cee065842818ce12700c64ed50491e4aadebdeb5d5e2ac567","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-32-36.pdf","title":"","llm_title":"A Topic-Based Approach for the Legal Case Retrieval Task","authors":["Luisa Pereira Novaes","Daniela Vianna","Altigran da Silva"],"llm_authors":"Luisa Pereira Novaes, Daniela Vianna, Altigran da Silva","author_string":"","year":2023,"abstract":"","llm_abstract":"This paper describes the method developed by the UFAM team in the 10th COLIEE for Task 1, the legal case retrieval task. In a nutshell, we propose a topic-based approach composed of two phases: filtering and ranking. In the filtering phase, a topic discovery technique is applied to the entire dataset to select an initial set of candidate cases for each query. Then, in the ranking phase, three different ranking functions can be applied to each pair query and candidate from the set producing a sorted list of relevant cases per query. Finally, using a predefined 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 (cut-off value), we select the most relevant documents for a given query. Based on this two-phased approach, we implemented three different solutions that achieved the two best precision values for this competition. Of a total of 22 results, our best result was ranked number 12 in the overall ranking.","llm_keywords":["topic discovery","legal case retrieval","Doc2Vec","cosine similarity","COLIEE","Rank aggregation","Similarity measures","Retrieval models","ranking"],"classifications":["Information Retrieval"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":5},{"id":"ed32614846e5eeea945e64b80e416da71c92001c1cc47c2ab972c0915c5f2c9a4bb312660273b852a52a950465559c5c4a8bae8f661603dcf0b952cf8a897042","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-77-81.pdf","title":"","llm_title":"HUKB at COLIEE 2023 Statute Law Task","authors":["Masaharu Yoshioka","Yasuhiro Aoki"],"llm_authors":"Masaharu Yoshioka, Yasuhiro Aoki","author_string":"","year":2023,"abstract":"","llm_abstract":"We participated in the statute law task (task 3: information retrieval and task 4: legal textual entailment) of the Competition on Legal Information Extraction/Entailment (COLIEE). For task 3, we modify the system used for the COLIEE 2022, which uses three different IR systems; a BERT-based IR system, an ordinal keyword-based IR system, and an ordinal keyword-based IR system that uses the similarity of judicial decision descriptions between questions and articles. For task 4, we try to include a module that selects the most relevant part of the article for the entailment to make the description of the article concise. We discuss the characteristics of the system using evaluation results for COLIEE 2023 submissions.","llm_keywords":["Information Retrieval","Textual entailment","BERT","Legal Information Extraction","Ensemble method","Statute Law","Judicial decision","Legal textual entailment","Competition on Legal Information Extraction"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":5},{"id":"72fbf750ecff034ceb8fedfed030a03cfe7032336247bb1377c51881227081b5043720725d38ad0b9c066af9a6f261d7ae0a444c91d660523c922b36f13a8852","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-22-31.pdf","title":"","llm_title":"JNLP @COLIEE-2023: Data Augmentation and Large Language Model for Legal Case Retrieval and Entailment","authors":["Quan Minh Bui","Dinh-Truong Do","Nguyen-Khang Le","Dieu-Hien Nguyen","Khac-Vu-Hiep Nguyen","Trang Pham Ngoc Anh","Minh Le Nguyen"],"llm_authors":"Quan Minh Bui, Dinh-Truong Do, Nguyen-Khang Le, Dieu-Hien Nguyen, Khac-Vu-Hiep Nguyen, Trang Pham Ngoc Anh, Minh Le Nguyen","author_string":"","year":2023,"abstract":"","llm_abstract":"The process of legal case retrieval involves identifying relevant cases that share similarities with a given case, while entailment requires assessing whether a legal statement can logically follow from another. These tasks are challenging due to the intricate nature of legal language and the vast quantity of legal documents. To overcome these difficulties, we propose implementing data augmentation techniques to produce additional training data and employing a large language model such as BART or T5 to capture the nuances of legal language. Specifically, we augment the provided dataset by generating synthetic cases that exhibit similar attributes to the original cases. We subsequently train a large language model on the augmented dataset and employ it to retrieve pertinent cases and determine entailment. Our findings also reveal that certain large language generative models, such as the Flan model have demonstrated potential for performing exceptionally well on the COLIEE task4 dataset. Notably, Flan model achieved state-of-the-art results on the COLIEE2023 and 2022 task 4 test sets.","llm_keywords":["Legal","Deep Learning","Contrastive Learning","Transformer Model","Large Language Model","Prompt Tuning"],"classifications":[],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":10},{"id":"b3403bdc2b9a68de5e7a36c00567cbd5a4721a88f585e5d8a75aaba4fd333da9fb08cb235321a76ea45062bad589ada9db88dd77e521deba08d0d0d9d5fc9da5","file_path":"legal-nlp-survey-20250328-002/team 3/21-COLIEE/COLIEE2023proceedings-82-91.pdf","title":"","llm_title":"AMHR Lab 2023 COLIEE Competition Approach","authors":["Onur Bilgin","Logan Fields","Antonio Laverghetta Jr.","Zaid Marji","Animesh Nighojkar","Stephen Steinle","John Licato"],"llm_authors":"Onur Bilgin, Logan Fields, Antonio Laverghetta Jr.*, Zaid Marji, Animesh Nighojkar, Stephen Steinle*, John Licato","author_string":"","year":2023,"abstract":"","llm_abstract":"We report on our submissions for Task 4 of the 2023 COLIEE competition. Our approach was to use prompt engineering techniques with large pre-trained language models, that were not fine-tuned for the task. Our most successful strategy used simple text similarity measures to retrieve articles and queries from the training set. We report on our efforts to optimize performance with both OpenAI’s GPT-4 and FLaN-T5. We then used an ensemble approach to find the best combination of models and prompts. We also report on our attempts to understand our results and suggest ideas for future improvements.","llm_keywords":["AI","NLP","Reasoning","Law","Legal"],"classifications":["Information Retrieval","Pre-Processing"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"bc7f6581ee3a5f3b0398cd068f4f6877605c3e7734827ecf75482451fe52edb24d2056b071d7300c64f2332195a7c0b543f0d628fee121e5b5fc93f3b8a63d4e","file_path":"legal-nlp-survey-20250328-002/team 3/16-ROCLING/2023.rocling-1.29.pdf","title":"","llm_title":"Analyzing Bid-Rigging Related Judicial Cases of Government Procurement Law Using Text Mining Techniques","authors":["Pei-Zhen Chen","Hsin-Yun Hsu","Jheng-Long Wu"],"llm_authors":"Pei-Zhen Chen, Hsin-Yun Hsu, Jheng-Long Wu","author_string":"","year":2023,"abstract":"","llm_abstract":"Most previous studies have manually labeled judgment data and used statistical methods to summarize their characteristics. Therefore, this study aims to extract key information from unstructured data, perform feature engineering through regular expressions, and find frequently occurring item sets. , helping auditors select high-risk government procurement cases more efficiently and accurately. This study uses Apriori and LDA topic analysis to identify the characteristics and frequent combinations of manufacturers, procurement bids, and bidding agencies that violate government procurement laws in the data set. This method can mark procurement cases with the characteristics of bid-rigging cases and summarize frequent items involving violations of common characteristics of government procurement cases. The research results found that the manufacturer is a limited company with a registered capital between NT$1 million and NT$10 million. The probability of occurrence of those who participate in the lowest bid amount is 0.62, which is a relatively frequent project; civil engineering contracting, construction business and local government partners are close to each other. These findings can become one of the references for selecting bid documents under limited audit manpower.","llm_keywords":["Text Mining","Government Procurement","Apriori","LDA","Bid-Rigging","Feature Engineering","Frequent Pattern Mining","NLP","Unstructured Data"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":9},{"id":"adbd5a4ae6bce140aeb2ede0eabeb71430ca2ceb5d1931c8cc7cc0221769559131e1d2fa3449a43da9cbbc57730bb7fc8c6bdc213cc0406622e02a56c4c44bc5","file_path":"legal-nlp-survey-20250328-002/team 3/16-ROCLING/2023.rocling-1.32.pdf","title":"","llm_title":"房屋租賃文本與法律條文相關性辨識之研究","authors":["Min-Chin Ho","Ya-Mien Cheng","Jheng-Long Wu"],"llm_authors":"Min-Chin Ho, Ya-Mien Cheng, Jheng-Long Wu","author_string":"","year":2023,"abstract":"","llm_abstract":"In recent years, the housing market in Taiwan has seen soaring prices due to various factors, leading many people to choose renting over buying. However, many renters are unfamiliar with the relevant regulations and details when signing rental agreements. Combined with a lack of thorough review or overlooking complex contract terms, these factors often lead to disputes. This study aims to develop an online housing lease identification system that allows tenants to assess whether their lease contracts have issues. It will also provide information on legal provisions that can be used in case of disputes during the rental process, helping renters reduce misunderstandings about legal regulations and contract terms. In this research, five models were used, and four influencing factors were selected for model training and evaluation. Among them, the distilbert-base-multilingual-cased model performed the best with a macro F1 score of 0.14 and a weighted F1 score of 0.21, without considering any influencing factors. However, the overall performance of all models on this research dataset was generally poor. The results suggest that the identification of relevant legal provisions for lease issues still requires the establishment of a larger and more diverse corpus of text data.","llm_keywords":["legal judgment","civil case","residential lease agreement"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":7},{"id":"30e94c5f96bbad2cb691b31e23f4fafe76ba4a20f57fa6db8c091c53b99c7c3f12c5059a6570cdce3d351380e20534c718a1dfc6d9f1c6afcd72fdc6da7fdece","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09349-8.pdf","title":"Ensemble methods for improving extractive summarization of legal case judgements","llm_title":"Ensemble methods for improving extractive summarization of legal case judgements","authors":["Aniket Deroy","Kripabandhu Ghosh","Saptarshi Ghosh"],"llm_authors":"Aniket Deroy, Kripabandhu Ghosh, Saptarshi Ghosh","author_string":"Aniket Deroy","year":2023,"abstract":"","llm_abstract":"Summarization of legal case judgement documents is a practical and challenging problem, for which many summarization algorithms of different varieties have been tried. In this work, rather than developing yet another summarization algorithm, we investigate if intelligently ensembling (combining) the outputs of multiple (base) summarization algorithms can lead to better summaries of legal case judgements than any of the base algorithms. Using two datasets of case judgement documents from the Indian Supreme Court, one with extractive gold standard summaries and the other with abstractive gold standard summaries, we apply various ensembling techniques on summaries generated by a wide variety of summarization algorithms. The ensembling methods applied range from simple voting-based methods to ranking-based and graph-based ensembling methods. We show that many of our ensembling methods yield summaries that are better than the summaries produced by any of the individual base algorithms, in terms of ROUGE and METEOR scores.","llm_keywords":["Legal case judgement summarization","Ensemble summarization","Extractive summarization","Unsupervised summarization","Supervised summarization"],"classifications":["Machine Summarization"],"num_cited_by":39,"num_cited_by_title_only":39,"num_pages":59},{"id":"fad69e95ddbab9d36d0e876962cf49313bfb8d1e90f7950e8059f500656e6675fa51223e77031941a9293d178a920bf20f8cad0cf0e41df2d55e4eed55ae98c4","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09377-4.pdf","title":"Integrating legal event and context information for Chinese similar case analysis","llm_title":"Integrating legal event and context information for Chinese similar case analysis","authors":["Jingpei Dan","Lanlin Xu","Yuming Wang"],"llm_authors":"Jingpei Dan, Lanlin Xu, Yuming Wang","author_string":"Jingpei Dan","year":2023,"abstract":"","llm_abstract":"Similar case analysis (SCA) is an essential topic in legal artificial intelligence, serving as a reference for legal professionals. Most existing works treat SCA as a traditional text classification task and ignore some important legal elements that affect the verdict and case similarity, like legal events, and thus are easily misled by semantic structure. To address this issue, we propose a Legal Event-Context Model named LECM to improve the accuracy and interpretability of SCA based on Chinese legal corpus. The event-context integration mechanism, which is an essential component of the LECM, is proposed to integrate the legal event and context information based on the attention mechanism, enabling legal events to be associated with their corresponding relevant contexts. We introduce an event detection module to obtain the legal event information, which is pre-trained on a legal event detection dataset to avoid labeling events manually. We conduct extensive experiments on two SCA tasks, i.e., similar case matching (SCM) and similar case retrieval (SCR). Compared with baseline models, LECM is validated by about 13% and 11% average improvement in terms of mean average precision and accuracy respectively, for SCR and SCM tasks. These results indicate that LECM effectively utilizes event-context knowledge to enhance SCA performance and its potential application in various legal document analysis tasks.","llm_keywords":["Natural language processing","Legal artificial intelligence","Similar case analysis","Event detection","Chinese legal corpus"],"classifications":["Classification","Information Retrieval","Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":42},{"id":"a92bca85687daf4c3ffb9560db2f8ba9d8464e6a774e4b86d19806a2a7a74d7080f87de4a18962fad9257ed57de6227f425a81309d5ee79b868c3db50096b39f","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09383-6.pdf","title":"Decision support for detecting sensitive text in government records","llm_title":"Decision support for detecting sensitive text in government records","authors":["Karl Branting","Bradford Brown","Chris Giannella","James Van Guilder","Jef Harrold","Sarah Howell","Jason R. Baron"],"llm_authors":"Karl Branting, Bradford Brown, Chris Giannella, James Van Guilder, Jef Harrold, Sarah Howell, Jason R. Baron","author_string":"Karl Branting","year":2023,"abstract":"","llm_abstract":"Freedom of information laws promote transparency by permitting individuals and organizations to obtain government documents. However, exemptions from disclosure are necessary to protect privacy and to permit government officials to deliberate freely. Deliberative language is often the most challenging and burdensome exemption to detect, leading to high processing costs and delays in responding to open-records requests. This paper describes a novel deliberative-language detection model trained on a new annotated training set. The deliberative-language detection model is a component of a decision-support system for open-records requests under the US Freedom of Information Act, the FOIA Assistant, that ingests documents responsive to an open-records requests, suggests passages likely to be subject to deliberative language, privacy, or other exemptions, and assists analysts in rapidly redacting suggested passages. The tool’s interface is based on extensive human-factors and usability studies with analysts and is currently in operational testing by multiple US federal agencies.","llm_keywords":["Artificial Intelligence and Law","Freedom of Information","Machine Learning","Human Language Technology","Deliberative Language Detection","Decision Support System","FOIA","Redaction","Human-Computer Interface","Usability"],"classifications":["Information Extraction","Classification","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":27},{"id":"008ff52d3331e7a0e88c0db46922944853db458f76e89a86f3b8fdd71c56200d21a9b01fcebcbd3a2ad90739bd193b504bf1a964194832f9bacf718119ab52eb","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09366-7.pdf","title":"Integrating text mining and system dynamics to evaluate financial risks of construction contracts","llm_title":"Integrating text mining and system dynamics to evaluate financial risks of construction contracts","authors":["Mahdi Bakhshayesh","Hamidreza Abbasianjahromi"],"llm_authors":"Mahdi Bakhshayesh, Hamidreza Abbasianjahromi","author_string":"Mahdi Bakhshayesh","year":2023,"abstract":"","llm_abstract":"Financial risks are among the most important risks in the construction industry projects, which significantly impact project objectives, including project cost. Besides, financial risks have many interactions with each other and project parameters, which must be taken into account to analyze risks correctly. In addition, a source of financial risks in a project is the contract, which is the most important project document. Identifying terms related to financial risks in a contract and considering their effects on the risk management process is an essential issue that has been neglected. Hence, an integrated model for evaluating financial risks and their related contractual clauses were presented. To this end, the effect of financial risks on the project cost was simulated using a system dynamics model. Moreover, terms related to financial risks in a contract text were identified and extracted using text mining, and their effect was included in the system dynamics model. The model was implemented in a hospital construction project in Tehran as a case study, and its results were analyzed. The innovation of the research is integrating text mining and the system dynamics model to investigate the effect of financial risks and related contractual clauses on the project cost.","llm_keywords":["Risk management","Financial risks","Text mining","Natural language processing","Construction contracts","System dynamics model"],"classifications":["Information Extraction","Information Retrieval"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":28},{"id":"6cf1e198c05973a6e191abaa54a09cfe1d234d7ec32801a349646cf24570ea6f550b36bdc6cd1edd6a447bcf68f7b4303d162cef0fc75525232a82b9a9942eef","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09365-8.pdf","title":"M-LAMAC: a model for linguistic assessment of mitigating and aggravating circumstances of criminal responsibility using computing with words","llm_title":"M‑LAMAC: a model for linguistic assessment of mitigating and aggravating circumstances of criminal responsibility using computing with words","authors":["Carlos Rafael Rodríguez Rodríguez","Yarina Amoroso Fernández","Denis Sergeevich Zuev","Marieta Peña Abreu","Yeleny Zulueta Veliz"],"llm_authors":"Carlos Rafael Rodríguez Rodríguez, Yarina Amoroso Fernández, Denis Sergeevich Zuev, Marieta Peña Abreu, Yeleny Zulueta Veliz","author_string":"Carlos Rafael Rodríguez Rodríguez","year":2023,"abstract":"","llm_abstract":"The general mitigating and aggravating circumstances of criminal liability are elements attached to the crime that, when they occur, affect the punishment quantum. Cuban criminal legislation provides a catalog of such circumstances and some general conditions for their application. Such norms give judges broad discretion in assessing circumstances and adjusting punishment based on the intensity of those circumstances. In the interest of broad judicial discretion, the law does not establish specific ways for measuring circumstances’ intensity. This gives judges more freedom and autonomy, but it also imposes on them more social responsibility and challenges them to manage the uncertainty and subjectivity inherent in this complex activity. This paper proposes a model to aid the linguistic assessment of circumstances’ intensity and to provide linguistic and numerical recommendations to determine an appropriate punishment interval. M-LAMAC determines the collective evaluation of circumstances of the same type, determines the prevalence of a type of circumstance by means of a compensation function, recommends the required modification in the input interval, and finally recommends a numerical interval adjusted to the judges’ initially expressed preferences. The model’s applicability is demonstrated by means of several experiments on a fictitious case of bank document forgery.","llm_keywords":["Criminal law","Mitigating circumstances","Aggravating circumstances","Linguistic assessment","Punishment adequacy","2-tuple linguistic model"],"classifications":["Classification","Information Extraction","Text Generation"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":43},{"id":"28807f96f58b3edc1550de778c938cc1fd3b3ac67a0130e036c60b0ec4f6ef42eb0dc69950c203e809026e3175cc10aceb40ddcd3280e43b65061dcc3c827abf","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09371-w.pdf","title":"A topic discovery approach for unsupervised organization of legal document collections","llm_title":"A topic discovery approach for unsupervised organization of legal document collections","authors":["Daniela Vianna","Edleno Silva de Moura","Altigran Soares da Silva"],"llm_authors":"Daniela Vianna, Edleno Silva de Moura, Altigran Soares da Silva","author_string":"Daniela Vianna","year":2023,"abstract":"","llm_abstract":"Technology has substantially transformed the way legal services operate in many different countries. With a large and complex collection of digitized legal documents, the judiciary system worldwide presents a promising scenario for the development of intelligent tools. In this work, we tackle the challenging task of organizing and summarizing the constantly growing collection of legal documents, uncovering hidden topics, or themes that later can support tasks such as legal case retrieval and legal judgment prediction. Our approach to this problem relies on topic discovery techniques combined with a variety of preprocessing techniques and learning-based vector representations of words, such as Doc2Vec and BERT-like models. The proposed method was validated using four different datasets composed of short and long legal documents in Brazilian Portuguese, from legal decisions to chapters in legal books. Analysis conducted by a team of legal specialists revealed the effectiveness of the proposed approach to uncover unique and relevant topics from large collections of legal documents, serving many purposes, such as giving support to legal case retrieval tools and also providing the team of legal specialists with a tool that can accelerate their work of labeling/tagging legal documents.","llm_keywords":["Topic modeling","Topic discovery","Contextualized embeddings","Legal domain","Brazilian judiciary system"],"classifications":["Machine Summarization","Pre-Processing","Information Retrieval","Information Extraction"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":30},{"id":"8720e4f76a16373ae490d21d17b52fde7973211be7a27740286cb011303d1502f6c1e68b5600ed75d013cdd3c7d287d6ce8a9f5c604fbf9e791b85b2f9593b4a","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09373-8.pdf","title":"Multi-language transfer learning for low-resource legal case summarization","llm_title":"Multi‑language transfer learning for low‑resource legal case summarization","authors":["Gianluca Moro","Nicola Piscaglia","Luca Ragazzi","Paolo Italiani"],"llm_authors":"Gianluca Moro, Nicola Piscaglia, Luca Ragazzi, Paolo Italiani","author_string":"Gianluca Moro","year":2023,"abstract":"","llm_abstract":"Analyzing and evaluating legal case reports are labor-intensive tasks for judges and lawyers, who usually base their decisions on report abstracts, legal principles, and commonsense reasoning. Thus, summarizing legal documents is time-consuming and requires excellent human expertise. Moreover, public legal corpora of specific languages are almost unavailable. This paper proposes a transfer learning approach with extractive and abstractive techniques to cope with the lack of labeled legal summarization datasets, namely a low-resource scenario. In particular, we conducted extensive multi- and cross-language experiments. The proposed work outperforms the state-of-the-art results of extractive summarization on the Australian Legal Case Reports dataset and sets a new baseline for abstractive summarization. Finally, syntactic and semantic metrics assessments have been carried out to evaluate the accuracy and the factual consistency of the machine-generated legal summaries.","llm_keywords":["Legal case reports","Extractive summarization","Abstractive summarization","Transfer learning","Multi-language","NLP"],"classifications":[],"num_cited_by":19,"num_cited_by_title_only":19,"num_pages":29},{"id":"66efdece2bb6c79878f5fe7eb9ffa3f164cce48423c951bb595c9e519344c277e0bec1018622e2cec065499c3628127b3661a7bf0548587ee9c389143f9c91c5","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09360-z.pdf","title":"Compliance checking on first-order knowledge with conflicting and compensatory norms: a comparison among currently available technologies","llm_title":"Compliance checking on first-order knowledge with conflicting and compensatory norms: a comparison among currently available technologies","authors":["Livio Robaldo","Sotiris Batsakis","Roberta Calegari","Francesco Calimeri","Megumi Fujita","Guido Governatori","Maria Concetta Morelli","Francesco Pacenza","Giuseppe Pisano","Ken Satoh","Ilias Tachmazidis","Jessica Zangari"],"llm_authors":"Livio Robaldo, Sotiris Batsakis, Roberta Calegari, Francesco Calimeri, Megumi Fujita, Guido Governatori, Maria Concetta Morelli, Francesco Pacenza, Giuseppe Pisano, Ken Satoh, Ilias Tachmazidis, Jessica Zangari","author_string":"Livio Robaldo","year":2023,"abstract":"","llm_abstract":"This paper analyses and compares some of the automated reasoners that have been used in recent research for compliance checking. Although the list of the considered reasoners is not exhaustive, we believe that our analysis is representative enough to take stock of the current state of the art in the topic. We are interested here in formalizations at the first-order level. Past literature on normative reasoning mostly focuses on the propositional level. However, the propositional level is of little usefulness for concrete LegalTech applications, in which compliance checking must be enforced on (large) sets of individuals. Furthermore, we are interested in technologies that are freely available and that can be further investigated and compared by the scientific community. In other words, this paper does not consider technologies only employed in industry and/or whose source code is non-accessible. This paper formalizes a selected use case in the considered reasoners and compares the implementations, also in terms of simulations with respect to shared synthetic datasets. The comparison will highlight that lot of further research still needs to be done to integrate the benefits featured by the different reasoners into a single standardized first-order framework, suitable for LegalTech applications. All source codes are freely available at https://github.com/liviorobaldo/compliancecheckers, together with instructions to locally reproduce the simulations.","llm_keywords":["compliance checking","first-order knowledge","LegalTech","deontic logic","normative reasoning","conflicting norms","compensatory norms","automated reasoners"],"classifications":[],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":51},{"id":"edf430295de9013d7a970d52b80e7af077d367f8f63efcdba05d947cb650e8f78d861dc294f73d52cd0e5c557f97c90bddb5e183db34ebdb4dc03a06576d6061","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09353-y.pdf","title":"The use of AI in legal systems: determining independent contractor vs. employee status","llm_title":"The use of AI in legal systems: determining independent contractor vs. employee status","authors":["Maxime C. Cohen","Samuel Dahan","Warut Khern-am-nuai","Hajime Shimao","Jonathan Touboul"],"llm_authors":"Maxime C. Cohen, Samuel Dahan, Warut Khern-am-nuai, Hajime Shimao, Jonathan Touboul","author_string":"Maxime C. Cohen","year":2023,"abstract":"","llm_abstract":"The use of artificial intelligence (AI) to aid legal decision making has become prominent. This paper investigates the use of AI in a critical issue in employment law, the determination of a worker’s status—employee vs. independent contractor—in two common law countries (the U.S. and Canada). This legal question has been a contentious labor issue insofar as independent contractors are not eligible for the same benefits as employees. It has become an important societal issue due to the ubiquity of the gig economy and the recent disruptions in employment arrangements. To address this problem, we collected, annotated, and structured the data for all Canadian and Californian court cases related to this legal question between 2002 and 2021, resulting in 538 Canadian cases and 217 U.S. cases. In contrast to legal literature focusing on complex and correlated characteristics of the employment relationship, our statistical analyses of the data show very strong correlations between the worker’s status and a small subset of quantifiable characteristics of the employment relationship. In fact, despite the variety of situations in the case law, we show that simple, off-the-shelf AI models classify the cases with an out-of-sample accuracy of more than 90%. Interestingly, the analysis of misclassified cases reveals consistent misclassification patterns by most algorithms. Legal analyses of these cases led us to identify how equity is ensured by judges in ambiguous situations. Finally, our findings have practical implications for access to legal advice and justice. We deployed our AI model via the open-access platform, https://MyOpenCourt.org/, to help users answer employment legal questions. This platform has already assisted many Canadian users, and we hope it will help democratize access to legal advice to large crowds.","llm_keywords":["Employment law","Artificial intelligence","Predictive models","Decision-support legal systems"],"classifications":["Classification","Resources"],"num_cited_by":35,"num_cited_by_title_only":35,"num_pages":30},{"id":"4230f51ef1b808ca8df3073ced73ded7602b3c31bc0428519b5fa088a8e4f9478ef0ea3a570964daf82268574c25acd33cf5ad6a30031f8f41c5b16e9a663b15","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09372-9.pdf","title":"Ant: a process aware annotation software for regulatory compliance","llm_title":"Ant: a process aware annotation software for regulatory compliance","authors":["Raphaël Gyory","David Restrepo Amariles","Gregory Lewkowicz","Hugues Bersini"],"llm_authors":"Raphaël Gyory, David Restrepo Amariles, Gregory Lewkowicz, Hugues Bersini","author_string":"Raphaël Gyory","year":2023,"abstract":"","llm_abstract":"Accurate data annotation is essential to successfully implementing machine learning (ML) for regulatory compliance. Annotations allow organizations to train supervised ML algorithms and to adapt and audit the software they buy. The lack of annotation tools focused on regulatory data is slowing the adoption of established ML methodologies and process models, such as CRISP-DM, in various legal domains, including in regulatory compliance. This article introduces Ant, an open-source annotation software for regulatory compliance. Ant is designed to adapt to complex organizational processes and enable compliance experts to be in control of ML projects. By drawing on Business Process Modeling (BPM), we show that Ant can contribute to lift major technical bottlenecks to effectively implement regulatory compliance through software, such as the access to multiple sources of heterogeneous data and the integration of process complexities in the ML pipeline. We provide empirical data to validate the performance of Ant, illustrate its potential to speed up the adoption of ML in regulatory compliance, and highlight its limitations.","llm_keywords":["Regulatory compliance","RegTech","Machine learning","Annotation tool","Legal-engineering cooperation"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":36},{"id":"82b767707041b4cf0f7502654c068a40bcece552434a095500cd5d93c9412725777d0b22adcc3f5188cd6955f14056945bc59b67035012e2680a4269a7d619c6","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09370-x.pdf","title":"Lessons learned building a legal inference dataset","llm_title":"Lessons learned building a legal inference dataset","authors":["Sungmi Park","Joshua I. James"],"llm_authors":"Sungmi Park · Joshua I. James","author_string":"Sungmi Park","year":2023,"abstract":"","llm_abstract":"Legal inference is fundamental for building and verifying hypotheses in police investigations. In this study, we build a Natural Language Inference dataset in Korean for the legal domain, focusing on criminal court verdicts. We developed an adversarial hypothesis collection tool that can challenge the annotators and give us a deep understanding of the data, and a hypothesis network construction tool with visualized graphs to show a use case scenario of the developed model. The data is augmented using a combination of Easy Data Augmentation approaches and round-trip translation, as crowd-sourcing might not be an option for datasets with sensible data. We extensively discuss challenges we have encountered, such as the annotator’s limited domain knowledge, issues in the data augmentation process, problems with handling long contexts and suggest possible solutions to the issues. Our work shows that creating legal inference datasets with limited resources is feasible and proposes further research in this area.","llm_keywords":["Legal inference","Natural language inference","Criminal court data","Data augmentation","Korean dataset"],"classifications":["Pre-Processing","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":34},{"id":"ba6458b08e7adbeaac836655b6e745a81164f832535fc8e2eb05b0d3ae9c3ca8025c7e355ea81d1bec45d3117d809c304c54afb7247b3822145570ba5e9fd6cf","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09381-8.pdf","title":"Enhancing legal judgment summarization with integrated semantic and structural information","llm_title":"Enhancing legal judgment summarization with integrated semantic and structural information","authors":["Jingpei Dan","Weixuan Hu","Yuming Wang"],"llm_authors":"Jingpei Dan, Weixuan Hu, Yuming Wang","author_string":"Jingpei Dan","year":2023,"abstract":"","llm_abstract":"Legal Judgment Summarization (LJS) can highly summarize legal judgment documents, improving judicial work efficiency in case retrieval and other occasions. Legal judgment documents are usually lengthy; however, most existing LJS methods are directly based on general text summarization models, which cannot handle long texts effectively. Additionally, due to the complex structural characteristics of legal judgment documents, some information may be lost by applying only one single kind of summarization model. To address these issues, we propose an integrated summarization method which leverages both semantic and structural information to improve the quality of LJS. Specifically, legal judgment documents are firstly segmented into three relatively short parts according to their specific structure. We propose an extractive summarization model named BSLT and an abstractive summarization model named LPGN by adopting Lawformer as the encoder. Lawformer is a new pre-trained language model for long legal documents, which specializes in capturing long-distance dependency and modeling legal semantic features. Then, we adopt different models to summarize the corresponding part regarding its structural characteristics. Finally, the obtained summaries are integrated to generate a high-quality summary involving semantic and structural information. We conduct comparative experiments to evaluate the performance of our model. The results show that our model outperforms the baseline model LEAD-3 by 14.78% on the mean ROUGE score, which demonstrates our method is effective in LJS and is prospected to be applied to assist other tasks in legal artificial intelligence.","llm_keywords":["Legal judgment summarization","Extractive summarization","Abstractive summarization","Lawformer","Semantic information","Structural information","LegalAI","Long-distance dependency"],"classifications":["Machine Summarization","Pre-Processing"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":22},{"id":"8629aa8292db287e72295bb64d20acde2ddd0c96bd3abb084854d58b7daf4855be5c8f40a699261741cd188e6fc8cc165dfce87c4736db69e0d487db8d9516bf","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09345-y.pdf","title":"A sentence is known by the company it keeps: Improving Legal Document Summarization Using Deep Clustering","llm_title":"A sentence is known by the company it keeps: Improving Legal Document Summarization Using Deep Clustering","authors":["Deepali Jain","Malaya Dutta Borah","Anupam Biswas"],"llm_authors":"Deepali Jain, Malaya Dutta Borah, Anupam Biswas","author_string":"Deepali Jain","year":2023,"abstract":"","llm_abstract":"The appropriate understanding and fast processing of lengthy legal documents are computationally challenging problems. Designing efficient automatic summarization techniques can potentially be the key to deal with such issues. Extractive summarization is one of the most popular approaches for forming summaries out of such lengthy documents, via the process of summary-relevant sentence selection. An efficient application of this approach involves appropriate scoring of sentences, which helps in the identification of more informative and essential sentences from the document. In this work, a novel sentence scoring approach DCESumm is proposed which consists of supervised sentence-level summary relevance prediction, as well as unsupervised clustering-based document-level score enhancement. Experimental results on two legal document summarization datasets, BillSum and Forum of Information Retrieval Evaluation (FIRE), reveal that the proposed approach can achieve significant improvements over the current state-of-the-art approaches. More specifically it achieves ROUGE metric F1-score improvements of (1−6)% and (6−12)% for the BillSum and FIRE test sets respectively. Such impressive summarization results suggest the usefulness of the proposed approach in finding the gist of a lengthy legal document, thereby providing crucial assistance to legal practitioners.","llm_keywords":["Legal document summarization","Extractive summarization","Legal BERT","Deep clustering","Sentence scoring"],"classifications":["Machine Summarization"],"num_cited_by":33,"num_cited_by_title_only":33,"num_pages":36},{"id":"239a7e1616d40149a7d6436178856fba3f9e7c1d899676cc2275c5538f60f79dd802673cbd1edbc683f022cd3534499313b52fb6a8f6ee3427babe5d01360dd5","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09364-9.pdf","title":"A RDF-based graph to representing and searching parts of legal documents","llm_title":"A RDF-based graph to representing and searching parts of legal documents","authors":["Francisco de Oliveira","Jose Maria Parente de Oliveira"],"llm_authors":"Francisco de Oliveira, Jose Maria Parente de Oliveira","author_string":"Francisco de Oliveira","year":2023,"abstract":"","llm_abstract":"Despite the public availability of legal documents, there is a need for finding specific information contained in them, such as paragraphs, clauses, items and so on. With such support, users could find more specific information than only finding whole legal documents. Some research efforts have been made in this area, but there is still a lot to be done to have legal information available more easily to be found. Thus, due to the large number of published legal documents and the high degree of connectivity, simple access to the document is not enough. It is necessary to recover the related legal framework for a specific need. In other words, the retrieval of the set of legal documents and their parts related to a specific subject is necessary. Therefore, in this work, we present a proposal of a RDF-based graph to represent and search parts of legal documents, as the output of a set of terms that represents the pursued legal information. Such a proposal is well-grounded on an ontological view, which makes possible to describe the general structure of a legal system and the structure of legal documents, providing this way the grounds for the implementation of the proposed RDF graph in terms of the meaning of their parts and relationships. We posed several queries to retrieve parts of legal documents related to sets of words and the results were significant.","llm_keywords":["Conceptual modeling","Legal ontologies","Legal knowledge graph","RDF graph","Semantic web","Linked data"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":29},{"id":"b191f14b89d10dfe362dc4efdf1ead0316f3327334e926962bdad11e26a33579c52ed90dfd17913092be26a0845c67415e18387e6e2c36f27816f4a8a543818c","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09385-4.pdf","title":"Automating petition classification in Brazil’s legal system: a two-step deep learning approach","llm_title":"Automating petition classifcation in Brazil’s legal system: a two‑step deep learning approach","authors":["Yuri D. R. Costa","Hugo Oliveira","Valério Nogueira Jr.","Lucas Massa","Xu Yang","Adriano Barbosa","Krerley Oliveira","Thales Vieira"],"llm_authors":"Yuri D. R. Costa, Hugo Oliveira, Valério Nogueira Jr., Lucas Massa, Xu Yang, Adriano Barbosa, Krerley Oliveira, Thales Vieira","author_string":"Yuri D. R. Costa","year":2023,"abstract":"","llm_abstract":"Automated classifcation of legal documents has been the subject of extensive research in recent years. However, this is still a challenging task for long documents, since it is difcult for a model to identify the most relevant information for classifcation. In this paper, we propose a two-stage supervised learning approach for the classifcation of petitions, a type of legal document that requests a court order. The proposed approach is based on a word-level encoder–decoder Seq2Seq deep neural network, such as a Bidirectional Long Short-Term Memory (BiLSTM) or a Bidirectional Encoder Representations from Transformers (BERT) model, and a document-level Support Vector Machine classifier. To address the challenges posed by the lengthy legal documents, the approach introduces a human-in-the-loop approach, whose task is to localize and tag relevant segments of text in the word-level training part, which dramatically reduces the dimension of the document classifier input vector. We performed experiments to validate our approach using a real-world dataset comprised of 270 intermediate petitions, which were carefully annotated by specialists from the 15th civil unit of the State of Alagoas, Brazil. Our results revealed that both BiLSTM and BERT-Convolutional Neural Networks variants achieved an accuracy of up to 95.49%, and also outperformed baseline classifiers based on the Term Frequency–Inverse Document Frequency test vectorizer. The proposed approach is currently being utilized to automate the aforementioned justice unit, thereby increasing its efficiency in handling repetitive tasks.","llm_keywords":["Legal document classification","BiLSTM","BERT","Deep learning","Petition classification","Support Vector Machine","Document analysis","Brazil's legal system"],"classifications":["Classification","Pre-Processing"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":25},{"id":"89de021ffcb08a4bc1e0d94f95c56612f15aebe59391035444db3ed82203a26e3c34c82ab9ef056d6d3a6bcda7a205d00857fabcf9c9f4fae7243b46830cdc30","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09378-3.pdf","title":"A large scale benchmark for session-based recommendations on the legal domain","llm_title":"A large scale benchmark for session‑based recommendations on the legal domain","authors":["Marcos Aurélio Domingues","Edleno Silva de Moura","Leandro Balby Marinho","Altigran da Silva"],"llm_authors":"Marcos Aurélio Domingues, Edleno Silva de Moura, Leandro Balby Marinho, Altigran da Silva","author_string":"Marcos Aurélio Domingues","year":2023,"abstract":"","llm_abstract":"The proliferation of legal documents in various formats and their dispersion across multiple courts present a significant challenge for users seeking precise matches to their information requirements. Despite notable advancements in legal information retrieval systems, research into legal recommender systems remains limited. A plausible factor contributing to this scarcity could be the absence of extensive publicly accessible datasets or benchmarks. While a few studies have emerged in this field, a comprehensive analysis of the distinct attributes of legal data that influence the design of effective legal recommenders is notably absent in the current literature. This paper addresses this gap by initially amassing a comprehensive session-based dataset from Jusbrasil, one of Brazil’s largest online legal platforms. Subsequently, we scrutinize and discourse key facets of legal session-based recommendation data, including session duration, types of recommendable legal artifacts, coverage, and popularity. Furthermore, we introduce the first session-based recommendation benchmark tailored to the legal domain, shedding light on the performance and constraints of several renowned session-based recommendation approaches. These evaluations are based on real-world data sourced from Jusbrasil.","llm_keywords":["Legal documents recommendation","Session-based recommender systems","Recommender systems","Benchmark","Large scale dataset"],"classifications":["Resources","Information Retrieval"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":36},{"id":"7b457e724c655a145dcb2efa60266e577d6124edebb24513f90d0fadc710612f4ac28a6f60321ca139bd7391777e375b40e390d2fe5f3d3c845598f5dacd9d0a","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09346-x.pdf","title":"Correction: Using attention methods to predict judicial outcomes","llm_title":"Correction: Using attention methods to predict judicial outcomes","authors":["Vithor Gomes Ferreira Bertalan","Evandro Eduardo Seron Ruiz"],"llm_authors":"Vithor Gomes Ferreira Bertalan, Evandro Eduardo Seron Ruiz","author_string":"Vithor Gomes Ferreira Bertalan","year":2023,"abstract":"","llm_abstract":"","llm_keywords":["Artificial Intelligence","Judicial Outcomes","Attention Methods","Law","Predictive Modeling"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":1},{"id":"c4f603d2463aafce7d79831d2e81e396f82a840e1a9a313a88e53a2ac184c2d3b4be02fb8b3959ac047f51e74dfb15ab459365a33337dd2190bcfbe6d5e60a8c","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09367-6.pdf","title":"Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model","llm_title":"Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model","authors":["Mingruo Yuan","Ben Kao","Tien-Hsuan Wu","Michael M. K. Cheung","Henry W. H. Chan","Anne S. Y. Cheung","Felix W. H. Chan","Yongxi Chen"],"llm_authors":"Mingruo Yuan, Ben Kao, Tien-Hsuan Wu, Michael M. K. Cheung, Henry W. H. Chan, Anne S. Y. Cheung, Felix W. H. Chan, Yongxi Chen","author_string":"Mingruo Yuan","year":2023,"abstract":"","llm_abstract":"Access to legal information is fundamental to access to justice. Yet accessibility refers not only to making legal documents available to the public, but also rendering legal information comprehensible to them. A vexing problem in bringing legal information to the public is how to turn formal legal documents such as legislation and judgments, which are often highly technical, to easily navigable and comprehensible knowledge to those without legal education. In this study, we formulate a three-step approach for bringing legal knowledge to laypersons, tackling the issues of navigability and comprehensibility. First, we translate selected sections of the law into snippets (called CLIC-pages), each being a small piece of article that focuses on explaining certain technical legal concept in layperson’s terms. Second, we construct a Legal Question Bank, which is a collection of legal questions whose answers can be found in the CLIC-pages. Third, we design an interactive CLIC Recommender. Given a user’s verbal description of a legal situation that requires a legal solution, CRec interprets the user’s input and shortlists questions from the question bank that are most likely relevant to the given legal situation and recommends their corresponding CLIC pages where relevant legal knowledge can be found. In this paper we focus on the technical aspects of creating an LQB. We show how large-scale pre-trained language models, such as GPT-3, can be used to generate legal questions. We compare machine-generated questions against human-composed questions and find that MGQs are more scalable, cost-effective, and more diversified, while HCQs are more precise. We also show a prototype of CRec and illustrate through an example how our 3-step approach effectively brings relevant legal knowledge to the public.","llm_keywords":["Legal knowledge dissemination","Navigability and comprehensibility of legal information","Machine question generation","Pre-trained language model"],"classifications":["Information Retrieval","Text Generation","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":37},{"id":"377b1dc7993e8317acff6642a33977a89ade8b451846ec001544501c8c50e0ca2041acef2f8ea40098f9a6958d740e2bd81951e882804d29505c92ac6c7c98a9","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09382-7.pdf","title":"Reasoning with inconsistent precedents","llm_title":"Reasoning with inconsistent precedents","authors":["Ilaria Canavotto"],"llm_authors":"Ilaria Canavotto","author_string":"Ilaria Canavotto","year":2024,"abstract":"","llm_abstract":"Computational models of legal precedent-based reasoning developed in AI and Law are typically based on the simplifying assumption that the background set of precedent cases is consistent. Besides being unrealistic in the legal domain, this assumption is problematic for recent promising applications of these models to the development of explainable AI methods. In this paper I explore a model of legal precedent-based reasoning that, unlike existing models, does not rely on the assumption that the background set of precedent cases is consistent. The model is a generalization of the reason model of precedential constraint. I first show that the model supports an interesting deontic logic, where consistent obligations can be derived from inconsistent case bases. I then provide an explanation of this surprising result by proposing a reformulation of the model in terms of cases that support a new potential decision and cases that conflict with it. Finally, I show that the reformulation of the model allows us to verify that inconsistent case bases do not make verification that a decision is permissible substantially more complex than consistent case bases and to introduce intuitive criteria to compare different permissible decisions.","llm_keywords":["Legal case-based reasoning","Reason model","Inconsistent case bases","Precedential constraint","Explainable AI","Deontic logic","Computational argumentation"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":30},{"id":"550e7708161b411717feed646b31479414a3068f44b30f05d5d45922011e36f6edcf05cb793dfb0e9e651dd087da4e4a4deca24aad6cd29322ae04535b93438a","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09376-5.pdf","title":"Automated legal reasoning with discretion to act using s(LAW)","llm_title":"Automated legal reasoning with discretion to act using s(LAW)","authors":["Joaquín Arias","Mar Moreno-Rebato","Jose A. Rodriguez-García","Sascha Ossowski"],"llm_authors":"Joaquín Arias, Mar Moreno-Rebato, Jose A. Rodriguez-García, Sascha Ossowski","author_string":"Joaquín Arias","year":2023,"abstract":"","llm_abstract":"Automated legal reasoning and its application in smart contracts and automated decisions are increasingly attracting interest. In this context, ethical and legal concerns make it necessary for automated reasoners to justify in human-understandable terms the advice given. Logic Programming, specially Answer Set Programming, has a rich semantics and has been used to very concisely express complex knowledge. However, modelling discretionality to act and other vague concepts such as ambiguity cannot be expressed in top-down execution models based on Prolog, and in bottom-up execution models based on ASP the justifications are incomplete and/or not scalable. We propose to use s(CASP), a top-down execution model for predicate ASP, to model vague concepts following a set of patterns. We have implemented a framework, called s(LAW), to model, reason, and justify the applicable legislation and validate it by translating (and benchmarking) a representative use case, the criteria for the admission of students in the “Comunidad de Madrid”.","llm_keywords":["Automated legal reasoning","s(LAW)","Answer Set Programming","Ambiguity","Administrative discretion","Smart contracts","Automated decisions"],"classifications":[],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":24},{"id":"f1ed97096d4067306c5b1d76b70eb81bfaea93ecfc1a423e4ac08e198ca832eb153a38ddcb4fbd41d870b64488e5c14497b92c2d6f30e35d57c6f93780968744","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09348-9.pdf","title":"Joining metadata and textual features to advise administrative courts decisions: a cascading classifier approach","llm_title":"Joining metadata and textual features to advise administrative courts decisions: a cascading classifier approach","authors":["Hugo Mentzingen","Nuno Antonio","Victor Lobo"],"llm_authors":"Hugo Mentzingen, Nuno Antonio, Victor Lobo","author_string":"Hugo Mentzingen","year":2023,"abstract":"","llm_abstract":"Decisions of regulatory government bodies and courts affect many aspects of citizens’ lives. These organizations and courts are expected to provide timely and coherent decisions, although they struggle to keep up with the increasing demand. The ability of machine learning (ML) models to predict such decisions based on past cases under similar circumstances was assessed in some recent works. The dominant conclusion is that the prediction goal is achievable with high accuracy. Nevertheless, most of those works do not consider important aspects for ML models that can impact performance and affect real-world usefulness, such as consistency, out-of-sample applicability, generality, and explainability preservation. To our knowledge, none considered all those aspects, and no previous study addressed the joint use of metadata and text-extracted variables to predict administrative decisions. We propose a predictive model that addresses the abovementioned concerns based on a two-stage cascade classifier. The model employs a first-stage prediction based on textual features extracted from the original documents and a second-stage classifier that includes proceedings’ metadata. The study was conducted using time-based cross-validation, built on data available before the predicted judgment. It provides predictions as soon as the decision date is scheduled and only considers the first document in each proceeding, along with the metadata recorded when the infringement is first registered. Finally, the proposed model provides local explainability by preserving visibility on the textual features and employing the SHapley Additive exPlanations (SHAP). Our findings suggest that this cascade approach surpasses the standalone stages and achieves relatively high Precision and Recall when both text and metadata are available while preserving real-world usefulness. With a weighted F1 score of 0.900, the results outperform the text-only baseline by 1.24% and the metadata-only baseline by 5.63%, with better discriminative properties evaluated by the receiver operating characteristic and precision-recall curves.","llm_keywords":["administrative decision prediction","cascade generalization","legal assistance","machine learning","natural language processing"],"classifications":["Classification","Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":30},{"id":"12414fd5463f4f3f629a054345fe7f243c4112e037a3fd44288406398b86da852183e1c41be5885f627b27f849ecb4bc25e3a0bd1b20935546c7e29f87a9d9e0","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09350-1.pdf","title":"Encoding legislation: a methodology for enhancing technical validation, legal alignment and interdisciplinarity","llm_title":"Encoding legislation: a methodology for enhancing technical validation, legal alignment and interdisciplinarity","authors":["Alice Witt","Anna Huggins","Guido Governatori","Joshua Buckley"],"llm_authors":"Alice Witt, Anna Huggins, Guido Governatori, Joshua Buckley","author_string":"Alice Witt","year":2023,"abstract":"","llm_abstract":"This article proposes an innovative methodology for enhancing the technical validation, legal alignment and interdisciplinarity of attempts to encode legislation. In the context of an experiment that examines how different legally trained participants convert select provisions of the Australian Copyright Act 1968 (Cth) into machine-executable code, we find that a combination of manual and automated methods for coding validation, which focus on formal adherence to programming languages and conventions, can significantly increase the similarity of encoded rules between coders. Participants nonetheless encountered various interpretive difficulties, including syntactic ambiguity, and intra- and intertextuality, which necessitated legal evaluation, as distinct from and in addition to coding validation. Many of these difficulties can be resolved through what we call a process of ‘legal alignment’ that aims to enhance the congruence between encoded provisions and the true meaning of a statute as determined by the courts. However, some difficulties cannot be overcome in advance, such as factual indeterminacy. Given the inherently interdisciplinary nature of encoding legislation, we argue that it is desirable for ‘rules as code’ (‘RaC’) initiatives to have, at a minimum, legal subject matter, statutory interpretation and technical programming expertise. Overall, we contend that technical validation, legal alignment and interdisciplinary teamwork are integral to the success of attempts to encode legislation. While legal alignment processes will vary depending on jurisdictionally-specific principles and practices of statutory interpretation, the technical and interdisciplinary components of our methodology are transferable across regulatory contexts, bodies of law and Commonwealth and other jurisdictions.","llm_keywords":["Encoding legislation","Rules as code","Digital law","Coding validation","Legal alignment","Interdisciplinarity"],"classifications":[],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":32},{"id":"ecd60d00259611d22d9204294334e29f0e85a6c67c6620e7724a3087846ba334449591341d6b2e760355d488ef0544686bef3f7c2ca5cce4ceb58f3857c0dcab","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09374-7.pdf","title":"Bringing order into the realm of Transformer-based language models for artificial intelligence and law","llm_title":"Bringing order into the realm of Transformer-based language models for artificial intelligence and law","authors":["Candida M. Greco","Andrea Tagarelli"],"llm_authors":"Candida M. Greco, Andrea Tagarelli","author_string":"Candida M. Greco","year":2023,"abstract":"","llm_abstract":"Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitations and opportunities for further research development.","llm_keywords":["Language models","BERT","GPT","Legal search","Legal document review","Legal outcome prediction","Retrieval","Entailment","Inference","Caselaw data"],"classifications":[],"num_cited_by":31,"num_cited_by_title_only":31,"num_pages":148},{"id":"934db3264cb5e6333a36225012be1e19399591dc964420080431d204f3da656982797ae125427f40c8df30b94ffc21348711c6cf0ed8b8994950f0afa89c1749","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09352-z.pdf","title":"Predicting inmates misconduct using the SHAP approach","llm_title":"Predicting inmates misconduct using the SHAP approach","authors":["Fábio Oliveira","Marcelo Balbino","Luis Zarate","Fawn Ngo","Ramakrishna Govindu","Anurag Agarwal","Cristiane Nobre"],"llm_authors":"Fábio M. Oliveira, Marcelo S. Balbino, Luis E. Zarate, Fawn Ngo, Ramakrishna Govindu, Anurag Agarwal, Cristiane N. Nobre","author_string":"Fábio M. Oliveira","year":2023,"abstract":"","llm_abstract":"Internal misconduct is a universal problem in prisons and affects the maintenance of social order. Consequently, correctional institutions often develop rehabilitation programs to reduce the likelihood of inmates committing internal offenses and criminal recidivism after release. Therefore, it is necessary to identify the profile of each offender, both for the appropriate indication of a rehabilitation program and the level of internal security to which he must be submitted. In this context, this work aims to discover the most significant characteristics in predicting inmate misconduct from ML methods and the SHAP approach. A database produced in 2004 through the Survey of Inmates in State and Federal Correctional Facilities in the United States of America was used, which provides nationally representative data on prisoners from state and federal facilities. The predictive model based on Random Forest performed the best, thus, we applied the SHAP to it. Overall, the results showed that features related to victimization, type of crime committed, age and age at first arrest, history of association with criminal groups, education, and drug and alcohol use are most relevant in predicting internal misconduct. Thus, it is expected to contribute to the prior classification of an inmate on time, to use programs and practices that aim to improve the lives of offenders, their reintegration into society, and consequently, the reduction of criminal recidivism.","llm_keywords":["misconduct","machine learning","interpretability","SHAP","prison","rehabilitation","criminal recidivism","predictive model","internal security","inmate behavior"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":27},{"id":"866afe8bbff0e09810175e08cabb3dccc941ae254a36343620198129ef17c04ae20a43e25e2b917277a7ddc901b1a25871858271f797163e9f0dd56af89d49da","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09357-8.pdf","title":"A Bayesian model of legal syllogistic reasoning","llm_title":"A Bayesian model of legal syllogistic reasoning","authors":["Axel Constant"],"llm_authors":"Axel Constant","author_string":"Axel Constant","year":2023,"abstract":"","llm_abstract":"Bayesian approaches to legal reasoning propose causal models of the relation between evidence, the credibility of evidence, and ultimate hypotheses, or verdicts. They assume that legal reasoning is the process whereby one infers the posterior probability of a verdict based on observed evidence, or facts. In practice, legal reasoning does not operate quite that way. Legal reasoning is also an attempt at inferring applicable rules derived from legal precedents or statutes based on the facts at hand. To make such an inference, legal reasoning follows syllogistic logic and first order transitivity. This paper proposes a Bayesian model of legal syllogistic reasoning that complements existing Bayesian models of legal reasoning using a Bayesian network whose variables correspond to legal precedents, statutes, and facts. We suggest that legal reasoning should be modelled as a process of finding the posterior probability of precedents and statutes based on available facts.","llm_keywords":["Computational law","Legal cognition","Bayesian legal reasoning","Legal syllogism","Bayesian network","Entropy"],"classifications":[],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":22},{"id":"6ae50a12e8d45f245bf0f49fae14fc88e8ab65c5f889282589d91a0e2489de631e91544127134bb1411f128372ab8d82cb612fcceb0f104dc851e5c01ac04f38","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09344-z.pdf","title":"A novel MRC framework for evidence extracts in judgment documents","llm_title":"A novel MRC framework for evidence extracts in judgment documents","authors":["Yulin Zhou","Lijuan Liu","Yanping Chen","Ruizhang Huang","Yongbin Qin","Chuan Lin"],"llm_authors":"Yulin Zhou, Lijuan Liu, Yanping Chen, Ruizhang Huang, Yongbin Qin, Chuan Lin","author_string":"Yulin Zhou","year":2023,"abstract":"","llm_abstract":"Evidences are important proofs to support judicial trials. Automatically extracting evidences from judgement documents can be used to assess the trial quality and support “Intelligent Court”. Current evidence extraction is primarily depended on sequence labelling models. Despite their success, they can only assign a label to a token, which is difficult to recognize nested evidence entities in judgment documents, where a token may belong to several evidences at the same time. In this paper, we present a novel evidence extraction architecture called ATT-MRC, in which extracting evidence entities is formalized as a question answer problem, where all evidence spans are screened out as possible correct answers. Furthermore, to address the data imbalance problem in the judgement documents, we revised the loss function and combined it with a data enhancement technique. Experimental results demonstrate that our model has better performance than related works in evidence extraction.","llm_keywords":["Judgement documents","Machine reading comprehension","Evidence extraction","Data augmentation","Artificial intelligence in law"],"classifications":["Information Extraction"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":17},{"id":"9ae2d2273bbac8429b004d18d4efabb4ffda2ff63f9b9084d98d9b1ebf60f07cc7ee0bf7245ae1a4f73e5a4f6fec36cadfa4ca976d14d23873461b42b50ea2d7","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09369-4.pdf","title":"I beg to differ: how disagreement is handled in the annotation of legal machine learning data sets","llm_title":"I beg to differ: how disagreement is handled in the annotation of legal machine learning data sets","authors":["Daniel Braun"],"llm_authors":"Daniel Braun","author_string":"Daniel Braun","year":2023,"abstract":"","llm_abstract":"Legal documents, like contracts or laws, are subject to interpretation. Diferent people can have diferent interpretations of the very same document. Large parts of judicial branches all over the world are concerned with settling disagreements that arise, in part, from these diferent interpretations. In this context, it only seems natural that during the annotation of legal machine learning data sets, disagreement, how to report it, and how to handle it should play an important role. This article presents an analysis of the current state-of-the-art in the annotation of legal machine learning data sets. The results of the analysis show that all of the analysed data sets remove all traces of disagreement, instead of trying to utilise the information that might be contained in conficting annotations. Additionally, the publications introducing the data sets often do provide little information about the process that derives the \"gold standard\" from the initial annotations, often making it difcult to judge the relia- bility of the annotation process. Based on the state-of-the-art, the article provides easily implementable suggestions on how to improve the handling and reporting of disagreement in the annotation of legal machine learning data sets.","llm_keywords":["Data annotation","Legal corpora","Annotator agreement","Disagreement","Machine learning","Artificial intelligence","Legal interpretation","Annotation process"],"classifications":[],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":24},{"id":"c45620a463297600d54a0357598a5b81cbda69dd2ee638ca74272ce7d238b51a8cdbb9b6c3f01e604f835a780e072d2bf5f31c97beb2bc798537f446a0152791","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09358-7.pdf","title":"Detecting the influence of the Chinese guiding cases: a text reuse approach","llm_title":"Detecting the influence of the Chinese guiding cases: a text reuse approach","authors":["Benjamin M. Chen","Zhiyu Li","David Cai","Elliott Ash"],"llm_authors":"Benjamin M. Chen, Zhiyu Li, David Cai, Elliott Ash","author_string":"Benjamin M. Chen","year":2023,"abstract":"","llm_abstract":"Socialist courts are supposed to apply the law, not make it, and socialist legality denies judicial decisions any precedential status. In 2011, the Chinese Supreme People's Court designated selected decisions as Guiding Cases to be referred to by all judges when adjudicating similar disputes. One decade on, the paucity of citations to Guiding Cases has been taken as demonstrating the incongruity of case-based adjudication and the socialist legal tradition. Citations are, however, an imperfect measure of influence. Reproduction of language uniquely traceable to Guiding Cases can also be evidence of their impact on judicial decision-making. We employ a local alignment tool to detect unattributed text reuse of Guiding Cases in local court decisions. Our findings suggest that Guiding Cases are more consequential than commonly assumed, thereby complicating prevailing narratives about the antagonism of socialist legality to case law.","llm_keywords":["Chinese guiding cases","text reuse","socialist legality","judicial decision-making","Chinese courts"],"classifications":["Information Retrieval","Pre-Processing"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":24},{"id":"bc653ef92d44a0de54da84d29058d286c6ea62c458613eeffa8c51bb5cf766bf360ec608ed0d5614007f689867beea7cfe6d510404f12971aa236019021d4857","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09362-x.pdf","title":"LK-IB: a hybrid framework with legal knowledge injection for compulsory measure prediction","llm_title":"LK‑IB: a hybrid framework with legal knowledge injection for compulsory measure prediction","authors":["Xiang Zhou","Qi Liu","Yiquan Wu","Qiangchao Chen","Kun Kuang"],"llm_authors":"Xiang Zhou, Qi Liu, Yiquan Wu, Qiangchao Chen, Kun Kuang","author_string":"Xiang Zhou","year":2023,"abstract":"","llm_abstract":"The interpretability of AI is just as important as its performance. In the LegalAI field, there have been efforts to enhance the interpretability of models, but a trade-off between interpretability and prediction accuracy remains inevitable. In this paper, we introduce a novel framework called LK-IB for compulsory measure prediction (CMP), one of the critical tasks in LegalAI. LK-IB leverages Legal Knowledge and combines an Interpretable model and a Black-box model to balance interpretability and prediction performance. Specifically, LK-IB involves three steps: (1) inputting cases into the first module, where first-order logic (FOL) rules are used to make predictions and output them directly if possible; (2) sending cases to the second module if FOL rules are not applicable, where a case distributor categorizes them as either “simple” or “complex”; and (3) sending simple cases to an interpretable model with strong interpretability and complex cases to a black-box model with outstanding performance. Experimental results demonstrate that the LK-IB framework provides more interpretable and accurate predictions than other state-of-the-art models. Given that the majority of cases in LegalAI are simple, the idea of model combination has significant potential for practical applications.","llm_keywords":["Legal knowledge","Model combination","Compulsory measure prediction","Interpretability","LegalAI","Artificial Intelligence","Natural Language Processing","Human rights"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":26},{"id":"11f5977210de83107e9a4acf4cac9762d6685a310583ee4d961d77836df14143cdb561213341b6f663316a76c9397eff1ebf4c6c36147527fa311a50efb30631","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09359-6.pdf","title":"Methods of incorporating common element characteristics for law article prediction","llm_title":"Methods of incorporating common element characteristics for law article prediction","authors":["Yifan Hou","Ge Cheng","Yun Zhang","Dongliang Zhang"],"llm_authors":"Yifan Hou, Ge Cheng, Yun Zhang, Dongliang Zhang","author_string":"Yifan Hou","year":2023,"abstract":"","llm_abstract":"Law article prediction is a task of predicting the relevant laws and regulations involved in a case according to the description text of the case, and it has broad application prospects in improving judicial efficiency. In the existing research work, researchers often only consider a single case, employing the neural network method to extract features for prediction, which lack the mining of related and common element information between different data. In order to solve this problem, we propose a law article prediction method that integrates the characteristics of common elements. It can effectively utilize the co-occurrence information of the training data, fully mine the relevant common elements between cases, and fuse local features. Experiments show that our method performs well.","llm_keywords":["law article prediction","text classification","feature fusion","graph neural network","attention mechanism"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":17},{"id":"6f462aa525255279743070c9703a4080b40feb4b4ebbde1d118c35834759a9587a498857a17bb02f7cbc34b0aa512018185dee0eaecbfacab76c53812919ac4a","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09368-5.pdf","title":"Predicting citations in Dutch case law with natural language processing","llm_title":"Predicting citations in Dutch case law with natural language processing","authors":["Iris Schepers","Masha Medvedeva","Michelle Bruijn","Martijn Wieling","Michel Vols"],"llm_authors":"Iris Schepers, Masha Medvedeva, Michelle Bruijn, Martijn Wieling, Michel Vols","author_string":"Iris Schepers","year":2023,"abstract":"","llm_abstract":"With the ever-growing accessibility of case law online, it has become challenging to manually identify case law relevant to one’s legal issue. In the Netherlands, the planned increase in the online publication of case law is expected to exacerbate this challenge. In this paper, we tried to predict whether court decisions are cited by other courts or not after being published, thus in a way distinguishing between more and less authoritative cases. This type of system may be used to process the large amounts of available data by filtering out large quantities of non-authoritative decisions, thus helping legal practitioners and scholars to find relevant decisions more easily, and drastically reducing the time spent on preparation and analysis. For the Dutch Supreme Court, the match between our prediction and the actual data was relatively strong (with a Matthews Correlation Coefficient of 0.60). Our results were less successful for the Council of State and the district courts (MCC scores of 0.26 and 0.17, relatively). We also attempted to identify the most informative characteristics of a decision. We found that a completely explainable model, consisting only of handcrafted metadata features, performs almost as well as a less well-explainable system based on all text of the decision.","llm_keywords":["Machine learning","Case law","Natural language processing","Citation analysis","Judicial decisions"],"classifications":["Classification"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":31},{"id":"89b43ff1043b283c2a1c12f01708c26d5e8356c5de3cd16c5470fffc6996e605b129b5272259b8037b2dabd8c4544caf9fc86d70230e65700eaa963f88e8dad5","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09356-9.pdf","title":"","llm_title":"The black box problem revisited. Real and imaginary challenges for automated legal decision making","authors":["Bartosz Brożek","Michał Furman","Marek Jakubiec","Bartłomiej Kucharzyk"],"llm_authors":"Bartosz Brożek, Michał Furman, Marek Jakubiec, Bartłomiej Kucharzyk","author_string":"","year":2024,"abstract":"","llm_abstract":"This paper addresses the black-box problem in artificial intelligence (AI), and the related problem of explainability of AI in the legal context. We argue, first, that the black box problem is, in fact, a superficial one as it results from an overlap of four different – albeit interconnected – issues: the opacity problem, the strangeness problem, the unpredictability problem, and the justification problem. Thus, we propose a framework for discussing both the black box problem and the explainability of AI. We argue further that contrary to often defended claims the opacity issue is not a genuine problem. We also dismiss the justification problem. Further, we describe the tensions involved in the strangeness and unpredictability problems and suggest some ways to alleviate them.","llm_keywords":["black box problem","explainable AI","AI and law","legal decision-making","automated decision-making"],"classifications":[],"num_cited_by":64,"num_cited_by_title_only":64,"num_pages":14},{"id":"657b9e58994ab2026a055407e54d0e04b4e9733454603befe3596e7b63815cb90ae10db40dca9f360818d5716677c9165b49856aa7e4154a34688441c9d22a1c","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09361-y.pdf","title":"Mining legal arguments in court decisions","llm_title":"Mining legal arguments in court decisions","authors":["Ivan Habernal","Daniel Faber","Nicola Recchia","Sebastian Bretthauer","Iryna Gurevych","Indra Spiecker genannt Döhmann","Christoph Burchard"],"llm_authors":"Ivan Habernal, Daniel Faber, Nicola Recchia, Sebastian Bretthauer, Iryna Gurevych, Indra Spiecker genannt Döhmann, Christoph Burchard","author_string":"Ivan Habernal","year":2023,"abstract":"","llm_abstract":"Identifying, classifying, and analyzing arguments in legal discourse has been a prominent area of research since the inception of the argument mining field. However, there has been a major discrepancy between the way natural language processing (NLP) researchers model and annotate arguments in court decisions and the way legal experts understand and analyze legal argumentation. While computational approaches typically simplify arguments into generic premises and claims, arguments in legal research usually exhibit a rich typology that is important for gaining insights into the particular case and applications of law in general. We address this problem and make several substantial contributions to move the field forward. First, we design a new annotation scheme for legal arguments in proceedings of the European Court of Human Rights (ECHR) that is deeply rooted in the theory and practice of legal argumentation research. Second, we compile and annotate a large corpus of 373 court decisions (2.3M tokens and 15k annotated argument spans). Finally, we train an argument mining model that outperforms state-of-the-art models in the legal NLP domain and provide a thorough expert-based evaluation. All datasets and source codes are available under open licenses at https://github.com/trusthlt/mining-legal-arguments.","llm_keywords":["Argument mining","Legal arguments","ECHR","Natural Language Processing","Annotation scheme","European Court of Human Rights","Corpus annotation","Argument mining model"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":57,"num_cited_by_title_only":57,"num_pages":38},{"id":"63a516df5124cbab80e025430fd8bef69fccd4820674c8e6f43cbfb923383288a23f43fe75ad57e725a5ed8027040267f3260bed0e17ba26ecf21151bf07e3d8","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09375-6.pdf","title":"A novel network-based paragraph filtering technique for legal document similarity analysis","llm_title":"A novel network‑based paragraph filtering technique for legal document similarity analysis","authors":["Mayur Makawana","Rupa G. Mehta"],"llm_authors":"Mayur Makawana, Rupa G. Mehta","author_string":"Mayur Makawana","year":2023,"abstract":"","llm_abstract":"The common law system is a legal system that values precedent, or previous court decisions, in the resolution of current cases. As the availability of legal documents in digital form has increased, it has become more difficult for legal professionals to manually identify relevant past cases due to the vast amount of data. Researchers have developed automated systems for determining the similarity between legal documents to address this issue. Our research explores various representations of a legal document and discusses a novel paragraph filtering process to identify key paragraphs using legal citation information to remove unnecessary text paragraphs without disturbing the concept of the legal document. State-of-the-art techniques like TF-IDF, BERT, Legal Bert, Doc2Vec, and Legal-longformer are used for the performance analysis of the proposed approach with document comparison. It has been shown that a model trained on the proposed filtered paragraphs can achieve better results than a model trained on the complete text and can also shorten the document by over 40%. The proposed filtering strategy could be helpful for models like BERT, where the maximum token length is fixed.","llm_keywords":["Legal document analysis","Co-citation network","Co-occurrence network","Paragraph filtering","Common law system","Automated similarity analysis"],"classifications":["Pre-Processing"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":23},{"id":"03aac05d62f604e10032a247fee1b98b508c40d356f4d099be988ba86a64daaaf993ec7feead320805bc0462aedf4dca02d79ba157590a303befe9113a2b8dbf","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2023/s10506-023-09354-x.pdf","title":"Semantic matching based legal information retrieval system for COVID-19 pandemic","llm_title":"Semantic matching based legal information retrieval system for COVID‑19 pandemic","authors":["Junlin Zhu","Jiaye Wu","Xudong Luo","Jie Liu"],"llm_authors":"Junlin Zhu, Jiaye Wu, Xudong Luo, Jie Liu","author_string":"Junlin Zhu","year":2023,"abstract":"","llm_abstract":"Recently, the pandemic caused by COVID-19 is severe in the entire world. The prevention and control of crimes associated with COVID-19 are critical for controlling the pandemic. Therefore, to provide efficient and convenient intelligent legal knowledge services during the pandemic, we develop an intelligent system for legal information retrieval on the WeChat platform in this paper. The data source we used for training our system is “The typical cases of national procuratorial authorities handling crimes against the prevention and control of the new coronary pneumonia pandemic following the law”, which is published online by the Supreme People’s Procuratorate of the People’s Republic of China. We base our system on convolutional neural network and use the semantic matching mechanism to capture inter-sentence relationship information and make a prediction. Moreover, we introduce an auxiliary learning process to help the network better distinguish the relation between two sentences. Finally, the system uses the trained model to identify the information entered by a user and responds to the user with a reference case similar to the query case and gives the reference legal gist applicable to the query case.","llm_keywords":["Information retrieval","Semantic matching","Convolutional neural network","Legal knowledge","COVID-19"],"classifications":["Information Retrieval"],"num_cited_by":5,"num_cited_by_title_only":16,"num_pages":30},{"id":"5ce68475a04efa488907a0b3e5a916141ac896fbf48a2e4faa9c31ce5ca74c601d26f1a1f298ab85df85ee3a34bad80b78cf8f2ac60014d75b40ed8c91166b8c","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-023-09380-9.pdf","title":"A neural network to identify requests, decisions, and arguments in court rulings on custody","llm_title":"A neural network to identify requests, decisions, and arguments in court rulings on custody","authors":["José Félix Muñoz-Soro","Rafael del Hoyo Alonso","Rosa Montañes","Francisco Lacueva"],"llm_authors":"José Félix Muñoz-Soro, Rafael del Hoyo Alonso, Rosa Montañes, Francisco Lacueva","author_string":"José Félix Muñoz-Soro","year":2024,"abstract":"","llm_abstract":"Court rulings are among the most important documents in all legal systems. This article describes a study in which natural language processing is used for the automatic characterization of Spanish judgments that deal with the physical custody (joint or individual) of minors. The model was trained to identify a set of elements: the type of custody requested by the plaintiff, the type of custody decided on by the court, and eight of the most commonly used arguments in this type of judgment. Two jurists independently annotated more than 3000 judgments, which were used to train a model based on transformers. The main difficulties encountered in this task were the complexity of the judicial language and the need to work with appellate court rulings that have a more complicated structure than decisions at first instance. For the complete court rulings, the F1 score of the inter-annotator agreement ranged from 0.60 to 0.86 and the Kappa index from 0.33 to 0.73. The F1 score of the agreement between the model and the annotators ranged from 0.66 to 0.93 and the Kappa index from 0.57 to 0.80. These results in which the model performance exceeds even the inter-annotator agreement show the high ability of transformers to identify abstract entities in legal texts.","llm_keywords":["Natural language processing","Neural networks","Judicial sentences","Custody of children","Inter-annotator agreement","Transformers"],"classifications":["Information Extraction","Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":35},{"id":"20c9dd7e0ee1e21a59a6d54078e59102e5df101fb097122ddce83cd4b660475491c18b31ed401f37b6595be5a6666c08e38fa756c88f8f128d2c71529c0b83a2","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09404-y.pdf","title":"","llm_title":"AI, Law and beyond. A transdisciplinary ecosystem for the future of AI & Law","authors":["Floris J. Bex"],"llm_authors":"Floris J. Bex","author_string":"","year":2024,"abstract":"","llm_abstract":"We live in exciting times for AI and Law: technical developments are moving at a breakneck pace, and at the same time, the call for more robust AI governance and regulation grows stronger. How should we as an AI & Law community navigate these dramatic developments and claims? In this Presidential Address, I present my ideas for a way forward: researching, developing and evaluating real AI systems for the legal field with researchers from AI, Law and beyond. I will demonstrate how we at the Netherlands National Police Lab AI are developing responsible AI by combining insights from different disciplines, and how this connects to the future of our field.","llm_keywords":["AI","Law","Governance","Regulation","AI systems","Transdisciplinary","Police Lab AI","Legal field","Artificial intelligence"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":18},{"id":"e108bb61c57d3f1d6046e7b4d75ea68690108f80b7e75eecfa2044fb17cf65fe12bf5e52bfe7122a658a810120ad5bf2cc837c5ddb695ac18b530a2cce567394","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09393-y.pdf","title":"A comparative user study of human predictions in algorithm-supported recidivism risk assessment","llm_title":"A comparative user study of human predictions in algorithm‑supported recidivism risk assessment","authors":["Manuel Portela","Carlos Castillo","Songül Tolan","Marzieh Karimi‑Haghighi","Antonio Andres Pueyo"],"llm_authors":"Manuel Portela, Carlos Castillo, Songül Tolan, Marzieh Karimi‑Haghighi, Antonio Andres Pueyo","author_string":"Manuel Portela","year":2024,"abstract":"","llm_abstract":"In this paper, we study the effects of using an algorithm-based risk assessment instrument (RAI) to support the prediction of risk of violent recidivism upon release. The instrument we used is a machine learning version of RiskCanvi used by the Justice Department of Catalonia, Spain. It was hypothesized that people can improve their performance on defining the risk of recidivism when assisted with a RAI. Also, that professionals can perform better than non-experts on the domain. Participants had to predict whether a person who has been released from prison will commit a new crime leading to re-incarceration, within the next two years. This user study is done with (1) general participants from diverse backgrounds recruited through a crowdsourcing platform, (2) targeted participants who are students and practitioners of data science, criminology, or social work and professionals who work with RisCanvi. We also run focus groups with participants of the targeted study, including people who use RisCanvi in a professional capacity, to interpret the quantitative results. Among other findings, we observe that algorithmic support systematically leads to more accurate predictions from all participants, but that statistically significant gains are only seen in the performance of targeted participants with respect to that of crowdsourced participants. Among other comments, professional participants indicate that they would not foresee using a fully-automated system in criminal risk assessment, but do consider it valuable for training, standardization, and to fine-tune or double-check their predictions on particularly difficult cases. We found that the revised prediction by using a RAI increases the performance of all groups, while professionals show a better performance in general. And, a RAI can be considered for extending professional capacities and skills along their careers.","llm_keywords":["Recidivism","Automated decision-making","Risk assessment instrument","Human oversight","Machine learning"],"classifications":[],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":47},{"id":"5d845cfb62c0e41f057d5721a22f0888baf0e9eea4eee724b068bd759d68ac340a6e2d1204679f1967b3c680a7b3c321371da1778a68b37319c7f375a9889701","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09403-z.pdf","title":"Self-training improves few-shot learning in legal artificial intelligence tasks","llm_title":"Self‑training improves few‑shot learning in legal artificial intelligence tasks","authors":["Yulin Zhou","Yongbin Qin","Ruizhang Huang","Yanping Chen","Chuan Lin","Yuan Zhou"],"llm_authors":"Yulin Zhou, Yongbin Qin, Ruizhang Huang, Yanping Chen, Chuan Lin, Yuan Zhou","author_string":"Yulin Zhou","year":2024,"abstract":"","llm_abstract":"As the labeling costs in legal artificial intelligence tasks are expensive. Therefore, it becomes a challenge to utilize low cost to train a robust model. In this paper, we propose a LAIAugment approach, which aims to enhance the few-shot learning capability in legal artificial intelligence tasks. Specifically, we first use the self-training approach to label the amount of unlabelled data to enhance the feature learning capability of the model. Moreover, we also search for datasets that are similar to the training set by improving the text similarity function. We conducted experimental analyses for three legal artificial intelligence tasks, including evidence extraction, legal element extraction, and case multi-label prediction, which composed of 3500 judgement documents. The experimental results show that the proposed LAIAugment method has an average F1-score of 72.3% on the three legal AI tasks, which is 1.93% higher than the baseline model. At the same time, it shows a huge improvement in few-shot learning.","llm_keywords":["Few-shot learning","Self-training","Legal artificial intelligence","Pre-training","LAIAugment","Semi-supervised learning","Text similarity","Legal tasks","Evidence extraction"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":17},{"id":"1d219bfe6ce0a8c032a0b349965f8336bcba498b22218e28a5bb635cae9d4b867e70f5a898c197e5319464765ecb57aff4ea9952c75d1c3f90959ece8e675318","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09425-7.pdf","title":"A case study for automated attribute extraction from legal documents using large language models","llm_title":"A case study for automated attribute extraction from legal documents using large language models","authors":["Subinay Adhikary","Procheta Sen","Dwaipayan Roy","Kripabandhu Ghosh"],"llm_authors":"Subinay Adhikary, Procheta Sen, Dwaipayan Roy, Kripabandhu Ghosh","author_string":"Subinay Adhikary","year":2024,"abstract":"","llm_abstract":"The escalating number of pending cases is a growing concern worldwide. Recent advancements in digitization have opened up possibilities for leveraging artificial intelligence (AI) tools in the processing of legal documents. Adopting a structured representation for legal documents, as opposed to a mere bag-of-words flat text representation, can significantly enhance processing capabilities. With the aim of achieving this objective, we put forward a set of diverse attributes for criminal case proceedings. To enhance the effectiveness of automatically extracting these attributes from legal documents within a sequence labeling framework, we propose the utilization of a few-shot learning approach based on Large Language Models (LLMs). Moreover, we demonstrate the efficacy of the extracted attributes in downstream tasks, such as legal judgment prediction and legal statute prediction.","llm_keywords":["Large language model","Legal attribute","Sequence labeling","Weak supervision","Attribute extraction","Criminal case proceedings","Legal judgment prediction","Legal statute prediction"],"classifications":["Information Extraction","Pre-Processing"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":22},{"id":"bbf084ff63ef1ea569fa15de397094f9cad7ea848d10045a3e514891453b56f0c5f5750a03737f5f855ad1fb48ea8e1964fa52578c5e65100fef8bf6cf9eb786","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09390-1.pdf","title":"The challenge of open-texture in law","llm_title":"The challenge of open-texture in law","authors":["Clement Guitton","Aurelia Tamò-Larrieux","Simon Mayer","Gijs van Dijck"],"llm_authors":"Clement Guitton, Aurelia Tamò-Larrieux, Simon Mayer, Gijs van Dijck","author_string":"Clement Guitton","year":2024,"abstract":"","llm_abstract":"An important challenge when creating automatically processable laws concerns open-textured terms. The ability to measure open-texture can assist in determining the feasibility of encoding regulation and where additional legal information is required to properly assess a legal issue or dispute. In this article, we propose a novel conceptualisation of open-texture with the aim of determining the extent of open-textured terms in legal documents. We conceptualise open-texture as a lever whose state is impacted by three types of forces: internal forces (the words within the text themselves), external forces (the resources brought to challenge the definition of words), and lateral forces (the merit of such challenges). We tested part of this conceptualisation with 26 participants by investigating agreement in paired annotators. Five key findings emerged. First, agreement on which words are open-texture within a legal text is possible and statistically significant. Second, agreement is even high at an average inter-rater reliability of 0.7 (Cohen’s kappa). Third, when there is agreement on the words, agreement on the Open-Texture Value is high. Fourth, there is a dependence between the Open-Texture Value and reasons invoked behind open-texture. Fifth, involving only four annotators can yield similar results compared to involving twenty more when it comes to only flagging clauses containing open-texture. We conclude the article by discussing limitations of our experiment and which remaining questions in real life cases are still outstanding.","llm_keywords":["Computational law","Open-textured","Ambiguity","Vagueness","Encodability"],"classifications":["Pre-Processing"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":31},{"id":"f1f5cf0024fd2c0a1e8d425db27b277746cad2312ce2535990103b16f31db859fa98888ec48399ee9af613af4ab59d14441ff761f4f245f84e6f5767cb88f3cc","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09426-6.pdf","title":"Mining EU consultations through AI","llm_title":"Mining EU consultations through AI","authors":["Fabiana Di Porto","Paolo Fantozzi","Maurizio Naldi","Nicoletta Rangone"],"llm_authors":"Fabiana Di Porto, Paolo Fantozzi, Maurizio Naldi, Nicoletta Rangone","author_string":"Fabiana Di Porto","year":2024,"abstract":"","llm_abstract":"Consultations are key to gather evidence that informs rulemaking. When analysing the feedback received, it is essential for the regulator to appropriately cluster stakeholders’ opinions, as misclustering may alter the representativeness of the positions, making some of them appear majoritarian when they might not be. The European Commission (EC)’s approach to clustering opinions in consultations lacks a standardized methodology, leading to reduced procedural transparency, while making use of computational tools only sporadically. This paper explores how natural language processing (NLP) technologies may enhance the way opinion clustering is currently conducted by the EC. We examine 830 responses to three legislative proposals (the Artificial Intelligence Act, the Digital Markets Act and the Digital Services Act) using both a lexical and semantic approach. We find that some groups (like small and medium companies) have low similarity across all datasets and methodologies despite being clustered in one opinion group by the EC. The same happens for citizens and consumer associations for the consultation run over the DSA. These results suggest that computational tools actually help reduce misclustering of stakeholders’ opinions and consequently allow greater representativeness of the different positions expressed in consultations. They further suggest that the EC could identify a convergent methodology for all its consultations, where such tools are employed in a consistent and replicable rather than occasionally. Ideally, it should also explain when one methodology is preferred to another. This effort should find its way into the Better Regulation toolbox (EC 2023). Our analysis also paves the way for further research to reach a transparent and consistent methodology for group clustering.","llm_keywords":["Consultations","NLP","Stakeholders’ opinions","Computational linguistics","Artificial intelligence","Regulation","DSA","DMA","AI act","Group clustering"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":38},{"id":"219ed413bf67efa281c7364bbab3a55dbecc8cefcc54930f83458f8681c6f3790794b77e6939ed7ad70d6876d34975f6887def304163a992dae6f9a201351734","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09400-2.pdf","title":"","llm_title":"Correction to: Code is law: how COMPAS affects the way the judiciary handles the risk of recidivism","authors":["Christopher Engel","Lorenz Linhardt","Marcel Schubert"],"llm_authors":"Christopher Engel, Lorenz Linhardt, Marcel Schubert","author_string":"","year":2024,"abstract":"","llm_abstract":"","llm_keywords":["Artificial Intelligence","Law","COMPAS","Judiciary","Recidivism","Machine Learning","Open Access","Correction"],"classifications":[],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":2},{"id":"2df87836db17408089c5b31793f365c8caa0e42c4246209ff04692ae7819abc72bfca9be2a8fcb6a119c5d4c1d861782ae89256bf96e18ac58d84dd712abb39e","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09409-7.pdf","title":"From PARIS to LE-PARIS: toward patent response automation with recommender systems and collaborative large language models","llm_title":"From PARIS to LE‑PARIS: toward patent response automation with recommender systems and collaborative large language models","authors":["Jung-Mei Chu","Hao-Cheng Lo","Jieh Hsiang","Chun-Chieh Cho"],"llm_authors":"Jung‑Mei Chu, Hao‑Cheng Lo, Jieh Hsiang, Chun‑Chieh Cho","author_string":"Jung-Mei Chu","year":2024,"abstract":"","llm_abstract":"In patent prosecution, timely and effective responses to Office Actions (OAs) are crucial for securing patents. However, past automation and artificial intelligence research have largely overlooked this aspect. To bridge this gap, our study introduces the Patent Office Action Response Intelligence System (PARIS) and its advanced version, the Large Language Model (LLM) Enhanced PARIS (LE-PARIS). These systems are designed to enhance the efficiency of patent attorneys in handling OA responses through collaboration with AI. The systems’ key features include the construction of an OA Topics Database, development of Response Templates, and implementation of Recommender Systems and LLM-based Response Generation. To validate the effectiveness of the systems, we have employed a multi-paradigm analysis using the USPTO Office Action database and longitudinal data based on attorney interactions with our systems over six years. Through five studies, we have examined the constructiveness of OA topics (studies 1 and 2) using topic modeling and our proposed Delphi process, the efficacy of our proposed hybrid LLM-based recommender system tailored for OA responses (study 3), the quality of generated responses (study 4), and the systems’ practical value in real-world scenarios through user studies (study 5). The results indicate that both PARIS and LE-PARIS significantly achieve key metrics and have a positive impact on attorney performance.","llm_keywords":["Patent","Office action","Response","Recommender system","Large language model","User study"],"classifications":["Information Retrieval","Information Extraction","Text Generation"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":27},{"id":"0378bcf8e92eb4eea9c29e2378b70b7f4c30104a3e0d552ab5b125a1f6743a4fa63910614da44d47e8385131a72f6c6000a34bb643a283825e24d762e9a5be2a","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09408-8.pdf","title":"A support system for the detection of abusive clauses in B2C contracts","llm_title":"A support system for the detection of abusive clauses in B2C contracts","authors":["Sławomir Dadas","Marek Kozłowski","Rafał Poświata","Michał Perełkiewicz","Marcin Białas","Małgorzata Grębowiec"],"llm_authors":"Sławomir Dadas, Marek Kozłowski, Rafał Poświata, Michał Perełkiewicz, Marcin Białas, Małgorzata Grębowiec","author_string":"Sławomir Dadas","year":2024,"abstract":"","llm_abstract":"Many countries employ systemic methods of protecting consumers from unfair business practices. One such practice is the use of abusive clauses in business-to-consumer (B2C) contracts, which unfairly impose additional obligations on the consumer or deprive them of their due rights. This article presents an information system that utilizes artificial intelligence methods to automate contract analysis and to detect abusive clauses. The goal of the system is to support the entire administrative process, from contract acquisition, through text extraction and the recommendation of potentially abusive clauses, to the generation of official administrative documents that can be sent to court or to the owners of firms. This article focuses on the components that use machine learning methods. The first is an intelligent crawler that is responsible for automatically detecting contract templates on websites and retrieving them into the system. The second is a document analysis module that implements a clause recommendation algorithm. The algorithm employs transformer-based language models and information retrieval methods to identify abusive passages in text. Our solution achieved first place in a competition on the automatic analysis of B2C contracts organized by the Polish Office of Competition and Consumer Protection (UOKiK), and has since been implemented as an official tool to support the contract analysis process in Poland.","llm_keywords":["B2C contracts","Natural language processing","Machine learning","Neural networks","Consumer protection","Abusive clauses","Artificial intelligence","Document analysis","Transformer-based language models"],"classifications":["Machine Summarization"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":39},{"id":"4bfae960023cab8ec39171164d9fe0d466c0a7fead24ed314478ece189fa4de0cb2d539e400c665587b1095e117f21ff69414831b2dfdf311923af5d7c5a43c4","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09410-0.pdf","title":"SIM-GCN: similarity graph convolutional networks for charges prediction","llm_title":"SIM‑GCN: similarity graph convolutional networks for charges prediction","authors":["Qiang Ge","Jing Zhang","Xiaoding Guo"],"llm_authors":"Qiang Ge, Jing Zhang, Xiaoding Guo","author_string":"Qiang Ge","year":2024,"abstract":"","llm_abstract":"In recent years, the analysis of legal judgments and the prediction of outcomes based on case factual descriptions have become hot research topics in the field of judiciary. Among them, the task of charge prediction aims to predict the applicable charges of a judicial case based on its factual description, making it an important research area in the intelligent judiciary. While significant progress has been made in machine learning and deep learning, traditional methods are limited to handling data in Euclidean space and cannot effectively capture the semantic information in the text. To overcome the limitations of traditional learning approaches, many studies have started exploring the use of graphs to represent rich relationships between entities in text and employing graph convolutional neural networks to learn text representations. In this paper, we propose a charge prediction method based on graph convolutional neural networks. By constructing a similarity graph between cases and utilizing graph convolutional neural networks to learn case feature representations, we can better capture the relational information between cases and improve the accuracy of charge prediction. Experimental results on multiple benchmark datasets demonstrate that our proposed model outperforms traditional methods in charge prediction tasks.","llm_keywords":["Graph convolutional neural networks","Charge prediction","Intelligent judiciary","Deep learning"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":23},{"id":"877ee479f1d78e901a595c2226a3882d74a84a7564fd0188e6ab3ec3a69b5e128d93f8998965f6ac48a825875c760e15a9b5e4c171f36e22239f7b7e5ee433f6","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09389-8.pdf","title":"Code is law: how COMPAS affects the way the judiciary handles the risk of recidivism","llm_title":"Code is law: how COMPAS affects the way the judiciary handles the risk of recidivism","authors":["Christoph Engel","Lorenz Linhardt","Marcel Schubert"],"llm_authors":"Christoph Engel, Lorenz Linhardt, Marcel Schubert","author_string":"Christoph Engel","year":2024,"abstract":"","llm_abstract":"Judges in multiple US states, such as New York, Pennsylvania, Wisconsin, California, and Florida, receive a prediction of defendants’ recidivism risk, generated by the COMPAS algorithm. If judges act on these predictions, they implicitly delegate normative decisions to proprietary software, even beyond the previously documented race and age biases. Using the ProPublica dataset, we demonstrate that COMPAS predictions favor jailing over release. COMPAS is biased against defendants. We show that this bias can largely be removed. Our proposed correction increases overall accuracy, and attenuates anti-black and anti-young bias. However, it also slightly increases the risk that defendants are released who commit a new crime before tried. We argue that this normative decision should not be buried in the code. The tradeoff between the interests of innocent defendants and of future victims should not only be made transparent. The algorithm should be changed such that the legislator and the courts do make this choice.","llm_keywords":["Algorithmic decision-aids","COMPAS","False positives","False negatives","Anti-defendant bias","Algorithmic correction"],"classifications":["Resources","Classification"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":22},{"id":"f671793448acf56b798953448b5e0ae360efb732650ef02bd8c0efc2f530a4bcc3c801c31eac06aa8b8462b20df2cdc9ceae62684129e8116198c4d7c80f1e67","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09419-5.pdf","title":"Segmenting Brazilian legislative text using weak supervision and active learning","llm_title":"Segmenting Brazilian legislative text using weak supervision and active learning","authors":["Felipe Siqueira","Diany Pressato","Fabíola Pereira","Nádia Silva","Ellen Souza","Márcio Dias","André Carvalho"],"llm_authors":"Felipe A. Siqueira, Diany Pressato, Fabíola S. F. Pereira, Nádia F. F. da Silva, Ellen Souza, Márcio S. Dias, André C. P. L. F. de Carvalho","author_string":"Felipe A. Siqueira","year":2024,"abstract":"","llm_abstract":"Legislative houses all over the world are adopting tools based on artificial intelligence to support their work. The incorporation of these tools can improve the analysis of the text of the proposed new laws and speed the preparation and discussion of new laws. The performance of artificial intelligence tools for text processing tasks is largely affected by the corpora used, which should ideally be adapted for the specific domain. When dealing with legislative corpora, text segmentation is often necessary due to the distinct purposes of legislative segments within the overall bill structure. While rule-based approaches can be effective in cases where the data follows a consistent format, they fail when inconsistencies arise in the formatting of legislative bills. In this study, we extensively investigate the use of weak supervision and active learning to accurately segment over 100,000 Brazilian federal legislative bills using a sequence tagging approach. The experiments demonstrated that both BERT and LSTM models achieved high statistical performance without the limitations of rule-based systems. In segmenting long documents beyond the limited context window of BERT, we find that simple moving windows suffice because the required context for accurate legislative segmentation is mostly local. We also conducted an analysis of transfer learning from our monolingual models to French, Italian, German, and English (US) legislative texts. According to our experimental results our models present non-trivial zero-shot and effective out-of-distribution fine-tuning performance, suggesting potential avenues for multilingual legislative segmentation without the need for computationally expensive models. The models, data, and code are publicly available at https://github.com/ulysses-camara/ulysses-segmenter.","llm_keywords":["Text segmentation","Legislative domain","Weak supervision","Active learning","Portuguese data"],"classifications":["Resources","Pre-Processing","Information Extraction","Text Generation"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":82},{"id":"ea858d0d3c4386999ba31c94927b9ff7860b98f6a8a5b508550bdef68e9664d71e6ca40bd620ba0cd494c226b09f999b011cd85d1b57f54abf9e9446451e7b6e","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-023-09387-2.pdf","title":"DiscoLQA: zero-shot discourse-based legal question answering on European Legislation","llm_title":"DiscoLQA: zero‑shot discourse‑based legal question answering on European Legislation","authors":["Francesco Sovrano","Monica Palmirani","Salvatore Sapienza","Vittoria Pistone"],"llm_authors":"Francesco Sovrano, Monica Palmirani, Salvatore Sapienza, Vittoria Pistone","author_string":"Francesco Sovrano","year":2024,"abstract":"","llm_abstract":"The structures of discourse used by legal and ordinary languages share diferences that foster technical issues when applying or fne-tuning general-purpose language models for open-domain question answering on legal resources. For example, longer sentences may be preferred in European laws (i.e., Brussels I bis Regulation EU 1215/2012) to reduce potential ambiguities and improve comprehensibility, distracting a language model trained on ordinary English. In this article, we investigate some mechanisms to isolate and capture the discursive patterns of legalese in order to perform zero-shot question answering, i.e., without training on legal documents. Specifcally, we use pre-trained open-domain answer retrieval systems and study what happens when changing the type of information to consider for retrieval. Indeed, by selecting only the important parts of discourse (e.g., elementary units of discourse, EDU for short, or abstract representations of meaning, AMR for short), we should be able to help the answer retriever identify the elements of interest. Hence, with this paper, we publish Q4EU, a new evaluation dataset that includes more than 70 questions and 200 answers on 6 diferent European norms, and study what happens to a baseline system when only EDUs or AMRs are used during information retrieval. Our results show that the versions using EDUs are overall the best, leading to state-of-the-art F1, precision, NDCG and MRR scores.","llm_keywords":["Legal question answering","European Legislation","Knowledge graph extraction","Discourse theory","Abstract meaning representations","Private international law","European arrest warrant","GDPR","Electronic signature"],"classifications":["Information Retrieval"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":37},{"id":"15aac0c838f7e07bdf6ee90acea76cde8c1cc1f3414e0726dd7cdf1bd3f10734684b861cfe8cd26d35abc4cc2fe44424b7c49df6f3144f59ae800979d67c7881","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09406-w.pdf","title":"The digital transformation of jurisprudence: an evaluation of ChatGPT-4’s applicability to solve cases in business law","llm_title":"The digital transformation of jurisprudence: an evaluation of ChatGPT-4’s applicability to solve cases in business law","authors":["Sascha Schweitzer","Markus Conrads"],"llm_authors":"Sascha Schweitzer, Markus Conrads","author_string":"Sascha Schweitzer","year":2024,"abstract":"","llm_abstract":"In the evolving landscape of legal information systems, ChatGPT-4 and other advanced conversational agents (CAs) offer the potential to disruptively transform the law industry. This study evaluates commercially available CAs within the German legal context, thereby assessing the generalizability of previous U.S.-based findings. Employing a unique corpus of 200 distinct legal tasks, ChatGPT-4 was benchmarked against Google Bard, Google Gemini, and its predecessor, ChatGPT-3.5. Human-expert and automated assessments of 4000 CA-generated responses reveal ChatGPT-4 to be the first CA to surpass the threshold of solving realistic legal tasks and passing a German business law exam. While ChatGPT-4 outperforms ChatGPT-3.5, Google Bard, and Google Gemini in both consistency and quality, the results demonstrate a considerable degree of variability, especially in complex cases with no predefined response options. Based on these findings, legal professionals should manually verify all texts produced by CAs before use. Novices must exercise caution with CA-generated legal advice, given the expertise needed for its assessment.","llm_keywords":["Legal information systems","Large language models","Generative artificial intelligence","Conversational agents","Chatbots","Performance assessment"],"classifications":["Machine Summarization","Text Generation"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":25},{"id":"9f80f9050b1ade6335c8b48d9a3b28acf5b1de9fcadb30138f0ae0c8a3e7f42b4ab778a4d141ccb0a373322e184fd0ce1f8a628eb5709c644ef3ae036ddd5a3e","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09405-x.pdf","title":"Intermediate factors and precedential constraint","llm_title":"Intermediate factors and precedential constraint","authors":["Trevor Bench-Capon"],"llm_authors":"Trevor Bench-Capon","author_string":"Trevor Bench-Capon","year":2024,"abstract":"","llm_abstract":"This paper explores the extension of formal accounts of precedential constraint to make use of a factor hierarchy with intermediate factors. A problem arises, however, because constraints expressed in terms of intermediate factors may give different outcomes from those expressed only using base level factors. We argue that constraints that use only base level factors yield the correct outcomes, but that intermediate factors play an important role in the justification and explanation of those outcomes. The discussion is illustrated with a running example.","llm_keywords":["Precedential constraint","Legal reasoning","Factors","Factor hierarchy","Explanation"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":20},{"id":"a0741cd7cc05e261df2bd7f69854bbad9e1a2959cb8b8a4437137434e4b4ce2e19a698f1a4029318bb5180c20d32e319eca3a0ca18d74185e7a9a2d3dc9af7d8","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09424-8.pdf","title":"Advancing legal recommendation system with enhanced Bayesian network machine learning","llm_title":"Advancing legal recommendation system with enhanced Bayesian network machine learning","authors":["Xukang Wang","Vanessa Hoo","Mingyue Liu","Jiale Li","Ying Cheng Wu"],"llm_authors":"Xukang Wang, Vanessa Hoo, Mingyue Liu, Jiale Li, Ying Cheng Wu","author_string":"Xukang Wang","year":2024,"abstract":"","llm_abstract":"The integration of machine learning algorithms into the legal recommendation system marks a burgeoning area of research, with a particular focus on enhancing the accuracy and efficiency of judicial decision-making processes. The application of Bayesian Network (BN) emerges as a potent tool in this context, promising to address the inherent complexities and unique nuances of legal texts and individual case subtleties. However, the challenge of achieving high accuracy in BN parameter learning, especially under conditions of limited data, remains a significant hurdle. This study proposes an Enhanced Maximum Parameter Learning (EMPL) algorithm, tailored for BN parameter optimization in scenarios characterized by small sample sizes. The EMPL algorithm, innovatively incorporating the Synthetic Minority Over-sampling Technique (SMOTE), begins with the formulation of inequality constraints derived from domain expertise. It establishes a minimal dataset threshold necessary for effective parameter learning. Through the introduction of an index weighting factor function that dynamically adjusts according to the sample size, the algorithm facilitates the derivation of refined BN parameters. The core innovation of the EMPL algorithm lies in its use of an exponentially weighted factor function, designed to be responsive to variations in sample size, and its capacity to expand the parameter space using SMOTE to align with qualitative constraints from expert insights. This approach enables the integration of data-derived parameters with those obtained through expert experience in an exponentially weighted manner, culminating in the optimization of BN parameters. Comparative analysis reveals that the EMPL algorithm achieves superior learning accuracy over traditional Maximum Likelihood Estimation (MLE) and qualitative maximum a posteriori (QMAP) approach, particularly in contexts of sparse data. Furthermore, it demonstrates enhanced performance relative to variable weight learning algorithms, underscoring its potential to significantly improve decision-making processes in the legal domain through advanced BN parameter learning.","llm_keywords":["US law","Machine learning","Bayesian network","Parameter learning","Legal recommendation","EMPL algorithm","SMOTE","Judicial decision-making","Artificial intelligence","Legal texts"],"classifications":["Resources"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":18},{"id":"37ef60153e3e422f9cb07e108d0311c7cc396982cca5d1dcd7a58069baf9c884aa236e104f8064185f5b66f1def9eed1fab1388e9ab25461007f53f2e8c4a34a","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09407-9.pdf","title":"Graph contrastive learning networks with augmentation for legal judgment prediction","llm_title":"Graph contrastive learning networks with augmentation for legal judgment prediction","authors":["Yao Dong","Xinran Li","Jin Shi","Yongfeng Dong","Chen Chen"],"llm_authors":"Yao Dong, Xinran Li, Jin Shi, Yongfeng Dong, Chen Chen","author_string":"Yao Dong","year":2024,"abstract":"","llm_abstract":"Legal Judgment Prediction (LJP) is a typical application of Artifcial Intelligence in the intelligent judiciary. Current research primarily focuses on automatically predicting law articles, charges, and terms of penalty based on the fact description of cases. However, existing methods for LJP have limitations, such as neglecting document structure and ignoring case similarities. We propose a novel framework called Graph Contrastive Learning with Augmentation (GCLA) for legal judgment prediction to address these issues. GCLA constructs trainable document-level graphs for fact description, capturing local and global context through sentence-level subgraphs. Graph augmentation enhances robustness. We introduce a comparison case relation perspective, using graph contrastive learning to model case-text label relationships effectively. Experimental results on real-world datasets demonstrate the competitive performance of GCLA.","llm_keywords":["Legal judgment prediction","Fact graph","Supervised contrastive learning","Graph augmentation","Artificial Intelligence","Graph Neural Network","Natural Language Processing","Transformer","Long text processing"],"classifications":["Classification","Information Retrieval"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":24},{"id":"1d6ee5610e96d0b5c53c02dff671c6f997382c71f700e004662bb035654ec453470228204362b4de3305cf363651dcc0ab556ece1a7cefd5dfa32b2bdf8fa0aa","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09399-6.pdf","title":"Large language models in cryptocurrency securities cases: can a GPT model meaningfully assist lawyers?","llm_title":"Large language models in cryptocurrency securities cases: can a GPT model meaningfully assist lawyers?","authors":["Arianna Trozze","Toby Davies","Bennett Kleinberg"],"llm_authors":"Arianna Trozze, Toby Davies, Bennett Kleinberg","author_string":"Arianna Trozze","year":2024,"abstract":"","llm_abstract":"Large Language Models (LLMs) could be a useful tool for lawyers. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying GPT-3.5’s legal reasoning and ChatGPT’s legal drafting capabilities. We examine whether a) GPT-3.5 can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to ChatGPT. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by ChatGPT and lawyers. GPT-3.5’s legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely missed additional, correct violations). ChatGPT performed better at legal drafting, and jurors’ decisions were not statistically significantly associated with the author of the document upon which they based their decisions. Because GPT-3.5 cannot satisfactorily conduct legal reasoning tasks, it would be unlikely to be able to help lawyers in a meaningful way at this stage. However, ChatGPT’s drafting skills (though, perhaps, still inferior to lawyers) could assist lawyers in providing legal services. Our research is the first to systematically study an LLM’s legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.","llm_keywords":["Cryptocurrency","Securities law","Artificial intelligence","Large language models","ChatGPT"],"classifications":[],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":47},{"id":"33ac42f54e10753fbaaea9830da7669c44fa1b3b1c9c91faf6f73c4db50d36b081e75ff7b657ad69d0fa9a38ca9cbc5482125b040440bde9601b2b2d88881dff","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09411-z.pdf","title":"Applicability of large language models and generative models for legal case judgement summarization","llm_title":"Applicability of large language models and generative models for legal case judgement summarization","authors":["Aniket Deroy","Kripabandhu Ghosh","Saptarshi Ghosh"],"llm_authors":"Aniket Deroy, Kripabandhu Ghosh, Saptarshi Ghosh","author_string":"Aniket Deroy","year":2024,"abstract":"","llm_abstract":"Automatic summarization of legal case judgements, which are known to be long and complex, has traditionally been tried via extractive summarization models. In recent years, generative models including abstractive summarization models and Large language models (LLMs) have gained huge popularity. In this paper, we explore the applicability of such models for legal case judgement summarization. We applied various domain-specific abstractive summarization models and general-domain LLMs as well as extractive summarization models over two sets of legal case judgements – from the United Kingdom (UK) Supreme Court and the Indian Supreme Court – and evaluated the quality of the generated summaries. We also perform experiments on a third dataset of legal documents of a different type – Government reports from the United States. Results show that abstractive summarization models and LLMs generally perform better than the extractive methods as per traditional metrics for evaluating summary quality. However, detailed investigation shows the presence of inconsistencies and hallucinations in the outputs of the generative models, and we explore ways to reduce the hallucinations and inconsistencies in the summaries. Overall, the investigation suggests that further improvements are needed to enhance the reliability of abstractive models and LLMs for legal case judgement summarization. At present, a human-in-the-loop technique is more suitable for performing manual checks to identify inconsistencies in the generated summaries.","llm_keywords":["Legal judgement summarization","Abstractive summarization","Large language models","Prompting","Hallucinations"],"classifications":["Machine Summarization","Text Generation"],"num_cited_by":26,"num_cited_by_title_only":26,"num_pages":44},{"id":"fed3fb7d754c25551c96aaa4065e67b4ba21fe81bcece423741845898b4413346a699b191f21e5f41b307fee96803a5ef9793bf0611ea72fa3b70d5a2af8a1d1","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09418-6.pdf","title":"DGGCCM: a hybrid neural model for legal event detection","llm_title":"DGGCCM: a hybrid neural model for legal event detection","authors":["Shutao Gong","Xudong Luo"],"llm_authors":"Shutao Gong, Xudong Luo","author_string":"Shutao Gong","year":2024,"abstract":"","llm_abstract":"This paper introduces an advanced event detection model for legal intelligence, focusing on identifying event types in legal cases by examining trigger word candidates. It employs the DeBERTa pre-trained language model for encoding sentences into enriched word representations, supplemented by the Global Pointer neural network for initial scoring. The model further uses a graph convolutional network, conditional layer normalisation, and a convolutional neural network to extract features from these representations. A multilayer perceptron then determines the event type based on these features and initial scores. Additionally, a dictionary-matching method revises the predicted event types, with adversarial training and a sentence-length mask employed to enhance model performance and address missing trigger words. The model’s effectiveness is proven through extensive experimentation, outperforming state-of-the-art baselines (including some large language models) and securing third prize in the event detection task at the Challenge of AI in Law (CAIL) 2022. The code of our model is available at https://github.com/1gst/DGGCCN/tree/main.","llm_keywords":["Event detection","Graph convolutional network","Large language model","Hybrid neural model","Legal intelligence"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":41},{"id":"62f9255a6edfc883799d1f230ed0024b236d5d8bb6da71198afeada03802b5a415c97f69f27af4ba30efbf6177dab9f89319c4a1d16972f129593dd2130e699c","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09394-x.pdf","title":"Legal sentence boundary detection using hybrid deep learning and statistical models","llm_title":"Legal sentence boundary detection using hybrid deep learning and statistical models","authors":["Reshma Sheik","Sneha Rao Ganta","S. Jaya Nirmala"],"llm_authors":"Reshma Sheik, Sneha Rao Ganta, S. Jaya Nirmala","author_string":"Reshma Sheik","year":2024,"abstract":"","llm_abstract":"Sentence boundary detection (SBD) represents an important first step in natural language processing since accurately identifying sentence boundaries significantly impacts downstream applications. Nevertheless, detecting sentence boundaries within legal texts poses a unique and challenging problem due to their distinct structural and linguistic features. Our approach utilizes deep learning models to leverage delimiter and surrounding context information as input, enabling precise detection of sentence boundaries in English legal texts. We evaluate various deep learning models, including domain-specific transformer models like LegalBERT and CaseLawBERT. To assess the efficacy of our deep learning models, we compare them with a state-of-the-art domain-specific statistical conditional random field (CRF) model. After considering model size, F1-score, and inference time, we identify the Convolutional Neural Network Model (CNN) as the top-performing deep learning model. To further enhance performance, we integrate the features of the CNN model into the subsequent CRF model, creating a hybrid architecture that combines the strengths of both models. Our experiments demonstrate that the hybrid model outperforms the baseline model, achieving a 4% improvement in the F1-score. Additional experiments showcase the superiority of the hybrid model over SBD open-source libraries when confronted with an out-of-domain test set. These findings underscore the importance of efficient SBD in legal texts and emphasize the advantages of employing deep learning models and hybrid architectures to achieve optimal performance.","llm_keywords":["Natural language processing","Sentence boundary detection","Deep learning","Transformer","LegalBERT","CaseLawBERT","CNN","CRF"],"classifications":["Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":31},{"id":"d7505a4f52b6cb9240cd8de4e09f9a5190ed0c3b54c16ad3e89321825cacc38243bbb3de5fc7f40ba94586b08be3500670beeca6663963af4b21e2a06da60b8f","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09396-9.pdf","title":"Re-evaluating GPT-4’s bar exam performance","llm_title":"Re‑evaluating GPT‑4’s bar exam performance","authors":["Eric Martínez"],"llm_authors":"Eric Martínez","author_string":"Eric Martínez","year":2024,"abstract":"","llm_abstract":"Perhaps the most widely touted of GPT-4’s at-launch, zero-shot capabilities has been its reported 90th-percentile performance on the Uniform Bar Exam. This paper begins by investigating the methodological challenges in documenting and verifying the 90th-percentile claim, presenting four sets of findings that indicate that OpenAI’s estimates of GPT-4’s UBE percentile are overinflated. First, although GPT-4’s UBE score nears the 90th percentile when examining approximate conversions from February administrations of the Illinois Bar Exam, these estimates are heavily skewed towards repeat test-takers who failed the July administration and score significantly lower than the general test-taking population. Second, data from a recent July administration of the same exam suggests GPT-4’s overall UBE percentile was below the 69th percentile, and ∼48th percentile on essays. Third, examining official NCBE data and using several conservative statistical assumptions, GPT-4’s performance against first-time test takers is estimated to be ∼62nd percentile, including ∼42nd percentile on essays. Fourth, when examining only those who passed the exam (i.e. licensed or license-pending attorneys), GPT-4’s performance is estimated to drop to ∼48th percentile overall, and ∼15th percentile on essays. In addition to investigating the validity of the percentile claim, the paper also investigates the validity of GPT-4’s reported scaled UBE score of 298. The paper successfully replicates the MBE score, but highlights several methodological issues in the grading of the MPT + MEE components of the exam, which call into question the validity of the reported essay score. Finally, the paper investigates the effect of different hyperparameter combinations on GPT-4’s MBE performance, finding no significant effect of adjusting temperature settings, and a significant effect of few-shot chain-of-thought prompting over basic zero-shot prompting. Taken together, these findings carry timely insights for the desirability and feasibility of outsourcing legally relevant tasks to AI models, as well as for the importance for AI developers to implement rigorous and transparent capabilities evaluations to help secure safe and trustworthy AI.","llm_keywords":["NLP","Legal NLP","Natural language processing","Machine learning","Artificial intelligence","Legal profession"],"classifications":["Classification"],"num_cited_by":52,"num_cited_by_title_only":52,"num_pages":24},{"id":"28ea18295b1c0582c39047201ad106257faf121ac8a85b9b5450487008d212d79211188f1b12221ee97fa53a7aa88edf62e4fc1c45fd11626104bb4a0e19a53c","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09420-y.pdf","title":"System for the anonymization of Romanian jurisprudence","llm_title":"System for the anonymization of Romanian jurisprudence","authors":["Vasile Păiş","Radu Ion","Elena Irimia","Verginica Barbu Mititelu","Valentin Badea","Dan Tufș"],"llm_authors":"Vasile Păiş, Radu Ion, Elena Irimia, Verginica Barbu Mititelu, Valentin Badea, Dan Tufș","author_string":"Vasile Păiş","year":2024,"abstract":"","llm_abstract":"The transparency of the judicial process and the consistency of judicial decisions can be improved through their publication. Access to jurisprudence is of paramount importance both for law professionals (judges, lawyers, law students) and for the larger public. However, public access must ensure the preservation of privacy for people involved, in accordance with national and international regulations. This paper presents the work behind building an artificial intelligence system for the anonymization of Romanian jurisprudence, allowing it to be accessed through the ReJust portal operated by the Superior Council of Magistracy in Romania.","llm_keywords":["Anonymization","Jurisprudence","Natural language processing","Romanian language","Judicial transparency","Legal technology","AI system","Public access","Human rights"],"classifications":["Pre-Processing","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":23},{"id":"9737f49fc23664c281914050b69153105a932f3470cc8f66dd506c4def544b9f5991325cfabf4e05b7e3cb1a9ee2605ebe85f21cdeabaa1718a800b94e6ba976","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09421-x.pdf","title":"Precedent-based reasoning with incomplete information for human-in-the-loop decision support","llm_title":"Precedent-based reasoning with incomplete information for human-in-the-loop decision support","authors":["Daphne Odekerken","Floris Bex","Henry Prakken"],"llm_authors":"Daphne Odekerken, Floris Bex, Henry Prakken","author_string":"Daphne Odekerken","year":2024,"abstract":"","llm_abstract":"We define and study the notions of stability and relevance for precedent-based reasoning, focusing on Horty’s result model of precedential constraint. According to this model, precedents constrain the possible outcomes for a focus case, which is a yet undecided case, where precedents and the focus case are compared on their characteristics (called dimensions). In this paper, we refer to the enforced outcome for the focus case as its justification status. In contrast to earlier work, we do not assume that all dimension values of the focus case or the precedent cases have been established with certainty: rather, each dimension is assigned a set of possible values. We define a focus case as stable if its justification status is the same for every choice of the possible values. For focus cases that are not stable, we study the task of identifying relevance: which possible values should be excluded to make the focus case stable? In addition, we introduce the notion of possibility to verify if a user can assign an outcome to an unstable focus case without making the case base of precedents inconsistent. We show how the tasks of identifying justification, stability, relevance and possibility can be applied for human-in-the-loop decision support. Finally, we discuss the computational complexity of these tasks and provide efficient algorithms.","llm_keywords":["precedential constraint","decision support","stability","relevance","algorithms","computational complexity","human-in-the-loop","precedent-based reasoning"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":46},{"id":"ef3e3ceabb42ecc4e7ca9cb52560a2effa9a17e1e492761d8b732075a6bf8292cb03bdd0fe75f0c10ac9cd3dff4be3fa3be3c8cc00e0882ec532df9fedc454c8","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09397-8.pdf","title":"Boosting court judgment prediction and explanation using legal entities","llm_title":"Boosting court judgment prediction and explanation using legal entities","authors":["Irene Benedetto","Alkis Koudounas","Lorenzo Vaiani","Eliana Pastor","Luca Cagliero","Francesco Tarasconi","Elena Baralis"],"llm_authors":"Irene Benedetto, Alkis Koudounas, Lorenzo Vaiani, Eliana Pastor, Luca Cagliero, Francesco Tarasconi, Elena Baralis","author_string":"Irene Benedetto","year":2024,"abstract":"","llm_abstract":"The automatic prediction of court case judgments using Deep Learning and Natural Language Processing is challenged by the variety of norms and regulations, the inherent complexity of the forensic language, and the length of legal judgments. Although state-of-the-art transformer-based architectures and Large Language Models (LLMs) are pre-trained on large-scale datasets, the underlying model reasoning is not transparent to the legal expert. This paper jointly addresses court judgment prediction and explanation by not only predicting the judgment but also providing legal experts with sentence-based explanations. To boost the performance of both tasks we leverage a legal named entity recognition step, which automatically annotates documents with meaningful domain-specific entity tags and masks the corresponding fine-grained descriptions. In such a way, transformer-based architectures and Large Language Models can attend to in-domain entity-related information in the inference process while neglecting irrelevant details. Furthermore, the explainer can boost the relevance of entity-enriched sentences while limiting the diffusion of potentially sensitive information. We also explore the use of in-context learning and lightweight fine-tuning to tailor LLMs to the legal language style and the downstream prediction and explanation tasks. The results obtained on a benchmark dataset from the Indian judicial system show the superior performance of entity-aware approaches to both judgment prediction and explanation.","llm_keywords":["eXplainable AI","Court judgment prediction","Legal named entity recognition","Legal AI","Transformer-based models","Large Language Models","Indian judicial system","Legal explanations"],"classifications":["Classification","Information Extraction","Pre-Processing"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":36},{"id":"c241c430c0a2a77eb989c429e758662fd851c34510ef4a983fa113d23219da1e6c07a0fc098da8554dd2a8880779ce2c0edc3c9a2dd2dae685ff0c7d6f2f5535","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09414-w.pdf","title":"LAWSUIT: a LArge expert-Written SUmmarization dataset of ITalian constitutional court verdicts","llm_title":"LAWSUIT: a LArge expert‑Written SUmmarization dataset of ITalian constitutional court verdicts","authors":["Luca Ragazzi","Gianluca Moro","Stefano Guidi","Giacomo Frisoni"],"llm_authors":"Luca Ragazzi, Gianluca Moro, Stefano Guidi, Giacomo Frisoni","author_string":"Luca Ragazzi","year":2024,"abstract":"","llm_abstract":"Large-scale public datasets are vital for driving the progress of abstractive summarization, especially in law, where documents have highly specialized jargon. However, the available resources are English-centered, limiting research advancements in other languages. This paper introduces LAWSUIT, a collection of 14K Italian legal verdicts with expert-authored abstractive maxims drawn from the Constitutional Court of the Italian Republic. LAWSUIT presents an arduous task with lengthy source texts and evenly distributed salient content. We offer extensive experiments with sequence-to-sequence and segmentation-based approaches, revealing that the latter achieve better results in full and few-shot settings. We openly release LAWSUIT to foster the development and automation of real-world legal applications.","llm_keywords":["Italian legal documents","Abstractive summarization","Large-scale dataset","Law","Natural language processing"],"classifications":["Resources","Machine Summarization"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":37},{"id":"536d298b8c0c48e6a0515537603c7ebf993967eca069248d22e09a52094f2be7badac35a497609e06dc326c93307bfd6dabcb1ea7b9468a1c87257565f0ce0bc","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09402-0.pdf","title":"Japanese tort-case dataset for rationale-supported legal judgment prediction","llm_title":"Japanese tort‑case dataset for rationale‑supported legal judgment prediction","authors":["Hiroaki Yamada","Takenobu Tokunaga","Ryutaro Ohara","Akira Tokutsu","Keisuke Takeshita","Mihoko Sumida"],"llm_authors":"Hiroaki Yamada, Takenobu Tokunaga, Ryutaro Ohara, Akira Tokutsu, Keisuke Takeshita, Mihoko Sumida","author_string":"Hiroaki Yamada","year":2024,"abstract":"","llm_abstract":"This paper presents the first dataset for Japanese Legal Judgment Prediction (LJP), the Japanese Tort-case Dataset (JTD), which features two tasks: tort prediction and its rationale extraction. The rationale extraction task identifies the court’s accepting arguments from alleged arguments by plaintiffs and defendants, which is a novel task in the field. JTD is constructed based on annotated 3477 Japanese Civil Code judgments by 41 legal experts, resulting in 7978 instances with 59,697 of their alleged arguments from the involved parties. Our baseline experiments show the feasibility of the proposed two tasks, and our error analysis by legal experts identifies sources of errors and suggests future directions of the LJP research.","llm_keywords":["Japanese Legal Judgment Prediction","tort prediction","rationale extraction","machine learning","dataset","annotation"],"classifications":["Resources","Information Extraction"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":25},{"id":"2d494428ec60266757134100840021dd88d8bdbcd0678c2b485c087344d02fedf0a30ff22be527f335342053e36f24c8ea69ea75d701855e696c6f5b22c5adcb","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09392-z.pdf","title":"Correction to: Reasoning with inconsistent precedents","llm_title":"Correction: Reasoning with inconsistent precedents","authors":["Ilaria Canavotto"],"llm_authors":"Ilaria Canavotto","author_string":"Ilaria Canavotto","year":2024,"abstract":"","llm_abstract":"","llm_keywords":["Artificial Intelligence","Law","Inconsistent Precedents","Reasoning","Correction","Case Law","Legal Philosophy"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":4},{"id":"6374778d66d9de91f544b9c3eca9d46d0d585dd45b3cba98f000c7b04fb598d19f8d061a2f4ef44221d28364e3a53216d74cc512aaea4d7af925ce421d3d16f6","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09428-4.pdf","title":"LaCour!: enabling research on argumentation in hearings of the European Court of Human Rights","llm_title":"LaCour!: enabling research on argumentation in hearings of the European Court of Human Rights","authors":["Lena Held","Ivan Habernal"],"llm_authors":"Lena Held, Ivan Habernal","author_string":"Lena Held","year":2024,"abstract":"","llm_abstract":"Why does an argument end up in the fnal court decision? Was it deliberated or questioned during the oral hearings? Was there something in the hearings that triggered a particular judge to write a dissenting opinion? Despite the availability of the fnal judgments of the European Court of Human Rights (ECHR), none of these legal research questions can currently be answered as the ECHR’s multilingual oral hearings are not transcribed, structured, or speaker-attributed. We address this fundamental gap by presenting LaCour!, the frst corpus of textual oral arguments of the ECHR, consisting of 154 full hearings (2.1 million tokens from over 267 h of video footage) in English, French, and other court languages, each linked to the corresponding fnal judgment documents. In addition to the transcribed and partially manually corrected text from the video, we provide sentence-level timestamps and manually annotated role and language labels. We also showcase LaCour! in a set of experiments that explore the interplay between questions and dissenting opinions. Apart from the use cases in legal NLP, we hope that law students or other interested parties will also use LaCour! as a learning resource, as it is freely available in various formats at https://huggingface.co/datasets/TrustHLT/LaCour.","llm_keywords":["ECHR","Legal arguments","Hearings","Corpus"],"classifications":["Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":24},{"id":"84b0a62d7a42fd58b7799cff9c0d0146f6eb6b9a8c016ffeaa20fb01c60969a949d91701dcded1e15deda5a61e19d03570b2ae8d415eea19f3c47f1ea7e34c90","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09395-w.pdf","title":"Exploring explainable AI in the tax domain","llm_title":"Exploring explainable AI in the tax domain","authors":["Łukasz Górski","Błażej Kuźniacki","Marco Almada","Kamil Tyliński","Madalena Calvo","Pablo Matias Asnaghi","Luciano Almada","Hilario Iñiguez","Fernando Rubianes","Octavio Pera","Juan Ignacio Nigrelli"],"llm_authors":"Łukasz Górski, Błażej Kuźniacki, Marco Almada, Kamil Tyliński, Madalena Calvo, Pablo Matias Asnaghi, Luciano Almada, Hilario Iñiguez, Fernando Rubianes, Octavio Pera, Juan Ignacio Nigrelli","author_string":"Łukasz Górski","year":2024,"abstract":"","llm_abstract":"This paper analyses whether current explainable AI (XAI) techniques can help to address taxpayer concerns about the use of AI in taxation. As tax authorities around the world increase their use of AI-based techniques, taxpayers are increasingly at a loss about whether and how the ensuing decisions follow the procedures required by law and respect their substantive rights. The use of XAI has been proposed as a response to this issue, but it is still an open question whether current XAI techniques are enough to meet existing legal requirements. The paper approaches this question in the context of a case study: a prototype tax fraud detector trained on an anonymized dataset of real-world cases handled by the Buenos Aires (Argentina) tax authority. The decisions produced by this detector are explained through the use of various classification methods, and the outputs of these explanation models are evaluated on their explanatory power and on their compliance with the legal obligation that tax authorities provide the rationale behind their decision-making. We conclude the paper by suggesting technical and legal approaches for designing explanation mechanisms that meet the needs of legal explanation in the tax domain.","llm_keywords":["Artificial intelligence","Tax fraud","Explanation methods","Legal requirements","Duty to give reasons"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":29},{"id":"50ad189480379c043908840ce434a54982651843686042320eedca560bfc9c0f68b58331c40c5038b473bfb1ed2a3fa5fcddb993f7772fbf68da21a7a4ae9da3","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09416-8.pdf","title":"","llm_title":"Jurisprudence in hard and soft law output of international organizations: a network analysis of the use of precedent in UN Security Council and general assembly resolutions","authors":["Rafael Mesquita","Antonio Pires"],"llm_authors":"Rafael Mesquita · Antonio Pires","author_string":"","year":2024,"abstract":"","llm_abstract":"Do hard law international organizations use jurisprudence differently than soft law ones? Precedent can be asset or an encumbrance to international organizations and their members, depending on their aims and on the policy area. Linking current decisions to previously-agreed ones helps to increase cohesion, facilitate consensus among members, and borrow authority – benefits that might be more necessary for some organizations than for others. To compare whether the features of norm-producing organizations correlate with their preference for jurisprudence, we compare two organs from the United Nations system: the Security Council, which produces binding decisions, and the General Assembly, which delivers soft law resolutions. We explore the citation networks formed by the approximately 20,400 resolutions adopted by each organ between 1946 and 2019 to test their differences with regards to the dynamics of citation formation, concentration of citations, and timing. Descriptive results reveal the main periods of jurisprudential activity by the Security Council and the General Assembly, but find no sizeable difference in their overall rate of precedent usage. We apply the Citation Exponential Random Graph Model (cERGM) to test for network determinants of citations and find additional similarities on transitivity and homophily, but also variations regarding preferential attachment.","llm_keywords":["UN general assembly","UN security council","International organizations","Network analysis","Citation network","Hard law","Soft law","International law","Bibliometrics","Exponential random graph model"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":30},{"id":"13f15b879d1a745ed74b0dc1ed68609cfa43efc84a37269c5750b6669ca30d95b8bd10cbdf6dafa5495d9a77b668aa18cd9df0cf53e91755cf0e8d46a1d08129","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-023-09388-1.pdf","title":"Combining prompt-based language models and weak supervision for labeling named entity recognition on legal documents","llm_title":"Combining prompt‑based language models and weak supervision for labeling named entity recognition on legal documents","authors":["Vitor Oliveira","Gabriel Nogueira","Thiago Faleiros","Ricardo Marcacini"],"llm_authors":"Vitor Oliveira, Gabriel Nogueira, Thiago Faleiros, Ricardo Marcacini","author_string":"Vitor Oliveira","year":2024,"abstract":"","llm_abstract":"Named entity recognition (NER) is a very relevant task for text information retrieval in natural language processing (NLP) problems. Most recent state-of-the-art NER methods require humans to annotate and provide useful data for model training. However, using human power to identify, circumscribe and label entities manually can be very expensive in terms of time, money, and effort. This paper investigates the use of prompt-based language models (OpenAI’s GPT-3) and weak supervision in the legal domain. We apply both strategies as alternative approaches to the traditional human-based annotation method, relying on computer power instead human effort for labeling, and subsequently compare model performance between computer and human-generated data. We also introduce combinations of all three mentioned methods (prompt-based, weak supervision, and human annotation), aiming to find ways to maintain high model efficiency and low annotation costs. We showed that, despite human labeling still maintaining better overall performance results, the alternative strategies and their combinations presented themselves as valid options, displaying positive results and similar model scores at lower costs. Final results demonstrate preservation of human-trained models scores averaging 74.0% for GPT-3, 95.6% for weak supervision, 90.7% for GPT + weak supervision combination, and 83.9% for GPT + 30% human-labeling combination.","llm_keywords":["Named entity recognition","GPT-3","Weak supervision","Legal documents","Natural language processing"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":21},{"id":"c536549f863c282166ddb90ffdd4fdf7fb6d8523fff3dad4124f46c88fc2ba1b6e282f8d906f095556b87a97b590c53acc953286ed21c22241fb419ca41df775","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09423-9.pdf","title":"Deciphering disagreement in the annotation of EU legislation","llm_title":"Deciphering disagreement in the annotation of EU legislation","authors":["Gijs van Dijck","Carlos Aguilera","Shashank M. Chakravarthy"],"llm_authors":"Gijs van Dijck, Carlos Aguilera, Shashank M. Chakravarthy","author_string":"Gijs van Dijck","year":2024,"abstract":"","llm_abstract":"The topic of annotating legal data has received surprisingly little attention. A key challenge of the annotation process is reaching a sufficient agreement between annotators and filtering mistakes from genuine disagreement. This study presents an approach that provides insights into and resolves potential disagreement amongst annotators. It (1) introduces different strategies to calculate agreement levels and compares (2) agreement levels between annotators (inter-annotator agreement) before and after a revision round and (3) agreement levels for annotators who annotate the same texts twice (intra-annotator agreement). The inter-annotator agreement levels are compared to a revision round in which an arbiter corrected the annotator’s labels. The analysis is based on the annotation of EU legislative provisions at two stages (initial annotations, after annotator revisions) and for various tasks (Definitions, References, Quantities, IF-THEN statements, Exceptions, Scope, Hierarchy, Deontic Clauses, Active and Passive Role) by multiple annotators. The results reveal that agreement levels vary based on the stage of measurement (before/after revisions), the nature of the task, the method of assessment, and the annotator combination. The agreement scores - along with some initial measurements—align with those reported in previous research but increase after each revision round. This suggests that annotator revisions can substantially reduce disagreement. Additionally, disagreements were found not only between but also among annotators. This inconsistency does not appear to stem from a lack of understanding of the guidelines or a lack of seriousness in task execution, as evidenced by moderate to substantial inter-annotator agreement scores. These findings suggest that annotators identified multiple valid interpretations, which highlights the complexity of annotating legislative provisions. The results underscore the significance of embracing, addressing, and reporting about (dis)agreement in different ways and at the various stages of an annotation task.","llm_keywords":["Interrater agreement","EU Law","Statutory provisions","Annotation","Legal datasets","Machine learning models","Annotation consistency","Legal text interpretation","Agreement calculation methods"],"classifications":["Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":36},{"id":"5af5cefcc412a43fcf92342375e14ac7a0a0dbe6c2aa8eeab404c3550283ac6c01771a1fca9d1bc28217046dfbb723447c3731a1c2ec58afc880f9dba6c45ccc","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09401-1.pdf","title":"InstructPatentGPT: training patent language models to follow instructions with human feedback","llm_title":"InstructPatentGPT: training patent language models to follow instructions with human feedback","authors":["Jieh-Sheng Lee"],"llm_authors":"Jieh‑Sheng Lee","author_string":"Jieh-Sheng Lee","year":2024,"abstract":"","llm_abstract":"In this research, patent prosecution is conceptualized as a system of reinforcement learning from human feedback. The objective of the system is to increase the likelihood for a language model to generate patent claims that have a higher chance of being granted. To showcase the controllability of the language model, the system learns from granted patents and pre-grant applications with different rewards. The status of “granted” and “pre-grant” are perceived as labeled human feedback implicitly. In addition, specific to patent drafting, the experiments in this research demonstrate the model’s capability to learn from adjusting claim length and inclusion of limiting terms for narrowing claim scope. As proof of concept, the experiments focus on claim ones only and the training data originates from a patent dataset tailored specifically for artificial intelligence. Although the available human feedback in patent prosecution are limited and the quality of generated patent text requires improvement, the experiments following the 3-stage reinforcement learning from human feedback have demonstrated that generative language models are capable of reflecting the human feedback or intent in patent prosecution. To enhance the usability of language models, the implementation in this research utilizes modern techniques that enable execution on a single consumer-grade GPU. The demonstrated proof of concept, which reduces hardware requirements, will prove valuable in the future as more human feedback in patent prosecution become available for broader use, either within patent offices or in the public domain.","llm_keywords":["Patent","Natural language generation","Natural language processing","Reinforcement learning","Human feedback","Patent prosecution","AI models"],"classifications":["Text Generation","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":44},{"id":"69918f1448ab790bdab752b90bbc06c3870c37122db5c89d82eb50c4709963fa3322e13cf2f3f9c687c528dfb2624009c7df1754896c542b5448beedb25fd350","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09415-9.pdf","title":"Classifying proportionality - identification of a legal argument","llm_title":"Classifying proportionality - identification of a legal argument","authors":["Kilian Lüders","Bent Stohlmann"],"llm_authors":"Kilian Lüders · Bent Stohlmann","author_string":"Kilian Lüders","year":2024,"abstract":"","llm_abstract":"Proportionality is a central and globally spread argumentation technique in public law. This article provides a conceptual introduction to proportionality and argues that such a domain-specific form of argumentation is particularly interesting for argument mining. As a major contribution of this article, we share a new dataset for which proportionality has been annotated. The dataset consists of 300 German Federal Constitutional Court decisions annotated at the sentence level (54,929 sentences). In addition to separating textual parts, a fine-grained system of proportionality categories was used. Finally, we used these data for a classification task. We built classifiers that predict whether or not proportionality is invoked in a sentence. We employed several models, including neural and deep learning models and transformers. A BERT-BiLSTM-CRF model performed best.","llm_keywords":["Proportionality","Constitutional court","Legal arguments","Transformer","BERT","BiLSTM","Argument mining","Deep learning"],"classifications":["Classification","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":28},{"id":"cafeb3036e154c2a9c297592f937b86513a3c5650512877abc08062df0d2b26c941323fe1f1499115cc488bb265d5cd6895b043b2740aedf83bc6b146aa89765","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09429-3.pdf","title":"Causality-inspired legal provision selection with large language model-based explanation","llm_title":"Causality‑inspired legal provision selection with large language model‑based explanation","authors":["Zheng Wang","Yuanzhi Ding","Caiyuan Wu","Yuzhen Guo","Wei Zhou"],"llm_authors":"Zheng Wang, Yuanzhi Ding, Caiyuan Wu, Yuzhen Guo, Wei Zhou","author_string":"Zheng Wang","year":2024,"abstract":"","llm_abstract":"Accurate identification of legal provisions is crucial for adjudicating criminal cases, but the complexity and volume of legal texts pose significant challenges for legal professionals. This paper addresses these challenges by introducing a novel legal provision selection framework that transforms the task from a simple classification problem into a sophisticated system combining semantic matching with causal relationship learning. Leveraging large language models, our approach enhances the understanding and interpretation of legal language, by extracting nuanced features from legal texts for deeper contextual comprehension. Additionally, integrating causal learning aligns with the inherent causality in legal reasoning, improving model interpretability and mitigating data bias. Our method demonstrates superior accuracy and robustness through extensive experiments on the CAIL2018 dataset and its subsets. This research significantly advances legal AI applications, promoting efficiency and fairness in the criminal justice system by providing precise and reliable legal provision selection.","llm_keywords":["Legal provision selection","Large language model","Causality","Feature selection","Legal AI","Criminal justice system","Semantic matching","Machine learning","Interpretability","Data bias"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":25},{"id":"66a87b648ef85b00765a2b31fbd3c70396611f35a14b0d97f6416af78e7d8dab286fcfbdc176e1744f3fa7be5b64a0e36157d5009e97433660f2ad5383e49315","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09422-w.pdf","title":"It cannot be right if it was written by AI: on lawyers’ preferences of documents perceived as authored by an LLM vs a human","llm_title":"It cannot be right if it was written by AI: on lawyers’ preferences of documents perceived as authored by an LLM vs a human","authors":["Jakub Harasta","Tereza Novotná","Jaromir Savelka"],"llm_authors":"Jakub Harasta, Tereza Novotná, Jaromir Savelka","author_string":"Jakub Harasta","year":2024,"abstract":"","llm_abstract":"Large Language Models (LLMs) enable a future in which certain types of legal documents may be generated automatically. This has a great potential to streamline legal processes, lower the cost of legal services, and dramatically increase access to justice. While many researchers focus on proposing and evaluating LLM-based applications supporting tasks in the legal domain, there is a notable lack of investigations into how legal professionals perceive content if they believe an LLM has generated it. Yet, this is a critical point as over-reliance or unfounded scepticism may influence whether such documents bring about appropriate legal consequences. This study is the necessary analysis of the ongoing transition towards mature generative AI systems. Specifically, we examined whether the perception of legal documents’ by lawyers and law students (n = 75) varies based on their assumed origin (human-crafted vs AI-generated). The participants evaluated the documents, focusing on their correctness and language quality. Our analysis revealed a clear preference for documents perceived as crafted by a human over those believed to be generated by AI. At the same time, most participants expect the future in which documents will be generated automatically. These findings could be leveraged by legal practitioners, policymakers, and legislators to implement and adopt legal document generation technology responsibly and to fuel the necessary discussions on how legal processes should be updated to reflect recent technological developments.","llm_keywords":["Generative AI","Large Language Model","Legal Document","AI-generated Content","Perception","Technology Adoption"],"classifications":["Text Generation"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":38},{"id":"9291f379201f52c19dcdc36c17e115ced65463cf5de1ad45299c120f13ba649a6a29c99beabdd2f62ff0f2497e45d2cf96f1ab9896498d91741a1d0b9c726c7e","file_path":"legal-nlp-survey-20250328-002/team 3/17- (Springer) Artificial Intelligence and Law/2024/s10506-024-09398-7.pdf","title":"Unfair clause detection in terms of service across multiple languages","llm_title":"Unfair clause detection in terms of service across multiple languages","authors":["Andrea Galassi","Francesca Lagioia","Agnieszka Jabłonowska","Marco Lippi"],"llm_authors":"Andrea Galassi, Francesca Lagioia, Agnieszka Jabłonowska, Marco Lippi","author_string":"Andrea Galassi","year":2024,"abstract":"","llm_abstract":"Most of the existing natural language processing systems for legal texts are developed for the English language. Nevertheless, there are several application domains where multiple versions of the same documents are provided in different languages, especially inside the European Union. One notable example is given by Terms of Service (ToS). In this paper, we compare different approaches to the task of detecting potential unfair clauses in ToS across multiple languages. In particular, after developing an annotated corpus and a machine learning classifier for English, we consider and compare several strategies to extend the system to other languages: building a novel corpus and training a novel machine learning system for each language, from scratch; projecting annotations across documents in different languages, to avoid the creation of novel corpora; translating training documents while keeping the original annotations; translating queries at prediction time and relying on the English system only. An extended experimental evaluation conducted on a large, original dataset indicates that the time-consuming task of re-building a novel annotated corpus for each language can often be avoided with no significant degradation in terms of performance.","llm_keywords":["Multilingualism","Terms of Service","Unfair clause detection","Machine translation","Natural language processing","Legal texts","European Union"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":49},{"id":"b4906e9dd1aa1b8b306c992a3bfd0f67ccae2303a53a9d503f75f5ceee31e597dd356c40c10cbba174b2eaf617a6a2b258a117829e309fdf574e5513c5b4bdc1","file_path":"legal-nlp-survey-20250328-002/team 3/15-RANLP/2023.ranlp-1.116.pdf","title":"Party Extraction from Legal Contract Using Contextualized Span Representations of Parties","llm_title":"Party Extraction from Legal Contract Using Contextualized Span Representations of Parties","authors":["Sanjeepan Sivapiran","Charangan Vasantharajan","Uthayasanker Thayasivam"],"llm_authors":"Sanjeepan Sivapiran, Charangan Vasantharajan, Uthayasanker Thayasivam","author_string":"Sanjeepan Sivapiran ; Charangan Vasantharajan ; Uthayasanker Thayasivam","year":2023,"abstract":"","llm_abstract":"Extracting legal entities from legal documents, particularly legal parties in contract documents, poses a significant challenge for legal assistive software. Many existing party extraction systems tend to generate numerous false positives due to the complex structure of the legal text. In this study, we present a novel and accurate method for extracting parties from legal contract documents by leveraging contextual span representations. To facilitate our approach, we have curated a large-scale dataset comprising 1000 contract documents with party annotations. Our method incorporates several enhancements to the SQuAD 2.0 question-answering system, specifically tailored to handle the intricate nature of the legal text. These enhancements include modifications to the activation function, an increased number of encoder layers, and the addition of normalization and dropout layers stacked on top of the output encoder layer. Baseline experiments reveal that our model, fine-tuned on our dataset, outperforms the current state-of-the-art model. Furthermore, we explore various combinations of the aforementioned techniques to further enhance the accuracy of our method. By employing a hybrid approach that combines 24 encoder layers with normalization and dropout layers, we achieve the best results, exhibiting an exact match score of 0.942 (+6.2% improvement).","llm_keywords":["legal entity extraction","party extraction","contract documents","contextual span representations","SQuAD 2.0","legal assistive software","false positives","encoder layers","machine learning","legal text analysis"],"classifications":["Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"4ad9e7803ba0d5e7a30f5a28b8ac0ef5b248d177a42b9d3c3a798e030cf2ffea623c13d8bcee9c2ee92154144d95652e301cf4c4433877bea30fe0464c1620f3","file_path":"legal-nlp-survey-20250328-002/team 3/15-RANLP/2023.ranlp-1.128(1).pdf","title":"Classification of US Supreme Court Cases Using BERT-Based Techniques","llm_title":"Classification of US Supreme Court Cases using BERT-Based Techniques","authors":["Shubham Vatsal","Adam Meyers","John E. Ortega"],"llm_authors":"Shubham Vatsal, Adam Meyers, John E. Ortega","author_string":"Shubham Vatsal ; Adam Meyers ; John E. Ortega","year":2023,"abstract":"","llm_abstract":"Models based on bidirectional encoder representations from transformers (BERT) produce state of the art (SOTA) results on many natural language processing (NLP) tasks such as named entity recognition (NER), part-of-speech (POS) tagging etc. An interesting phenomenon occurs when classifying long documents such as those from the US supreme court where BERT-based models can be considered difficult to use on a first-pass or out-of-the-box basis. In this paper, we experiment with several BERT-based classification techniques for US supreme court decisions or supreme court database (SCDB) and compare them with the previous SOTA results. We then compare our results specifically with SOTA models for long documents. We compare our results for two classification tasks: (1) a broad classification task with 15 categories and (2) a fine-grained classification task with 279 categories. Our best result produces an accuracy of 80% on the 15 broad categories and 60% on the fine-grained 279 categories which marks an improvement of 8% and 28% respectively from previously reported SOTA results.","llm_keywords":["BERT","US Supreme Court","classification","NLP","legal documents","machine learning","artificial intelligence","long documents","accuracy improvement","transformers"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":9},{"id":"62563c845e8454f46abfd8e6cd78cc578c9256f7de23aff86ce12b946fd33d37158961c79d458b1f0ddb70375a4a676e41a5d67a3253e2290c3593eaeacedb25","file_path":"legal-nlp-survey-20250328-002/team 3/15-RANLP/2023.ranlp-1.29.pdf","title":"BB25HLegalSum: Leveraging BM25 and BERT-Based Clustering for the Summarization of Legal Documents","llm_title":"BB25HLegalSum: Leveraging BM25 and BERT-based clustering for the summarization of legal documents","authors":["Leonardo de Andrade","Karin Becker"],"llm_authors":"Leonardo Bonalume, Karin Becker","author_string":"Leonardo de Andrade ; Karin Becker","year":2023,"abstract":"","llm_abstract":"Legal document summarization aims to provide a clear understanding of the main points and arguments in a legal document, contributing to the efficiency of the judicial system. In this paper, we propose BB25HLegalSum, a method that combines BERT clusters with the BM25 algorithm to summarize legal documents and present them to users with highlighted important information. The process involves selecting unique, relevant sentences from the original document, clustering them to find sentences about a similar subject, combining them to generate a summary according to three strategies, and highlighting them to the user in the original document. We outperformed baseline techniques using the BillSum dataset, a widely used benchmark in legal document summarization. Legal workers positively assessed the highlighted presentation.","llm_keywords":["legal document summarization","BERT","BM25","extractive summarization","information retrieval","highlighting","legal systems","text summarization"],"classifications":[],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":9},{"id":"3392f6e73bc5a6a7695f0a1265a601285e7b313a26f8b5d391c1d9e64df338b757b171f1d81a6d8aa1c044b87dbe92366373ff6e80ba3730e755c2b3ea807ec7","file_path":"legal-nlp-survey-20250328-002/original/Dehio_2022_0590.pdf","title":"Claim Extraction and Law Matching for COVID-19-related Legislation","llm_title":"Claim Extraction and Law Matching for COVID-19-related Legislation","authors":["Niklas Dehio","Malte Ostendorff","Georg Rehm"],"llm_authors":"Niklas Dehio, Malte Ostendorff, Georg Rehm","author_string":"Niklas Dehio ; Malte Ostendorff ; Georg Rehm","year":2022,"abstract":"","llm_abstract":"To cope with the COVID-19 pandemic, many jurisdictions have introduced new or altered existing legislation. Even though these new rules are often communicated to the public in news articles, it remains challenging for laypersons to learn about what is currently allowed or forbidden since news articles typically do not reference underlying laws. We investigate an automated approach to extract legal claims from news articles and to match the claims with their corresponding applicable laws. We examine the feasibility of the two tasks concerning claims about COVID-19-related laws from Berlin, Germany. For both tasks, we create and make publicly available the data sets and report the results of initial experiments. We obtain promising results with Transformer-based models that achieve 46.7 F1 for claim extraction and 91.4 F1 for law matching, albeit with some conceptual limitations. Furthermore, we discuss challenges of current machine learning approaches for legal language processing and their ability for complex legal reasoning tasks.","llm_keywords":["Natural Legal Language Processing","Text Matching","Claim Extraction","Legal Reasoning","COVID-19"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":11},{"id":"cc93af2be6a3aec8eb6d9ca0c66e19b8f1db9d598cd6ab23de1d9bc29e82f6a6066ba1d886dc11d43dfad44768dc3a5b047b6463e0f18763f9beb87b18d5291e","file_path":"legal-nlp-survey-20250328-002/original/Glaser_2018_0170.pdf","title":"","llm_title":"Classifying Semantic Types of Legal Sentences: Portability of Machine Learning Models","authors":["Ingo Glaser","Elena Scepankova","Florian Matthes"],"llm_authors":"Ingo Glaser, Elena Scepankova, Florian Matthes","author_string":"","year":2018,"abstract":"","llm_abstract":"Legal contract analysis is an important research area. The classification of clauses or sentences enables valuable insights such as the extraction of rights and obligations. However, datasets consisting of contracts are quite rare, particularly regarding German language. Therefore this paper experiments the portability of machine learning (ML) models with regard to different document types. We trained different ML classifiers on the tenancy law of the German Civil Code (BGB) to apply the resulting models on a set of rental agreements afterwards. The performance of our models varies on the contract set. Some models perform significantly worse, while certain settings reveal a portability. Additionally, we trained and evaluated the same classifiers on a dataset consisting solely of contracts, to be able to observe a reference performance. We could show that the performance of ML models may depend on the document type used for training, while certain setups result in portable models.","llm_keywords":["legal sentence classification","portability of machine learning models","natural language processing","text mining","legal contract analysis","rights extraction","obligations extraction","German legal domain"],"classifications":["Classification","Resources"],"num_cited_by":33,"num_cited_by_title_only":33,"num_pages":10},{"id":"8a41ecc02ecb4f9335213860e83e130c555260bfa94be38c15a18f5ae48ed5cf348c2449d3c665e9ec5af567c953ff64cf08021dea7abbc5834491b7bf3d738e","file_path":"legal-nlp-survey-20250328-002/original/Kim_2015_0052.pdf","title":"","llm_title":"Applying a Convolutional Neural Network to Legal Question Answering","authors":["Mi-Young Kim","Ying Xu","Randy Goebel"],"llm_authors":"Mi-Young Kim, Ying Xu, and Randy Goebel","author_string":"u6fonter","year":2017,"abstract":"","llm_abstract":"Our legal question answering system combines legal information retrieval and textual entailment, and we describe a legal question answering system that exploits a deep convolutional neural network. We have evaluated our system using the training/test data from the competition on legal information extraction/entailment (COLIEE). The competition focuses on the legal information processing related to answering yes/no questions from Japanese legal bar exams, and it consists of three phases: ad-hoc legal information retrieval, textual entailment, and a learning model-driven combination of the two phases. Phase 1 requires the identification of Japan civil law articles relevant to a legal bar exam query. For that phase, we have implemented a combined TF-IDF and Ranking SVM information retrieval component. Phase 2 requires the system to answer 'Yes' or 'No' to previously unseen queries, by comparing extracted meanings of queries with relevant articles. Our training of an entailment model focuses on features based on word embeddings, syntactic similarities and identification of negation/antonym relations. We augment our textual entailment component with a convolutional neural network with dropout regularization and Rectified Linear Units. To our knowledge, our study is the first to adapt deep learning for textual entailment. Experimental evaluation demonstrates the effectiveness of the convolutional neural network and dropout regularization. The results show that our deep learning-based method outperforms our baseline SVM-based supervised model and K-means clustering.","llm_keywords":["Legal question answering","Textual entailment","Information retrieval","Convolutional neural network","Deep learning","Legal information processing","Semantic similarity"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":27,"num_cited_by_title_only":27,"num_pages":13},{"id":"0dbd690bfa3e1ace77d4d6acf64d64c8f4e24ad7d2d3d492e0ec0a3ca966b5690716306b1fb1aa374f5a8d3892ab4ddd71e1021a6fdad13ea4b0598a42cc66d0","file_path":"legal-nlp-survey-20250328-002/original/Castilho_2018_0159.pdf","title":"","llm_title":"A Legal Perspective on Training Models for Natural Language Processing","authors":["Richard Eckart de Castilho","Giulia Dore","Thomas Margoni","Penny Labropoulou","Iryna Gurevych"],"llm_authors":"Richard Eckart de Castilho, Giulia Dore, Thomas Margoni, Penny Labropoulou, Iryna Gurevych","author_string":"","year":2018,"abstract":"","llm_abstract":"A significant concern in processing natural language data is the often unclear legal status of the input and output data/resources. In this paper, we investigate this problem by discussing a typical activity in Natural Language Processing: the training of a machine learning model from an annotated corpus. We examine which legal rules apply at relevant steps and how they affect the legal status of the results, especially in terms of copyright and copyright-related rights.","llm_keywords":["Copyright","Licensing","Machine Learning","Annotated Corpora","Natural Language Processing","Text Mining","Legal Perspective","Training Models"],"classifications":["Resources"],"num_cited_by":22,"num_cited_by_title_only":22,"num_pages":8},{"id":"93b0126b3f433260b1072416d340d78ea411e6ad0d9803384d9d7a9bdb3518dfc258f612f151cec7d136c2cd061c9ee5362b264d16fffb910236873af82e3caf","file_path":"legal-nlp-survey-20250328-002/original/van-der-Veen_2021_0465.pdf","title":"","llm_title":"Signal Phrase Extraction: Gateway to Information Retrieval Improvement in Law Texts","authors":["Michael Van Der Veen","Natalia Sidorova"],"llm_authors":"Michael VAN DER VEEN and Natalia SIDOROVA","author_string":"","year":2021,"abstract":"","llm_abstract":"NLP-based techniques can support in improving understanding of legal text documents. In this work we present a semi-automatic framework to extract signal phrases from legislative texts for an arbitrary European language. Through a case study using Dutch legislation, we demonstrate that it is feasible to extract these phrases reliably with a small number of supporting domain experts. Finally, we argue how in future works our framework could be utilized with existing methods to be applied to different languages.","llm_keywords":["information retrieval","legislative texts","signal phrase extraction","NLP","Dutch legislation","language-independent techniques","legal text annotation","rule extraction"],"classifications":["Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":4},{"id":"bbd35ee304b7be9405ae3ce14049acc3314a5b79fa32e5d048897a564702d3a921f0b52811537ca979752343c4474b77fb656de61a1a0941be9b3d21b8d194ea","file_path":"legal-nlp-survey-20250328-002/original/Xu_2021_0455.pdf","title":"Ontology and rule-based natural language processing approach for interpreting textual regulations on underground utility infrastructure","llm_title":"Ontology and rule-based natural language processing approach for interpreting textual regulations on underground utility infrastructure","authors":["Xin Xu","Hubo Cai"],"llm_authors":"Xin Xu, Hubo Cai","author_string":"Xin Xu","year":2021,"abstract":"","llm_abstract":"The nation’s massive underground utility infrastructure must comply with a multitude of regulations. The regulatory compliance checking of underground utilities requires an objective and consistent interpretation of the regulations. However, utility regulations contain a variety of domain-specific terms and numerous spatial constraints regarding the location and clearance of underground utilities. It is challenging for the interpreters to understand both the domain and spatial semantics in utility regulations. To address the challenge, this paper adopts an ontology and rule-based Natural Language Processing (NLP) framework to automate the interpretation of utility regulations – the extraction of regulatory information and the subsequent transformation into logic clauses. Two new ontologies have been developed. The urban product ontology (UPO) is domain-specific to model domain concepts and capture domain semantics on top of heterogeneous terminologies in utility regulations. The spatial ontology (SO) consists of two layers of semantics – linguistic spatial expressions and formal spatial relations – for better understanding the spatial language in utility regulations. Pattern-matching rules defined on syntactic features (captured using common NLP techniques) and semantic features (captured using ontologies) were encoded for information extraction. The extracted information elements were then mapped to their semantic correspondences via ontologies and finally transformed into deontic logic (DL) clauses to achieve the semantic and logical formalization. The approach was tested on the spatial configuration-related requirements in utility accommodation policies. Results show it achieves a 98.2% precision and a 94.7% recall in information extraction, a 94.4% precision and a 90.1% recall in semantic formalization, and an 83% accuracy in logical formalization.","llm_keywords":["Ontology","Natural language processing","Pattern-matching rules","Information extraction","Information formalization","Utility regulations"],"classifications":["Information Extraction","Information Retrieval"],"num_cited_by":71,"num_cited_by_title_only":71,"num_pages":16},{"id":"8c6db9a9a032e47500eda53040d398f8b512cae341965bf3a74b4a7106d20808d80581fa760a39fefc9809d08aa43d633cf0e262e475284aec1d28b8638b84dc","file_path":"legal-nlp-survey-20250328-002/original/Moodley_2019_0284.pdf","title":"","llm_title":"Similarity and Relevance of Court Decisions: A Computational Study on CJEU Cases","authors":["Kody Moodley","Pedro V. Hernandez Serrano","Gijs Van Dijck","Michel Dumontier"],"llm_authors":"Kody MOODLEY, Pedro V. HERNANDEZ SERRANO, Gijs VAN DIJCK, Michel DUMONTIER","author_string":"","year":2019,"abstract":"","llm_abstract":"Identification of relevant or similar court decisions is a core activity in legal decision making for case law researchers and practitioners. With an ever increasing body of case law, a manual analysis of court decisions can become practically impossible. As a result, some decisions are inevitably overlooked. Alternatively, network analysis may be applied to detect relevant precedents and landmark cases. Previous research suggests that citation networks of court decisions frequently provide relevant precedents and landmark cases. The advent of text similarity measures (both syntactic and semantic) has meant that potentially relevant cases can be identified without the need to manually read them. However, how close do these measures come to approximating the notion of relevance captured in the citation network? In this contribution, we explore this question by measuring the level of agreement of state-of-the-art text similarity algorithms with the citation behavior in the case citation network. For this paper, we focus on judgements by the Court of Justice of the European Union (CJEU) as published in the EUR-Lex database. Our results show that similarity of the full texts of CJEU court decisions does not closely mirror citation behaviour, there is a substantial overlap. In particular, we found syntactic measures surprisingly outperform semantic ones in approximating the citation network.","llm_keywords":["Text Similarity","Word Embeddings","Network Analysis","CJEU","Court Decisions","Citation Networks","Legal Information Retrieval"],"classifications":[],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":10},{"id":"f07acb08c4af3df1a2a31f3dc0fc1b8a1195793da52ba3dba60bc9fa738a57de1565e74b0695cd0af480167ae0e3101aad2d0709a7a7f9d3120305c7bb401dbd","file_path":"legal-nlp-survey-20250328-002/original/Delfino_2017_0147.pdf","title":"","llm_title":"Passing the Brazilian OAB Exam: Data","authors":["Pedro Delfino","Bruno Cuconato","Edward Hermann Haeusler","Alexandre Rademaker"],"llm_authors":"Pedro DELFINO, Bruno CUCONATO, Edward Hermann HAEUSLER, Alexandre RADEMAKER","author_string":"","year":2017,"abstract":"","llm_abstract":"In Brazil, all legal professionals must demonstrate their knowledge of the law and its application by passing the OAB exams, the national Bar exams. This article describes the construction of a new data set and some preliminary experiments on it, treating the problem of finding the justification for the answers to questions. The results provide a baseline performance measure against which to evaluate future improvements. We discuss the reasons to the poor performance and propose next steps.","llm_keywords":["OAB","bar exam","question-answering","justification","logic","legal knowledge","data set","experiments","law","Brazil"],"classifications":["Classification","Resources"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":6},{"id":"3758558c469be67a7a0e0d3022132a02636928d1f0f9c925e88881f19b1f9269e17041becb2fbcfe298f317fb6b6d72354c0d7b8e90f942558b9f10793f254f8","file_path":"legal-nlp-survey-20250328-002/original/Yao_2022_0529.pdf","title":"","llm_title":"LEVEN: A Large-Scale Chinese Legal Event Detection Dataset","authors":["Feng Yao","Chaojun Xiao","Xiaozhi Wang","Zhiyuan Liu","Lei Hou","Cunchao Tu","Juanzi Li","Yun Liu","Weixing Shen","Maosong Sun"],"llm_authors":"Feng Yao, Chaojun Xiao, Xiaozhi Wang, Zhiyuan Liu, Lei Hou, Cunchao Tu, Juanzi Li, Yun Liu, Weixing Shen, Maosong Sun","author_string":"","year":2022,"abstract":"","llm_abstract":"Recognizing facts is the most fundamental step in making judgments, hence detecting events in the legal documents is important to legal case analysis tasks. However, existing Legal Event Detection (LED) datasets only concern incomprehensive event types and have limited annotated data, which restricts the development of LED methods and their downstream applications. To alleviate these issues, we present LEVEN, a large-scale Chinese Legal Event Detection dataset, with 8,116 legal documents and 150,977 human-annotated event mentions in 108 event types. Not only charge-related events, LEVEN also covers general events, which are critical for legal case understanding but neglected in existing LED datasets. To our knowledge, LEVEN is the largest LED dataset and has dozens of times the data scale of others, which shall significantly promote the training and evaluation of LED methods. The results of extensive experiments indicate that LED is challenging and needs further effort. Moreover, we simply utilize legal events as side information to promote downstream applications. The method achieves improvements of average 2.2 points precision in low-resource judgment prediction, and 1.5 points mean average precision in unsupervised case retrieval, which suggests the fundamentality of LED. The source code and dataset can be obtained from https://github.com/thunlp/LEVEN.","llm_keywords":["Legal Event Detection","Chinese Legal Dataset","Machine Learning","Language Processing","Judgement Prediction","Case Retrieval"],"classifications":["Text Generation","Pre-Processing","Information Extraction","Classification","Machine Summarization","Resources","Information Retrieval"],"num_cited_by":73,"num_cited_by_title_only":73,"num_pages":19},{"id":"88e29527535b2af8ec930dcc5e3de7dd6b7e19a13f820403b7efe3b22daee15a4e4f175f58a7c147f69522c73528437c7363dcb9f98651a895ae8f639f8e4337","file_path":"legal-nlp-survey-20250328-002/original/Valle_2022_0557.pdf","title":"RegBR: A novel Brazilian government framework to classify and analyze industry-specific regulations","llm_title":"RegBR: A novel Brazilian government framework to classify and analyze industry-specific regulations","authors":["Letícia Moreira Valle","Stefano Giacomazzi Dantas","Daniel Guerreiro e Silva","Ugo Silva Dias","Leonardo Monteiro Monasterio"],"llm_authors":"Letícia Moreira Valle, Stefano Giacomazzi Dantas, Daniel Guerreiro e Silva, Ugo Silva Dias, Leonardo Monteiro Monasterio","author_string":"Letícia Moreira Valle, Stefano Giacomazzi Dantas, Daniel Guerreiro e Silva, Ugo Silva Dias, Leonardo Monteiro Monasterio","year":2022,"abstract":"","llm_abstract":"Government transparency and openness are key factors to bring forth the modernization of the state. The combination of transparency and digital information has given rise to the concept of Open Government, that increases citizen understanding and monitoring of government actions, which in turn improves the quality of public services and of the government decision making process. With the goal of improving legislative transparency and the understanding of the Brazilian regulatory process and its characteristics, this paper introduces RegBR, the first national framework to centralize, classify and analyze regulations from the Brazilian government. A centralized database of Brazilian federal legislation built from automated ETL routines and processed with data mining and machine learning techniques was created. Our framework evaluates different NLP models in a text classification task on our novel Portuguese legal corpus and performs regulatory analysis based on metrics that concern linguistic complexity, restrictiveness, law interest, and industry-specific citation relevance. Our results were examined over time and validated by correlating them with known episodes of regulatory changes in Brazilian history, such as the implementation of new economic plans or the emergence of an energy crisis. Methods and metrics proposed by this framework can be used by policy makers to measure their own work and serve as inputs for future studies that could analyze government changes and their relationship with federal regulations.","llm_keywords":["Brazilian government","regulatory framework","legislative transparency","NLP","data mining","machine learning","Open Government","regulatory analysis","federal regulations","ETL routines"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":25},{"id":"220d2baac323d727e8e947e532f04b427ea689c24b2d47e491bffed71fbc955cf28d111bdbfbce40d6a388fc5d17845ddaff5b35f3a836a4799d235a206ad3bb","file_path":"legal-nlp-survey-20250328-002/original/Cemri_2022_0588.pdf","title":"","llm_title":"Unsupervised Simplification of Legal Texts","authors":["Mert Cemri","Tolga Çukur","Aykut Koç"],"llm_authors":"Mert Cemri, Tolga Çukur*, Senior Member, IEEE, and Aykut Koç*, Senior Member, IEEE","author_string":"","year":2022,"abstract":"","llm_abstract":"The processing of legal texts has been developing as an emerging field in natural language processing (NLP). Legal texts contain unique jargon and complex linguistic attributes in vocabulary, semantics, syntax, and morphology. Therefore, the development of text simplification (TS) methods specific to the legal domain is of paramount importance for facilitating comprehension of legal text by ordinary people and providing inputs to high-level models for mainstream legal NLP applications. While a recent study proposed a rule-based TS method for legal text, learning-based TS in the legal domain has not been considered previously. Here we introduce an unsupervised simplification method for legal texts (USLT). USLT performs domain-specific TS by replacing complex words and splitting long sentences. To this end, USLT detects complex words in a sentence, generates candidates via a masked-transformer model, and selects a candidate for substitution based on a rank score. Afterward, USLT recursively decomposes long sentences into a hierarchy of shorter core and context sentences while preserving semantic meaning. We demonstrate that USLT outperforms state-of-the-art domain-general TS methods in text simplicity while keeping the semantics intact.","llm_keywords":["Text Simplification","Computational Law","Legal Text Processing","BERT","Legalese"],"classifications":["Text Generation","Pre-Processing"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":11},{"id":"152a2c92dc22681f2d3aafebfaf4544f18b7e1c97a45c90d7f220982f10daf5c5a94298cab43f58b30ae8bc7d34934a7bcf59a4d81c2cc7f7de900fc284b9afd","file_path":"legal-nlp-survey-20250328-002/original/Rossi_2019_0256.pdf","title":"Legal Information Retrieval with Generalized Language Models","llm_title":"Legal Information Retrieval with Generalized Language Models: ILPS Participation to COLIEE 2019","authors":["Julien Rossi","Evangelos Kanoulas"],"llm_authors":"Julien Rossi, Evangelos Kanoulas","author_string":"Julien Rossi and Evangelos Kanoulas","year":2019,"abstract":"","llm_abstract":"This paper describes a new method to identify text pairwise relevance, in the context of the Case Law retrieval task from COLIEE 2019. This method combines text summarizing and a generalized language model in order to assess pairwise relevance. With still lots of possibilities for improvement and optimization, it achieves a competitive performance in the setting of the Retrieval for the Noticed Cases.","llm_keywords":["legal text","case retrieval","document representation","ranking","neural language models","BERT"],"classifications":["Information Retrieval","Machine Summarization"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":5},{"id":"409fa2b6412cf7bc6e16129da53fcd6e7a676794a31c22abdf9604fcc8c5dbedd6a8f3e651c9097db0b3ff57040a94c43468c88e8306c4f0d619e4d0dfe41b4f","file_path":"legal-nlp-survey-20250328-002/original/Sanchez_2020_0375.pdf","title":"Using Unlabeled Data for US Supreme Court Case Classification","llm_title":"Using Unlabeled Data for US Supreme Court Case Classification","authors":["George Sanchez"],"llm_authors":"George Sanchez","author_string":"","year":2021,"abstract":"","llm_abstract":"The Supreme Court Database provided by Washington University (in St. Louis) School of Law is an essential legal research tool. The Supreme Court Database is organized and categorized to Issue Areas to make it easy for legal researchers to find on-point cases for an area of law. This paper used a semi-supervised learning approach to automatically categorize the Supreme Court’s opinions to Issue Areas. An inductive method of clustering then labeling approach was used by employing a non-metric space of a fast Hierarchical Navigable Small World graph index containing USE (Universal Sentence Encoder) embeddings. After obtaining the labels from the semi-supervised approach, we evaluate several classification approaches to use with the data achieving the weighted average F1-Scores: SVM with Max Norm Features 0.75, RNN 0.78, and BERT 0.68","llm_keywords":["semi-supervised learning","Supreme Court Database","legal research","issue areas","clustering","classification","Universal Sentence Encoder","Hierarchical Navigable Small World Graph"],"classifications":["Classification","Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"acf80de7c98082cbef182ca5a790528c968c87b2b19617393de2749ed70b5a8505eaf6024e814a5ad805b43006c21f95e41240012964f3f455c417e9f14e4375","file_path":"legal-nlp-survey-20250328-002/original/Alberts_2020_0310.pdf","title":"","llm_title":"COLIEE 2020: Legal Information Retrieval & Entailment with Legal Embeddings and Boosting?","authors":["Houda Alberts","Akin Ipek","Roderick Lucas","Phillip Wozny"],"llm_authors":"Houda Alberts, Akin Ipek, Roderick Lucas, and Phillip Wozny","author_string":"","year":2020,"abstract":"","llm_abstract":"In this paper we investigate three different methods for several legal document retrieval and entailment tasks; namely, new low complexity pre-trained embeddings, specifically trained on documents in the legal domain, transformer models and boosting algorithms. Task 1, a case law retrieval task, utilized a pairwise CatBoost resulting in an F1 score of .04. Task 2, a case law entailment task, utilized a combination of BM25+, embeddings and natural language inference (NLI) features winning third place with an F1 of 0.6180. Task 3, a statutory information retrieval task, utilized the aforementioned pre-trained embeddings in combination with TF-IDF features resulting in an F2 score of 0.4546. Lastly, task 4, a statutory entailment task, utilized BERT embeddings with XGBoost and achieved an accuracy of 0.5357. Notably, our Task 2 submission was the third best in the competition. Our findings illustrate that using legal embeddings and auxiliary linguistic features, such as NLI, show the most promise for future improvements.","llm_keywords":["Legal Information Retrieval","Textual Entailment","Natural Language Inference","Legal Embeddings","BERT","Boosting"],"classifications":["Information Retrieval","Classification","Pre-Processing"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":15},{"id":"341dfcbc5f29b946ee98a984d1e6c98d20a2dd9f67e5a9020f7b637258441d1701d277d352d23b3273e2e395a9a91ffbc6609b9a1a04e12249d3f50038cdf039","file_path":"legal-nlp-survey-20250328-002/original/Mouloudi_2021_0377.pdf","title":"","llm_title":"A Bottom-Up Approach for Moroccan Legal Ontology Learning from Arabic Texts","authors":["Kaoutar Belhoucine","Mohammed Mourchid","Samir Mbarki","Abdelaaziz Mouloudi"],"llm_authors":"Kaoutar Belhoucine, Mohammed Mourchid, Samir Mbarki, Abdelaaziz Mouloudi","author_string":"","year":2021,"abstract":"","llm_abstract":"Ontologies constitute an exciting model for representing a domain of interest, since they enable information-sharing and reuse. Existing inference machines can also use them to reason about various contexts. However, ontology construction is a time-consuming and challenging task. The ontology learning field answers this problem by providing automatic or semi-automatic support to extract knowledge from various sources, such as databases and structured and unstructured documents. This paper reviews the ontology learning process from unstructured text and proposes a bottom-up approach to building legal domain-specific ontology from Arabic texts. In this work, the learning process is based on Natural Language Processing (NLP) techniques and includes three main tasks: corpus study, term acquisition, and conceptualization. Corpus study enriches the original corpus with valuable linguistic information. Term acquisition selects tagged lemmas sequences as potential term candidates, and conceptualization drives concepts and their relationships from the extracted terms. We used the NooJ platform to implement the required linguistic resources for each task. Further, we developed a Java module to enrich the ontology vocabulary from the Arabic WordNet (AWN) project. The obtained results were essential but incomplete. The legal expert revised them manually, and then they were used to refine and expand a domain ontology for a Moroccan Legal Information Retrieval System (LIRS).","llm_keywords":["Ontology learning","Taxonomies definition","Arabic WordNet","NooJ","Legal field","Arabic text"],"classifications":["Information Extraction","Resources","Information Retrieval"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":14},{"id":"8f173cf1d1bf9794f0e4fe470e12082e05c2dd0e4119cee3d9469c9f1a9b52dfbae7fe0bebcbfc5c573c48bd179328cd51bc8c33df60dbbd5e05f505a8e246b8","file_path":"legal-nlp-survey-20250328-002/original/Eidelman_2019_0221.pdf","title":"156_Eidelman.pdf","llm_title":"Argument Identification in Public Comments from eRulemaking","authors":["Vlad Eidelman","Brian Grom"],"llm_authors":"Vlad Eidelman, Brian Grom","author_string":"","year":2019,"abstract":"","llm_abstract":"Administrative agencies in the United States receive millions of comments each year concerning proposed agency actions during the eRulemaking process. These comments represent a diversity of arguments in support and opposition of the proposals. While agencies are required to identify and respond to substantive comments, they have struggled to keep pace with the volume of information. In this work we address the tasks of identifying argumentative text, classifying the type of argument claims employed, and determining the stance of the comment. First, we propose a taxonomy of argument claims based on an analysis of thousands of rules and millions of comments. Second, we collect and semi-automatically bootstrap annotations to create a dataset of millions of sentences with argument claim type annotation at the sentence level. Third, we build a system for automatically determining argumentative spans and claim type using our proposed taxonomy in a hierarchical classification model.","llm_keywords":["eRulemaking","argument mining","stance detection","public comments","argument taxonomy","natural language processing","machine learning","legal informatics"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":5},{"id":"7565777e8f89fd5d7bada98f2b1a43951c8850857d4dfefb3118d64cbf8e6786576186118dd60f8963443d25de437a1ef2b5b45ae57b7bc6ae385d65f332b21c","file_path":"legal-nlp-survey-20250328-002/original/Aires_2017_0144.pdf","title":"Norm conflict identification in contracts","llm_title":"Norm conflict identification in contracts","authors":["João Paulo Aires","Daniele Pinheiro","Vera Strube de Lima","Felipe Meneguzzi"],"llm_authors":"Joa˜o Paulo Aires, Daniele Pinheiro, Vera Strube de Lima, Felipe Meneguzzi","author_string":"João Paulo Aires","year":2017,"abstract":"","llm_abstract":"The exchange of goods and services between individuals is often formalised by a contract in which the parties establish norms to define what is expected of each one. Norms use deontic statements of obligation, prohibition, and permission, which may be in conflict. The task of manually detecting norm conflicts can be time–consuming and error-prone since contracts can be vast and complex. To automate such tasks, we develop an approach to identify potential conflicts between norms. We show the effectiveness of our approach and its individual components empirically using two publicly available corpora, and contribute with a new annotated test corpus for norm conflict identification.","llm_keywords":["Norms","Natural language processing","Normative conflicts","Deontic logic"],"classifications":["Pre-Processing","Information Extraction","Resources","Classification"],"num_cited_by":32,"num_cited_by_title_only":32,"num_pages":32},{"id":"517075421204d42e82381ec44eb860b84c93a3a58fdfc2beee3c5dafdd1c00b0d17573df3f0a88c02678d5f1fbcc54c26b93b73331dc943edc9edc415debc285","file_path":"legal-nlp-survey-20250328-002/original/Kanapala_2019_0288.pdf","title":"Text summarization from legal documents: a survey","llm_title":"Text summarization from legal documents: a survey","authors":["Ambedkar Kanapala","Sukomal Pal","Rajendra Pamula"],"llm_authors":"Ambedkar Kanapala, Sukomal Pal, Rajendra Pamula","author_string":"Ambedkar Kanapala","year":2017,"abstract":"","llm_abstract":"Enormous amount of online information, available in legal domain, has made legal text processing an important area of research. In this paper, we attempt to survey different text summarization techniques that have taken place in the recent past. We put special emphasis on the issue of legal text summarization, as it is one of the most important areas in legal domain. We start with general introduction to text summarization, briefly touch the recent advances in single and multi-document summarization, and then delve into extraction based legal text summarization. We discuss different datasets and metrics used in summarization and compare performances of different approaches, first in general and then focused to legal text. we also mention highlights of different summarization techniques. We briefly cover a few software tools used in legal text summarization. We finally conclude with some future research directions.","llm_keywords":["Text summarization","Legal documents","Single-document summarization","Multi-document summarization","Legal domain"],"classifications":["Machine Summarization"],"num_cited_by":233,"num_cited_by_title_only":233,"num_pages":32},{"id":"8fb09d8b8a4051631cf132ab692c214cc3623ccbb16a1932105e8fa1610a2701cea4580af9a37a236ad8217d93d24725ee50aa13ca02b712bc2994bf4b210ed8","file_path":"legal-nlp-survey-20250328-002/original/Hu_2018_0180.pdf","title":"Few-Shot Charge Prediction with Discriminative Legal Attributes","llm_title":"Few-Shot Charge Prediction with Discriminative Legal Attributes","authors":["Zikun Hu","Xiang Li","Cunchao Tu","Zhiyuan Liu","Maosong Sun"],"llm_authors":"Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, Maosong Sun","author_string":"Zikun Hu ; Xiang Li ; Cunchao Tu ; Zhiyuan Liu ; Maosong Sun","year":2018,"abstract":"","llm_abstract":"Automatic charge prediction aims to predict the final charges according to the fact descriptions in criminal cases and plays a crucial role in legal assistant systems. Existing works on charge prediction perform adequately on those high-frequency charges but are not yet capable of predicting few-shot charges with limited cases. Moreover, these exist many confusing charge pairs, whose fact descriptions are fairly similar to each other. To address these issues, we introduce several discriminative attributes of charges as the internal mapping between fact descriptions and charges. These attributes provide additional information for few-shot charges, as well as effective signals for distinguishing confusing charges. More specifically, we propose an attribute-attentive charge prediction model to infer the attributes and charges simultaneously. Experimental results on real-work datasets demonstrate that our proposed model achieves significant and consistent improvements than other state-of-the-art baselines. Specifically, our model outperforms other baselines by more than 50% in the few-shot scenario. Our codes and datasets can be obtained from https://github.com/thunlp/attribute_charge.","llm_keywords":["automatic charge prediction","legal assistant systems","few-shot learning","discriminative attributes","attribute-attentive model","neural networks","text classification","legal intelligence","confusing charge pairs"],"classifications":["Classification"],"num_cited_by":295,"num_cited_by_title_only":295,"num_pages":12},{"id":"e70d8133f8c1f546eb1dc15708ea83aa9bba5e669e5f5491f1a701a26ad4798b2bee3dfb260398c2b9d537689241fc58e90954313d08a14d2176899399b17c80","file_path":"legal-nlp-survey-20250328-002/original/Yamada_2019_0273.pdf","title":"","llm_title":"Neural Network Based Rhetorical Status","authors":["Hiroaki Yamada","Simone Teufel","Takenobu Tokunaga"],"llm_authors":"Hiroaki YAMADA, Simone TEUFEL, Takenobu TOKUNAGA","author_string":"","year":2019,"abstract":"","llm_abstract":"We address the legal text understanding task, and in particular we treat Japanese judgment documents in civil law. Rhetorical status classification (RSC) is the task of classifying sentences according to the rhetorical functions they fulfil; it is an important preprocessing step for our overall goal of legal summarisation. We present several improvements over our previous RSC classifier, which was based on CRF. The first is a BiLSTM-CRF based model which improves performance significantly over previous baselines. The BiLSTM-CRF architecture is able to additionally take the context in terms of neighbouring sentences into account. The second improvement is the inclusion of section heading information, which resulted in the overall best classifier. Explicit structure in the text, such as headings, is an information source which is likely to be important to legal professionals during the reading phase; this makes the automatic exploitation of such information attractive. We also considerably extended the size of our annotated corpus of judgment documents.","llm_keywords":["Japanese NLP","Legal NLP","Argument understanding","Machine learning","Sentence classification","Natural language processing","Neural network","Deep learning","Rhetorical status classification"],"classifications":["Classification"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":10},{"id":"f6e3869384f461a5faeae209523c3d23951ea687d7a21a664d4a01b8e79bea4f6ba1f427156ad63e35a790f5932806cd12b29647a8b52c04b15d0a61190af183","file_path":"legal-nlp-survey-20250328-002/original/Miyazaki_2022_0568.pdf","title":"Cross-domain Analysis on Japanese Legal Pretrained Language Models","llm_title":"Cross-domain Analysis on Japanese Legal Pretrained Language Models","authors":["Keisuke Miyazaki","Hiroaki Yamada","Takenobu Tokunaga"],"llm_authors":"Keisuke Miyazaki, Hiroaki Yamada, Takenobu Tokunaga","author_string":"Keisuke Miyazaki ; Hiroaki Yamada ; Takenobu Tokunaga","year":2022,"abstract":"","llm_abstract":"This paper investigates the pretrained language model (PLM) specialised in the Japanese legal domain. We create PLMs using different pretraining strategies and investigate their performance across multiple domains. Our findings are (i) the PLM built with general domain data can be improved by further pretraining with domain-specific data, (ii) domain-specific PLMs can learn domain-specific and general word meanings simultaneously and can distinguish them, (iii) domain-specific PLMs work better on its target domain; still, the PLMs retain the information learnt in the original PLM even after being further pretrained with domain-specific data, (iv) the PLMs sequentially pretrained with corpora of different domains show high performance for the later learnt domains.","llm_keywords":["pretrained language models","Japanese legal domain","domain-specific PLMs","cross-domain performance","domain adaptation"],"classifications":["Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":8},{"id":"2339ea041c80bcd3fcbdb960832b9c082671c0e75cc482b83f03391f1e97c455327cf912695a604e026beb0e6f872120847f434f795bb6f87cd898c1de6071bb","file_path":"legal-nlp-survey-20250328-002/original/Westermann_2020_0359.pdf","title":"","llm_title":"Sentence Embeddings and High-Speed Similarity Search for Fast Computer Assisted Annotation of Legal Documents","authors":["Hannes Westermann","Jaromír Savelka","Vern R. Walker","Kevin D. Ashley","Karim Benyekhlef"],"llm_authors":"Hannes Westermann, Jaromír Savelka, Vern R. Walker, Kevin D. Ashley, Karim Benyekhlef","author_string":"","year":2020,"abstract":"","llm_abstract":"Human-performed annotation of sentences in legal documents is an important prerequisite to many machine learning based systems supporting legal tasks. Typically, the annotation is done sequentially, sentence by sentence, which is often time consuming and, hence, expensive. In this paper, we introduce a proof-of-concept system for annotating sentences “laterally.” The approach is based on the observation that sentences that are similar in meaning often have the same label in terms of a particular type system. We use this observation in allowing annotators to quickly view and annotate sentences that are semantically similar to a given sentence, across an entire corpus of documents. Here, we present the interface of the system and empirically evaluate the approach. The experiments show that lateral annotation has the potential to make the annotation process quicker and more consistent.","llm_keywords":["Annotation","Language Models","Sentence Embeddings","Approximate Nearest Neighbour","Interactive Machine Learning"],"classifications":["Pre-Processing","Resources"],"num_cited_by":32,"num_cited_by_title_only":32,"num_pages":10},{"id":"cd586ddaefa09699de1ead9fba0700cbe93d0a77265c0476d8b86a017c814e44b8bd2c018f66c3b41612f9f5806aa65326f71c2bc143451ddcd501d2fb7bdabf","file_path":"legal-nlp-survey-20250328-002/original/Joshi_2018_0194.pdf","title":"Location Identification, Extraction and Disambiguation using Machine Learning in Legal Contracts","llm_title":"Location Identification, Extraction and Disambiguation using Machine Learning in Legal Contracts","authors":["Sandeep Joshi","Parth Shah","Amaresh Kumar Pandey"],"llm_authors":"Sandeep Joshi, Parth Shah, Amaresh Kumar Pandey","author_string":"","year":2019,"abstract":"","llm_abstract":"Identifying the context of location (disambiguation) in legal contracts plays an import role in multiple use cases for lawyers (e.g. due diligence and M&A). Identifying the locations of the parties involved in the contract or agreement and also identifying the Governing law and Jurisdiction from the contract is an interesting problem in the legal space. AI has changed and changing many industries for a number of years (e.g. finance, e-comm, medical, education etc.) but it is relatively new to the legal domain. In this paper, we present a novel approach through which, a system can automatically determine the location of the parties involved and the law under which the contract is governed, as well as the jurisdiction under which contract belongs. The key concept of our approach is to look this problem as a classification task, followed by the extraction and then disambiguation of entities. In this view, we have examined each location context and determined whether it is a Party Location or Governing Law & Jurisdiction. A similar approach can be extended for identifying other key pieces of information from the legal contracts (e.g. change of control clauses, consideration amount, contract dates etc.). We have achieved relatively good accuracy on the limited training and test set described in section 4.","llm_keywords":["classification","location type identification","TF/IDF","legal contracts","NLP","Governing law","Jurisdiction","Machine learning","Entity extraction"],"classifications":["Classification","Information Extraction"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":5},{"id":"303db066e7aaac5291f029bd8ad068a445e5114dd05918228ca30d7f91b3d875ca53a0aba9ebf011369429567dfafffb37c4b7b0b995909bda048ba13750b5e9","file_path":"legal-nlp-survey-20250328-002/original/Masala_2021_0433.pdf","title":"jurBERT: A Romanian BERT Model for Legal Judgement Prediction","llm_title":"jurBERT: A Romanian BERT Model for Legal Judgement Prediction","authors":["Mihai Masala","Radu Cristian Alexandru Iacob","Ana Sabina Uban","Marina Cidota","Horia Velicu","Traian Rebedea","Marius Popescu"],"llm_authors":"Mihai Masala, Radu Iacob, Ana Sabina Uban, Marina Cidota, Horia Velicu, Traian Rebedea, Marius Popescu","author_string":"Mihai Masala ; Radu Cristian Alexandru Iacob ; Ana Sabina Uban ; Marina Cidota ; Horia Velicu ; Traian Rebedea ; Marius Popescu","year":2021,"abstract":"","llm_abstract":"Transformer-based models have become the de facto standard in the field of Natural Language Processing (NLP). By leveraging large unlabeled text corpora, they enable efficient transfer learning leading to state-of-the-art results on numerous NLP tasks. Nevertheless, for low resource languages and highly specialized tasks, transformer models tend to lag behind more classical approaches (e.g. SVM, LSTM) due to the lack of aforementioned corpora. In this paper we focus on the legal domain and we introduce a Romanian BERT model pre-trained on a large specialized corpus. Our model outperforms several strong baselines for legal judgement prediction on two different corpora consisting of cases from trials involving banks in Romania.","llm_keywords":["BERT","transformer models","legal judgement prediction","Romanian language","NLP","pre-trained language models","transfer learning"],"classifications":["Classification","Resources"],"num_cited_by":40,"num_cited_by_title_only":40,"num_pages":9},{"id":"3f86c8b3c2f533b3cd114b3b872a06bee8833ee43f99c82b8b51afcc75cf689e6a1d44acff14e172ea34416d1e8c7c657573111f1f28f48201b7fb061e4e6ccb","file_path":"legal-nlp-survey-20250328-002/original/Gupta_2022_0502.pdf","title":"Creation and Analysis of an International Corpus of Privacy Laws","llm_title":"Creation and Analysis of an International Corpus of Privacy Laws","authors":["Sonu Gupta","Ellen Poplavska","Nora O'Toole","Siddhant Arora","Thomas Norton","Norman Sadeh","Shomir Wilson"],"llm_authors":"Sonu Gupta, Ellen Poplavska, Nora O’Toole, Siddhant Arora, Thomas Norton, Norman Sadeh, Shomir Wilson","author_string":"","year":2022,"abstract":"","llm_abstract":"The landscape of privacy laws and regulations around the world is complex and ever-changing. National and super-national laws, agreements, decrees, and other government-issued rules form a patchwork that companies must follow to operate internationally. To examine the status and evolution of this patchwork, we introduce the Government Privacy Instructions Corpus, or GPI Corpus, of 1,043 privacy laws, regulations, and guidelines, covering 182 jurisdictions. This corpus enables a large-scale quantitative and qualitative examination of legal foci on privacy. We examine the temporal distribution of when GPIs were created and illustrate the dramatic increase in privacy legislation over the past 50 years, although a finer-grained examination reveals that the rate of increase varies depending on the personal data types that GPIs address. Our exploration also demonstrates that most privacy laws respectively address relatively few personal data types, showing that comprehensive privacy legislation remains rare. Additionally, topic modeling results show the prevalence of common themes in GPIs, such as finance, healthcare, and telecommunications. Finally, we release the corpus to the research community to promote further study.","llm_keywords":["corpus","text analysis","privacy","law","legal text","privacy legislation","natural language processing","GPI Corpus","topic modeling","government privacy instructions"],"classifications":["Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":14},{"id":"9519dcf7d477bae9fea2c19760f2914bcc66cef35d3474df562c03ab61a48a9a9c4dbf3ebf3af9ad4725b2118da516a7317aba7779c42eee49f186649268e8e8","file_path":"legal-nlp-survey-20250328-002/original/Zhong_2022_0576.pdf","title":"","llm_title":"Computing and Exploiting Document Structure to Improve Unsupervised Extractive Summarization of Legal Case Decisions","authors":["Yang Zhong","Diane Litman"],"llm_authors":"Yang Zhong, Diane Litman","author_string":"","year":2022,"abstract":"","llm_abstract":"Though many algorithms can be used to automatically summarize legal case decisions, most fail to incorporate domain knowledge about how important sentences in a legal decision relate to a representation of its document structure. For example, analysis of a legal case summarization dataset demonstrates that sentences serving different types of argumentative roles in the decision appear in different sections of the document. In this work, we propose an unsupervised graph-based ranking model that uses a reweighting algorithm to exploit properties of the document structure of legal case decisions. We also explore the impact of using different methods to compute the document structure. Results on the Canadian Legal Case Law dataset show that our proposed method outperforms several strong baselines.","llm_keywords":["Unsupervised Extractive Summarization","Legal Case Decisions","Document Structure","Graph-based Ranking Model","Canadian Legal Case Law Dataset"],"classifications":["Machine Summarization","Information Retrieval"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":16},{"id":"0e62fa24dc2323b766c2ef00c1a1644f9a059300e67058f51f78cf14f6ea4c71fa03b081af13bf939bb4cc3c2b851276f321b8048688055890dbfd09cdfc17f7","file_path":"legal-nlp-survey-20250328-002/original/An-Vo_2017_0124.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"Experimenting Word Embeddings in Assisting Legal Review","authors":["Ngoc Phuoc An Vo","Caroline Privault","Fabien Guillot"],"llm_authors":"Ngoc Phuoc An Vo, Caroline Privault, Fabien Guillot","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"As advanced technologies, such as data mining become part of the everyday workflow of document reviews in litigations, keyword-search still appears to serve as a cornerstone approach in responsive or privilege review. Keywords are conceptually easy to understand and help culling documents at the early stages of the review. But developing proper keywords to minimize the risk of under/over-inclusiveness can lead to complex strategies. To cope with the burden of designing search terms, we propose to use word embedding techniques in a dynamic manner. This paper describes a system leveraging semantic models in a smart review environment in order to support knowledge workers in eDiscovery.","llm_keywords":["Legal Review","eDiscovery","Machine Learning","Semantic Relatedness","Word Embeddings","Document Filtering","Predictive Coding","Keyword Search"],"classifications":["Information Retrieval","Resources"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":10},{"id":"6169f1a3e22ed5e4175a4805688878b4d8900472d5a6163ef02c1421460dd285704e418684192c7510eea0c59ed72c18df5d330c42de79f1833212ddfacec7bf","file_path":"legal-nlp-survey-20250328-002/original/Habernal_2022_0531.pdf","title":"","llm_title":"Mining Legal Arguments in Court Decisions","authors":["Ivan Habernal","Daniel Faber","Nicola Recchia","Sebastian Bretthauer","Iryna Gurevych","Indra Spiecker genannt Döhmann","Christoph Burchard"],"llm_authors":"Ivan Habernal, Daniel Faber, Nicola Recchia, Sebastian Bretthauer, Iryna Gurevych, Indra Spiecker genannt Döhmann, Christoph Burchard","author_string":"","year":2022,"abstract":"","llm_abstract":"Identifying, classifying, and analyzing arguments in legal discourse has been a prominent area of research since the inception of the argument mining field. However, there has been a major discrepancy between the way natural language processing (NLP) researchers model and annotate arguments in court decisions and the way legal experts understand and analyze legal argumentation. While computational approaches typically simplify arguments into generic premises and claims, arguments in legal research usually exhibit a rich typology that is important for gaining insights into the particular case and applications of law in general. We address this problem and make several substantial contributions to move the field forward. First, we design a new annotation scheme for legal arguments in proceedings of the European Court of Human Rights (ECHR) that is deeply rooted in the theory and practice of legal argumentation research. Second, we compile and annotate a large corpus of 373 court decisions (2.3M tokens and 15k annotated argument spans). Finally, we train an argument mining model that outperforms state-of-the-art models in the legal NLP domain and provide a thorough expert-based evaluation. All datasets and source codes are available under open licenses.","llm_keywords":["argument mining","legal arguments","ECHR","transformers","NLP","annotation scheme","legal NLP"],"classifications":["Classification","Resources"],"num_cited_by":57,"num_cited_by_title_only":57,"num_pages":37},{"id":"eaac2bfcb263ca732bebfb93454c52245551f415271eb199fe98078eba11e215fa734fd91146a9dc8c6f1e2dc4ba1a568766335416effdd5542a0dc8de8bcdb0","file_path":"legal-nlp-survey-20250328-002/original/Auriemma_2022_0567.pdf","title":"Evaluating Pre-Trained Transformers on Italian Administrative Texts","llm_title":"Evaluating Pre-Trained Transformers on Italian Administrative Texts","authors":["Serena Auriemma","Martina Miliani","Alessandro Bondielli","Lucia C. Passaro","Alessandro Lenci"],"llm_authors":"Serena Auriemma, Martina Miliani, Alessandro Bondielli, Lucia C. Passaro, Alessandro Lenci","author_string":"","year":2022,"abstract":"","llm_abstract":"In recent years, Transformer-based models have been widely used in NLP for various downstream tasks and in different domains. However, a language model explicitly built for the Italian administrative language is still lacking. Therefore, in this paper, we decided to compare the performance of five different Transformer models, pre-trained on general purpose texts, on two main tasks in the Italian administrative domain: Name Entity Recognition and multi-label document classification on Public Administration (PA) documents. We evaluate the performance of each model on both tasks to identify the best model in this particular domain. We also discuss the effect of model size and pre-training data on the performances on domain data. Our evaluation identifies UmBERTo as the best-performing model, with an accuracy of 0.71, an F1 score of 0.89 for multi-label document classification, and an F1 score of 0.87 for NER-PA.","llm_keywords":["Natural Language Processing","Neural Language Models","Domain Language","Public Administration","Transformer Models","Name Entity Recognition","Document Classification"],"classifications":["Classification","Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":16},{"id":"57f06e8ab4275aa64cda48ca18befb31b518bdd745cbf7c774f7f4a6c3172e49f0e99e029b929118040181f402c6cf0374a17d520e83850022e98b36dcfe4369","file_path":"legal-nlp-survey-20250328-002/original/Coltrinari_2020_0363.pdf","title":"","llm_title":"Surviving the Legal Jungle: Text Classification of Italian Laws in extremely Noisy conditions","authors":["Riccardo Coltrinari","Alessandro Antinori","Fabio Celli"],"llm_authors":"Riccardo Coltrinari, Alessandro Antinori, Fabio Celli","author_string":"","year":2020,"abstract":"","llm_abstract":"In this paper, we present a method based on Linear Discriminant Analysis for legal text classification of extremely noisy data, such as duplicated documents classified in different classes. The results show that Linear Discriminant Analysis obtains very good performances both in clean and noisy conditions, if used as classifier in ensemble learning and in multi-label text classification.","llm_keywords":["Legal text classification","Linear Discriminant Analysis","Noisy data","Multi-label classification","Ensemble learning"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"8ad3ac8e5109d8206644907a8450805aeabe8894cf795a22a4877b904d5d31ced48aa1a6512555c767eb11abed4e72216f39fde771430c63b17bae21d4013f35","file_path":"legal-nlp-survey-20250328-002/original/Bartolo_2019_0275.pdf","title":"","llm_title":"Pre-trained Contextual Embeddings for Litigation Code Classification","authors":["Max Bartolo","Kamil Tylinski","Alastair Moore"],"llm_authors":"Max Bartolo, Kamil Tylinski, Alastair Moore","author_string":"","year":2019,"abstract":"","llm_abstract":"Models for a variety of natural language processing tasks, such as question answering or text classification, are potentially important components for a wide range of legal machine learning systems. These tasks may include examining whole legal corpora, but may also include a broad range of tasks that can support automation in the digital workplace. Importantly, recent advances in pre-trained contextual embeddings have substantially improved the performance of text classification across a wide range of tasks. In this paper, we investigate the application of these recent approaches on a legal time-recording task. We demonstrate improved performance on a 40-class J-code classification task over a variety of baseline techniques. The best performing single model achieves performance gains of 2.23 micro-averaged accuracy points and 9.39 macro-averaged accuracy points over the next best classifier on the test set. This result suggests these techniques will find broad utility in the development of legal language models for a range of automation tasks.","llm_keywords":["pre-trained embeddings","litigation code classification","natural language processing","legal machine learning","automation","BERT","time-recording"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":8},{"id":"eef36a9d793a1dd5093fe2c0476e317138dd1c28560780474e224a7327023755ebec1fa133844954122114acc9c592bd47ee6c86fb5236881cbb0226cc477b45","file_path":"legal-nlp-survey-20250328-002/original/De-Martino_2022_0582.pdf","title":"","llm_title":"Identification of Paragraph Regularities in Legal Judgements through Clustering and Textual Embedding","authors":["Graziella De Martino","Gianvito Pio"],"llm_authors":"Graziella De Martino and Gianvito Pio","author_string":"","year":2022,"abstract":"","llm_abstract":"In an era characterized by fast technological progresses, working in the law field is very difficult if not supported by the right tools. In this paper, we present a novel method, called JPReg, that identifies paragraph regularities in legal case judgments to support legal experts during the preparation of new legal documents (i.e., paragraphs of existing documents that are similar to those of a document under preparation). JPReg adopts a two-step approach that first clusters similar documents, according to their semantic content, and then identifies regularities in the paragraphs for each cluster. Text embedding methods are adopted to represent documents and paragraphs into a numerical feature space, and an Approximated Nearest Neighbor Search method is adopted to efficiently retrieve the most similar paragraphs with respect to those of a target document. Our extensive experimental evaluation, performed on a real-world dataset, shows the effectiveness and the computational efficiency of the proposed method even in presence of noise in the data.","llm_keywords":["Legal Information Retrieval","Embedding","Clustering","Approximate Nearest Neighbor Search","Artificial Intelligence","Legal Judgments","Textual Embedding","Document Clustering","Semantic Analysis","Text Embedding"],"classifications":["Pre-Processing","Classification","Information Retrieval"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"309d7c0a54ea842a41ab177e048b83814ddf4bf51e09a76bd6db90e8d5662284421e68dbc6877ea9f802fa1e5f6ae2d69a9ad0144c5e902d8d9627a0a179a2cf","file_path":"legal-nlp-survey-20250328-002/original/Sarsa_2019_0252.pdf","title":"","llm_title":"Information Retrieval with Finnish Case Law Embeddings","authors":["Sami Sarsa"],"llm_authors":"Sami Sarsa","author_string":"","year":2019,"abstract":"","llm_abstract":"Information is nowadays abundantly available in human readable and easily accessible form in the Internet. However, the vast amount of text becomes a problem when searching for a specific piece of information and thus, the effectiveness of information retrieval methods carries great importance. The most common method to retrieve information from a collection of documents is to input a set of keywords as a query [BYRN+99]. The query is then compared against the documents in the collection. An algorithm will rank documents in the collection based on relevance to the query and return the documents to the end user in the order of the ranking. This work studies an alternative to the traditional keyword query: the usage of a whole document as a query. A query consisting of a whole document has an advantage over the common keyword query, since there is no requirement for formulating the keywords. In this work, document ranking for retrieval is based on the assumption of vector space models: The relevance of a set of retrieved documents to a query is approximately equal to the similarity between the query and documents in the retrieved set [GRG18]. Therefore, this work focuses on semantic textual similarity, a field of ongoing interest [BCA+17] in natural language processing, which has been mostly focused on paragraph, sentence or word similarity instead of full text documents. To compute numerical inter-document similarities for ranking, texts are mapped into vector space with the use of document embedding models. A widely used word frequency based model TF-IDF [SJ72] and probabilistic model LDA [BNJ02] serve as baseline document embedding models for text similarity computation. More recent, neural network models, inspired by the popular Word2Vec [MCCD13], Doc2Vec [LM14] and Doc2VecC [Che17], are compared to and combined with TF-IDF and LDA in an attempt to improve on the standard methods. A comparison of the document embedding models’ performance in capturing the semantics of Finnish case law documents for similarity comparison is provided. A gold standard set of human evaluated document pair similarities is created for evaluating the models. Also, topic classification with keywords is studied as an alternative evaluation method due to arduousness of human labelled similarity acquisition. In addition, an effective full document query information retrieval system for Finnish case law is created and presented as a part of this work. The case law data set [OTM+17] used in the work consists of ca. 13 000 Finnish case law judgements from 1980 to 2019 and is provided by the Finnish Ministry of Justice.","llm_keywords":["Information Retrieval","Document Embedding","Natural Language Processing","Neural Networks","Semantic Similarity","Finnish Case Law","Machine Learning","Textual Similarity","Neural Network Models","Document Ranking"],"classifications":["Information Retrieval","Classification","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":70},{"id":"3b41c929123ea9536ae146c42d7683dacd6b25562cc310d7f04a915528d332a9052a9dd268091f07a1b683275244371b9153c8e828bdb3ce59aca56d009a6c26","file_path":"legal-nlp-survey-20250328-002/original/Alschner_2017_0155.pdf","title":"","llm_title":"Towards an Automated Production of Legal Texts Using Recurrent Neural Networks","authors":["Wolfgang Alschner","Dmitriy Skougarevskiy"],"llm_authors":"Wolfgang Alschner, Dmitriy Skougarevskiy","author_string":"TEW940 PAF","year":2017,"abstract":"","llm_abstract":"This paper constructs a legal text generation and assembly system in the domain of international investment law. We rely on a corpus of 1600 bilateral investment treaties split into 22 600 articles to train a character-level recurrent neural network (char-RNN). Prior work has shown that while char-RNNs can produce legally meaningful texts, its output tends to be repetitive. In this contribution, we remedy this shortcoming by proposing a new framework for RNN-based text production. First, we elicit priors at the training stage to give more weight to under-represented treaty practice. Second, we use q-gram distance and GloVe word embeddings as filters imposed on the generated texts to draw them closer to a target document. Third, we develop a validation routine that compares the distribution of pre-defined legal concepts in actual and generated texts. Our results indicate that the RNN produces texts that are not repetitive and convey meaningful legal concepts. We conclude by showcasing a practical application of our framework by predicting provisions of the USA-China bilateral investment treaty currently under negotiation.","llm_keywords":["recurrent neural network","artificial intelligence","law","document production","investment treaties","international law"],"classifications":["Text Generation"],"num_cited_by":21,"num_cited_by_title_only":21,"num_pages":5},{"id":"3772264cbd3ef3e48f7c811a2b88942a349538f31dbebf7380ecf28172051b7ea3b21bfc6e393047929281fb3f3dd057169639f3ebbcd9d6a6e557afe05b228f","file_path":"legal-nlp-survey-20250328-002/original/Zeni_2014_0048.pdf","title":"Usability  Relaw 2014","llm_title":"Usability issues for systems supporting requirements extraction from legal documents","authors":["Nicola Zeni","Luisa Mich"],"llm_authors":"Nicola Zeni, Luisa Mich","author_string":"luisa.mich","year":2014,"abstract":"","llm_abstract":"Usability as ease of use and learnability, is critical for systems supporting requirements elicitation for regulatory compliance. The main problem is that these systems have to analyze documents in a specialized natural language, a task that is far from being completely automated. Usability issues are also related to a variety of other characteristics of such systems. Reasons why an early adoption of usability practices is desirable and beneficial in their development are described. Main lessons learned in developing and applying a complex framework for requirements elicitation from regulatory documents are presented to illustrate some of the most relevant usability concerns.","llm_keywords":["usability design","natural language analysis","support system","users","roles","regulatory compliance","requirements elicitation","legal documents"],"classifications":[],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":5},{"id":"a3f06144fb9e5009adc40327301b684117c468a35ac8092958bcc1170ac546edea5fe4f7adb44f023511c90cdcf04ba5120b46007046554288ccbb95f466733e","file_path":"legal-nlp-survey-20250328-002/original/Savelka_2015_0053.pdf","title":"","llm_title":"Applying an Interactive Machine Learning Approach to Statutory Analysis","authors":["Jaromír Savelka","Gaurav Trivedi","Kevin D. Ashley"],"llm_authors":"Jaromír Savelka, Gaurav Trivedi, Kevin D. Ashley","author_string":"","year":2015,"abstract":"","llm_abstract":"Statutory analysis is a significant component of research on almost any legal issue and determining if a statutory provision applies is an integral part of the analysis. In this paper we present the initial results from an attempt to support the applicability assessment in situations where the number of statutory provisions to be considered is large. We propose the use of a framework in which a single human expert cooperates with a machine learning text classification algorithm. Our experiments show that an adoption of the approach leads to a better performance during the relevance assessment. In addition, we suggest how to re-use a classification model trained during one statutory analysis for another related analysis. This points to a new way of capturing and re-using knowledge produced in the course of statutory analysis. Our experiments confirm the viability of this approach.","llm_keywords":["Statutory Analysis","Interactive Machine Learning","Text Classification","Technology Assisted Review","Predictive Coding"],"classifications":["Classification","Information Retrieval"],"num_cited_by":19,"num_cited_by_title_only":19,"num_pages":10},{"id":"445f10781f107c1449a9bdef7f31b1ef39d3185604e1495ca2626f0a8085f56afb86a3ff0d417d9d901220c078d4282b545eb43e42a0f8461aef6500dfdb051f","file_path":"legal-nlp-survey-20250328-002/original/Moreno-Schneider_2020_0351.pdf","title":"","llm_title":"Orchestrating NLP Services for the Legal Domain","authors":["Julian Moreno-Schneider","Georg Rehm","Elena Montiel-Ponsoda","Víctor Rodríguez-Doncel","Artem Revenko","Sotirios Karampatakis","Maria Khvalchik","Christian Sageder","Jorge Gracia","Filippo Maganza"],"llm_authors":"Julian Moreno-Schneider, Georg Rehm, Elena Montiel-Ponsoda, Víctor Rodríguez-Doncel, Artem Revenko, Sotirios Karampatakis, Maria Khvalchik, Christian Sageder, Jorge Gracia, Filippo Maganza","author_string":"","year":2020,"abstract":"","llm_abstract":"Legal technology is currently receiving a lot of attention from various angles. In this contribution we describe the main technical components of a system that is currently under development in the European innovation project Lynx, which includes partners from industry and research. The key contribution of this paper is a workflow manager that enables the flexible orchestration of workflows based on a portfolio of Natural Language Processing and Content Curation services as well as a Multilingual Legal Knowledge Graph that contains semantic information and meaningful references to legal documents. We also describe different use cases with which we experiment and develop prototypical solutions.","llm_keywords":["Text Analytics","Tools","Systems","Applications","Knowledge Discovery/Representation"],"classifications":["Information Extraction","Resources"],"num_cited_by":33,"num_cited_by_title_only":33,"num_pages":9},{"id":"cea6e450c43231e5e27fad965bb0514a2c73fefbd6e03c4e67bc4541a33565756c1deb60cb195f6c9d80d3db5eb2be96f39858d6463d0b8c18f37ef5174c0e2c","file_path":"legal-nlp-survey-20250328-002/original/Manor_2019_0274.pdf","title":"","llm_title":"Plain English Summarization of Contracts","authors":["Laura Manor","Junyi Jessy Li"],"llm_authors":"Laura Manor, Junyi Jessy Li","author_string":"","year":2019,"abstract":"","llm_abstract":"Unilateral contracts, such as terms of service, play a substantial role in modern digital life. However, few users read these documents before accepting the terms within, as they are too long and the language too complicated. We propose the task of summarizing such legal documents in plain English, which would enable users to have a better understanding of the terms they are accepting. We propose an initial dataset of legal text snippets paired with summaries written in plain English. We verify the quality of these summaries manually and show that they involve heavy abstraction, compression, and simplification. Initial experiments show that unsupervised extractive summarization methods do not perform well on this task due to the level of abstraction and style differences. We conclude with a call for resource and technique development for simplification and style transfer for legal language.","llm_keywords":["legal summarization","plain English","unilateral contracts","terms of service","dataset","abstraction","simplification","style transfer"],"classifications":["Machine Summarization","Resources"],"num_cited_by":52,"num_cited_by_title_only":52,"num_pages":11},{"id":"61ca6f13327485e8ce96811217ecf4357abbe78e5ca7cb674cbbc070f913a08b4b0c3bd602072d7db685c82552ba90553b19cb172c8f421e55d8c15b2173f010","file_path":"legal-nlp-survey-20250328-002/original/McConnell_2021_0403.pdf","title":"","llm_title":"Case-level Prediction of Motion Outcomes in Civil Litigation","authors":["Devin McConnell","James Zhu","Sachin Pandya","Derek Aguiar"],"llm_authors":"Devin J. McConnell, James Zhu, Sachin Pandya, Derek Aguiar","author_string":"","year":2021,"abstract":"","llm_abstract":"Lawyers regularly predict court outcomes to make strategic decisions, including when, if at all, to sue or settle, what to argue, and how to reduce their clients’ liability risk. Yet, lawyer predictions tend to be poorly calibrated and biased, which exacerbate unjustifiable disparities in civil case outcomes. Current machine learning (ML) approaches for predicting court outcomes are typically constrained to final dispositions or are based on features unavailable in real-time during litigation, like judicial opinions. Here, we present the first ML-based methods to support lawyer and client decision making in real-time for motion filings in civil proceedings. Using the State of Connecticut Judicial Branch administrative data and court case documents, we trained six classifiers to predict motion to strike outcomes in tort and vehicular cases between July 1, 2004 and February 18, 2019. Integrating dense word embeddings from complaint documents, which contain information specific to the claims alleged, with the Judicial Branch data improved classification accuracy across all models. Subsequent models defined using a novel attorney case-entropy feature, dense word embeddings using corpus specific TF-IDF weightings, and algorithmic classification rules yielded the best predictor, Adaboost, with a classification accuracy of 64.4%. An analysis of feature importance weights confirmed the usefulness of incorporating attorney case-entropy and natural language features from complaint documents. Since all features used in model training are available during litigation, these methods will help lawyers make better predictions than they otherwise could given disparities in lawyer and client resources. All ML models, training code, and evaluation scripts are available at https://github.com/aguiarlab/motionpredict.","llm_keywords":["machine learning","civil litigation","motion outcomes","prediction","real-time decision making","attorney case-entropy","word embeddings","TF-IDF","classifier","Adaboost"],"classifications":["Classification"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":10},{"id":"4bbb61c0f013fba2f740eda928d1b6048c1d9695c6549796ce425fbc85ddc9f69d3783708c7d653b9e1898ad4bc0043cae6711af54cb357e43a034621e07e24c","file_path":"legal-nlp-survey-20250328-002/original/Liepina_2020_0323.pdf","title":"Explaining potentially unfair clauses to the consumer with the CLAUDETTE tool","llm_title":"Explaining potentially unfair clauses to the consumer with the CLAUDETTE tool","authors":["Ruta Liepina","Federico Ruggeri","Francesca Lagioia","Marco Lippi","Kasper Drazewski","Paolo Torroni"],"llm_authors":"Ruta Liepina, Federico Ruggeri, Francesca Lagioia, Marco Lippi, Kasper Drazewski, Paolo Torroni","author_string":"Rūta Liepiņa, Federico Ruggeri, Francesca Lagioia, Marco Lippi, Kasper Drazewski, and Paolo Torroni","year":2020,"abstract":"","llm_abstract":"This paper presents the latest developments of the use of memory network models in detecting and explaining unfair terms in online consumer contracts. We extend the CLAUDETTE tool for the detection of potentially unfair clauses in online Terms of Service, by providing to the users the explanations of unfairness (legal rationales) for five different categories: arbitration, unilateral change, content removal, unilateral termination, and limitation of liability.","llm_keywords":["Memory Networks","Terms of Service","NLP","unfair clauses","consumer protection","legal rationale"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":4},{"id":"f6e315c3b944961215c7798e44c2fc0254ecdd7892cf000d541294d51dc26f8291fa6d529e7109cc300cbd45f0c1b83888fbfd760b0cdac9def5cdc8f65e07eb","file_path":"legal-nlp-survey-20250328-002/original/Sannier_2015_0050.pdf","title":"An automated framework for detection and resolution of cross references in legal texts","llm_title":"An automated framework for detection and resolution of cross references in legal texts","authors":["Nicolas Sannier","Morayo Adedjouma","Mehrdad Sabetzadeh","Lionel Briand"],"llm_authors":"Nicolas Sannier, Morayo Adedjouma, Mehrdad Sabetzadeh, Lionel Briand","author_string":"Nicolas Sannier","year":2015,"abstract":"","llm_abstract":"When identifying and elaborating compliance requirements, analysts need to follow the cross references in legal texts and consider the additional information in the cited provisions. Enabling easier navigation and handling of cross references requires automated support for the detection of the natural language expressions used in cross references, the interpretation of cross references in their context, and the linkage of cross references to the targeted provisions. In this article, we propose an approach and tool support for automated detection and resolution of cross references. The approach leverages the structure of legal texts, formalized into a schema, and a set of natural language patterns for legal cross reference expressions. These patterns were developed based on an investigation of Luxembourg’s legislation, written in French. To build confidence about their applicability beyond the context where they were observed, these patterns were validated against the Personal Health Information Protection Act (PHIPA) by the Government of Ontario, Canada, written in both French and English. We report on an empirical evaluation where we assess the accuracy and scalability of our framework over several Luxembourgish legislative texts as well as PHIPA.","llm_keywords":["Legal compliance","Natural language processing","Cross references","Conceptual modeling","Legal texts","Automated detection","Resolution","Tool support"],"classifications":["Classification","Information Extraction","Information Retrieval","Resources"],"num_cited_by":52,"num_cited_by_title_only":52,"num_pages":23},{"id":"fc3584aab8068e9f71d393400535d886ef36095002c16628a23c38d341280ca6a03002784c82f8838fa6fc0adfd8df2b8bfe68a1522339ef5e0abae18e521e64","file_path":"legal-nlp-survey-20250328-002/original/Poudyal_2019_0294.pdf","title":"Using Clustering Techniques to Identify Arguments in Legal Documents","llm_title":"Using Clustering Techniques to Identify Arguments in Legal Documents","authors":["Prakash Poudyal","Teresa Gonçalves","Paulo Quaresma"],"llm_authors":"Prakash Poudyal, Teresa Gonçalves, Paulo Quaresma","author_string":"Prakash Poudyal, Teresa Gonçalves, and Paulo Quaresma","year":2019,"abstract":"","llm_abstract":"A proposal to automatically identify arguments in legal documents is presented. In this approach, cluster algorithms are applied to argumentative sentences in order to identify arguments. One potential problem with this process is that an argumentative sentence belonging to one specific argument can also simultaneously be part of another, distinct argument. To address this issue, a Fuzzy c-means (FCM) clustering algorithm was used and the proposed approach was evaluated with a set of case-law decisions from the European Court of Human Rights (ECHR). An extensive evaluation of the most relevant and discriminant features to this task was performed and the obtained results are presented. In the context of this work two additional algorithms were developed: 1) the “Distribution of Sentence to the Cluster Algorithm” (DSCA) was developed to transfer fuzzy membership values (between 0 and 1) generated by the FCM to a set of clusters; 2) the “Appropriate Cluster Identification Algorithm” (ACIA) to evaluate the proposed clusters against the gold-standard clusters defined by human experts. The overall results are quite promising and may be the basis for further research work and extensions.","llm_keywords":["Clustering","Fuzzy c-means","Argument mining","Legal documents","Natural Language Processing"],"classifications":["Classification","Information Extraction"],"num_cited_by":22,"num_cited_by_title_only":22,"num_pages":8},{"id":"90d9529133eaac64cd04f9ed7a40ca8a43434b5cf84d85900cda8f431b2d0bda9620e5c9f5158c1e3ba01981bf76d70f8b679369859db3fb2652f905d5c13bea","file_path":"legal-nlp-survey-20250328-002/original/Savelka_2021_0415.pdf","title":"Discovering Explanatory Sentences in Legal Case Decisions Using Pre-trained Language Models","llm_title":"Discovering Explanatory Sentences in Legal Case Decisions Using Pre-trained Language Models","authors":["Jaromir Savelka","Kevin D. Ashley"],"llm_authors":"Jaromir Savelka, Kevin D. Ashley","author_string":"Jaromir Savelka ; Kevin Ashley","year":2021,"abstract":"","llm_abstract":"Legal texts routinely use concepts that are difficult to understand. Lawyers elaborate on the meaning of such concepts by, among other things, carefully investigating how have they been used in past. Finding text snippets that mention a particular concept in a useful way is tedious, time-consuming, and, hence, expensive. We assembled a data set of 26,959 sentences, coming from legal case decisions, and labeled them in terms of their usefulness for explaining selected legal concepts. Using the dataset we study the effectiveness of transformer-based models pre-trained on large language corpora to detect which of the sentences are useful. In light of models’ predictions, we analyze various linguistic properties of the explanatory sentences as well as their relationship to the legal concept that needs to be explained. We show that the transformer-based models are capable of learning surprisingly sophisticated features and outperform the prior approaches to the task.","llm_keywords":["legal texts","explanatory sentences","pre-trained language models","transformer-based models","legal case decisions","semantic features","information retrieval"],"classifications":["Classification","Information Extraction"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":11},{"id":"6eadf8105be7b88d2c5b9eec3c49bddd10d54391b2d44aa989a2380223be022276560de7e9e3fac3adaec31d35c724f2b637740a1a1d51c9b723cbae08ac8920","file_path":"legal-nlp-survey-20250328-002/original/Da-Silva-Amaral_2022_0490.pdf","title":"A Model for Selecting Relevant Topics in Documents Aimed at Compliance Processes","llm_title":"A Model for Selecting Relevant Topics in Documents Aimed at Compliance Processes","authors":["João Alberto da Silva Amaral","Fernando Buarque de Lima Neto"],"llm_authors":"João Alberto da Silva Amaral, Fernando Buarque de Lima Neto","author_string":"Joao Alberto Da Silva Amaral; Fernando Buarque De Lima Neto","year":2022,"abstract":"","llm_abstract":"This paper proposes a semantic Natural Language Processing (NLP) approach used to assist in the automated characterization of information relevant to compliance activities. In this context, the proposed model combines two topic modeling techniques: Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA), the first used to assist in the dimensionality reduction process, while the second, used to identify the number of relevant topics addressed in the processed data. Interesting results were achieved when three large databases tested the model, namely: Database of European Laws (period 1952 to 1990), Database of Audit reports issued by the State General Secretariat of Management of Pernambuco (period 2010 to 2019), and Database of Appellate Decisions issued by the Brazilian Federal Accountability Office (year of 2019). We compared the performance of three machine learning methods: K-means, LSA and LDA. In our experiments, we observed that (i) pre-processing techniques have a marked influence on the result of topic extraction; that (ii) Silhouette techniques and topic coherence produced the best value for the quantitative topics in all databases; that LSA associated with LDA presented the best performance in all three databases, regarding the identification of relevant themes (topics) identified. Overall, the best results were obtained using the database in English (European Union Laws).","llm_keywords":["Dimensionality reduction","Clustering","Topic modeling","Latent semantic analysis","Natural language processing","Text mining"],"classifications":["Classification","Information Retrieval","Pre-Processing"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"ff0aaa45c0a3675f03c1a8438ee7e9436373bbf3313606d96cb483f0e3a236474fa55d88c4350cad005c102c86a025fc8474f69fdfa2fa1b10b55ab8d028ff62","file_path":"legal-nlp-survey-20250328-002/original/Berrazega_2016_0077.pdf","title":"","llm_title":"A Semantic Annotation Model for Arabic Legal Texts","authors":["Ines Berrazega","Asma Bouhafs","Rim Faiz","Ghassan Mourad"],"llm_authors":"Ines Berrazega, Asma Bouhafs, Rim Faiz, Ghassan Mourad","author_string":"ines berrazega","year":2016,"abstract":"","llm_abstract":"This paper addresses an issue in the field of Artificial Intelligence and Law. It’s concerned with the problem of automatically identifying and semantically annotating normative provisions’ categories in Arabic legal texts. This goal has been achieved through the construction of a semantic annotation model, which combines three linguistic resources namely a taxonomy of Arabic normative provisions’ categories, an Arabic normative terminological base and a semantic annotation rule base. The performance of the model has been evaluated over a test dataset of Arabic normative texts collected from the Official Gazette of the Republic of Tunisia. Precision, Recall and F-score measures have been used for evaluation. Obtained results are very promising: 96,4% for Precision, 96,06% for Recall and 96,23% for F-score.","llm_keywords":["Artificial Intelligence and Law","Natural Language Processing","Semantic Annotation","Information Extraction","Arabic language","Legal Corpora","Normative provisions"],"classifications":["Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":8},{"id":"fa69b9c4de118cc6a4fe045acae60cf7cca45cdb24ec43c7e7b121579b0c60cf514c95a0044e805f1506468bac11df993fb10fe6fb8c7e4438694d590af27a23","file_path":"legal-nlp-survey-20250328-002/original/Branting_2020_0334.pdf","title":"","llm_title":"Judges Are from Mars, Pro Se Litigants from Lay Text","authors":["Karl Branting","Carlos Balhana","Craig Pfeifer","John Aberdeen","Bradford Brown"],"llm_authors":"Karl BRANTING, Carlos BALHANA, Craig PFEIFER, John ABERDEEN, Bradford BROWN","author_string":"","year":2020,"abstract":"","llm_abstract":"Access to justice could be significantly expanded if decision support systems were able to accurately interpret statements of fact by pro se (self-represented) litigants. Prior research, which has demonstrated that case decisions can often be predicted by machine-learning models trained on judges’ statements of facts, suggests the hypothesis that these same learning algorithms could be effectively applied to pro se litigants’ fact statements. However, there has been a dearth of corpora on which to test this hypothesis. This paper describes an experiment testing the ability to predict the outcome of pro se litigants’ complaints on a corpus of 5,842 cases initiated by citizen complaints. The results of this experiment were strikingly negative, suggesting that fact statements by unguided pro se litigants are far less amenable to simple machine-learning techniques than judges’ texts and appearing to disconfirm the hypothesis above.","llm_keywords":["access to justice","pro se litigants","machine learning","legal language","decision support systems","complaint data","natural language processing"],"classifications":["Classification","Pre-Processing","Information Extraction","Information Retrieval","Machine Summarization","Resources"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":4},{"id":"1fe26bcb2efcd579ee5daa66ab1cf21b55b16bab3f1c997a5c3880d514cc6971ecb94d0010020f3b16c2a115b11b656ea66e8e0fe5af78436770a0b2f2b70ab4","file_path":"legal-nlp-survey-20250328-002/original/Nay_2018_0197.pdf","title":"","llm_title":"Natural Language Processing and Machine Learning for Law and Policy Texts","authors":["John J Nay"],"llm_authors":"John Nay","author_string":"John J Nay","year":2019,"abstract":"","llm_abstract":"","llm_keywords":["Natural Language Processing","Machine Learning","Legal Texts","Prediction","Data Exploration","Supervised Learning","Unsupervised Learning","Statutory Law","Case Law","Contracts"],"classifications":[],"num_cited_by":30,"num_cited_by_title_only":30,"num_pages":35},{"id":"d99c9da675607f5ff4c43fdcf9deea7b0a640935f69fbd0c97107297f86314fc5fa188e2fa1f5856a0fffa8c17c3e9557944c3aac0ad6617c97525ce088323b0","file_path":"legal-nlp-survey-20250328-002/original/Fawei_2015_0070.pdf","title":"","llm_title":"Passing a USA National Bar Exam: a First Corpus for Experimentation","authors":["Biralatei Fawei","Adam Wyner","Jeff Pan"],"llm_authors":"Biralatei Fawei, Adam Wyner, and Jeff Pan","author_string":"","year":2016,"abstract":"","llm_abstract":"Bar exams provide a key watershed by which legal professionals demonstrate their knowledge of the law and its application. Passing the bar entitles one to practice the law in a given jurisdiction. The bar provides an excellent benchmark for the performance of legal information systems since passing the bar would arguably signal that the system has acquired key aspects of legal reason on a par with a human lawyer. The paper provides a corpus and experimental results with material derived from a real bar exam, treating the problem as a form of textual entailment from the question to an answer. The providers of the bar exam material set the Gold Standard, which is the answer key. The experiments carried out using the ‘out of the box’ the Excitement Open Platform for textual entailment. The results and evaluation show that the tool can identify wrong answers (non-entailment) with a high F1 score, but it performs poorly in identifying the correct answer (entailment). The results provide a baseline performance measure against which to evaluate future improvements. The reasons for the poor performance are examined, and proposals are made to augment the tool in the future. The corpus facilitates experimentation by other researchers.","llm_keywords":["textual entailment","bar exam","legal reasoning","natural language processing","question answering"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":26,"num_cited_by_title_only":26,"num_pages":6},{"id":"1275766a9d9f7da93fc8593a48b233f4f0a88d3dff537eee63f21fa1080b1c69e62caf588e8f77c65b7752fa0e6b54193fdbeb26ab2d4bb8a917936e33813696","file_path":"legal-nlp-survey-20250328-002/original/Antonini_2014_0040.pdf","title":"","llm_title":"Requirements of Legal Knowledge Management Systems to Aid Normative Reasoning in Specialist Domains","authors":["Alessio Antonini","Guido Boella","Joris Hulstijn","Llio Humphreys"],"llm_authors":"Alessio Antonini, Guido Boella, Joris Hulstijn, Llio Humphreys","author_string":"","year":2014,"abstract":"","llm_abstract":"This paper discusses the challenges of legal norms in specialist domains - the interplay between industry/professional standards and legal norms, the information gap between legal and specialist domains and the need for interpretation at all stages of compliance - design, operation and justification. We propose extensions to the Eunomos legal knowledge management tool to help address the information gap, with particular attention to aligning norms with operational procedures, and the use of domain-specific specialist ontologies from multiple domains to help users understand and reason with norms on specialist topics. The paper focuses mainly on medical law and clinical guidelines.","llm_keywords":["legal ontology","knowledge representation","norm compliance","ontology alignment","clinical guidelines"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":16},{"id":"d6df9b3091075b2a64afcc512bc258404e24a035137322ab377935a8080fe96a838d1fd58b3f798e61d5d44bd7a7124a87ff6c931872e380ab7809a0e4e8c6c8","file_path":"legal-nlp-survey-20250328-002/original/Li_2021_0473.pdf","title":"","llm_title":"Text-Guided Legal Knowledge Graph Reasoning","authors":["Luoqiu Li","Zhen Bi","Hongbin Ye","Shumin Deng","Hui Chen","Huaixiao Tou"],"llm_authors":"Luoqiu Li, Zhen Bi, Hongbin Ye, Shumin Deng, Hui Chen, Huaixiao Tou","author_string":"","year":2021,"abstract":"","llm_abstract":"Recent years have witnessed the prosperity of legal artificial intelligence with the development of technologies. In this paper, we propose a novel legal application of legal provision prediction (LPP), which aims to predict the related legal provisions of affairs. We formulate this task as a challenging knowledge graph completion problem, which requires not only text understanding but also graph reasoning. To this end, we propose a novel text-guided graph reasoning approach. We collect amounts of real-world legal provision data from the Guangdong government service website and construct a legal dataset called LegalLPP. Extensive experimental results on the dataset show that our approach achieves better performance compared with baselines. The code and dataset are available in https://github.com/zjunlp/LegalPP for reproducibility.","llm_keywords":["Legal Artificial Intelligence","Legal Provision Prediction","Knowledge Graph Completion","Text Understanding","Graph Reasoning","BERT","Graph Neural Networks","R-GCN","GAT","Legal Dataset"],"classifications":["Classification","Information Retrieval","Information Extraction","Resources"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":13},{"id":"2370df12e4b59eab2946c08b9193dd17a08f018ceca9ec35b609126b318fbf20c383afd6a88657bf2369e01e927544dfcb95fdb8dd3933550616f4ffed40dbf2","file_path":"legal-nlp-survey-20250328-002/original/Nay_2017_0148.pdf","title":"Predicting and understanding law-making with word vectors and an ensemble model","llm_title":"Predicting and understanding law-making with word vectors and an ensemble model","authors":["John J. Nay"],"llm_authors":"John J. Nay","author_string":"John J. Nay","year":2017,"abstract":"","llm_abstract":"Out of nearly 70,000 bills introduced in the U.S. Congress from 2001 to 2015, only 2,513 were enacted. We developed a machine learning approach to forecasting the probability that any bill will become law. Starting in 2001 with the 107th Congress, we trained models on data from previous Congresses, predicted all bills in the current Congress, and repeated until the 113th Congress served as the test. For prediction we scored each sentence of a bill with a language model that embeds legislative vocabulary into a high-dimensional, semantic-laden vector space. This language representation enables our investigation into which words increase the probability of enactment for any topic. To test the relative importance of text and context, we compared the text model to a context-only model that uses variables such as whether the bill’s sponsor is in the majority party. To test the effect of changes to bills after their introduction on our ability to predict their final outcome, we compared using the bill text and meta-data available at the time of introduction with using the most recent data. At the time of introduction context-only predictions outperform text-only, and with the newest data text-only outperforms context-only. Combining text and context always performs best. We conducted a global sensitivity analysis on the combined model to determine important variables predicting enactment.","llm_keywords":["machine learning","legislative prediction","U.S. Congress","word vectors","ensemble model","text analysis","probability forecasting","bill enactment"],"classifications":["Classification","Information Extraction"],"num_cited_by":46,"num_cited_by_title_only":46,"num_pages":14},{"id":"f5686a3a4dd49ec84837a31b03b88abc62756db76521ede46eb7c43a817a2569f9736d81cb982b97889e4a49f45682e7de9772e88f9363c5df007d2aab6c4aa2","file_path":"legal-nlp-survey-20250328-002/original/Rossi_2021_0483.pdf","title":"VerbCL: A Dataset of Verbatim Quotes for Highlight Extraction in Case Law","llm_title":"VerbCL: A Dataset of Verbatim Quotes for Highlight Extraction in Case Law","authors":["Julien Rossi","Svitlana Vakulenko","Evangelos Kanoulas"],"llm_authors":"Julien Rossi, Svitlana Vakulenko, Evangelos Kanoulas","author_string":"Julien Rossi","year":2021,"abstract":"","llm_abstract":"Citing legal opinions is a key part of legal argumentation, an expert task that requires retrieval, extraction and summarization of information from court decisions. The identification of legally salient parts in an opinion for the purpose of citation may be seen as a domain-specific formulation of a highlight extraction or passage retrieval task. As similar tasks in other domains such as web search show significant attention and improvement, progress in the legal domain is hindered by the lack of resources for training and evaluation. This paper presents a new dataset that consists of the citation graph of court opinions, which cite previously published court opinions in support of their arguments. In particular, we focus on the verbatim quotes, i.e., where the text of the original opinion is directly reused. With this approach, we explain the relative importance of different text spans of a court opinion by showcasing their usage in citations, and measuring their contribution to the relations between opinions in the citation graph. We release VerbCL1, a large-scale dataset derived from CourtListener and introduce the task of highlight extraction as a single-document summarization task based on the citation graph establishing the first baseline results for this task on the VerbCL dataset.","llm_keywords":["case law","information retrieval","summarization","highlight extraction","legal opinions","citation graph","verbatim quotes","CourtListener","training resources","evaluation"],"classifications":["Information Retrieval","Information Extraction","Machine Summarization","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":11},{"id":"13c67e4befbfb8d47dbbddeefdb9ebdaaff940bd602fb45b7af767f04309e164eb71193d131892bf36f62f02ca43343e3c5a069d83d23fa881970a49c18a9a6d","file_path":"legal-nlp-survey-20250328-002/original/Vacek_2019_0266.pdf","title":"Litigation Analytics: Case Outcomes Extracted from US Federal Court Dockets","llm_title":"Litigation Analytics: Case outcomes extracted from US federal court dockets","authors":["Thomas Vacek","Ronald Teo","Dezhao Song","Timothy Nugent","Conner Cowling","Frank Schilder"],"llm_authors":"Thomas Vacek, Ronald Teo, Dezhao Song, Conner Cowling, Frank Schilder, Timothy Nugent","author_string":"Thomas Vacek ; Ronald Teo ; Dezhao Song ; Timothy Nugent ; Conner Cowling ; Frank Schilder","year":2019,"abstract":"","llm_abstract":"Dockets contain a wealth of information for planning a litigation strategy, but the information is locked up in semi-structured text. Manually deriving the outcomes for each party (e.g., settlement, verdict) would be very labor intensive. Having such information available for every past court case, however, would be very useful for developing a strategy because it potentially reveals tendencies and trends of judges and courts and the opposing counsel. We used Natural Language Processing (NLP) techniques and deep learning methods allowing us to scale the automatic analysis of millions of US federal court dockets. The automatically extracted information is fed into a Litigation Analytics tool that is used by lawyers to plan how they approach concrete litigations.","llm_keywords":["Litigation Analytics","NLP","Deep Learning","US Federal Court Dockets","Case Outcomes","Machine Learning","PACER","Text Analysis","Legal Technology"],"classifications":["Information Extraction"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":10},{"id":"be75dc1606b1428ed51438263b4b092c7594be84277ef45b5bb35daa1bd8df0b22f3e297478b7ab21f62a20b20c942f6cd26d96e39a5c3883b2010a9414a0afc","file_path":"legal-nlp-survey-20250328-002/original/Shankar_2019_0271.pdf","title":"163_Shankar.pdf","llm_title":"\"Foundation Learning for Legal Query Reformulation\"","authors":["Arunprasath Shankar","Venkat Nagaraju Buddarapu"],"llm_authors":"Arunprasath Shankar, Venkat Nagaraju Buddarapu","author_string":"","year":2019,"abstract":"","llm_abstract":"Every reformulation is the process of iteratively modifying a query to improve the quality of search engine results. In recent years, the task of reformulating natural language queries has received considerable diligence from both industry and academic communities. Since legal queries are diverse and multi-faceted, traditional approaches cannot effectively handle low frequency and out-of-vocabulary words. Motivated by these issues, we rethink the task of legal query reformulation as a type of monolingual neural machine translation problem, where the input source query is potentially erroneous and the output target query is its corrected form. We propose a unified and principled framework with multiple levels of granularity.","llm_keywords":["Legal Query Reformulation","Natural Language Processing","Machine Translation","Query Correction","Artificial Neural Networks"],"classifications":["Information Retrieval","Pre-Processing"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":2},{"id":"8fb386a3061652539780b29eee77211bacc841014b70848b0a41860520b7d1e27da4cade2b64324c257a5d9d3e4344917b8981e9e3ace5524a8b8f5c456ce97e","file_path":"legal-nlp-survey-20250328-002/original/Hatsutori_2016_0091.pdf","title":"453751_Print.indd","llm_title":"New Frontiers in Artificial Intelligence: JSAI-isAI 2016 Workshops, LENLS, HAT-MASH, AI-Biz, JURISIN and SKL","authors":["Setsuya Kurahashi","Yuiko Ohta","Sachiyo Arai","Ken Satoh","Daisuke Bekki"],"llm_authors":"Setsuya Kurahashi, Yuiko Ohta, Sachiyo Arai, Ken Satoh, Daisuke Bekki (Eds.)","author_string":"0002624","year":2017,"abstract":"","llm_abstract":"","llm_keywords":["Artificial Intelligence","JSAI-isAI 2016","Workshops","Natural Language Semantics","Healthy Aging Technology","Business Intelligence","Juris-informatics"],"classifications":[],"num_cited_by":49,"num_cited_by_title_only":49,"num_pages":347},{"id":"cfd59a72b271725c4201be66f7bbe87af30095b7f15c0b852f962a73a1f11a333dc25f2f9d8f4d0e7483a5b095a6bd3ee1c5cd048c6623336627d723f67c82e9","file_path":"legal-nlp-survey-20250328-002/original/Liu_2019_0241.pdf","title":"158_Liu.pdf","llm_title":"Extracting the Gist of Chinese Judgments of the Supreme Court","authors":["Chao-Lin Liu","Kuan-Chun Chen"],"llm_authors":"Chao-Lin Liu and Kuan-Chun Chen","author_string":"","year":2019,"abstract":"","llm_abstract":"The gist of judgement documents encodes important experience and viewpoints of the Supreme Court, and provides instrumental and educational information for judges, lawyers, practitioners, and students. The Supreme Court in Taiwan appoints senior members to produce the gist for selected judgments of the Supreme Court, but is unable to offer the gist for all judgment documents. Based on our observation of the existing gist statements, we can treat the generation of the gist as a sentence classification problem. We apply machine-learning methods, including gradient boosting, multilayer perceptrons, and deep learning methods with long short-term memory units; and consider legal, linguistic, statistical information, and different word embedding methods to build several classifiers. By using more sophisticated classifiers and more relevant features, we gradually achieved better results, and the best result was 0.9372 in F1 measure.","llm_keywords":["Legal Informatics","Information Extraction","Extractive Summarization","Machine Learning","Gradient Boosting","Random Forest","Multilayer Perceptrons","Deep Learning","Long Short-Term Memory"],"classifications":["Classification"],"num_cited_by":33,"num_cited_by_title_only":33,"num_pages":10},{"id":"7626164f468a21467ad26836115ca2b46552980c31a35e152f01ed125ba6c35430f95dadb0f6247092d3b34addf15b8d9ea9f53c9d547ba0b46a91e0ca9548f9","file_path":"legal-nlp-survey-20250328-002/original/Winkels_2013_0009.pdf","title":"Experiments in automated support for argument reconstruction","llm_title":"Experiments in Automated Support for Argument Reconstruction","authors":["Radboud Winkels","Jochem Douw","Sara Veldhoen"],"llm_authors":"Radboud Winkels, Jochem Douw, Sara Veldhoen","author_string":"Radboud Winkels, Jochem Douw, Sara Veldhoen","year":2013,"abstract":"","llm_abstract":"This paper describes the outcomes of experiments in automated support for argument reconstruction from natural language texts. We investigated several possibilities to support a manual process by using natural language processing, from classifying pieces of text as either argumentative or non-argumentative to clustering text fragments in the hope that these clusters would contain similar arguments. Results are diverse, but also show that we cannot come a long way without an extensive pre-tagged corpus.","llm_keywords":["argument mining","clustering","policy modelling","natural language processing","automated argument reconstruction"],"classifications":["Classification","Pre-Processing"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":5},{"id":"aa92c93b0cb80811a4d803bee4d86b7f0e9239dd4d8ad8159b789e7fe106e06b0777bed47a3fccabfa2348f5c709bbbc17c54b4c8f79740a9d15522b83fb7f29","file_path":"legal-nlp-survey-20250328-002/original/Boella_2013_0003.pdf","title":"A system for classifying multi-label text into EuroVoc","llm_title":"A System for Classifying Multi-label Text into EuroVoc","authors":["Guido Boella","Luigi Di Caro","Daniele Rispoli","Livio Robaldo"],"llm_authors":"Guido Boella, Luigi Di Caro, Daniele Rispoli, Livio Robaldo","author_string":"Guido Boella, Luigi Di Caro, Daniele Rispoli, Livio Robaldo","year":2013,"abstract":"","llm_abstract":"In this work we present a working system for automatic classification of text documents into the EuroVoc multilingual thesaurus. EuroVoc contains around 7,000 categories with different levels of specificity. The system relies on a simple approach for the treatment of multi-label texts where each document may have more than one associated category. The classifier is based on the well-known Support Vector Machine algorithm trained using the JRC-Acquis corpus, containing around 23,000 documents labeled with six EuroVoc categories in average. The demonstration scenario will show the ability of the system to classify documents taken on site from the Eur-Lex web portal of the European Union, together with features for visualization and navigation of the texts at different granulatity.","llm_keywords":["multi-label classification","EuroVoc","Support Vector Machine","text classification","JRC-Acquis corpus","machine learning","document management","Eur-Lex","multilingual thesaurus"],"classifications":["Classification"],"num_cited_by":27,"num_cited_by_title_only":27,"num_pages":2},{"id":"54f51f20448a4b0c6042f8dea0a5c8c16802ae62f78eecae4be05d4eb28b4eb58f60387ba72fc8d4d936e3e71d0518572b45f23130f29e22f28ffd38eb8638f5","file_path":"legal-nlp-survey-20250328-002/original/Michel_2022_0518.pdf","title":"","llm_title":"Identification of Decision Rules from Legislative Documents Using Machine Learning and Natural Language Processing","authors":["Maximilian Michel","Djordje Djurica","Jan Mendling"],"llm_authors":"Maximilian Michel, Djordje Djurica, Jan Mendling","author_string":"","year":2021,"abstract":"","llm_abstract":"Decision logic extraction from natural language texts can be a tedious, labor-intensive task. This is especially true for legislative texts, since they do not always follow usual speech and writing patterns. This paper explores the possibility of using machine learning and natural language processing approaches to identify decision rules within legislative documents, and ultimately provides the possibility of building an extraction algorithm on top of the solution to extract and visualize decision logic automatically. Such a novel method for decision rules identification bears the potential to reduce human labor, minimize mistakes, and lessen context dependency. To accomplish this, we use pre-trained word vectorization in conjunction with a complex multi-layer convolutional neural network (CNN). The relevant data used in this project was generated from the Austrian income tax code and labeled by hand. A quantitative evaluation shows that our approach can be trained on as little as a single code of law and still obtain significant accuracy.","llm_keywords":["machine learning","natural language processing","decision rules","legislative documents","convolutional neural network","word vectorization","Austrian income tax code","automated rule extraction","semantic content","information systems"],"classifications":["Information Extraction","Resources"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":11},{"id":"ce203820463396473f0b6656cf4d38239f7d5fd2240bfffc0eca456963a2cfc00607bcb15ecab744ceb433db60759af3cd98e1289e216d235dc3bbf813d20ac3","file_path":"legal-nlp-survey-20250328-002/original/Elnaggaer_2018_0195.pdf","title":"","llm_title":"Multi-Task Deep Learning for Legal Document Translation, Summarization and Multi-Label Classification","authors":["Pengcheng Dai","Ahmed Elnaggar","Christoph Gebendorfer","Ingo Glaser","Florian Matthes"],"llm_authors":"Ahmed Elnaggar, Christoph Gebendorfer, Ingo Glaser and Florian Matthes","author_string":"Pengcheng Dai","year":2019,"abstract":"","llm_abstract":"The digitalization of the legal domain has been ongoing for a couple of years. In that process, the application of different machine learning (ML) techniques is crucial. Tasks such as the classification of legal documents or contract clauses as well as the translation of those are highly relevant. On the other side, digitized documents are barely accessible in this field, particularly in Germany. Today, deep learning (DL) is one of the hot topics with many publications and various applications. Sometimes it provides results outperforming the human level. Hence this technique may be feasible for the legal domain as well. However, DL requires thousands of samples to provide decent results. A potential solution to this problem is multi-task DL to enable transfer learning. This approach may be able to overcome the data scarcity problem in the legal domain, specifically for the German language. We applied the state of the art multi-task model on three tasks: translation, summarization, and multi-label classification. The experiments were conducted on legal document corpora utilizing several task combinations as well as various model parameters. The goal was to find the optimal configuration for the tasks at hand within the legal domain. The multi-task DL approach outperformed the state of the art results in all three tasks. This opens a new direction to integrate DL technology more efficiently in the legal domain.","llm_keywords":["Multi-task Deep Learning","Translation","Summarization","Multi-label Classification","Legal Domain","Transfer Learning","Natural Language Processing","Data Scarcity"],"classifications":[],"num_cited_by":37,"num_cited_by_title_only":37,"num_pages":7},{"id":"a741b0325110c9660569094c59a6ec5c2267b98dbc9915eaa379365ac291eacaaef1c6522e9d98895d9cc68ad65a969bc621ab3625849112d4daf0962d375a3d","file_path":"legal-nlp-survey-20250328-002/original/Rossi_2019_0263.pdf","title":"","llm_title":"Legal Search in Case Law and Statute Law","authors":["Julien Rossi","Evangelos Kanoulas"],"llm_authors":"Julien ROSSI, Evangelos KANOULAS","author_string":"","year":2019,"abstract":"","llm_abstract":"In this work we describe a method to identify document pairwise relevance in the context of a typical legal document collection: limited resources, long queries and long documents. We review the usage of generalized language models, including supervised and unsupervised learning. We observe how our method, while using text summaries, overperforms existing baselines based on full text, and motivate potential improvement directions for future work.","llm_keywords":["Legal Search","Case Law","Statute Law","Language Models","Transfer Learning","Information Retrieval","Generalized Language Models","Pairwise Relevance"],"classifications":["Text Generation","Information Retrieval","Machine Summarization"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":10},{"id":"b2140ca0d12a9f8a84051dcdfb72960a813162a943560b6d164f4ab0a78aa2370560e9b367b1193de1e0d41748c7204e22270bd2eadc0b4179f0db71a3da35ec","file_path":"legal-nlp-survey-20250328-002/original/Li_2018_0185.pdf","title":"Law text classification using semi-supervised convolutional neural networks","llm_title":"Law Text Classification Using Semi-supervised Convolutional Neural Networks","authors":["Penghua Li","Fen Zhao","Yuanyuan Li","Ziqin Zhu"],"llm_authors":"Penghua Li, Fen Zhao, Yuanyuan Li, Ziqin Zhu","author_string":"","year":2018,"abstract":"","llm_abstract":"With the developments of internet technologies, dealing with a mass of law cases urgently and assigning classification cases automatically are the most basic and critical steps. Convolutional Neural Networks (CNNs), has been shown to be effective for text classification. To better apply CNNs into law text classification, this paper presents a new semi-supervised Convolutional Neural Networks (SSC) framework. Our method combines unlabeled data with a small labeled training set to train better models, and then integrates into a supervised CNN. More specifically, for effective use of word order for text categorization, we use the feature of not low-dimensional word vectors but high-dimensional text data, that is, a small text regions is learned based on sequences of one-hot vectors. To better improve the prediction accuracy of the scheme, we seek effective use of unlabeled data for text categorization for integration into a supervised CNN. We compare the proposed scheme to state-of-the-art methods by the real datasets. The results demonstrate that the semi-supervised learning model can get best text classification accuracy.","llm_keywords":["Convolutional Neural Networks","Law Text Classification","Semi-supervised Learning","Text Categorization","Word Embeddings","NLP","Deep Learning","Artificial Intelligence"],"classifications":["Classification"],"num_cited_by":34,"num_cited_by_title_only":34,"num_pages":5},{"id":"b4fbdb1af0fdce78a8cf81b53d5717d7363545f737f25120608d51087d4ac82f7eb321fa35a9b7fe5c9774afb62ced2331b889d72569124d03de470d8f807bd4","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2017_0105.pdf","title":"","llm_title":"A Deep Learning Approach to Contract Element Extraction","authors":["Ilias Chalkidis","Ion Androutsopoulos"],"llm_authors":"Ilias Chalkidis, Ion Androutsopoulos","author_string":"","year":2017,"abstract":"","llm_abstract":"We explore how deep learning methods can be used for contract element extraction. We show that a BILSTM operating on word, POS tag, and token shape embeddings outperforms the linear sliding-window classifiers of our previous work, without any manually written rules. Further improvements are observed by stacking an additional LSTM on top of the BILSTM, or by adding a CRF layer on top of the BILSTM. The stacked BILSTM-LSTM misclassifies fewer tokens, but the BILSTM-CRF combination performs better when methods are evaluated for their ability to extract entire, possibly multi-token contract elements.","llm_keywords":["Natural language processing","deep learning","legal text analytics","contract element extraction","BILSTM","LSTM","CRF","word embeddings","POS tag embeddings","token-shape embeddings"],"classifications":[],"num_cited_by":95,"num_cited_by_title_only":95,"num_pages":10},{"id":"5fbff22387b394cc58523e469c13452a449352d6963727d21712a266c927fe19d4d14ae3ee35b0fa777f178fa9979dbe017a1a3e1703e1933fe5aebc4611beb0","file_path":"legal-nlp-survey-20250328-002/original/Badji_2018_0190.pdf","title":"2018 - Badji, Ines.pdf","llm_title":"Legal Entity Extraction with NER Systems","authors":["Ines Badji"],"llm_authors":"Ines Badji","author_string":"magdalena","year":2018,"abstract":"","llm_abstract":"Named Entity Recognition over texts belonging to the legal domain focuses on categories (legal entities) like references to specific laws, judgments, name of courts or stages in a legal process. Although there is a rich choice of libraries for implementing NER systems, these late ones are not domain specific and do not work well on text pertaining to the Legal domain. Similarly, little focus is given to Spanish since most research is done on the English language. The objective of the work presented in this thesis is the identification of legal entities in Spanish and English texts, with a main focus on informal references to legislative documents found in news, Twitter, contracts or journal articles. The work is framed in the H2020 Lynx project, aimed at creating a Legal Knowledge Graph enabling the provision of compliance-related services. A Rule Based approach can be used to recognize references to norms in Spanish and English documents belonging to the legal domain applied on top of a combination of Natural Language Processing Tools. To recognize the mentions in documents of a less formal nature, a number of vulgar variants for the names of the public acts or judgments is necessary. By querying on Wikidata, DBpedia and BOE a table of synonyms is produced. These resources have been published along with a small annotated data set taken as gold standard.","llm_keywords":["Named Entity Recognition","Legal domain","Spanish text processing","English text processing","Informal references","Legal Knowledge Graph","H2020 Lynx project","Natural Language Processing","Rule Based approach","Wikidata","DBpedia","BOE"],"classifications":["Information Extraction","Resources"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":66},{"id":"fdaf0024336a2de744ef87837d051aecfd298869aa605e39c279e1c2afa895a07dd992b1fed676d1e0b3d0d928e92cc7e5cebe2d57b4580ce7268c2b974262e6","file_path":"legal-nlp-survey-20250328-002/original/Castano_2020_0297.pdf","title":"","llm_title":"A Bootstrapping Approach for Semi-Automated Legal Knowledge Extraction and Enrichment","authors":["Silvana Castano","Mattia Falduti","Alfio Ferrara","Stefano Montanelli"],"llm_authors":"Silvana Castano, Mattia Falduti, Alfio Ferrara, Stefano Montanelli","author_string":"","year":2020,"abstract":"","llm_abstract":"In this paper, we propose a bootstrapping approach for semi- automated legal knowledge extraction. The approach is characterized by the use of a reference legal ontology that is progressively enriched with relevant concepts and related terms extracted from a corpus of legal documents (i.e., Court Decision documents). Supervised, multi-label classification techniques and black-box model explanation techniques are the core components of the bootstrapping approach i) to associate CD documents with appropriate concepts in the ontology and ii) to choose the terms that are decisive for determining the association between a document and a certain ontology concept, respectively. The goal of the proposed approach is to reduce the manual involvement of legal experts as much as possible and to improve the accuracy of document classification, by progressively enriching the term sets associated with ontology concepts. Preliminary experimental results are finally provided to show the contribution of the proposed approach on a corpus of real Court Decision documents.","llm_keywords":["legal ontology","legal knowledge extraction","automated Court-Decision analysis","bootstrapping","multi-label classification","legal documents","natural language processing","supervised techniques","black-box model explanation","legal domain"],"classifications":["Information Extraction","Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":11},{"id":"72736c26535ea8f644de695b7532db600f6fcf1015cc37aeb26bb5c5120be79e279d85f8f20df97dc0b76bbaf719e51ee95776890b9285cc7980fb35182b8137","file_path":"legal-nlp-survey-20250328-002/original/Qin_2022_0489.pdf","title":"A Comparison Study of Pre-trained Language Models for Chinese Legal Document Classification","llm_title":"A Comparison Study of Pre-trained Language Models for Chinese Legal Document Classification","authors":["Ruyu Qin","Min Huang","Yutong Luo"],"llm_authors":"Ruyu Qin, Min Huang, Yutong Luo","author_string":"Ruyu Qin; Min Huang; Yutong Luo","year":2022,"abstract":"","llm_abstract":"Legal artificial intelligence (LegalAI), aiming to benefit the legal domain using artificial intelligence technologies, is the hot topic of the moment. As the basis for various LegalAI tasks such as judgment prediction and similar case matching, the classification of legal documents is an issue that has to be addressed. The majority of current approaches focus on the legal systems of native English-speaking countries. However, both Chinese language and legal system differ significantly from that of English. Given the success of pre-trained Language Models (PLMs) and outperformance compared with feature-engineering-based machine learning models as well as traditional deep neural network models such as CNNs and RNNs in NLP, their effectiveness in specific domains needs to be further investigated, especially in legal domain. Moreover, few studies have made comparisons of these PLMs for specific legal tasks. Therefore, in this paper we train several strong PLMs which differ in pre-training corpus on three datasets of Chinese legal documents. Experimental results show that the model pre-trained on the legal corpus demonstrates its high efficiency on all datasets.","llm_keywords":["legal document","document classification","pre-trained language models","Chinese legal documents","LegalAI"],"classifications":["Classification","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":6},{"id":"3cf4e2243b4c4d2552d621eea062f49427af0053379313c0e2018be0a018b6106bb936d9a65e41c9afa6041c00e62ee236a2e4bbbd7b82ab32fa59e6e569d34a","file_path":"legal-nlp-survey-20250328-002/original/Bex_2021_0454.pdf","title":"","llm_title":"On the relevance of algorithmic decision predictors for judicial decision making","authors":["Floris Bex","Henry Prakken"],"llm_authors":"Floris Bex, Henry Prakken","author_string":"","year":2021,"abstract":"","llm_abstract":"In this article, we discuss case decision predictors, algorithms which, given some features of a legal case predict the outcome of the case (i.e. the decision of the judge). We discuss whether, and if so how, such prediction algorithms can be used to support judges in their decision making process. We conclude that case decision predictors can only be useful in individual cases if they can give legal justifications for their predictions, and that only these legal justifications are what should matter for a judge.","llm_keywords":["legal prediction","judicial decision making","algorithmic decision predictors","machine learning","AI in law","natural language processing","legal justifications","case decision predictors","judicial consistency"],"classifications":["Classification"],"num_cited_by":31,"num_cited_by_title_only":31,"num_pages":5},{"id":"263a66220ac008b553e7d3cd07d661535b1eb49b796e57567ee1a3d0685166a3b6aec49f093ddb4a80237cc06964ab95bd26790af47108979101708f15468586","file_path":"legal-nlp-survey-20250328-002/original/Yaqin_2020_0316.pdf","title":"Design of Contract Review System in Enterprise Legal Department Based on Natural Language Processing","llm_title":"Design of Contract Review System in Enterprise Legal Department Based on Natural Language Processing","authors":["Yaqin Liang","Gang Cen","Runkai Zhu","Mengting Shen"],"llm_authors":"Liang Yaqin, Cen Gang, Zhu Runkai, Shen Mengting","author_string":"","year":2020,"abstract":"","llm_abstract":"In recent years, information technology and analytical algorithms are highly developed. In order to solve the problems of low efficiency, high repeatability and no fixed standard faced by legal specialists in enterprises in the process of contract review, the research group proposed the contract review system for enterprise legal department based on natural language processing technology. The system makes intelligent draft according to the contract signing scenario and artificial intelligence. After the legal specialist enters the contract, the system analyzes the contract type, extracts and reviews the terms of the contract, verifies whether they conform to the standard, and carries out risk assessment by mining the historical operation data of the enterprise. At the same time, it also provides a set of efficient and feasible scheme for contract visual management and monitoring. The system liberates the productivity of legal specialists and enables them to devote more energy to solving professional legal problems. The application of the system not only reduces legal disputes, but also plays an important role in promoting the healthy development of enterprises and social stability.","llm_keywords":["natural language processing","contract review","risk estimation","contract management system","legal technology","office automation","artificial intelligence","big data","technical innovation","enterprise legal department"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":5},{"id":"10cf59ea7674b3d0bd8fd272886670ef1b64fc3bac5e63637cbad35db00920c593092e0bc93f6e5c4d5b0e088c9084a0774e8712daade2395c207c0057fe4446","file_path":"legal-nlp-survey-20250328-002/original/Sovrano_2021_0380.pdf","title":"","llm_title":"A Dataset for Evaluating Legal Question Answering on Private International Law","authors":["Francesco Sovrano","Monica Palmirani","Biagio Distefano","Salvatore Sapienza","Fabio Vitali"],"llm_authors":"Francesco Sovrano, Monica Palmirani, Biagio Distefano, Salvatore Sapienza, Fabio Vitali","author_string":"","year":2021,"abstract":"","llm_abstract":"International Private Law (PIL) is a complex legal domain that presents frequent conflicting norms between the hierarchy of legal sources, legal domains, and the adopted procedures. Scientific research on PIL reveals the need to create a bridge between European and national laws. In this context, legal experts have to access heterogeneous sources, being able to recall all the norms and to combine them using case-laws and following the principles of interpretation theory. This clearly poses a daunting challenge to humans, whenever Regulations change frequently or are big-enough in size. Automated reasoning over legal texts is not a trivial task, because legal language is very specific and in many ways different from a commonly used natural language. When applying state-of-the-art language models to legalese understanding, one of the challenges is always to figure how to optimally use the available amount of data. This makes hard to apply state-of-the-art sub-symbolic question answering algorithms on legislative texts, especially the PIL ones, because of data scarcity. In this paper we try to expand previous works on legal question answering, publishing a larger and more curated dataset for the evaluation of automated question answering on PIL.","llm_keywords":["Legal Question Answering","Private International Law","Knowledge Graph Extraction","automated reasoning","legal language","deep neural networks"],"classifications":["Resources"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":5},{"id":"f4d86dd158d110473a2221a535c067a9b80ca761eb1cf79f5d1a22ce5d0ce9ba7b4d9591640596e80b4d924659dd84746f97d4fd9f5ff98febed478979f78050","file_path":"legal-nlp-survey-20250328-002/original/Schmedding_2018_0176.pdf","title":"AI Approaches to the Complexity of Legal Systems","llm_title":"EuroVoc-Based Summarization of European Case Law","authors":["Ugo Pagallo","Florian Schmedding","Peter Klügl","David Baehrens","Christian Simon","Kai Simon","Katrin Tomanek"],"llm_authors":"Florian Schmedding, Peter Klügl, David Baehrens, Christian Simon, Kai Simon, and Katrin Tomanek","author_string":"Ugo Pagallo","year":2021,"abstract":"","llm_abstract":"This work reports on the ongoing development of a multilingual pipeline for the summarization of European case law. We apply the TextRank algorithm on concepts of the EuroVoc thesaurus in order to extract summarizing keywords and sentences. In a first case study, we demonstrate the feasibility and usefulness of the presented approach for five different languages and 18 document sources.","llm_keywords":["EuroVoc","TextRank","multilingual pipeline","European case law","text summarization","natural language processing","UIMA framework","legal information systems"],"classifications":["Machine Summarization","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":15},{"id":"948cd0dcf7ec8956ca26318821c42b34c3499c03711958b2c91df757e3c6fcfdbcf5985747e3ab787511e5912248a854626dec514c41c219a0b880448a922f98","file_path":"legal-nlp-survey-20250328-002/original/Xenouleas_2022_0591.pdf","title":"Realistic Zero-Shot Cross-Lingual Transfer in Legal Topic Classification","llm_title":"Realistic Zero-Shot Cross-Lingual Transfer in Legal Topic Classification","authors":["Stratos Xenouleas","Alexia Tsoukara","Giannis Panagiotakis","Ilias Chalkidis","Ion Androutsopoulos"],"llm_authors":"Stratos Xenouleas [1,2], Alexia Tsoukara [2], Giannis Panagiotakis [2], Ilias Chalkidis [1,2,3], Ion Androutsopoulos [1]","author_string":"","year":2022,"abstract":"","llm_abstract":"We consider zero-shot cross-lingual transfer in legal topic classification using the recent Multi-EURLEX dataset. Since the original dataset contains parallel documents, which is unrealistic for zero-shot cross-lingual transfer, we develop a new version of the dataset without parallel documents. We use it to show that translation-based methods vastly outperform cross-lingual fine-tuning of multilingually pre-trained models, the best previous zero-shot transfer method for Multi-EURLEX. We also develop a bilingual teacher-student zero-shot transfer approach, which exploits additional unlabeled documents of the target language and performs better than a model fine-tuned directly on labeled target language documents.","llm_keywords":["natural language processing","legal text classification","zero-shot cross-lingual transfer learning","transformer-based language models","multi-EURLEX dataset","multilingual pre-trained models","neural machine translation","bilingual teacher-student approach"],"classifications":["Classification","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":8},{"id":"470cb33db48271b31a92ff4760988fba9b11545e81f6d0b769cac09b5b45d7cb554e20fadaec9e77d7880778dee9ada625115afc311c1636bae7286f2863a4a5","file_path":"legal-nlp-survey-20250328-002/original/Lam_2021_0413.pdf","title":"Microsoft Word - MLLD workshop_final_version (1).docx","llm_title":"Detection of Similar Legal Cases on Personal Injury","authors":["Jason Lam","Yuhao Chen","Farhana Zulkernine","Samuel Dahan"],"llm_authors":"Jason Lam, Yuhao Chen, Farhana Zulkernine, Samuel Dahan","author_string":"","year":2021,"abstract":"","llm_abstract":"The Canadian case system is based on the principle of stare decisis and the concept that like cases should be decided alike. Each judge, when deciding a matter before him or her, selects the prior cases on which to rely. Recently researchers have begun exploring the use of legal text data to find similar cases to assist lawyers with legal research as well as to assist self-represented litigants with legal aid tools. Due to differences in writing style, verbosity, variation in feature importance, case complexity, and subjective bias in judgements, the analysis of legal text using computational models offers interesting challenges for computer scientists. In this study, we explore the problem of finding similar personal injury cases in which plaintiffs claimed compensation specifically for neck and/or back injuries. We extracted and pre-processed unlabeled legal text data and developed deep-learning models across three stages to gradually improve model performance. At each stage, the subset of results was evaluated and validated by a team of lawyers based on qualitative criteria, with the feedback used to refine the model at the next stage. The results demonstrate that semantic similarity between two cases does not ensure that they are legally similar, and artificial intelligence and deep learning techniques for analyzing legal text data can help detect legally similar cases.","llm_keywords":["personal injury","neck and/or back injuries","legal case","statutory law","text analytics","deep learning","Natural Language Processing","AI in legal domain","case-law precedent"],"classifications":["Classification","Pre-Processing","Information Retrieval","Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":9},{"id":"13dd62ba5ef4c35cc532332d2a2066c24c2b80788e9139139911e3b1936cea1fc7ee15d9b582da8d58ee64df91fa703817bc55d05aec8316938eadc99c140297","file_path":"legal-nlp-survey-20250328-002/original/Tziafas_2021_0382.pdf","title":"A Multilingual Approach to Identify and Classify Exceptional Measures against COVID-19","llm_title":"A Multilingual Approach to Identify and Classify Exceptional Measures Against COVID-19","authors":["Georgios Tziafas","Eugenie de Saint-Phalle","Wietse de Vries","Clara Egger","Tommaso Caselli"],"llm_authors":"Georgios Tziafas, Eugenie de Saint-Phalle, Wietse de Vries, Clara Egger, Tommaso Caselli","author_string":"Georgios Tziafas ; Eugenie de Saint-Phalle ; Wietse de Vries ; Clara Egger ; Tommaso Caselli","year":2021,"abstract":"","llm_abstract":"The COVID-19 pandemic has witnessed the implementations of exceptional measures by governments across the world to counteract its impact. This work presents the initial results of an on-going project, EXCEPTIUS, aiming to automatically identify, classify and compare exceptional measures against COVID-19 across 32 countries in Europe. To this goal, we created a corpus of legal documents with sentence-level annotations of eight different classes of exceptional measures that are implemented across these countries. We evaluated multiple multi-label classifiers on a manually annotated corpus at sentence level. The XLM-RoBERTa model achieves highest performance on this multilingual multi-label classification task, with a macro-average F1 score of 59.8%.","llm_keywords":["COVID-19","exceptional measures","multilingual","legal documents","classification","XLM-RoBERTa","Europe","LegalAI"],"classifications":["Classification","Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":17},{"id":"fa01f07602f63ce71171dbca41f80423c50bd7da4484c5b6e2fe5043133113ea195f97b5d990b5584d24b3655ed0c63c8df6a5b4653a3fcecef5f2d2f8086929","file_path":"legal-nlp-survey-20250328-002/original/Polsley_2016_0086.pdf","title":"CaseSummarizer: A System for Automated Summarization of Legal Texts","llm_title":"CaseSummarizer: A System for Automated Summarization of Legal Texts","authors":["Seth Polsley","Pooja Jhunjhunwala","Ruihong Huang"],"llm_authors":"Seth Polsley, Pooja Jhunjhunwala, Ruihong Huang","author_string":"Seth Polsley ; Pooja Jhunjhunwala ; Ruihong Huang","year":2016,"abstract":"","llm_abstract":"Attorneys, judges, and others in the justice system are constantly surrounded by large amounts of legal text, which can be difficult to manage across many cases. We present CaseSummarizer, a tool for automated text summarization of legal documents which uses standard summary methods based on word frequency augmented with additional domain-specific knowledge. Summaries are then provided through an informative interface with abbreviations, significance heat maps, and other flexible controls. It is evaluated using ROUGE and human scoring against several other summarization systems, including summary text and feedback provided by domain experts.","llm_keywords":["automated text summarization","legal documents","extraction-based methods","domain-specific knowledge","significance heat map"],"classifications":["Machine Summarization"],"num_cited_by":124,"num_cited_by_title_only":124,"num_pages":5},{"id":"a15bd75c9e4d61999133af3582a24c497babb7ccbdbbf281475ea31bae5a6edd3099c5e1e06a4b7578830c7509c56f23a83e46c144ccb498cd981f05b0e5107a","file_path":"legal-nlp-survey-20250328-002/original/Khasianov_2018_0186.pdf","title":"Lawyer&#x0027;s Intellectual Tool for Analysis of Legal Documents in Russian","llm_title":"Lawyer’s Intellectual Tool for Analysis of Legal Documents in Russian","authors":["A. Khasianov","I. Alimova","A. Marchenko","G. Nurhambetova","E. Tutubalina","D. Zuev"],"llm_authors":"A. Khasianov, I. Alimova, A. Marchenko, G. Nurhambetova, E. Tutubalina, D. Zuev","author_string":"","year":2018,"abstract":"","llm_abstract":"In the field of jurisprudence, document management plays a key role. Lawyers have to process a large volume of text documents in order to find necessary information. In this paper, we present “Robot Lawyer” intellectual system. The main goal of the system is to assist lawyers and citizens in providing the necessary information regarding legal processes. “Robot Lawyer” includes an expert system that use a set of rules to provide reference information and neural network models to give an answer on more complex questions. The article also describes the methods applied for processing textual information. The system developed for the Russian language.","llm_keywords":["legal text processing","expert system","neural network","named entity recognition","jurisprudence","document management","information system"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":5},{"id":"15ff5ee8dd994fc8c05136c4893b4b5ccb509e05bc93f0f3852102fe7e09612ac6353c40b8c5b3deac735b3a5eb4e9d4fdbddd48948ecc43b74622b9efef4912","file_path":"legal-nlp-survey-20250328-002/original/Waltl_2016_0089.pdf","title":"","llm_title":"Differentiation and Empirical Analysis of Reference Types in Legal Documents","authors":["Bernhard Waltl","Jorg Landthaler","Florian Matthes"],"llm_authors":"Bernhard Waltl, Jorg Landthaler, Florian Matthes","author_string":"","year":2016,"abstract":"","llm_abstract":"This paper proposes an extensible model distinguishing between reference types within legal documents. It differentiates between four types of references, namely fully-explicit, semi-explicit, implicit, and tacit references. We conducted a case study on German laws to evaluate both: the model and the proposed differentiation of reference types. We adapted text mining algorithms to determine and classify the different references according to their type. The evaluation shows that the consideration of additional reference types heavily impacts the resulting network structure by inducing a plethora of new edges and relationships. This work extends the approaches made in network analysis and argues for the necessity of detailed differentiation between references throughout legal documents.","llm_keywords":["references","reference types","citations","natural language processing","text mining","legal documents","German laws","data analysis"],"classifications":["Classification","Information Extraction"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":4},{"id":"47adbee6c21df36bab7b9addda0ed1fbb9769fdedcfb00164fda53c389c6687b90146671ce7b624791033f09ec787eb26c94a8a944e40c28fb5961e7e173a7cf","file_path":"legal-nlp-survey-20250328-002/original/Shao_2020_0308.pdf","title":"BERT-PLI: Modeling Paragraph-Level Interactions for Legal Case Retrieval","llm_title":"BERT-PLI: Modeling Paragraph-Level Interactions for Legal Case Retrieval","authors":["Yunqiu Shao","Jiaxin Mao","Yiqun Liu","Weizhi Ma","Ken Satoh","Min Zhang","Shaoping Ma"],"llm_authors":"Yunqiu Shao, Jiaxin Mao, Yiqun Liu, Weizhi Ma, Ken Satoh, Min Zhang, Shaoping Ma","author_string":"Yunqiu Shao, Jiaxin Mao, Yiqun Liu, Weizhi Ma, Ken Satoh, Min Zhang, Shaoping Ma","year":2020,"abstract":"","llm_abstract":"Legal case retrieval is a specialized IR task that involves retrieving supporting cases given a query case. Compared with traditional ad-hoc text retrieval, the legal case retrieval task is more challenging since the query case is much longer and more complex than common keyword queries. Besides that, the definition of relevance between a query case and a supporting case is beyond general topical relevance and it is therefore difficult to construct a large-scale case retrieval dataset, especially one with accurate relevance judgments. To address these challenges, we propose BERT-PLI, a novel model that utilizes BERT to capture the semantic relationships at the paragraph-level and then infers the relevance between two cases by aggregating paragraph-level interactions. We fine-tune the BERT model with a relatively small-scale case law entailment dataset to adapt it to the legal scenario and employ a cascade framework to reduce the computational cost. We conduct extensive experiments on the benchmark of the relevant case retrieval task in COLIEE 2019. Experimental results demonstrate that our proposed method outperforms existing solutions.","llm_keywords":["Legal case retrieval","BERT","Paragraph-level interactions","Semantic relationships","Relevance judgments","Cascade framework","Legal information retrieval","COLIEE 2019"],"classifications":["Information Retrieval","Classification"],"num_cited_by":179,"num_cited_by_title_only":179,"num_pages":7},{"id":"ed3e92b3699af26fc249f531b1224d5b3a57d5a996d11227bbb5b5d0a556fb51ed939553f8ac1dc49fa647c7817e5c50475a5e761a32e1e738cc5a96d075e5e7","file_path":"legal-nlp-survey-20250328-002/original/Asooja_2017_0115.pdf","title":"","llm_title":"Automatic Detection of Significant Updates in Regulatory Documents","authors":["Kartik Asooja","Oscar O Foghlú","Breiffni Ó Domhnaill","George Marchin","Sean McGrath"],"llm_authors":"Kartik Asooja, Oscar O Foghlú, Breiffni Ó Domhnaill, George Marchin, Sean McGrath","author_string":"","year":2017,"abstract":"","llm_abstract":"Regulations and legislations are regularly updated, which significantly burdens up the lawyers and compliance officers with a firehose of changes. However, not all changes are significant, and only a percentage of them are of legal importance. This percentage can certainly vary in different types of regulations. This paper focuses on automatic detection or ranking of meaningful legal changes, and presents a preliminary approach based on machine learning for the same, in the domain of Internal Revenue Code (IRC) related regulatory documents. Such system would provide the users with a means to quickly identify significant legal changes.","llm_keywords":["Change detection","Version","Regulation","Regulatory Change Management","Machine Learning"],"classifications":["Classification","Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"a761d303e85231ab31bd304f13b83913e6402ac6a395d9e4b42953cc000cc6ac160f39de35b644e198133b06a5643f5ec5c319d27addf2656763a3c4a5b66b77","file_path":"legal-nlp-survey-20250328-002/original/Tang_2019_0216.pdf","title":"","llm_title":"An Examination of the Validity of General Word Embedding Models for Processing Japanese Legal Texts","authors":["Linyuan Tang","Kyo Kageura"],"llm_authors":"Linyuan Tang, Kyo Kageura","author_string":"","year":2019,"abstract":"","llm_abstract":"Thanks to the recent developments in distributed representation learning and the large amounts of published and digitized legal texts, computational linguistic analysis of legal language becomes possible and efficient. However, most of these open language resources and shared tasks are in English. For the languages that have little open legal texts like Japanese, a word embedding model trained on the specific language usages is accompanied by the concern of less accuracy and representativeness. Based on the observation that legal language shares a modest common vocabulary with general language, we examined the validity of using the pre-trained general word embedding model for processing legal texts by an intrinsic evaluation constructed on pairs of synonyms and related terms which were extracted from a legal term dictionary. We first investigated the settings of hyperparameters of the embedding models trained on legal texts. Then we compared the performances of our domain-specific models with general models. The pre-trained Wikipedia model conducted a better performance than domain-specific models on detecting semantic relations. This model also showed a higher compatibility with legal texts than the general model trained on newspaper articles. Although researchers tend to indicate the importance of domain-specific representation models, a general model can still be an alternative solution when there is little language resource.","llm_keywords":["word embedding","Japanese legal texts","distributed representation learning","general vs domain-specific models","semantic analysis","language resources"],"classifications":["Resources","Pre-Processing"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":4},{"id":"431349f24dd254b42792e8f5bc24db6db6fdcf85ae51118d6e790775d57756d423008a7baa67ec174109e9e1c8f90d1977e255621487d6cb7ca1886909c74f94","file_path":"legal-nlp-survey-20250328-002/original/George_2014_0042.pdf","title":"SMART Electronic Legal Discovery via Topic Modeling","llm_title":"SMART Electronic Legal Discovery via Topic Modeling","authors":["Clint P. George","Sahil Puri","Daisy Zhe Wang","Joseph N. Wilson","William F. Hamilton"],"llm_authors":"Clint P. George, Sahil Puri, Daisy Zhe Wang, and Joseph N. Wilson, William F. Hamilton","author_string":"Clint P. George, Sahil Puri, Daisy Zhe Wang, Joseph N. Wilson, William F. Hamilton","year":2014,"abstract":"","llm_abstract":"Electronic discovery is an interesting sub problem of information retrieval in which one identifies documents that are potentially relevant to issues and facts of a legal case from an electronically stored document collection (a corpus). In this paper, we consider representing documents in a topic space using the well-known topic models such as latent Dirichlet allocation and latent semantic indexing, and solving the information retrieval problem via finding document similarities in the topic space rather doing it in the corpus vocabulary space. We also develop an iterative SMART ranking and categorization framework including human-in-the-loop to label a set of seed (training) documents and using them to build a semi-supervised binary document classification model based on Support Vector Machines. To improve this model, we propose a method for choosing seed documents from the whole population via an active learning strategy. We report the results of our experiments on a real dataset in the electronic discovery domain.","llm_keywords":["e-discovery","information retrieval","topic modeling","latent Dirichlet allocation","latent semantic indexing","Support Vector Machines","active learning","computer assisted review","document categorization","relevance-ranking"],"classifications":["Information Retrieval","Classification"],"num_cited_by":2,"num_cited_by_title_only":7,"num_pages":6},{"id":"efc4b1dd7f666dc4cf94e26d64c545fc88e0a8bfac85b3e59f5d4a7d5077df0b93ba9b1752bf0583f6c5953c205e3a21478162110caa40b4df987a9ac6be294c","file_path":"legal-nlp-survey-20250328-002/original/Moraes-Rosa_2021_0475.pdf","title":"","llm_title":"To Tune or Not To Tune? Zero-shot Models for Legal Case Entailment","authors":["Guilherme Moraes Rosa","Ruan Chaves Rodrigues","Roberto de Alencar Lotufo","Rodrigo Nogueira"],"llm_authors":"Guilherme Moraes Rosa, Ruan Chaves Rodrigues, Roberto de Alencar Lotufo, Rodrigo Nogueira","author_string":"","year":2021,"abstract":"","llm_abstract":"There has been mounting evidence that pretrained language models fine-tuned on large and diverse supervised datasets can transfer well to a variety of out-of-domain tasks. In this work, we investigate this transfer ability to the legal domain. For that, we participated in the legal case entailment task of COLIEE 2021, in which we use such models with no adaptations to the target domain. Our submissions achieved the highest scores, surpassing the second-best submission by more than six percentage points. Our experiments confirm a counter-intuitive result in the new paradigm of pretrained language models: given limited labeled data, models with little or no adaption to the target task can be more robust to changes in the data distribution than models fine-tuned on it. Code is available at https://github.com/neuralmind-ai/coliee.","llm_keywords":["Legal NLP","Legal Case Entailment","Deberta","T5","Zero-shot"],"classifications":["Classification"],"num_cited_by":21,"num_cited_by_title_only":21,"num_pages":6},{"id":"3bb33d753ab10785a93c2308a23841802306731d0a913964123d6277f0dc9b818e282921b20396eaaa61af3a05b620c3dc3cde00d1cdb0abfa75e3bbf248a2d9","file_path":"legal-nlp-survey-20250328-002/original/Xu_2020_0373.pdf","title":"","llm_title":"Using Argument Mining for Legal Text Summarization","authors":["Huihui Xu","Jaromír Šavelka","Kevin D. Ashley"],"llm_authors":"Huihui Xu, Jaromír Šavelka, and Kevin D. Ashley","author_string":"","year":2020,"abstract":"","llm_abstract":"Argument mining, a subfield of natural language processing and text mining, is a process of extracting argumentative text portions and identifying the role the selected texts play. Legal argument mining targets the argumentative parts of a legal text. In order to better understand how to apply legal argument mining as a step toward improving case summarization, we have assembled a sizeable set of cases and human-expert-prepared summaries annotated in terms of legal argument triples that capture the most important skeletal argument structures in a case. We report the results of applying multiple machine learning techniques to demonstrate and analyze the advantages and disadvantages of different methods to identify sentence components of these legal argument triples.","llm_keywords":["argument mining","legal text","summarization","machine learning","legal argument triples","information retrieval","legal analysis","relevant sentences"],"classifications":["Information Extraction","Machine Summarization"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":10},{"id":"1a8921076d6374c7963966dd7dbfa69dfd76385497727aa38a5266b5e57133208091343a60735cd10827ffa809010c714d24ab6bf6f568f67919aa70795d1c68","file_path":"legal-nlp-survey-20250328-002/original/Wang_2018_0163.pdf","title":"Microsoft Word - grad_thesis_v5.docx","llm_title":"An Unsupervised Approach to Relatedness Analysis of Legal Language","authors":["Ying Wang"],"llm_authors":"Ying Wang","author_string":"","year":2018,"abstract":"","llm_abstract":"Learning distributed representations of sentences and analyzing semantic similarity between sentences is one of the essential works in the field of Natural Language Processing. In the domain of legal language, the future of Artificial Intelligence-related legal-tech applications is very promising. This thesis comprises a very detailed investigation of distributional representations of words and sentences, and the related machine learning and deep learning techniques. Then, we proposed an innovative approach, Word2Sent, for measuring the degree of similarity between sentences. The proposed model is completely in an unsupervised manner. Thus, it can be well applied with unlabeled data. An enhancement of the other unsupervised sentence embeddings model, SIF-model, is made by this thesis. Demonstrated by multiple experiments, our proposed model can effectively work with long legal sentences on several textual similarity tasks.","llm_keywords":["Natural Language Processing","Legal Language","Sentence Similarity","Deep Learning","Unsupervised Learning","Word2Sent","Machine Learning","Sentence Embeddings","AI in Legal Tech"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":90},{"id":"80ee80d1bacb9991c2b111b6485b1800ffe27314e80d933e64a4114d97cf0413784b6704e5b215791752d3d165ca45d93a7ec83ac1b89b61f02ef043896f2ced","file_path":"legal-nlp-survey-20250328-002/original/Torrisi_2019_0222.pdf","title":"178_Torrisi.pdf","llm_title":"Automated Bundle Pagination Using Machine Learning","authors":["Alessandro Torrisi","Robert Bevan","Katie Atkinson","Danushka Bollegala","Frans Coenen"],"llm_authors":"Alessandro Torrisi, Robert Bevan, Katie Atkinson, Danushka Bollegala, Frans Coenen","author_string":"","year":2019,"abstract":"","llm_abstract":"Coherent division of legal document bundles, whether this is done in the context of court bundles, briefs or some other application, is a time consuming and challenging task. We propose an approach whereby this process can be automated. Two variations are considered. The first addresses the scenario where the topic labelling is pre-defined and adopts a supervised learning approach. The second addresses the scenario where the topic labelling, for whatever reason, is not specified in advance and adopts an unsupervised learning approach. This paper reports on an investigation of both mechanisms using accident claims bundles. The evaluation results indicate that the proposed approaches can be successfully applied to divide legal document bundles.","llm_keywords":["machine learning","legal documents","pagination","unsupervised learning","supervised learning","document classification","text processing","artificial intelligence"],"classifications":["Classification"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":5},{"id":"2534f1b4d79c8d9f343ec4382e8e63c010dfdb2f9a0c23f735b56c04e0232c05599e2b0731028798bbcafdef31c22bda7464ee32e069534f9049c183b980a77d","file_path":"legal-nlp-survey-20250328-002/original/Xu_2021_0476.pdf","title":"","llm_title":"Toward Summarizing Case Decisions via Extracting Argument Issues, Reasons, and Conclusions","authors":["Huihui Xu","Jaromir Savelka","Kevin D. Ashley"],"llm_authors":"Huihui Xu, Jaromir Savelka, Kevin D. Ashley","author_string":"","year":2021,"abstract":"","llm_abstract":"In this paper, we assess the use of several deep learning classification algorithms as a step toward automatically preparing succinct summaries of legal decisions. Short case summaries that tease out the decision’s argument structure by making explicit its issues, conclusions, and reasons (i.e., argument triples) could make it easier for the lay public and legal professionals to gain an insight into what the case is about. We have obtained a sizeable dataset of expert-crafted case summaries paired with full texts of the decisions issued by various Canadian courts. As the manual annotation of the full texts is prohibitively expensive, we explore various ways of leveraging the existing longer summaries which are much less time-consuming to annotate. We compare the performance of the systems trained on the annotations that are manually ported to the full texts from the summaries to the performance of the same systems trained on annotations that are projected from the summaries automatically. The results show the possibility of pursuing the automatic annotation in the future.","llm_keywords":["Information retrieval","argument mining","legal analysis","relevant sentences","summarization"],"classifications":["Classification","Machine Summarization"],"num_cited_by":25,"num_cited_by_title_only":25,"num_pages":5},{"id":"89d7635dab5e970aefbac43ff3936810c6b6037e8981f66a2d183be9fd13e312b9a10e39431676ac64e31cfa6ad41e3e4685de1df49bae61b35763808f806223","file_path":"legal-nlp-survey-20250328-002/original/Adebayo_2016_0097.pdf","title":"","llm_title":"Neural Reasoning For Legal Text Understanding","authors":["Kolawole John Adebayo","Guido Boella","Luigi Di Caro"],"llm_authors":"Kolawole John ADEBAYO, Guido BOELLA, Luigi DI CARO","author_string":"","year":2016,"abstract":"","llm_abstract":"We propose a domain specific Question Answering system. We deviate from approaching this problem as a Textual Entailment task. We implemented a Memory Network-based Question Answering system which test a Machine’s understanding of legal text and identifies whether an answer to a question is correct or wrong, given some background knowledge. We also prepared a corpus of real USA MBE Bar exams for this task. We report our initial result and direction for future works.","llm_keywords":["Question Answering","LSTM","LQA","Memory Networks","Neural networks"],"classifications":["Information Retrieval"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":4},{"id":"e96b2be1d481edf86e1b3a8c315e23962aee2a32358aca9e9b40b76d5f1c0ea533b10f6a4be01fe9064010da20ac7254f2e541ce5dc2390991aeed34f6b9974d","file_path":"legal-nlp-survey-20250328-002/original/Vinjumur_2015_0059.pdf","title":"","llm_title":"Evaluating Expertise and Sample Bias Effects for Privilege Classification in E-Discovery","authors":["Anne Gardner","Jyothi K. Vinjumur"],"llm_authors":"Jyothi K. Vinjumur","author_string":"Anne Gardner","year":2015,"abstract":"","llm_abstract":"In civil litigation, documents that are found to be relevant to a production request are usually subjected to an exhaustive manual review for privilege (e.g., for attorney-client privilege, attorney-work product doctrine) in order to be sure that materials that could be withheld are not inadvertently revealed. Usually, the majority of the cost associated with such a review process is due to the procedure of having human annotators linearly review documents (for privilege) that the classifier predicts as responsive. This paper investigates the extent to which such privilege judgments obtained by the annotators are useful for training privilege classifiers. The judgments utilized in this paper are derived from the privilege test collection that was created during the 2010 TREC Legal Track. The collection consists of two classes of annotators: “expert” judges, who are topic originators called the Topic Authority (TA) and “non-expert” judges called assessors. The questions asked in this paper are; (1) Are cheaper, non-expert annotations from assessors sufficient for classifier training? (2) Does the process of selecting special (adjudicated) documents for training affect the classifier results? The paper studies the effect of training classifiers on multiple annotators (with different expertise) and training sets (with and without selection bias). The findings in this paper show that automated privilege classifiers trained on the unbiased set of annotations yield the best results. The usefulness of the biased annotations (from experts and non-experts) for classifier training are comparable.","llm_keywords":["E-Discovery","Privilege Classification","Civil Litigation","Manual Review","Attorney-Client Privilege","Training Classifiers","Annotators","Privilege Judgments"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":9},{"id":"814c03e6aaaf118b9a0a92fb7de099af36d4265888e79d27d2d5e649e9f6989e35cf8d7b35c7dbee9cdac55ed663d28af87558accfd63153720fb78395572495","file_path":"legal-nlp-survey-20250328-002/original/Risch_2019_0237.pdf","title":"Domain-specific word embeddings for patent classification","llm_title":"Domain-specific word embeddings for patent classification","authors":["Julian Risch","Ralf Krestel"],"llm_authors":"Julian Risch, Ralf Krestel","author_string":"Julian Risch and Ralf Krestel","year":2019,"abstract":"","llm_abstract":"Purpose – Patent offices and other stakeholders in the patent domain need to classify patent applications according to a standardized classification scheme. The purpose of this paper is to examine the novelty of an application it can then be compared to previously granted patents in the same class. Automatic classification would be highly beneficial, because of the large volume of patents and the domain-specific knowledge needed to accomplish this costly manual task. However, a challenge for the automation is patent-specific language use, such as special vocabulary and phrases. Design/methodology/approach – To account for this language use, the authors present domain-specific pre-trained word embeddings for the patent domain. The authors train the model on a very large data set of more than 5m patents and evaluate it at the task of patent classification. To this end, the authors propose a deep learning approach based on gated recurrent units for automatic patent classification built on the trained word embeddings. Findings – Experiments on a standardized evaluation data set show that the approach increases average precision for patent classification by 17 percent compared to state-of-the-art approaches. In this paper, the authors further investigate the model’s strengths and weaknesses. An extensive error analysis reveals that the learned embeddings indeed mirror patent-specific language use. The imbalanced training data and underrepresented classes are the most difficult remaining challenge. Originality/value – The proposed approach fulfills the need for domain-specific word embeddings for downstream tasks in the patent domain, such as patent classification or patent analysis.","llm_keywords":["Deep learning","Document classification","Word embedding","Patents","Patent classification","Domain-specific language","Gated recurrent units","Automatic classification","Patent domain"],"classifications":["Classification","Pre-Processing","Resources"],"num_cited_by":90,"num_cited_by_title_only":90,"num_pages":16},{"id":"f2d076b7215d6c5d3e1b3704951de9ef451c8dde47404aaa564b0d17047e8cecb97952c2520474477f1d60cc562240e0f929d8ce36ee3d0dae3456883594b529","file_path":"legal-nlp-survey-20250328-002/original/Niklaus_2021_0471.pdf","title":"Swiss-Judgment-Prediction: A Multilingual Legal Judgment Prediction Benchmark","llm_title":"Swiss-Judgment-Prediction: A Multilingual Legal Judgment Prediction Benchmark","authors":["Joel Niklaus","Ilias Chalkidis","Matthias Stürmer"],"llm_authors":"Joel Niklaus, Ilias Chalkidis, Matthias Stürmer","author_string":"Joel Niklaus ; Ilias Chalkidis ; Matthias Stürmer","year":2021,"abstract":"","llm_abstract":"In many jurisdictions, the excessive workload of courts leads to high delays. Suitable predictive AI models can assist legal professionals in their work, and thus enhance and speed up the process. So far, Legal Judgment Prediction (LJP) datasets have been released in English, French, and Chinese. We publicly release a multilingual (German, French, and Italian), diachronic (2000-2020) corpus of 85K cases from the Federal Supreme Court of Switzerland (FSCS). We evaluate state-of-the-art BERT-based methods including two variants of BERT that overcome the BERT input (text) length limitation (up to 512 tokens). Hierarchical BERT has the best performance (approx. 68-70% Macro-F1-Score in German and French). Furthermore, we study how several factors (canton of origin, year of publication, text length, legal area) affect performance. We release both the benchmark dataset and our code to accelerate future research and ensure reproducibility.","llm_keywords":["Legal Judgment Prediction","Multilingual Dataset","BERT","Natural Language Processing","AI in Law","Federal Supreme Court of Switzerland","Text Classification","Judicial Process Automation"],"classifications":["Classification","Resources"],"num_cited_by":82,"num_cited_by_title_only":82,"num_pages":17},{"id":"6386217e57c2121887dd5064e45fa4af72bdce757ceedbb1de1add4a9c51537d1cbacdb4d852016ab8d770ad462f5c111930cb071980e3882da0ea5cc7a7dd59","file_path":"legal-nlp-survey-20250328-002/original/Mastropaolo_2013_0017.pdf","title":"Legal documents categorization by compression","llm_title":"Legal Documents Categorization by Compression","authors":["Antonio Mastropaolo","Francesco Pallante","Daniele P. Radicioni"],"llm_authors":"Antonio Mastropaolo, Francesco Pallante, Daniele P. Radicioni","author_string":"Antonio Mastropaolo, Francesco Pallante, Daniele P. Radicioni","year":2013,"abstract":"","llm_abstract":"In this paper we investigate how to categorize text excerpts from Italian normative texts. Although text categorization is a problem of broader interest, we single out a specific issue. Namely, we are concerned with categorizing the set of subjects in which Italian Regions are allowed to produce norms: this is the so-called residual legislative power problem. It basically consists in making explicit a set of subjects that was originally defined only in a residual and negative fashion. The categorization of legal text fragments is acknowledged to be a difficult problem, featured by abstract concepts along with a variety of locutions used to denote them, by convoluted sentence structure, and by several other facets. In addition, in the present case subjects are often partially overlapped, and a training set of sufficient size (for the problem under consideration) does not exist: all these aspects make our task challenging. In this setting, classical feature-based approaches provide poor quality results, so we explored algorithms based on compression techniques. We tested three such techniques: we illustrate their main features and report the results of an experimentation where our implementation of such algorithms is compared with the output of standard machine learning algorithms. Far from having found a silver bullet, we show that compression-based techniques provide the best results for the problem at hand, and argue that these approaches can be effectively coupled with more informative and semantically grounded ones.","llm_keywords":["Legal text categorization","Compression techniques","Residual legislative power","Italian normative texts","Machine learning","Document indexing"],"classifications":["Classification","Information Extraction"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":9},{"id":"c3d299d94639441019a5c661c187193b65bf99a9287728feb7f723d6189e8b285f2dbe6a93e2c98e796bd31bf48b0ee76103e66186f394a4b510e4c697f35045","file_path":"legal-nlp-survey-20250328-002/original/Rossi_2018_0201.pdf","title":"","llm_title":"Query Generation for Patent Retrieval with Keyword Extraction Based on Syntactic Features","authors":["Julien Rossi","Evangelos Kanoulas"],"llm_authors":"Julien ROSSI, Evangelos KANOULAS","author_string":"","year":2018,"abstract":"","llm_abstract":"This paper describes a new method to extract relevant keywords from patent claims, as part of the task of retrieving other patents with similar claims (search for prior art). The method combines a qualitative analysis of the writing style of the claims with NLP methods to parse text, in order to represent a legal text as a specialization arborescence of terms. In this setting, the set of extracted keywords are yielding better search results than keywords extracted with traditional method such as tf-idf.","llm_keywords":["Patent","Claims","Legal Text","NLP","Information Retrieval"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":5},{"id":"21e4cd1b9214e06924f8d8b6d7f9a8b8f6795028574e9ce228faec7490212d4ef5a2339a7213961dda20ed4ea785e55578cb977bdca8d1cf190c3b84646f6b4b","file_path":"legal-nlp-survey-20250328-002/original/Abdurahman_2021_0444.pdf","title":"Lex2KG: Automatic Conversion of Legal Documents to Knowledge Graph","llm_title":"Lex2KG: Automatic Conversion of Legal Documents to Knowledge Graph","authors":["Muhamad Abdurahman","Fariz Darari","Hans Lesmana","Muhtar Hartopo","Immanuel Rhesa","Berty Chrismartin Lumban Tobing"],"llm_authors":"Muhamad Abdurahman, Fariz Darari, Hans Lesmana, Muhtar Hartopo, Immanuel Rhesa, Berty Chrismartin Lumban Tobing","author_string":"Muhamad Abdurahman; Fariz Darari; Hans Lesmana; Muhtar Hartopo; Immanuel Rhesa; Berty Chrismartin Lumban Tobing","year":2021,"abstract":"","llm_abstract":"Legal documents are generally available in the form of PDF which is not machine-readable. A knowledge graph (KG) is a graph describing real-world entities and their relationships, providing structured, machine-readable information. In this paper, we present Lex2KG, a framework for converting legal (PDF) documents into a KG. The legal KG contains various kinds of structured data, such as metadata, document structures, textual content, and relations between legal resources (e.g., amendments and citations). Through Lex2KG, we have successfully converted 784 Indonesian laws into a KG with a total size of over 1.1 million triples. We also present use cases of the legal KG for SPARQL querying, simple chatbots, and legal visualizations, showing how the legal KG generated can be useful in practice.","llm_keywords":["Law","PDF","Conversion","RDF","SPARQL","Legal Documents","Knowledge Graph"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":5},{"id":"93f22f0ac2147cfde867c44f20fd04660b92ac44d4513854e6d3ead907d4f437386fe385879b8f0b1aff9357339996f5940f7ec510108f73ffe57abce2d23d22","file_path":"legal-nlp-survey-20250328-002/original/Nguyen_2018_0202.pdf","title":"Recurrent neural network-based models for recognizing requisite and effectuation parts in legal texts","llm_title":"Recurrent neural network-based models for recognizing requisite and effectuation parts in legal texts","authors":["Truong-Son Nguyen","Le-Minh Nguyen","Satoshi Tojo","Ken Satoh","Akira Shimazu"],"llm_authors":"Truong-Son Nguyen, Le-Minh Nguyen, Satoshi Tojo, Ken Satoh, Akira Shimazu","author_string":"Truong-Son Nguyen","year":2018,"abstract":"","llm_abstract":"This paper proposes several recurrent neural network-based models for recognizing requisite and effectuation (RE) parts in Legal Texts. Firstly, we propose a modification of BiLSTM-CRF model that allows the use of external features to improve the performance of deep learning models in case large annotated corpora are not available. However, this model can only recognize RE parts which are not overlapped. Secondly, we propose two approaches for recognizing overlapping RE parts including the cascading approach which uses the sequence of BiLSTM-CRF models and the unified model approach with the multilayer BiLSTM-CRF model and the multilayer BiLSTM-MLP-CRF model. Experimental results on two Japan law RRE datasets demonstrated advantages of our proposed models. For the Japanese National Pension Law dataset, our approaches obtained an F1 score of 93.27% and exhibited a significant improvement compared to previous approaches. For the Japan Civil Code RRE dataset which is written in English, our approaches produced an F1 score of 78.24% in recognizing RE parts that exhibited a significant improvement over strong baselines. In addition, using external features and in-domain pre-trained word embeddings also improved the performance of RRE systems.","llm_keywords":["Deep learning","Recurrent neural networks","Legal text analysis","Sequence labeling","BiLSTM-CRF","Conditional random fields","Requisite parts","Effectuation parts"],"classifications":["Information Extraction","Classification"],"num_cited_by":62,"num_cited_by_title_only":62,"num_pages":31},{"id":"7e455e8fe47b4494eec0487793578ee3e26306ab01764105557390bb3ccc31c0193045faef1f8098704266bb74c3b0b2d61e4fe9476fe0e27e02900474b4ea6f","file_path":"legal-nlp-survey-20250328-002/original/Gargett_2020_0320.pdf","title":"LegalOps: A Summarization Corpus of Legal Opinions","llm_title":"LegalOps: A Summarization Corpus of Legal Opinions","authors":["Andrew Gargett","Rob Firth","Nikolaos Aletras"],"llm_authors":"Andrew Gargett, Rob Firth, Nikolaos Aletras","author_string":"","year":2020,"abstract":"","llm_abstract":"We present a new, large-scale corpus for training and evaluating text summarization systems on legal opinions, called LegalOps. The corpus includes ∼14K opinions together with their summaries from U.S. Federal Courts, e.g. the Supreme Court and Federal Appeals Courts. The aim of this paper is to provide a novel data source of sufficient variety that it will advance theoretical work on modeling the particular patterns within legal discourse, but also of sufficient size that it will provide a new challenging testbed for state-of-the-art automatic summarization models.","llm_keywords":["legal","corpus","automatic summarization","U.S. Federal Courts","natural language processing","artificial intelligence","legal data","text summarization","legal opinions"],"classifications":["Machine Summarization","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":4},{"id":"56930edc6f536f44f5803be31e981314f3ee6bd0d82235e1f0fa5b6dff2e49d78449a6a2d9cedd851b4d85532d6455fe0b877cfcb85d7382c4af11191b0a2292","file_path":"legal-nlp-survey-20250328-002/original/Pham_2021_0442.pdf","title":"Legal Terminology Extraction with the Termolator","llm_title":"Legal Terminology Extraction with the Termolator","authors":["Nhi Pham","Lachlan Pham","Adam Meyers"],"llm_authors":"Nhi Pham, Lachlan Pham, Adam Meyers","author_string":"Nhi Pham ; Lachlan Pham ; Adam L. Meyers","year":2021,"abstract":"","llm_abstract":"Domain-specific terminology is ubiquitous in legal documents. Despite potential utility in populating glossaries and ontologies or as arguments in information extraction and document classification tasks, there has been limited work done for legal terminology extraction. This paper describes some work to remedy this omission. In the described research, we make some modifications to the Termolator, a high-performing, open-source terminology extractor which has been tuned to scientific articles. Our changes are designed to improve the Termolator’s results when applied to United States Supreme Court decisions. Unaltered and using the recommended settings, the original Termolator provides a list of terminology with a precision of 23% and 25% for the categories of economic activity (development set) and criminal procedures (test set) respectively. These were the most frequently occurring broad issues in Washington University in St. Louis Database corpus, a database of Supreme Court decisions that have been manually classified by topic. Our contribution includes the introduction of several legal domain-specific filtration steps and changes to the web search relevance score; each incrementally improved precision culminating in a combined precision of 63% and 65%. We also evaluated the baseline version of the Termolator on more specific subcategories and on broad issues with fewer cases. Our results show that a narrowed scope as well as smaller document numbers significantly lower the precision. In both cases, the modifications to the Termolator improve precision.","llm_keywords":["Legal Terminology","Termolator","Supreme Court","Natural Language Processing","Terminology Extraction","Document Classification","Relevance Score","Precision Improvement"],"classifications":["Pre-Processing","Information Extraction","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":8},{"id":"833f855f28b248d27e2bd09fecb0aecb27b64e902fcadf31a4fcbc6864139c34dc01e3966d2fa16ee971448ad9b45d18d87c631b64d64719160387241a225168","file_path":"legal-nlp-survey-20250328-002/original/Khasanah_2021_0419.pdf","title":"Extreme Multilabel Text Classification on Indonesian Tax Court Ruling using Single Channel CNN and IndoBERT Embedding","llm_title":"Extreme Multilabel Text Classification on Indonesian Tax Court Ruling using Single Channel CNN and IndoBERT Embedding","authors":["Isnaini Nurul Khasanah","Adila Alfa Krisnadhi"],"llm_authors":"Isnaini Nurul Khasanah, Adila Alfa Krisnadhi","author_string":"Isnaini Nurul Khasanah; Adila Alfa Krisnadhi","year":2021,"abstract":"","llm_abstract":"Manual searching for legal basis such as paragraphs, articles, and laws when preparing for a tax court hearing is time-consuming. In this paper, we use extreme multilabel text classification approach to predict paragraphs, articles, and laws relevant to an appeal on the Indonesian Tax Court Ruling documents. Traditional machine learning methods, such as random forest, can produce a good performance for an extreme multilabel text classification problem but requires training a huge number of separate classifiers. Meanwhile, deep learning methods such as convolutional neural networks (CNN) can effectively solve the extreme multilabel text classification problem. Furthermore, the use of IndoBERT embedding to represent Indonesian text in multilabel classification problems has not been explored much. This research proposes a single channel CNN model with IndoBERT embedding to solve extreme multilabel text classification problems on Indonesian Tax Court Ruling documents. We use three labeling scenarios: paragraph-level label scenario, article-level label scenario, and law-level label scenario. Our experiments demonstrate that our proposed model (CNN+IndoBERT) outperforms the single channel CNN with Word2Vec embedding and the single channel CNN with fastText embedding in all three labeling scenarios. In addition, our model also outperforms the multiple channel CNN with IndoBERT embedding in both paragraph and article-level label scenarios.","llm_keywords":["extreme multilabel classification","Indonesian Tax Court","CNN","IndoBERT","text classification","machine learning","legal documents","natural language processing"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":8},{"id":"2f3c5ee688589404162a0ed1bcfdb8834854f7d70cba728d5e278995dbd0d1f2f5b181ba3bc449f22437e1824975cbf751e8df1a45eb86d300c2b9fc76d40eb3","file_path":"legal-nlp-survey-20250328-002/original/Westermann_2019_0232.pdf","title":"","llm_title":"Computer-Assisted Creation of Boolean Search Rules for Text Classification in the Legal Domain","authors":["Hannes Westermann","Jaromír Savelka","Vern R. Walker","Kevin D. Ashley","Karim Benyekhlef"],"llm_authors":"Hannes Westermann, Jaromír Savelka, Vern R. Walker, Kevin D. Ashley, Karim Benyekhlef","author_string":"","year":2019,"abstract":"","llm_abstract":"In this paper, we present a method of building strong, explainable classifiers in the form of Boolean search rules. We developed an interactive environment called CASE (Computer Assisted Semantic Exploration) which exploits word co-occurrence to guide human annotators in selection of relevant search terms. The system seamlessly facilitates iterative evaluation and improvement of the classification rules. The process enables the human annotators to leverage the benefits of statistical information while incorporating their expert intuition into the creation of such rules. We evaluate classifiers created with our CASE system on 4 datasets, and compare the results to machine learning methods, including SKOPE rules, Random forest, Support Vector Machine, and fastText classifiers. The results drive the discussion on trade-offs between superior compactness, simplicity, and intuitiveness of the Boolean search rules versus the better performance of state-of-the-art machine learning models for text classification.","llm_keywords":["Artificial Intelligence & Law","Text Classification","Semantic exploration","Boolean search","Natural language processing","Explainable artificial intelligence"],"classifications":["Classification","Information Retrieval"],"num_cited_by":21,"num_cited_by_title_only":21,"num_pages":10},{"id":"100684e2271c4650d3f184bebda46161aa82559da029532a37659b5ead1fd92f52e78977d852648233c3c4e1d7a60f72d7e9ce1862540dbb2936c3f8a2d6f1f0","file_path":"legal-nlp-survey-20250328-002/original/Heo_2017_0132.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"Legal Content Fusion for Legal Information Retrieval","authors":["Seongwan Heo","Kihyun Hong","Young-Yik Rhim"],"llm_authors":"Seongwan Heo, Kihyun Hong, Young-Yik Rhim","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"With recent increasing attention to legal information processing, legal information retrieval (IR) has become one of the active research fields. However, there are still many hindrances obtaining rigorous results in legal IR applications in comparison with IR applications for general document retrieval. It is mainly due to the characteristics of legal information such as the complicated structure of legal contents and usage of legal jargon. In this paper, we present a legal IR method, which is a structure-wise IR approach. The presented method in this study focuses on analyzing the contents of legal documents and applying the content contributions to the IR processing. We demonstrate the performance of the proposed IR method with the COILEE data set, which are derived from Japanese bar exams.","llm_keywords":["legal information retrieval","legal text mining","machine learning","natural language processing","COILEE data set","legal content","legal documents","legal provisions"],"classifications":["Information Retrieval"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":5},{"id":"0f0480e1e4f537c71f9d0629397031d17354fd6e3990fefd27071513551948b48cbdc321b1a948223dd3228a1a530053341ea13c2e87af60ee3f35f51ab9ee22","file_path":"legal-nlp-survey-20250328-002/original/Leitner_2019_0244.pdf","title":"Semantic Systems. The Power of AI and Knowledge Graphs","llm_title":"Semantic Systems: The Power of AI and Knowledge Graphs","authors":["Maribel Acosta","Philippe Cudré-Mauroux","Maria Maleshkova","Tassilo Pellegrini","Harald Sack","York Sure-Vetter"],"llm_authors":"Maribel Acosta, Philippe Cudré-Mauroux, Maria Maleshkova, Tassilo Pellegrini, Harald Sack, York Sure-Vetter","author_string":"Maribel Acosta","year":2019,"abstract":"","llm_abstract":"","llm_keywords":["Semantic Systems","Artificial Intelligence","Knowledge Graphs","Machine Learning","Semantic Web","Data Science","Ontology Management","Natural Language Processing","Blockchain","LegalTech"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":400},{"id":"f7f6700e1f79c3bc204fb787aedec8c72b8b1b3384f1845c9ef82eaaa5bf3818a5c19f608312519c9a834d914a1a97bc9c15197154b6e3be3e865d945b88ec0c","file_path":"legal-nlp-survey-20250328-002/original/Nayak_2019_0224.pdf","title":"Automatic Detection and Analysis of DPP Entities in Legal Contract Documents","llm_title":"Automatic detection and analysis of DPP entities in legal contract documents","authors":["Shiva Prasad Nayak","Suresh Pasumarthi"],"llm_authors":"Shiva Prasad Nayak, Suresh Pasumarthi","author_string":"","year":2019,"abstract":"","llm_abstract":"Due to introduction of General Data Protection Regulation (GDPR) in EU; all the cloud hosted applications (span across multi geo location) wherein captures the personal data need to first identify data privacy protection (DPP) entities and handle it as per EU norms and regulations. The company’s legal contracts or transactions in tie up with other parties (customers, partners, suppliers, etc.) are usually stored in to repository; on termination of the contracts either by agreement or mutual consent then the other parties’ information are usually archived for historical reasons. The other parties are usually interested in knowing what all documents or transactions they were participated earlier and expects the data to be pruned on need basis. As these documents are unstructured in nature, this paper proposes a solution in identifying all DPP entities with in legal contract documents, index the corpus level accumulated knowledgebase, apply customized ranking algorithm for the retrieved legal contract documents based on DPP search query, derive DPP entities specific legal contract document dependency relation graph for which the parties are participating by using techniques from Information Retrieval, Information Extraction, Natural Language Processing (NLP) and Ontology.","llm_keywords":["Legal Contract Documents","GDPR","DPP","Information Retrieval","Information Extraction","Natural Language Processing","Ontology"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":6},{"id":"89f3ef5aa21c918a8bbde27f4f3e6cedd349b5f9b095aff29bb4e0597d190cd332f63e92a9365ef4135340217966ff941e4630ff6bdd87ceea70b66ccb28ed98","file_path":"legal-nlp-survey-20250328-002/original/Pires_2022_0542.pdf","title":"","llm_title":"Sequence-to-Sequence Models for Extracting Information from Registration and Legal Documents","authors":["Ramon Pires","Fábio C. de Souza","Guilherme Rosa","Roberto A. Lotufo","Rodrigo Nogueira"],"llm_authors":"Ramon Pires, Fábio C. de Souza, Guilherme Rosa, Roberto A. Lotufo, Rodrigo Nogueira","author_string":"","year":2022,"abstract":"","llm_abstract":"A typical information extraction pipeline consists of tokenÐor span-level classification models coupled with a series of pre- and postÐprocessing scripts. In a production pipeline, requirements often change, with classes being added and removed, which leads to nontrivial modifications to the source code and the possible introduction of bugs. In this work, we evaluate sequence-to-sequence models as an alternative to token-level classification methods for information extraction of legal and registration documents. We finetune models that jointly extract the information and generate the output already in a structured format. Post-processing steps are learned during training, thus eliminating the need for rule-based methods and simplifying the pipeline. Furthermore, we propose a novel method to align the output with the input text, thus facilitating system inspection and auditing. Our experiments on four real-world datasets show that the proposed method is an alternative to classical pipelines.","llm_keywords":["Information Extraction","Sequence-to-sequence","Legal Texts","Token-level classification","Pretrained language models","Question answering","Generative models","Machine translation","Text summarization"],"classifications":["Information Extraction","Text Generation","Pre-Processing"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":14},{"id":"674ce18bafa3afdb4382fcf971cf655f659ffc1643dd29f447b5bc6e55c03573fed855dab7e12c0e0545983cdb0be04afe68da638e8fd3ef0aaa6e24c5e86939","file_path":"legal-nlp-survey-20250328-002/original/Collantes_2015_0072.pdf","title":"","llm_title":"Simpatico: A Text Simplification System for Senate and House Bills","authors":["Miguel Collantes","Maureen Hipe","Juan Lorenzo Sorilla","Laurenz Tolentino","Briane Samson"],"llm_authors":"Miguel Collantes, Maureen Hipe, Juan Lorenzo Sorilla, Laurenz Tolentino, Briane Samson","author_string":"","year":2015,"abstract":"","llm_abstract":"In the Philippines, public participation in the creation of Senate and the House bills is very minimal. This could be the case because of the lack of accessibility of an ordinary citizen to take part in the lawmaking process and the complexity of the terms and grammar rules being used in legal proceedings called legalese. eParticipation is seen to be a solution to increase public participation but it only solves the process’ accessibility and not the complexity of the bills. Simplification solves this problem by transforming technical jargons and complicated phrases into words or phrases that are easier to understand. Also, existing simplification systems do not cover Philippine Senate and House bills as part of their domain. This research focuses on developing a text simplification system using lexical and syntactic simplification method for Philippine Senate and House bills called Simpatico. It aims to simplify legalese to plain English, which a majority of the Philippine population can understand. The system is based on a mix of previous simplification systems and makes use of different tools in order to accomplish certain tasks for simplification. It is composed of 3 major components: the preprocessing module, lexical simplification module, and the syntactic simplification module.","llm_keywords":["eParticipation","Philippine Senate","House bills","Legalese","Text Simplification","Lexical Simplification","Syntactic Simplification","Natural Language Processing"],"classifications":["Pre-Processing","Text Generation"],"num_cited_by":19,"num_cited_by_title_only":19,"num_pages":7},{"id":"f1c382c16cca13497a49ca4d8297ae40cb0ade93a9fad08e9db43315378998c8776283e0539d5fbbe365769a18e645c5c6aca57dc8812302883135f6b6401f93","file_path":"legal-nlp-survey-20250328-002/original/Araujo_2017_0146.pdf","title":"Ontology-based information extraction for juridical events with case studies in Brazilian legal realm","llm_title":"Ontology-based information extraction for juridical events with case studies in Brazilian legal realm","authors":["Denis Andrei de Araujo","Sandro José Rigo","Jorge Luis Victória Barbosa"],"llm_authors":"Denis Andrei de Araujo, Sandro José Rigo, Jorge Luis Victória Barbosa","author_string":"Denis Andrei Araujo","year":2017,"abstract":"","llm_abstract":"The number of available legal documents has presented an enormous growth in recent years, and the digital processing of such materials is prompting the necessity of systems that support the automatic relevant information extraction. This work presents a system for ontology-based information extraction from natural language texts, able to identify a set of legal events. The system is based on an innovative methodology based on domain ontology of legal events and a set of linguistic rules, integrated through inference mechanism, resulting in a flexible approach and scalable approach. A case study with the use of documents from the Superior Court in Brazil is related, with satisfactory results in precision and recall.","llm_keywords":["Information extraction","Ontology","Natural language processing","Inference","Legal domain","Digital documents","Linguistic rules","Brazilian legal realm"],"classifications":[],"num_cited_by":39,"num_cited_by_title_only":39,"num_pages":18},{"id":"9bcb2701e706b4c94386858dffcd918e6482e5054648028da011f285e83f33187245c6e62c843e18d8a246543d649f4f854917b7a44bed66aa5862efaff157ee","file_path":"legal-nlp-survey-20250328-002/original/Kapoor_2022_0515.pdf","title":"","llm_title":"HLDC: Hindi Legal Documents Corpus","authors":["Arnav Kapoor","Mudit Dhawan","Anmol Goel","T.H. Arjun","Akshala Bhatnagar","Vibhu Agrawal","Amul Agrawal","Arnab Bhattacharya","Ponnurangam Kumaraguru","Ashutosh Modi"],"llm_authors":"Arnav Kapoor, Mudit Dhawan, Anmol Goel, T.H. Arjun, Akshala Bhatnagar, Vibhu Agrawal, Amul Agrawal, Arnab Bhattacharya, Ponnurangam Kumaraguru, Ashutosh Modi","author_string":"","year":2022,"abstract":"","llm_abstract":"Many populous countries including India are burdened with a considerable backlog of legal cases. Development of automated systems that could process legal documents and augment legal practitioners can mitigate this. However, there is a dearth of high-quality corpora that is needed to develop such data-driven systems. The problem gets even more pronounced in the case of low resource languages such as Hindi. In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of more than 900K legal documents in Hindi. Documents are cleaned and structured to enable the development of downstream applications. Further, as a use-case for the corpus, we introduce the task of bail prediction. We experiment with a battery of models and propose a Multi-Task Learning (MTL) based model for the same. MTL models use summarization as an auxiliary task along with bail prediction as the main task. Experiments with different models are indicative of the need for further research in this area.","llm_keywords":["Hindi Legal Documents Corpus","legal NLP","bail prediction","automated systems","multi-task learning","low resource languages","legal text processing","corpora","Hindi language"],"classifications":["Resources","Machine Summarization","Classification"],"num_cited_by":32,"num_cited_by_title_only":32,"num_pages":16},{"id":"d85964b16f37a87cd0da9952615e6df084d7c22a96b26defc50ceb4402b47a3cf751b5af632afa6b7a37314a867adf1b999e8595bc7a75f09c82a8f12533664c","file_path":"legal-nlp-survey-20250328-002/original/Palmirani_2021_0427.pdf","title":"","llm_title":"Hybrid AI Framework for Legal Analysis of the EU Legislation Corrigenda","authors":["Monica Papalimarani","Francesco Sovrano","Davide Liga","Salvatore Sapienza","Fabio Vitali"],"llm_authors":"Monica Papalimarani, Francesco Sovrano, Davide Liga, Salvatore Sapienza, Fabio Vitali","author_string":"","year":2021,"abstract":"","llm_abstract":"This paper presents an AI use-case developed in the project “Study on legislation in the era of artificial intelligence and digitization” promoted by the EU Commission Directorate-General for Informatics. We propose a hybrid technical framework where AI techniques, Data Analytics, Semantic Web approaches and LegalXML modelisation produce benefits in legal drafting activity. This paper aims to classify the corrigenda of the EU legislation with the goal to detect some criteria that could prevent errors during the drafting or during the publication process. We use a pipeline of different techniques combining AI, NLP, Data Analytics, Semantic annotation and LegalXML instruments for enriching the non-symbolic AI tools with legal knowledge interpretation to offer to the legal experts.","llm_keywords":["Akoma Ntoso","Classification AI","NLP","legal drafting techniques","corrigenda","EU legislation","LegalXML","Semantic Web","Data Analytics"],"classifications":["Classification","Pre-Processing","Information Extraction"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":8},{"id":"6c2509e381c046c9685029f417b6c4413c8b651fe081d34d11d31623f0e4cc03f0dd3a34bf925df6784710922250c446c68add2a46d811afbf4d7d1b5aa54f9d","file_path":"legal-nlp-survey-20250328-002/original/Ash_2020_0372.pdf","title":"Unsupervised Extraction of Workplace Rights and Duties from Collective Bargaining Agreements","llm_title":"Unsupervised Extraction of Workplace Rights and Duties from Collective Bargaining Agreements","authors":["Elliott Ash","Jeff Jacobs","Bentley MacLeod","Suresh Naidu","Dominik Stammbach"],"llm_authors":"Elliott Ash, Jeff Jacobs, Bentley MacLeod, Suresh Naidu, Dominik Stammbach","author_string":"","year":2021,"abstract":"","llm_abstract":"This paper describes an unsupervised legal document parser which performs a decomposition of labor union contracts into discrete assignments of rights and duties among agents of interest. We use insights from deontic logic applied to modal categories and other linguistic patterns to generate topic-specific measures of relative legal authority. We illustrate the consistency and efficiency of the pipeline by applying it to a large corpus of 35K contracts and validating the resulting outputs.","llm_keywords":["Unsupervised Extraction","Information Mining","Legal Corpus Analysis","Collective Bargaining Agreements","Natural Language Processing","Deontic Logic","Contract Parsing","Labor Economics"],"classifications":[],"num_cited_by":7,"num_cited_by_title_only":22,"num_pages":9},{"id":"664a27ef5793b47c1d0c129da0ba6c36616c8e885b2c97f4889715793bb7dd207f42b4625533015d6616dde46326e67c9c5126cf0cd78b447667b643c3d1e9ec","file_path":"legal-nlp-survey-20250328-002/original/Chakravarty_2019_0251.pdf","title":"","llm_title":"Improving the Processing of Question Answer Based Legal Documents","authors":["Saurabh Chakravarty","Maanav Mehrotra","Raja Venkata Satya Phanindra Chava","Han Liu","Matthew Krivansky","Edward A. Fox"],"llm_authors":"Saurabh CHAKRAVARTY, Maanav MEHROTRA, Raja Venkata Satya Phanindra CHAVA, Han LIU, Matthew KRIVANSKY, Edward A. FOX","author_string":"","year":2019,"abstract":"","llm_abstract":"In the legal domain, documents of various types are created in connection with a case. Some are transcripts prepared by court reporters, based on notes taken during the proceedings of a trial or deposition. For example, deposition transcripts capture the conversations between attorneys and deponents. These documents are mostly in the form of question-answer (QA) pairs. Summarizing the information contained in these documents is a challenge for attorneys and paralegals because of their length and form. Having automated methods to convert a QA pair into a canonical form could aid with the extraction of insights from depositions. These insights could be in the form of a short summary, a list of key facts, a set of answers to specific questions, or a similar result from text processing of these documents. In this paper, we describe methods using NLP and Deep Learning techniques to transform such QA pairs into a canonical form. The resulting transformed documents can be used for summarization and other downstream tasks.","llm_keywords":["NLP","QA Normalization","Chunking","Deep learning","Legal Deposition"],"classifications":["Pre-Processing","Machine Summarization"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"1da87380a79f0cd3bb4f81325c819442a2d7ac61b56d7fd51d0c2dbb41abcff33388d9e8ddd95f9ef32ca2e35dcc16a48b8d5d84d7cf59ccbb2831d26a0227d1","file_path":"legal-nlp-survey-20250328-002/original/Nejadgholi_2017_0109.pdf","title":"","llm_title":"A Semi-Supervised Training Method for Semantic Search of Legal Facts in Canadian Immigration Cases","authors":["Isar Nejadgholi","Renaud Bougueng","Samuel Witherspoon"],"llm_authors":"Isar Nejadgholi, Renaud Bougueng, Samuel Witherspoon","author_string":"","year":2017,"abstract":"","llm_abstract":"A semi-supervised approach was introduced to develop a semantic search system, capable of finding legal cases whose fact-asserting sentences are similar to a given query, in a large legal corpus. First, an unsupervised word embedding model learns the meaning of legal words from a large immigration law corpus. Then this knowledge is used to initiate the training of a fact detecting classifier with a small set of annotated legal cases. We achieved 90% accuracy in detecting fact sentences, where only 150 annotated documents were available. The hidden layer of the trained classifier is used to vectorize sentences and calculate cosine similarity between fact-asserting sentences and the given queries. We reached 78% mean average precision score in searching semantically similar sentences.","llm_keywords":["semantic modeling","automatic annotation","semantic similarity search","legal information retrieval","semi-supervised learning","word embeddings","fact detection","Canadian immigration law"],"classifications":["Classification","Information Extraction","Information Retrieval"],"num_cited_by":46,"num_cited_by_title_only":46,"num_pages":10},{"id":"4040cb78bbbe2b38b6b5e3553e852fd73788e09880bdcacd947469697dcf56035b15c173cf6bd7f8325cc7ae11c04cd0a9549de5acdb1e1a57c6540a227d0491","file_path":"legal-nlp-survey-20250328-002/original/Kaltenhäuser_2022_0504.pdf","title":"Deconstructing Gender in Asylum Categories: An Archival Perspective on a Practice with Limited Access","llm_title":"Deconstructing Gender in Asylum Categories: An Archival Perspective on a Practice with Limited Access","authors":["Kristin Kaltenhäuser","Tijs Slaats","Thomas Gammeltoft-Hansen","Naja Holten Møller"],"llm_authors":"Kristin Kaltenhäuser, Tijs Slaats, Thomas Gammeltoft-Hansen, Naja Holten Møller","author_string":"Kristin Kaltenhäuser, Tijs Slaats, Thomas Gammeltoft-Hansen, Naja Holten Møller","year":2022,"abstract":"","llm_abstract":"Public authorities make decisions that greatly impact both citizens and non-citizens. Decision-making on asylum, which is regulated by international law but administered by states, in particular is characterised by a higher level of secrecy than other public services. The 1951 Refugee Convention defines refugeehood as the fear of being persecuted for reasons of race, religion, nationality, social group, or political opinion. Although fear of gender-related persecution was not included as one of the grounds meriting asylum, state practice means that it is today generally recognised as such. The United Nations Refugee Agency (UNHCR) recommends that states \"ensure a gender-sensitive interpretation of the 1951 Refugee Convention.\" Using natural language processing (NLP) to analyse an open dataset of Danish asylum case summaries, we first identify five empirical categories connected to gender in the case summaries: 1) gender-related persecution, 2) LGBT 3) sexual conditions, 4) marital conditions and 5) other gender-related forms of persecution. Secondly, we illustrate the relationship between these gender-related categories and other categories/topics in asylum motives. Finally, we discuss how data science techniques can be applied to better understand complex, cooperative work practices in an area where access for researchers is limited, but archival data is available.","llm_keywords":["asylum","gender-related persecution","natural language processing","Danish Refugee Appeals Board","archival perspective","Refugee Convention","data science","empirical categories","international law"],"classifications":["Classification","Resources","Information Extraction"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":19},{"id":"e256051b3915716f8b7ce5b5012da579621901a807de1bf5f01ffc00f4f6650d9e4d7510214d0d0715d1c6e59ccc837eeede9cbf9ba678c1367d786398b252a2","file_path":"legal-nlp-survey-20250328-002/original/Bhattacharya_2019_0248.pdf","title":"","llm_title":"Identification of Rhetorical Roles of Sentences in Indian Legal Judgments","authors":["Paheli Bhattacharya","Shounak Paul","Kripabandhu Ghosh","Saptarshi Ghosh","Adam Wyner"],"llm_authors":"Paheli BHATTACHARYA, Shounak PAUL, Kripabandhu GHOSH, Saptarshi GHOSH, Adam WYNER","author_string":"","year":2019,"abstract":"","llm_abstract":"Automatically understanding the rhetorical roles of sentences in a legal case judgement is an important problem to solve, since it can help in several downstream tasks like summarization of legal judgments, legal search, and so on. The task is challenging since legal case documents are usually not well-structured, and these rhetorical roles may be subjective (as evident from variation of opinions between legal experts). In this paper, we address this task for judgments from the Supreme Court of India. We label sentences in 50 documents using multiple human annotators, and perform an extensive analysis of the human-assigned labels. We also attempt automatic identification of the rhetorical roles of sentences. While prior approaches towards this task used Conditional Random Fields over manually handcrafted features, we explore the use of deep neural models which do not require hand-crafting of features. Experiments show that neural models perform much better in this task than baseline methods which use handcrafted features.","llm_keywords":["Semantic Segmentation","Rhetorical Roles","Legal Case Documents","Deep Learning","BiLSTM"],"classifications":["Classification"],"num_cited_by":107,"num_cited_by_title_only":107,"num_pages":10},{"id":"c2d9da611375d079ab5ece7a7c5fc5d392e121d1ca2cc877764a87cb79f73397dba042b095c6393de687e4ba4de9dd536c52562e36eca0e2e5c2e06f3aac9015","file_path":"legal-nlp-survey-20250328-002/original/Li_2020_0355.pdf","title":"Manuscript Preparation Instruction for Publishing in Computer Modeling in Engineering and Science (CMES)","llm_title":"Prison Term Prediction on Criminal Case Description with Deep Learning","authors":["Shang Li","Hongli Zhang","Lin Ye","Shen Su","Xiaoding Guo","Haining Yu","Binxing Fang"],"llm_authors":"Shang Li, Hongli Zhang, Lin Ye, Shen Su, Xiaoding Guo, Haining Yu, Binxing Fang","author_string":"becky","year":2020,"abstract":"","llm_abstract":"The task of prison term prediction is to predict the term of penalty based on textual fact description for a certain type of criminal case. Recent advances in deep learning frameworks inspire us to propose a two-step method to address this problem. To obtain a better understanding and more specific representation of the legal texts, we summarize a judgment model according to relevant law articles and then apply it in the extraction of case feature from judgment documents. By formalizing prison term prediction as a regression problem, we adopt the linear regression model and the neural network model to train the prison term predictor. In experiments, we construct a real-world dataset of theft case judgment documents. Experimental results demonstrate that our method can effectively extract judgment-specific case features from textual fact descriptions. The best performance of the proposed predictor is obtained with a mean absolute error of 3.2087 months, and the accuracy of 72.54% and 90.01% at the error upper bounds of three and six months, respectively.","llm_keywords":["Neural networks","prison term prediction","criminal case","text comprehension","deep learning","legal texts","regression model","case feature extraction"],"classifications":["Classification"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":16},{"id":"635829d04b663c9d5a1357fbd35778bc387eed03e329af8d157ec601e009a32d2fc5045baf05b369476609d6557bb222747ebdeba31734e2fe29207fe7f6aa29","file_path":"legal-nlp-survey-20250328-002/original/Seyler_2020_0325.pdf","title":"Finding Contextually Consistent Information Units in Legal Text","llm_title":"Finding Contextually Consistent Information Units in Legal Text","authors":["Dominic Seyler","Paul Bruin","Pavan Bayyapu","ChengXiang Zhai"],"llm_authors":"Dominic Seyler, Paul Bruin, Pavan Bayyapu, ChengXiang Zhai","author_string":"Dominic Seyler, Paul Bruin, Pavan Bayyapu, and ChengXiang Zhai","year":2020,"abstract":"","llm_abstract":"Terms in the laws of a legislature can be highly contextual: especially for corpora of codified laws and regulations where the reader has to be aware of the correct context when the corpus lacks a single level of hierarchy. The goal of this work is to assist professionals when reading legal text within a codified corpus by finding contextually consistent information units. To achieve this, we combine NLP and data mining techniques to develop novel methodology that can find these information units in an unsupervised manner. Our method draws on expert experience and is modeled to emulate the “contextualization process” of experienced readers of legal content. We experimentally evaluate our method by comparing it to multiple expert-annotated datasets and find that our method achieves near perfect performance on four state corpora and high precision on one federal corpus.","llm_keywords":["information units","logical document organization","legal text mining","contextualization process","NLP","data mining","root context identification","hierarchy-reference graph","legal corpus evaluation"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":4},{"id":"d3cc778203ad2f6a1c2c3d7d6ed7edf7645f61cd947912b516bf330e5395adb6a6f7f9024e3cd1ed06882f67e7aef70005b1a5e6952998eb3cbca63262665fb9","file_path":"legal-nlp-survey-20250328-002/original/Atkinson_2022_0572.pdf","title":"","llm_title":"AI for Patent Essentiality Review","authors":["Katie Atkinson","Danushka Bollegala"],"llm_authors":"Katie Atkinson and Danushka Bollegala","author_string":"","year":2022,"abstract":"","llm_abstract":"","llm_keywords":["Patent Essentiality","Standard Essential Patents","Artificial Intelligence","Textual Similarity","Latent Semantic Analysis","4G LTE","5G New Radio","Hypothetical Judgments","Intellectual Property","Machine Learning"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":23},{"id":"02dd266b17a80368e9ff59e0c6bd0c6754d5cdcdcae60bfda634f70772a935d06d49da108b547f596c353acfed3c642654dc3886c16036d245c21ab0af4184e1","file_path":"legal-nlp-survey-20250328-002/original/Waltl_2019_0281.pdf","title":"Semantic types of legal norms in German laws: classification and analysis using local linear explanations","llm_title":"Semantic types of legal norms in German laws: classification and analysis using local linear explanations","authors":["Bernhard Waltl","Georg Bonczek","Elena Scepankova","Florian Matthes"],"llm_authors":"Bernhard Waltl, Georg Bonczek, Elena Scepankova, Florian Matthes","author_string":"Bernhard Waltl","year":2018,"abstract":"","llm_abstract":"This paper describes the automated classification of legal norms in German statutes with regard to their semantic type. We propose a semantic type taxonomy for norms in the German civil law domain consisting of nine different types focusing on functional aspects, such as Duties, Prohibitions, Permissions, etc. We performed four iterations in classifying legal norms with a rule-based approach using a manually labeled dataset, i.e., tenancy law, of the German Civil Code (n = 601). During this experiment the F1 score continuously improved from 0.52 to 0.78. In contrast, a machine learning based approach for the classification was implemented. A performance of F1 = 0.83 was reached. Traditionally, machine learning classifiers lack of transparency with regard to their decisions. We extended our approach using so-called local linear approximations, which is a novel technique to analyze and inspect a trained classifier’s behavior. We can show that there are significant similarities of manually crafted knowledge, i.e., rules and pattern definitions, and the trained decision structures of machine learning approaches.","llm_keywords":["Natural language processing","Classifying legal norms","Rule-based information extraction","Supervised machine learning","Explainable machine learning","Local interpretable models"],"classifications":[],"num_cited_by":47,"num_cited_by_title_only":47,"num_pages":29},{"id":"0cd2871abf5c39d5b1e24a595f8c8e97e5f3dd48c8bb2b4a7d1326d396d2ce694a3cbbcc79fff0e566ce87050aada741801f080219e06157095d9eaaa58c719a","file_path":"legal-nlp-survey-20250328-002/original/Lyu_2022_0519.pdf","title":"Improving legal judgment prediction through reinforced criminal element extraction","llm_title":"Improving legal judgment prediction through reinforced criminal element extraction","authors":["Yougang Lyu","Zihan Wang","Zhaochun Ren","Pengjie Ren","Zhumin Chen","Xiaozhong Liu","Yujun Li","Hongsong Li","Hongye Song"],"llm_authors":"Yougang Lyu, Zihan Wang, Zhaochun Ren, Pengjie Ren, Zhumin Chen, Xiaozhong Liu, Yujun Li, Hongsong Li, Hongye Song","author_string":"Yougang Lyu","year":2021,"abstract":"","llm_abstract":"Legal text mining is targeted at automatically analyzing the texts in the legal domain by employing various natural language processing techniques and has attracted enormous attention from the NLP community. As one of the most crucial tasks of legal text mining, Legal Judgment Prediction (LJP) aims to automatically predict judgment results (e.g., applicable law articles, charges, and terms of penalty) according to fact descriptions on law cases and becomes a promising application of artificial intelligence techniques. Unfortunately, ambiguous fact descriptions and law articles often appear due to a great number of shared words and legal concepts. Prior works are proposed to partially address these problems, focusing on introducing additional attributes to distinguish similar fact descriptions, or differentiating confusing law articles by grouping and distilling law articles. However, existing works still face two severe challenges: (1) indistinguishable fact descriptions with different criminals and targets and (2) misleading law articles with highly similar TF–IDF representations, both of which lead to serious misjudgments for the LJP task. In this paper, we present a novel reinforcement learning (RL) based framework, named Criminal Element Extraction Network (CEEN), to handle above challenges simultaneously. In CEEN, we propose four types of discriminative criminal elements, including the criminal, target, intentionality, and criminal behavior. To discriminate ambiguous fact descriptions, an reinforcement learning based extractor is designed to accurately locate elements for different cases. To enhance law article predictions, distinctive element representations are constructed for each type of criminal element. Finally, with the input of element representations, a multi-task predictor is adopted for the judgment predictions. Experimental results on real-world datasets show that extracting criminal elements is highly useful for predicting the judgment results.","llm_keywords":["Legal text mining","Legal judgment prediction","Criminal element extraction","Reinforcement learning","Neural networks","Attention mechanism"],"classifications":["Classification","Information Extraction","Pre-Processing","Resources"],"num_cited_by":63,"num_cited_by_title_only":63,"num_pages":16},{"id":"f2be461c8e8f0ef1d4225bea242824f051bfdd92e9f6ed21f2f6240fcb30ba5e4ee210af103a6a0b2b154996d712c00eb0fea53b85d9aada7746c54bf2a07bdf","file_path":"legal-nlp-survey-20250328-002/original/Mokanov_2019_0243.pdf","title":"113_Mokanov.pdf","llm_title":"Facts2Law – using deep learning to provide a legal qualification to a set of facts","authors":["Ivan Mokanov","Daniel Shane","Benjamin Cerat"],"llm_authors":"Ivan Mokanov, Daniel Shane, Benjamin Cerat","author_string":"","year":2019,"abstract":"","llm_abstract":"Over the course of the last year Lexum has started exploring the potential of deep learning (DL) and machine learning (ML) technologies for legal research. Although these projects are still under the umbrella of Lexum’s research and development team (Lexum Lab, https://lexum.com/en/ailab/), concrete applications have recently started to become available. This demo focuses on one of these applications: Facts2Law. The project benefits from a combination of factors. First, the millions of legal documents available in the CanLII database in parsable format along with structured metadata constitute a significant dataset to train AI algorithms. Second, Lexum has direct access to the knowledge and experience of one of the leading teams in AI and deep learning worldwide at the Montreal Institute for Learning Algorithms (MILA) of the University of Montreal. Third, the availability of computer engineers with cutting-edge expertise in the specifics of legal documents facilitates the transition from theory to practical applications. Regarding concrete outcomes, Lexum’s Facts2Law can predict the most relevant sources of law for any given piece of text (incorporating legal citations or not).","llm_keywords":["deep learning","machine learning","legal research","Facts2Law","CanLII","legal citation prediction","AI in law","Lexum","Montreal Institute for Learning Algorithms","legal documents"],"classifications":["Classification"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":2},{"id":"99cc2b370df776a9774432c56dba71ad9706f2bc977e563a6225d43b2a7ea2b260a6eb6b68dc63afc206feeec31de4989d40e30418ec3efae4eb44e5a8999672","file_path":"legal-nlp-survey-20250328-002/original/Panagis_2015_0073.pdf","title":"1","llm_title":"The Force of EU Case Law: A Multi-dimensional Study of Case Citations","authors":["Ioannis Damastianos Panagis","Yannis Panagis","Urška Šadl"],"llm_authors":"Yannis Panagis and Urška Šadl","author_string":"Ioannis Damastianos Panagis","year":2015,"abstract":"","llm_abstract":"The power of courts to change law via case law is among the most persistent and contested themes in the study of courts. In this article we empirically investigate whether the Court of Justice of the European Union (the Court) is constrained by its case law, and whether this can have a legitimatizing effect on its decision making. In contrast to previous literature on citation networks, which takes into account entire documents in constructing citation networks, we build a network of references to individual paragraphs of judgments, and their adjacent texts. We then analyze the paragraph texts with the aid of keyword extraction and topic modelling. Our findings can explain the legal relevance of citations and cited cases, as well as their normative force.","llm_keywords":["Case citation networks","Text annotation","Court of Justice of the European Union","Precedent (case law)","EU Citizenship","Topic modelling"],"classifications":[],"num_cited_by":21,"num_cited_by_title_only":21,"num_pages":11},{"id":"19d4028fda002414c9ed7a84252093b49b1ee8c8c539b6991fcd9f7b9921ebf4dc2c77315763b3d27bf132cb752ba4768e4391da4081288101bdeb8b72c60779","file_path":"legal-nlp-survey-20250328-002/original/Mumcuoğlu_2022_0538.pdf","title":"Prediction of outcomes in higher courts of Turkey using natural language processing","llm_title":"PREDICTION OF OUTCOMES IN HIGHER COURTS OF TURKEY USING NATURAL LANGUAGE PROCESSING","authors":["Emre Mumcuoğlu"],"llm_authors":"Emre Mumcuoğlu","author_string":"Emre Mumcuoğlu","year":2022,"abstract":"","llm_abstract":"The use of Natural Language Processing (NLP) in the field of law has become a topic of interest in the recent years. Applications to Turkish law, however, have remained unexplored to this day. In this thesis, first, a review of existing NLP applications in law is provided, and then, the problem of predicting Turkish court decisions is studied using NLP techniques. An extensive corpus that consists of case texts from Turkish higher courts, namely, the Constitutional Court and District Courts, is compiled. In addition, a numerical analysis and comparison of NLP methods at predicting the outcomes of these higher court cases is provided. The methods used for prediction are based on Decision Trees, Random Forests, Support Vector Machines and various deep learning models; specifically Gated Recurrent Units, unidirectional and bidirectional Long Short-Term Memory networks, and their attention-integrated counterparts. Prediction results for all algorithms are presented comparatively across all courts. The results show that decisions of Turkish higher courts can be predicted with high accuracy, especially with deep learning-based methods. Similar performance to existing work in the literature on case outcome prediction, which focus on different languages and different legal systems, is achieved.","llm_keywords":["Natural Language Processing","Law","Machine Learning","Deep Learning","Artificial Intelligence","Turkish Courts","Court Decision Prediction"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":70},{"id":"192bff720ea0b2792a1855dc7139eeb7c8b00457ff4289f4f1ad117fcfbeb1aa2989b5bb93e8d5b82e1d3fe6b67fa09bdda3bcc59bd651860d1c220d53be413e","file_path":"legal-nlp-survey-20250328-002/original/Yamakoshi_2019_0289.pdf","title":"","llm_title":"Thai Legal Term Correction using Random Forests with Outside-the-sentence Features","authors":["Takahiro Yamakoshi","Vee Satayamas","Hutchatai Chanlekha","Yasuhiro Ogawa","Takahiro Komamizu","Asanee Kawtrakul","Katsuhiko Toyama"],"llm_authors":"Takahiro Yamakoshi, Vee Satayamas, Hutchatai Chanlekha, Yasuhiro Ogawa, Takahiro Komamizu, Asanee Kawtrakul, Katsuhiko Toyama","author_string":"","year":2019,"abstract":"","llm_abstract":"We propose a method for finding and correcting misused Thai legal terms in Thai statutory sentences. Our method predicts legal terms using Random Forest classifiers, each of which is optimized for each set of similar legal terms. Each classifier utilizes outside-the-sentence features, namely, promulgation year, title keywords, and section keywords of statutes, in addition to words adjacent to the targeted legal term. Our experiment shows that our method outperformed not only a Random Forest method without the outside-the-sentence features, but also BERT (Bidirectional Encoder Representations from Transformers), a powerful language representation model, in overall accuracy.","llm_keywords":["Thai legal terms","Random Forests","statutory sentences","legal term correction","BERT","language representation","outside-the-sentence features"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":9},{"id":"2563e336d5a2f712a8503e5e02d244c1865b904dfa5d053b4530729868246e6bb6a138ae3f63e649731b14835ac447a31cb7895dc657676f33cc24c9d3fe59c8","file_path":"legal-nlp-survey-20250328-002/original/Michalopoulos_2019_0215.pdf","title":"143_Michalopoulos.pdf","llm_title":"AI-Enabled Litigation Evaluation Data-Driven Empowerment for Legal Decision Makers","authors":["Dennis P. Michalopoulos","Jessica Jacob","Alfredo Coviello"],"llm_authors":"Dennis P. Michalopoulos, Jessica Jacob, Alfredo Coviello","author_string":"","year":2019,"abstract":"","llm_abstract":"Lawsuits are expensive, time consuming, and often confusing to non-lawyers who are faced with making important legal decisions. For making informed legal decisions, as it stands today, there is a dearth of tools to aid legal decision makers in the costly and complex landscape of litigation. To address this need, we present a framework for standardizing and structuring key information contained in case dockets. This data can be used for numerous analytics use cases to provide legal decision makers with data-driven insights to help them understand and navigate the events that occur in their lawsuits.","llm_keywords":["AI","litigation","legal decision making","docket standardization","machine learning","classification","analytics","Proactive litigation management"],"classifications":["Information Extraction","Information Retrieval"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":2},{"id":"f218536d4e1c81b848ede60d8ad7dbba1f5bbcccad52fcf67c4cae107667b3974cca282e89ae0140343b0c7a391bc1ef0a45f82085f15717b130bb535f8eeea1","file_path":"legal-nlp-survey-20250328-002/original/Ash_2021_0445.pdf","title":"Machine Extraction of Tax Laws from Legislative Texts","llm_title":"Machine Extraction of Tax Laws from Legislative Texts","authors":["Elliott Ash","Malka Guillot","Luyang Han"],"llm_authors":"Elliott Ash, Malka Guillot, Luyang Han","author_string":"Elliott Ash ; Malka Guillot ; Luyang Han","year":2021,"abstract":"","llm_abstract":"Using a corpus of compiled codes from U.S. states containing labeled tax law sections, we train text classifiers to automatically tag tax-law documents and, further, to identify the associated revenue source (e.g. income, property, or sales). After evaluating classifier performance in held-out test data, we apply them to an historical corpus of U.S. state legislation to extract the flow of relevant laws over the years 1910 through 2010. We document that the classifiers are effective in the historical corpus, for example by automatically detecting establishments of state personal income taxes. The trained models with replication code are published at https://github.com/luyang521/tax-classification.","llm_keywords":["tax law","machine learning","text classification","legal NLP","U.S. state legislation"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"5be8e6a4fc6642b6462a12fde2e4209d6c5827ea861b7c546fd1a15f7a0753b5004323ce86b281f9e101e5e71219888c44075096ad038ab913b26e1291cfa692","file_path":"legal-nlp-survey-20250328-002/original/Hassan_2022_0508.pdf","title":"Microsoft Word - CRC2022Manuscript-ActivitiesInformationExtraction_Le.docx","llm_title":"Extraction of activities information from construction contracts using natural language processing (NLP) methods to support scheduling","authors":["Fahad ul Hassan","Tuyen Le"],"llm_authors":"Fahad ul Hassan and Tuyen Le, Ph.D.","author_string":"","year":2022,"abstract":"","llm_abstract":"A pPrecise extraction of a required activities list from construction contract documents is crucial to develop a complete and accurate construction schedule. Currently, the scheduler is required to read the complete lengthy contract package to extract activities and convert them into a structured format to prepare a schedule. The current manual methods of activities extraction for schedule development are inefficient, laborious, and error-prone. Although a few researchers have developed models for automated information extraction from legal documents, those models are applicable to quantitative requirements only. To address this, the current study proposes an automated information retrieval system to extract the activities provided in contracts using natural language processing (NLP) methods. The study implemented the dependency parsing technique that employed the syntactic features of requirement text to extract the actors, actions, and objects specified in the requirement. The model achieved an average recall and precision of 94% and 95% respectively on the requirements of a real design-build project. The proposed automated activities retrieval system is expected to help the schedulers develop the construction schedules.","llm_keywords":["Natural Language Processing","Construction contracts","Activity extraction","Scheduling","Dependency parsing","Automated information retrieval","Design-build projects","Construction management","Project planning","Error reduction"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"688705120c94812e22a051dda119ac481a59e037dd7aa3daffc92299ef6deca00eacf5f3051872a8563949900b211f41eaaa8a8b81178310c63ea1fa03dd1e52","file_path":"legal-nlp-survey-20250328-002/original/Alcántara_2022_0556.pdf","title":"Survey of Text Mining Techniques Applied to Judicial Decisions Prediction","llm_title":"Survey of Text Mining Techniques Applied to Judicial Decisions Prediction","authors":["Olga Alejandra Alcántara Francia","Miguel Nunez-del-Prado","Hugo Alatrista-Salas"],"llm_authors":"Olga Alejandra Alcántara Francia, Miguel Nunez-del-Prado, Hugo Alatrista-Salas","author_string":"Olga Alejandra Alcántara Francia, Miguel Nunez-del-Prado and Hugo Alatrista-Salas","year":2022,"abstract":"","llm_abstract":"This paper reviews the most recent literature on experiments with different Machine Learning, Deep Learning and Natural Language Processing techniques applied to predict judicial and administrative decisions. Among the most outstanding findings, we have that the most used data mining techniques are Support Vector Machine (SVM), K Nearest Neighbours (K-NN) and Random Forest (RF), and in terms of the most used deep learning techniques, we found Long-Term Memory (LSTM) and transformers such as BERT. An important finding in the papers reviewed was that the use of machine learning techniques has prevailed over those of deep learning. Regarding the place of origin of the research carried out, we found that 64% of the works belong to studies carried out in English-speaking countries, 8% in Portuguese and 28% in other languages (such as German, Chinese, Turkish, Spanish, etc.). Very few works of this type have been carried out in Spanish-speaking countries. The classification criteria of the works have been based, on the one hand, on the identification of the classifiers used to predict situations (or events with legal interference) or judicial decisions and, on the other hand, on the application of classifiers to the phenomena regulated by the different branches of law: criminal, constitutional, human rights, administrative, intellectual property, family law, tax law and others. The corpus size analyzed in the reviewed works reached 100,000 documents in 2020. Finally, another important finding lies in the accuracy of these predictive techniques, reaching predictions of over 60% in different branches of law.","llm_keywords":["judicial prediction","legal tech","legal prediction","machine learning","natural language processing","deep learning"],"classifications":[],"num_cited_by":28,"num_cited_by_title_only":28,"num_pages":23},{"id":"553265577c0b1031ac903bf53aee7d0a96d6217b9e9cbfa0284a4d2b0405d7e4222b5ad1a210f13d7811d0375e12ab0c8a9b54dceaa1e0cee9f10c9c98b747e7","file_path":"legal-nlp-survey-20250328-002/original/Vardhan_2020_0349.pdf","title":"","llm_title":"Advanced Machine Learning Technologies and Applications: Proceedings of AMLTA 2020","authors":["Aboul Ella Hassanien","Roheet Bhatnagar","Ashraf Darwish"],"llm_authors":"Aboul Ella Hassanien, Roheet Bhatnagar, Ashraf Darwish","author_string":"0014431","year":2020,"abstract":"","llm_abstract":"","llm_keywords":["Machine Learning","Intelligent Systems","Computing","Advanced Technologies","Conference Proceedings"],"classifications":[],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":737},{"id":"a0bf504dc3af145c9c900b1ac547ce9c3a3b3261432857e7b027d5e9444335a6cac4dcbf0259d13e6efbaf11c8985b2f090c4ec7996ec2832118fe39ba772080","file_path":"legal-nlp-survey-20250328-002/original/Rosca_2020_0358.pdf","title":"Return of the AI: An Analysis of Legal Research on Artificial Intelligence Using Topic Modeling","llm_title":"Return of the AI: An Analysis of Legal Research on Artificial Intelligence Using Topic Modeling","authors":["Constanta Rosca","Bogdan Covrig","Catalina Goanta","Gijs van Dijck","Gerasimos Spanakis"],"llm_authors":"Constanta Rosca, Bogdan Covrig, Catalina Goanta, Gijs van Dijck, Gerasimos Spanakis","author_string":"Constanta Rosca, Bogdan Covrig, Catalina Goanta, Gijs van Dijck, Gerasimos Spanakis","year":2020,"abstract":"","llm_abstract":"AI research finds itself in the third boom of its history, and in recent years, AI-related themes have gained considerable popularity in new disciplines, such as law. This paper explores what legal research on AI constitutes of and how it has evolved, while addressing the issues of information retrieval and research duplication. Using Latent Dirichlet Allocation (LDA) topic modeling on a dataset of 3931 journal articles, we explore three questions: (a) Which topics within legal research on AI can be distinguished? (b) When were these topics addressed? and (c) Can similar papers be detected? The topic modeling results in a total of 32 meaningful topics. Additionally, it is found that legal research on AI drastically increased as of 2016, with topics becoming more granular and diverse over time. Finally, a comparison of the similarity assessments produced by the algorithm and a human expert suggest that the assessments often coincide. The results provide insights into how a legal research on AI has evolved over time, and support for the development of machine learning and information retrieval tools like LDA that assist in structuring large document collections and identifying relevant articles.","llm_keywords":["AI","Legal research","Topic modeling","Information retrieval","Machine learning","Research duplication","Latent Dirichlet Allocation","Document analysis","Artificial intelligence","Law"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":8},{"id":"1286b006f1c297169683259ccba3b24dd8ea4b9fdfc19b8b679d4b87829ea726ca7ae1f06eac017ae49883009680dff42b58cb42f1cc360af76dd9c0955ca7d0","file_path":"legal-nlp-survey-20250328-002/original/Ovádek_2021_0388.pdf","title":"Analysing EU Treaty-Making and Litigation With Network Analysis and Natural Language Processing","llm_title":"Analysing EU Treaty-Making and Litigation With Network Analysis and Natural Language Processing","authors":["Michal Ovádek","Arthur Dyevre","Kyra Wigard"],"llm_authors":"Michal Ovádek, Arthur Dyevre, Kyra Wigard","author_string":"Arthur Dyevre","year":2021,"abstract":"","llm_abstract":"We apply network analysis and topic modeling techniques to explore the evolution of the European Union’s treaty making activity and the patterns of litigation they have given rise to. Our analysis reveals that, despite the expansion of the bloc’s policy remit, its treaty-making activity retains a strong economic focus. Among the many agreements negotiated by EU institutions, the European Economic Agreement, the Ankara Agreement with Turkey and the World Trade Organization Agreement form the largest clusters of litigated cases. EU international agreements are disproportionately litigated in cases pertaining to residence rights and competition law.","llm_keywords":["network analysis","natural language processing","topic modeling","international agreements","European Union","litigation"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"2f85647fc2bf2d609d9d2530979cbdd5b86e25b104d96c860087a1b1271a6270f2c0d718455b4eebb3b8041b2054704ba8bf0040c62ea283ab979445059dae88","file_path":"legal-nlp-survey-20250328-002/original/Venkatesh_2013_0018.pdf","title":"Sebuah Kajian Pustaka:","llm_title":"Legal Documents Clustering and Summarization using Hierarchical Latent Dirichlet Allocation","authors":["Ravi Kumar V","K. Raghuveer"],"llm_authors":"Ravi kumar V, K. Raghuveer","author_string":"cairo","year":2014,"abstract":"","llm_abstract":"In a common law system and in a country like India, decisions made by judges are significant sources of application and understanding of law. Online access to the Indian Legal Judgments in the digital form creates an opportunities and challenges to the both legal community and information technology researchers. This necessitates organizing, analyzing and presenting it in a useful manner to the legal community for quick understanding and for taking necessary decision pertaining to a present case. In this paper we propose an approach, to cluster legal judgments based on the topics obtained from hierarchical Latent Dirichlet Allocation (hLDA), using similarity measure between topics and documents and to find the summarry of each document using the same topics. The developed topic based model, is capable of grouping the legal judgments into different clusters and to generate summary of each legal judgment in the cluster, in effective manner compare to our previous approach [1].","llm_keywords":["Latent Dirichlet Allocation","hierarchical Latent Dirichlet Allocation","Legal Documents Clustering","Similarity measure","Legal Document Summarization"],"classifications":["Machine Summarization","Classification"],"num_cited_by":24,"num_cited_by_title_only":24,"num_pages":9},{"id":"a29fda10ec29855502ee9bca8de43f994b7dfb5b3ef907c8308e6cb2882d109e64bccc7d9bc903a0996a581e7c0a9a7ba6f6ee6e3965a31944ba9610d65569c8","file_path":"legal-nlp-survey-20250328-002/original/Li_2019_0268.pdf","title":"MANN: A Multichannel Attentive Neural Network for Legal Judgment Prediction","llm_title":"MANN: A Multichannel Attentive Neural Network for Legal Judgment Prediction","authors":["Shang Li","Hongli Zhang","Lin Ye","Xiaoding Guo","Binxing Fang"],"llm_authors":"SHANG LI, HONGLI ZHANG, LIN YE, XIAODING GUO, AND BINXING FANG","author_string":"","year":2019,"abstract":"","llm_abstract":"Recent years have witnessed an opportunity to improve trial efficiency and quality by predictive analysis of massive judgment documents. A practical legal judgment prediction (LJP) system should provide a judge with feasible judgment suggestions, including the charges, applicable law articles, and prison term, whereas most existing works focus on only part of the LJP task. Inspired by the impressive success of deep neural networks in a wide range of application scenarios, we propose a multichannel attentive neural network model, MANN, which learns from previous judgment documents and performs the integrated LJP task in a unified framework. In general, MANN takes the textual description of a criminal case as the input for attention-based neural networks to learn its latent feature representations oriented to the case fact, the defendant persona, and relevant law articles. Moreover, we adopt a two-tier structure to empower attentive sequence encoders to hierarchically model the semantic interactions from different parts of case description at both the word and sentence levels. The experiments are conducted on four real-world datasets of criminal cases in mainland China. The experimental results demonstrate that MANN achieves state-of-the-art LJP performance on all evaluation metrics.","llm_keywords":["Legal intelligence","judgment prediction","neural networks","attention mechanism","deep learning","case analysis","artificial intelligence","natural language processing","criminal cases","semantic representation"],"classifications":["Classification","Information Extraction"],"num_cited_by":70,"num_cited_by_title_only":70,"num_pages":12},{"id":"0eecf07aa04617cb65c7fbf4febc09a3e21fe8eee6e4f170fe51a074bc166fa3cda01b403453622cd66290e6f380a72e9556a6dfa6d27aebaf516dc31d922d7d","file_path":"legal-nlp-survey-20250328-002/original/de-Vargas-Feijó_2018_0203.pdf","title":"RulingBR: A Summarization Dataset for Legal Texts","llm_title":"RulingBR: A Summarization Dataset for Legal Texts","authors":["Diego de Vargas Feijó","Viviane Pereira Moreira"],"llm_authors":"Diego de Vargas Feijó and Viviane Pereira Moreira","author_string":"Diego de Vargas Feijó","year":2018,"abstract":"","llm_abstract":"Text summarization consists in generating a shorter version of an input document, which captures its main ideas. Despite the recent developments in this area, most of the existing techniques have been tested mostly in English and Chinese, due in part to the low availability of datasets in other languages. In addition, experiments have been run mostly on collections of news articles, which could lead to some bias in the research. In this paper, we address both these limitations by creating a dataset for the summarization of legal texts in Portuguese. The dataset, called RulingBR, contains about 10K rulings from the Brazilian Federal Supreme Court. We describe how the dataset was assembled and we also report on the results of standard summarization methods which may serve as a baseline for future works.","llm_keywords":["Summarization","Dataset","Legal","Law","RulingBR","Portuguese language","Brazilian Federal Supreme Court","Text corpus","Natural Language Processing"],"classifications":["Machine Summarization","Resources"],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":10},{"id":"9522cb9cb66dd76c855a0fbe62f5af3faa7133885adc3215cb282297fd53bd9d07821d7794e2ae9be75d907dd3bc872b4848ec6b1b3161bc033d3e796bf3e2a8","file_path":"legal-nlp-survey-20250328-002/original/Landthaler_2018_0206.pdf","title":"","llm_title":"Towards Explainable Semantic Text Matching","authors":["Jörg Landthaler","Ingo Glaser","Florian Matthes"],"llm_authors":"Jörg LANDTHALER, Ingo GLASER and Florian MATTHES","author_string":"","year":2018,"abstract":"","llm_abstract":"The growing amount of textual data in the legal domain leads to a demand for better text analysis tools adapted to legal domain specific use cases. Semantic Text Matching (STM) is the general problem of linking text fragments of one or more document types. The STM problem is present in many legal document analysis tasks, such as argumentation mining. A common solution approach to the STM problem is to use text similarity measures to identify matching text fragments. In this paper, we recapitulate the STM problem and a use case in German tenancy law, where we match tenancy contract clauses and legal comment chapters. We propose an approach similar to local interpretable model-agnostic explanations (LIME) to better understand the behavior of text similarity measures like TFIDF and word embeddings. We call this approach eXplainable Semantic Text Matching (XSTM).","llm_keywords":["Semantic Text Matching","Explainable AI","Word Embeddings","TFIDF","Text Similarity Measure","German Tenancy Law"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":5},{"id":"864db12a5d11e5e658f88552561c0a21d8431362988ea15e7cfd71fdd0e5be8a0c70ce4381556ce2b5947029bc0e1a378a43986b58454a82dbfc2031874c8869","file_path":"legal-nlp-survey-20250328-002/original/Curtotti_2015_0068.pdf","title":"","llm_title":"Machine Learning for Readability of Legislative Sentences","authors":["Anne Gardner","Michael Curtotti","Eric McCreath","Tom Bruce","Sara Frug","Wayne Weibel","Nicolas Ceynowa"],"llm_authors":"Michael Curtotti, Eric McCreath, Tom Bruce, Sara Frug, Wayne Weibel, Nicolas Ceynowa","author_string":"Anne Gardner","year":2015,"abstract":"","llm_abstract":"Improving the readability of legislation is an important and unresolved problem. Recently, researchers have begun to apply legal informatics to this problem. This paper applies machine learning to predict the readability of sentences from legislation and regulations. A corpus of sentences from the United States Code and US Code of Federal Regulations was created. Each sentence was labelled for language difficulty using results from a large-scale crowdsourced study undertaken during 2014. The corpus was used as training and test data for machine learning. The corpus includes a version tagged using the Stanford parser context free grammar and a version tagged using the Stanford dependency grammar parser. The corpus is described and made available to interested researchers. We investigated whether extending natural language features available as input to machine learning improves the accuracy of prediction. Among features evaluated are those from the context free and dependency grammars. Letter and word ngrams were also studied. We found the addition of such features improves accuracy of prediction on legal language. We also undertake a correlation study of natural language features and language difficulty drawing insights as to the characteristics that may make legal language more difficult. These insights, and those from machine learning, enable us to describe a system for reducing legal language difficulty and to identify a number of suggested heuristics for improving the writing of legislation and regulations.","llm_keywords":["readability","legal informatics","machine learning","natural language processing","corpus linguistics","plain language","supervised learning","legislative drafting"],"classifications":["Classification","Resources"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":10},{"id":"fd8c31eac41d697323346db73a06736ed02df1299b84853870a2925fa6241e4433288a12ebb74e1f0f5a56423b3d373c969bae0ef31f396fcbfe70c82e2db7b5","file_path":"legal-nlp-survey-20250328-002/original/Barreiro_2015_0054.pdf","title":"","llm_title":"Automatic Anonymisation of a New Portuguese-English Parallel Corpus in the Legal-Financial Domain","authors":["Eckhard Bick","Ana Bela Barreiro"],"llm_authors":"Eckhard Bick and Ana Bela Barreiro","author_string":"","year":2015,"abstract":"","llm_abstract":"Este artigo apresenta o processo de anonimização automática de entidades mencionadas num novo corpo paralelo pesquisável do domínio jurídico-financeiro para o par de línguas português-inglês. O corpo resulta de memórias de tradução utilizadas em tradução profissional. Contém cerca de 40.000 pares de frases alinhadas, ou seja, frases que são traduções umas das outras. A anotação das entidades mencionadas foi feita com regras especiais da Gramática de Restrições otimizadas para o domínio jurídico-financeiro, que permitiram alcançar uma abrangência balanceada em termos de precisão de quase 90% para as entidades mencionadas candidatas (pessoa, organização, endereço e identificadores pessoais) e uma abrangência consideravelmente superior com modificações heurísticas e otimizadas para a produção. O corpo destina-se a estudos de tradução e à linguística computacional (tradução automática estatística) e será publicamente pesquisável, permitindo ao seu utilizador procurar uma palavra ou expressão e devolvendo os resultados da pesquisa em contexto na língua da busca e na sua tradução.","llm_keywords":["automatic anonymisation","parallel corpus","Portuguese-English translation","legal-financial domain","named entities","data privacy","natural language processing","statistical machine translation","corpus resources"],"classifications":["Resources","Information Retrieval","Pre-Processing","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":24},{"id":"66158d50ef6e378c47aa6705e4d35ec4dcf1c763b24f0260fb2d4ecc2d5ff786a56d0799f3da9f8a49deaca230529e46287a86b92505e0f010a3c6043fec621f","file_path":"legal-nlp-survey-20250328-002/original/Wang_2019_0249.pdf","title":"IFlyLegal: A Chinese Legal System for Consultation, Law Searching, and Document Analysis","llm_title":"IFlyLegal: A Chinese Legal System for Consultation, Law Searching, and Document Analysis","authors":["Ziyue Wang","Baoxin Wang","Xingyi Duan","Dayong Wu","Shijin Wang","Guoping Hu","Ting Liu"],"llm_authors":"Ziyue Wang, Baoxin Wang, Xingyi Duan, Dayong Wu, Shijin Wang, Guoping Hu, Ting Liu","author_string":"Ziyue Wang ; Baoxin Wang ; Xingyi Duan ; Dayong Wu ; Shijin Wang ; Guoping Hu ; Ting Liu","year":2019,"abstract":"","llm_abstract":"Legal Tech is developed to help people with legal services and solve legal problems via machines. To achieve this, one of the key requirements for machines is to utilize legal knowledge and comprehend legal context. This can be fulfilled by natural language processing (NLP) techniques, for instance, text representation, text categorization, question answering (QA) and natural language inference, etc. To this end, we introduce a freely available Chinese Legal Tech system (IFlyLegal) that benefits from multiple NLP tasks. It is an integrated system that performs legal consulting, multi-way law searching, and legal document analysis by exploiting techniques such as deep contextual representations and various attention mechanisms. To our knowledge, IFlyLegal is the first Chinese legal system that employs up-to-date NLP techniques and caters for needs of different user groups, such as lawyers, judges, procurators, and clients. Since Jan, 2019, we have gathered 2,349 users and 28,238 page views (till June, 23, 2019).","llm_keywords":["Legal Tech","Chinese Legal System","Natural Language Processing","Legal Consultation","Document Analysis","Law Searching","Text Representation","Question Answering","Deep Learning","Artificial Lawyer"],"classifications":[],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":6},{"id":"50018db7b1420b00d9a9097cdebed5b136aa79cb533d041c7f296b983898d73902d7f36feb3103c013da335aff77cbe8ba89b3b26edd6c216f2b5c7c71a3e302","file_path":"legal-nlp-survey-20250328-002/original/Martinze-Gill_2019_0269.pdf","title":"Multiple Choice Question Answering in the Legal Domain Using Reinforced Co-occurrence","llm_title":"Multiple Choice Question Answering in the Legal Domain Using Reinforced Co-occurrence","authors":["Jorge Martinez-Gil","Bernhard Freudenthaler","A Min Tjoa"],"llm_authors":"Jorge Martinez-Gil, Bernhard Freudenthaler, A Min Tjoa","author_string":"Jorge Martinez-Gil","year":2019,"abstract":"","llm_abstract":"Nowadays, the volume of legal information available is continuously growing. As a result, browsing and querying this huge legal corpus in search of specific information is currently a tedious task exacerbated by the fact that data presentation does not usually meet the needs of professionals in the sector. To satisfy these ever-increasing needs, we have designed an appropriate solution to provide an adaptive and intelligent solution for the automatic answer of questions of legal content based on the computation of reinforced co-occurrence, i.e. a very demanding type of co-occurrence that requires large volumes of information but guarantees good results. This solution is based on the pattern-based methods that have been already successfully applied in information extraction research. An empirical evaluation over a dataset of legal questions seems to indicate that this solution is promising.","llm_keywords":["Expert systems","Legal information processing","Knowledge engineering","Information retrieval","Question answering"],"classifications":["Information Extraction","Information Retrieval","Text Generation","Resources"],"num_cited_by":2,"num_cited_by_title_only":11,"num_pages":11},{"id":"d9f5c5da1dcf01c72913ddc29923950574f61945e11dfaff92e439d5ab17b10bae7257037367beeb068b54ff989e1978a8c04e30b21e800f425f41bf538317a4","file_path":"legal-nlp-survey-20250328-002/original/Mok_2021_0464.pdf","title":"","llm_title":"Sentence Classification for Contract Law Cases: A Natural Language Processing Approach","authors":["Jonathan R. Mok","Wai Yin Mok","Rachel V. Mok"],"llm_authors":"Jonathan R. Mok, Norris Injury Lawyers PC, jonrexmok@gmail.com; Wai Yin Mok, University of Alabama in Huntsville, mokw@uah.edu; Rachel V. Mok, Independent Researcher, rmok57@gmail.com","author_string":"","year":2021,"abstract":"","llm_abstract":"","llm_keywords":["sentence classification","contract law","legal research","machine learning","natural language processing","case law","judicial precedent","United States","legal practice","automation in law"],"classifications":[],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":2},{"id":"289400165bd8babe90e985ba3e5da7f573fc583f2c2899a4fb28c18d1c0f3a5c792c5deae785a91abdbdd75169556daf97e90aac4854d712ee169e3d625d879a","file_path":"legal-nlp-survey-20250328-002/original/Gupta_2017_0153.pdf","title":"","llm_title":"Toward Building a Legal Knowledge-Base of Chinese Judicial Documents for Large-Scale Analytics","authors":["Amarnath Gupta","Alice Z. Wang","Kai Lin","Haoshen Hong","Haoran Sun","Benjamin L. Liebman","Rachel E. Stern","Subhasis Dasgupta","Margaret E. Roberts"],"llm_authors":"Amarnath GUPTA, Alice Z. WANG, Kai LIN, Haoshen HONG, Haoran SUN, Benjamin L. LIEBMAN, Rachel E. STERN, Subhasis DASGUPTA, Margaret E. ROBERTS","author_string":"","year":2017,"abstract":"","llm_abstract":"We present an approach for constructing a legal knowledge-base that is sufficiently scalable to allow for large-scale corpus-level analyses. We do this by creating a polymorphic knowledge representation that includes hybrid ontologies, semistructured representations of sentences, and unsupervised statistical extraction of topics. We apply our approach to over one million judicial decision documents from Henan, China. Our knowledge-base allows us to make corpus-level queries that enable discovery, retrieval, and legal pattern analysis that shed new light on everyday law in China.","llm_keywords":["legal ontology","information extraction","knowledge representation","topic model","Chinese legal documents","text analytics"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":10},{"id":"89d71e8e532607b7730fa47aa272a13fed4d6a780349bde57373133cc27aa2849bb35bf95570b159e0f96006f6b92df92cc4a6a06af230a8116dfd62ee34e0cd","file_path":"legal-nlp-survey-20250328-002/original/Le_2015_0061.pdf","title":"Extracting indices from Japanese legal documents","llm_title":"Extracting indices from Japanese legal documents","authors":["Tho Thi Ngoc Le","Kiyoaki Shirai","Minh Le Nguyen","Akira Shimazu"],"llm_authors":"Tho Thi Ngoc Le, Kiyoaki Shirai, Minh Le Nguyen, Akira Shimazu","author_string":"Tho Thi Ngoc Le","year":2015,"abstract":"","llm_abstract":"This article addresses the problem of automatically extracting legal indices which express the important contents of legal documents. Legal indices are not limited to single-word keywords and compound-word (or phrase) keywords, they are also clause keywords. We approach index extraction using structural information of Japanese sentences, i.e. chunks and clauses. Based on the assumption that legal indices are composed of important tokens from the documents, extracting legal indices is treated as a problem of collecting chunks and clauses that contain as many important tokens as possible. Each token is assigned a weight which is a statistical score, e.g. TF–IDF and Okapi BM25, to indicate its importance. The importance of a chunk or clause is determined based on the average weight of tokens included in that chunk or clause. Then, highly weighted chunks and clauses are recognized as the indices for legal documents. The experimental results on Japanese National Pension Act data show that our proposed method achieves better performance (8.6% higher on F1-score) than TextRank, the most popular unsupervised method in extracting single-word and compound-word keywords. In addition, this approach is also applicable to extract clause keywords with high performance.","llm_keywords":["legal index extraction","Japanese legal document","unsupervised approach","Japanese chunk","Japanese clause"],"classifications":[],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":30},{"id":"4bbf9df5f5e7f2242dd6e0f0629a084b390cfb220089212465fd487d519b553d2f8bcc10045bdb121ad3fe5cb4763b6f58c3bb5dd541dbe17e70d677b64c6688","file_path":"legal-nlp-survey-20250328-002/original/Keppens_2019_0240.pdf","title":"159_Keppens.pdf","llm_title":"Explainable Bayesian Network Query Results via Natural Language Generation Systems","authors":["Jeroen Keppens"],"llm_authors":"Jeroen Keppens","author_string":"","year":2019,"abstract":"","llm_abstract":"Bayesian networks (BNs) are an important modelling technique used to support certain types of decision making in law and forensics. Their value lies in their ability to infer the rational implications of probabilistic knowledge and beliefs, a task that human decision makers struggle with. However, their use is controversial. One of the main obstacles to the more widespread use of BNs is the difficulty to acquire good explanations of the results obtained with BNs. While useful techniques exist to visualise, verbalise or abstract BNs and the inner workings of belief propagation algorithms, these techniques provide generic, one-size-fits-all explanations, that have, thus far, failed to stem the criticism of lack of explainable BN results. Building on the qualified support graph method introduced in earlier work, this paper outlines how a natural language generation system can be constructed to explain Bayesian inference. This constitutes a novel approach to BN explanation that has the potential to produce more focussed and compelling explanations of Bayesian inference as the narratives such a system produces can be tailored to address specific communicative goals and, by extension, the needs of the user.","llm_keywords":["Bayesian networks","natural language generation","explainable AI","probabilistic reasoning","decision support","legal applications","belief propagation","controversy in AI","qualified support graph"],"classifications":["Text Generation"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":10},{"id":"08f8755b244cac0e44e0bc5ec1986c6082322d021ae8f3112b188cdd766b07dc9c910e245156855ed7f6fdda735985857d145c02e2a4fe2cd3a8ddb2c64e0d99","file_path":"legal-nlp-survey-20250328-002/original/Zhu_2020_0341.pdf","title":"","llm_title":"Legal Judgment Prediction Based on Multiclass Information Fusion","authors":["Kongfan Zhu","Rundong Guo","Weifeng Hu","Zeqiang Li","Yujun Li"],"llm_authors":"Kongfan Zhu, Rundong Guo, Weifeng Hu, Zeqiang Li, and Yujun Li","author_string":"","year":2020,"abstract":"","llm_abstract":"","llm_keywords":["legal judgment prediction","multiclass information fusion","Transformer-Hierarchical-Attention-Multi-Extra Network","fact determination","external information","Natural Language Processing","Recurrent Neural Network","Convolutional Neural Network","long-term dependency"],"classifications":[],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":12},{"id":"589b0530d3621b2914e090039b08f852a9c025306225b7049a5a679da99560eee6e74681a05e0768fac5676006e556e299812beb0ef5ca13c77cdd25be19a34c","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2017_0126.pdf","title":"Extracting Contract Elements","llm_title":"Extracting Contract Elements","authors":["Ilias Chalkidis","Ion Androutsopoulos","Achilleas Michos"],"llm_authors":"Ilias Chalkidis, Ion Androutsopoulos, Achilleas Michos","author_string":"Ilias Chalkidis, Ion Androutsopoulos and Achilleas Michos","year":2017,"abstract":"","llm_abstract":"We study how contract element extraction can be automated. We provide a labeled dataset with gold contract element annotations, along with an unlabeled dataset of contracts that can be used to pre-train word embeddings. Both datasets are provided in an encoded form to bypass privacy issues. We describe and experimentally compare several contract element extraction methods that use manually written rules and linear classifiers (logistic regression, SVMs) with hand-crafted features, word embeddings, and part-of-speech tag embeddings. The best results are obtained by a hybrid method that combines machine learning (with hand-crafted features and embeddings) and manually written post-processing rules.","llm_keywords":["Natural language processing","machine learning","legal text analytics","information extraction","contracts","datasets","evaluation"],"classifications":["Information Extraction","Resources","Pre-Processing","Classification"],"num_cited_by":155,"num_cited_by_title_only":155,"num_pages":10},{"id":"ff3bdc5f6df918dfcd8593cbf551a799515227d07312e1740efb8082ba497205faf8061424dd1aefc7bad667fe99fff690c8a3f0c93346931326b32d232eaed3","file_path":"legal-nlp-survey-20250328-002/original/Metsker_2019_0270.pdf","title":"Microsoft Word - paper_3","llm_title":"Natural Language Processing of Russian Court Decisions for Digital Indicators Mapping for Oversight Process Control Efficiency: Disobeying a Police Officer Case","authors":["Oleg Metsker","Egor Trofimov","Sofia Grechishcheva"],"llm_authors":"Oleg Metsker, Egor Trofimov, Sofia Grechishcheva","author_string":"oleg.m","year":2019,"abstract":"","llm_abstract":"This article describes the study results in the development of the method of natural language processing (NLP) of semi-structured Russian court decisions to improve the quality of knowledge extraction describing legal process. Improving the accuracy of information retrieval from electronic records of court decisions was achieved with using combination of TF-IDF and latent semantic analysis. As a result, the word combinations of facts of offenses and procedural facts that may affect the decision-making of the court are identified. The applicability of the results is shown on the example of development a decision tree ML model of the appointment of arrest or fine punishment if disobeying a police officer. Automated mapping of court decisions texts on Russian language is also possible use for the development of artificial intelligence systems and new generation decision support systems in law domain.","llm_keywords":["Natural language processing","Artificial intelligence","Law","Russian court decisions","Digital indicators","Oversight process","Knowledge extraction","TF-IDF","Latent semantic analysis","Decision support systems"],"classifications":[],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":15},{"id":"74c16f6675b2206704bf3f22fa8e264b14f872509d6eff40801d5920b2ad3cf2cb82026b355b88561118df99f377544c86527510999384b4aba68a352d27f2f4","file_path":"legal-nlp-survey-20250328-002/original/Savelka_2021_0443.pdf","title":"","llm_title":"Lex Rosetta: Transfer of Predictive Models Across Languages, Jurisdictions, and Legal Domains","authors":["Jaromir Savelka","Hannes Westermann","Karim Benyekhlef","Charlotte S. Alexander","Jayla C. Grant","David Restrepo Amariles","Rajaa El Hamdani","Sébastien Meeùs","Aurore Troussel","Michał Araszkiewicz","Kevin D. Ashley","Alexandra Ashley","Karl Branting","Mattia Falduti","Matthias Grabmair","Jakub Harašta","Tereza Novotná","Elizabeth Tippett","Shiwanni Johnson"],"llm_authors":"Jaromir Savelka, Hannes Westermann, Karim Benyekhlef, Charlotte S. Alexander, Jayla C. Grant, David Restrepo Amariles, Rajaa El Hamdani, Sébastien Meeùs, Aurore Troussel, Michał Araszkiewicz, Kevin D. Ashley, Alexandra Ashley, Karl Branting, Mattia Falduti, Matthias Grabmair, Jakub Harašta, Tereza Novotná, Elizabeth Tippett, Shiwanni Johnson","author_string":"","year":2021,"abstract":"","llm_abstract":"In this paper, we examine the use of multi-lingual sentence embeddings to transfer predictive models for functional segmentation of adjudicatory decisions across jurisdictions, legal systems (common and civil law), languages, and domains (i.e. contexts). Mechanisms for utilizing linguistic resources outside of their original context have significant potential benefits in AI & Law because differences between legal systems, languages, or traditions often block wider adoption of research outcomes. We analyze the use of Language-Agnostic Sentence Representations in sequence labeling models using Gated Recurrent Units (GRUs) that are transferable across languages. To investigate transfer between different contexts we developed an annotation scheme for functional segmentation of adjudicatory decisions. We found that models generalize beyond the contexts on which they were trained (e.g., a model trained on administrative decisions from the US can be applied to criminal law decisions from Italy). Further, we found that training the models on multiple contexts increases robustness and improves overall performance when evaluating on previously unseen contexts. Finally, we found that pooling the training data from all the contexts enhances the models’ in-context performance.","llm_keywords":["multi-lingual sentence embeddings","transfer learning","domain adaptation","adjudicatory decisions","document segmentation","annotation"],"classifications":["Pre-Processing","Classification","Resources"],"num_cited_by":25,"num_cited_by_title_only":25,"num_pages":10},{"id":"de5a1f60542024f63c31bb244ade15a052831a282919885d4f488e7826ee59a4187a06fd86c93221f481d6c2f8a1af161e9aae2eb2254b5a3fdfc7a8be725114","file_path":"legal-nlp-survey-20250328-002/original/Kalamkar_2022_0575.pdf","title":"","llm_title":"Named Entity Recognition in Indian court judgments","authors":["Prathamesh Kalamkar","Astha Agarwal","Aman Tiwari","Smita Gupta","Saurabh Karn","Vivek Raghavan"],"llm_authors":"Prathamesh Kalamkar, Astha Agarwal, Aman Tiwari, Smita Gupta, Saurabh Karn, Vivek Raghavan","author_string":"","year":2022,"abstract":"","llm_abstract":"Identification of named entities from legal texts is an essential building block for developing other legal Artificial Intelligence applications. Named Entities in legal texts are slightly different and more fine-grained than commonly used named entities like Person, Organization, Location etc. In this paper, we introduce a new corpus of 46545 annotated legal named entities mapped to 14 legal entity types. The Baseline model for extracting legal named entities from judgment text is also developed. We publish the training, dev data and trained baseline model https://github.com/ Legal-NLP-EkStep/legal_NER.","llm_keywords":["Named Entity Recognition","Legal AI","Indian court judgments","legal texts","judicial system","annotated corpus","transformer-based model","information extraction","judgment text","legal entity types"],"classifications":["Information Extraction","Resources"],"num_cited_by":46,"num_cited_by_title_only":46,"num_pages":10},{"id":"808463da85ca82696aff571513110d2df0ae943edd6f60caeeb3275c6d46dab23e13e2ad8348df14bc702ea6318c09af5a1940b929fbfcc87decc858e491a0a3","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2019_0242.pdf","title":"","llm_title":"Extreme Multi-Label Legal Text Classification: A case study in EU Legislation","authors":["Ilias Chalkidis","Manos Fergadiotis","Prodromos Malakasiotis","Nikolaos Aletras","Ion Androutsopoulos"],"llm_authors":"Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, Ion Androutsopoulos","author_string":"","year":2019,"abstract":"","llm_abstract":"We consider the task of Extreme Multi-Label Text Classification (XMTC) in the legal domain. We release a new dataset of 57k legislative documents from EUR-LEX, the European Union’s public document database, annotated with concepts from EUROVOC, a multidisciplinary thesaurus. The dataset is substantially larger than previous EUR-LEX datasets and suitable for XMTC, few-shot and zero-shot learning. Experimenting with several neural classifiers, we show that BIGRUs with self-attention outperform the current multi-label state-of-the-art methods, which employ label-wise attention. Replacing CNNs with BIGRUs in label-wise attention networks leads to the best overall performance.","llm_keywords":["Extreme Multi-Label Text Classification","legal text processing","EU Legislation","EURLEX57K","neural classifiers","BIGRU","self-attention","EUROVOC","few-shot learning","zero-shot learning"],"classifications":["Classification","Resources"],"num_cited_by":103,"num_cited_by_title_only":103,"num_pages":10},{"id":"6dba09dd7a5728cdf17e1d5d459e19ccdba550ab3f4bdc9bea02133644987b7209edfac7f1cda520d70df7cc9027e0284403237d413514e63c9e319b6e9228ed","file_path":"legal-nlp-survey-20250328-002/original/Dragoni_2015_0057.pdf","title":"Combining Natural Language Processing Approaches for Rule Extraction from Legal Documents","llm_title":"Combining Natural Language Processing Approaches for Rule Extraction from Legal Documents","authors":["Mauro Dragoni","Serena Villata","Williams Rizzi","Guido Governatori"],"llm_authors":"Mauro Dragoni, Serena Villata, Williams Rizzi, and Guido Governatori","author_string":"Mauro Dragoni","year":2018,"abstract":"","llm_abstract":"Legal texts express conditions in natural language describing what is permitted, forbidden or mandatory in the context they regulate. Despite the numerous approaches tackling the problem of moving from a natural language legal text to the respective set of machine-readable conditions, results are still unsatisfiable and it remains a major open challenge. In this paper, we propose a preliminary approach which combines different Natural Language Processing techniques towards the extraction of rules from legal documents. More precisely, we combine the linguistic information provided by WordNet together with a syntax-based extraction of rules from legal texts, and a logic-based extraction of dependencies between chunks of such texts. Such a combined approach leads to a powerful solution towards the extraction of machine-readable rules from legal documents. We evaluate the proposed approach over the Australian 'Telecommunications consumer protections code'.","llm_keywords":["Natural Language Processing","Rule Extraction","Legal Documents","Deontic Reasoning","Machine-readable rules","WordNet","Stanford Parser","Boxer framework","Telecommunications consumer protections code"],"classifications":["Information Extraction"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":14},{"id":"625d69ee263919861351f18e0a31919c9e39fd7727c5feba1107d0f8e7d68fe93fe4084456b6f6454381aa21a2f3e5487ddebcaa44624809803cceb485520576","file_path":"legal-nlp-survey-20250328-002/original/Alschner_2016_0085.pdf","title":"ALSCHNER_9","llm_title":"Can Robots Write Treaties? Using Recurrent Neural Networks to Draft International Investment Agreements","authors":["Wolfgang Alschner","Dmitriy Skougarevskiy"],"llm_authors":"Wolfgang Alschner and Dmitriy Skougarevskiy","author_string":"Wolfgang","year":2016,"abstract":"","llm_abstract":"Negotiating international investment agreements is costly, complex, and prone to power asymmetries. Would it then not make sense to let computers do part of the work? In this contribution, we train a character-level recurrent neural network (RNN) to write international investment agreements. Benefitting from the formulaic nature of treaty language, the RNN generates texts of lawyer-like quality on the article-level, but fails to compose treaties in a legally sensible manner. By embedding RNNs in a user-controlled pipeline we overcome this problem. First, users can specify the treaty content categories ex ante on which the RNN is trained. Second, the pipeline allows a filtering of output ex post by identifying output that corresponds most closely to a user-selected treaty design benchmark. The result is an improved system that produces meaningful texts with legally sensible composition. We test the pipeline by comparing predicted treaties to actually concluded ones and by verifying that our filter captures latent policy preferences by predicting the outcome of current investment treaty negotiations between China and the United States.","llm_keywords":["Recurrent neural network","investment treaties","machine learning","legal drafting","artificial intelligence"],"classifications":["Text Generation","Pre-Processing"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":6},{"id":"b1a548903e65a8ee2189bab0de8a7b8329fe18ded8b3f06f8a49c62768ba8cd467af79cbeecedfbf913045f8dbeaba9979709ada24a4a7a944dd84d1930f55f6","file_path":"legal-nlp-survey-20250328-002/original/Taniguchi_2016_0094.pdf","title":"453751_1_En_19_Chapter 284..298","llm_title":"Legal Yes/No Question Answering System Using Case-Role Analysis","authors":["Ryosuke Taniguchi","Yoshinobu Kano"],"llm_authors":"Ryosuke Taniguchi and Yoshinobu Kano","author_string":"","year":2017,"abstract":"","llm_abstract":"A central issue of yes/no question answering is the usage of knowledge source given a question. While yes/no question answering has been studied for a long time, legal yes/no question answering largely differs from other domains. The most distinguishing characteristic is that legal issues require precise analysis of roles and relationships of agents named in sentences. We have developed a yes/no question answering system for answering questions about a statute legal domain. Our system uses case-role analysis, in order to find correspondences of roles and relationships between given problem sentences and knowledge source sentences. We applied our system to the JURISIN’s COLIEE (Competition on Legal Information Extraction/Entailment) 2016 task. Our system performance was better than systems of previous task participants and shared first place in current year’s task in Phase Two. This result shows the importance of the points described above, while revealing opportunities to continue further work on improving our system’s accuracy.","llm_keywords":["COLIEE","Question answering","Legal bar exam","Legal Information Extraction","Case-role analysis","JURISIN","Textual entailment","Natural language processing"],"classifications":["Information Extraction","Classification"],"num_cited_by":25,"num_cited_by_title_only":25,"num_pages":15},{"id":"0ac0ee76364a518b012dbbc3d89df68f36c78773d5fd79e424d83758296d614a03ebeed0a8bd9ed934f3df87d968e3c30f90542fd50dc9a9652549782435c520","file_path":"legal-nlp-survey-20250328-002/original/Sierra_2018_0177.pdf","title":"","llm_title":"CoUSBi: A Structured and Visualized Legal Corpus of US State Bills","authors":["Aikaterini-Lida Kalouli","Leo Vrana","Vigile Marie Fabella","Luna Bellani","Annette Hautli-Janisz"],"llm_authors":"Aikaterini-Lida Kalouli, Leo Vrana, Vigile Marie Fabella, Luna Bellani, Annette Hautli-Janisz","author_string":"","year":2018,"abstract":"","llm_abstract":"","llm_keywords":["Legal Knowledge Graph","Semantic Web technologies","language resources","cross-border commerce","regtech","cognitive computing","text resources","interoperable language technologies","European Union"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":56},{"id":"a406a13f8da51ce6dff9d33b5b09bf05f0a01a62a9336c8336c14d5ddad06a21b9c0cde965c4e8dd7d75b7e53452692ee4719f07b79a0b47d9b82a9039ea7336","file_path":"legal-nlp-survey-20250328-002/original/Marques_2019_0267.pdf","title":"198_Marques.pdf","llm_title":"Machine learning for explaining and ranking the most influential matters of law","authors":["Max R. S. Marques","Tommaso Bianco","Maxime Roodnejad","Thomas Baduel","Claude Berrou"],"llm_authors":"Max R. S. Marques, Tommaso Bianco, Maxime Roodnejad, Thomas Baduel, Claude Berrou","author_string":"","year":2019,"abstract":"","llm_abstract":"In this work, we propose a novel method in order to rank the most relevant legal principle citations in law-cases to support a certain motion. The first score relies on feature importance metrics, where each law article is a feature supplied to a classifier for the decision outcome. The second score is based on word embeddings text similarity. As a result, our method outperforms the baseline techniques based on feature importance selection and Information Retrieval methods in the ranking evaluation relevance criteria.","llm_keywords":["Machine learning","model explanation","feature selection","argument mining","legal principles","text similarity","word embeddings","NLP"],"classifications":["Information Retrieval","Classification"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":5},{"id":"275e525b1422101c67c082bd2697799f7bffad302c7caf04bce1021baca46584c2aeef873c6fa339d84bf767aabed0247f2ac5cc716d08b3b260d3c0c97bad12","file_path":"legal-nlp-survey-20250328-002/original/Andrew_2018_0167.pdf","title":"Automatic Extraction of Entities and Relation from Legal Documents","llm_title":"Automatic Extraction of Entities and Relation from Legal Documents","authors":["Judith Jeyafreeda Andrew","Xavier Tannier"],"llm_authors":"Judith Jeyafreeda Andrew, Xavier Tannier","author_string":"Judith Jeyafreeda Andrew","year":2018,"abstract":"","llm_abstract":"In recent years, the journalists and computer sciences speak to each other to identify useful technologies which would help them in extracting useful information. This is called ”computational Journalism”. In this paper, we present a method that will enable the journalists to automatically identifies and annotates entities such as names of people, organizations, role and functions of people in legal documents; the relationship between these entities are also explored. The system uses a combination of both statistical and rule based technique. The statistical method used is Conditional Random Fields and for the rule based technique, document and language specific regular expressions are used.","llm_keywords":["named entity recognition","legal documents","entity extraction","relation extraction","conditional random fields","computational journalism","statistical methods","rule-based techniques"],"classifications":["Information Extraction"],"num_cited_by":27,"num_cited_by_title_only":27,"num_pages":8},{"id":"bcd8e4f664cc758b00afb365dbca4f748959b5bbb656ca1a1e51a14c7b170f5fc533dcf44edebeaf12a732eb1ba0c5e4c17c55f5e76f117b50cabcbb91594e8f","file_path":"legal-nlp-survey-20250328-002/original/Arts_2021_0452.pdf","title":"Natural Language Processing to Identify the Creation and Impact of New Technologies in Patent Text: Code, Data, and New Measures","llm_title":"Natural Language Processing to Identify the Creation and Impact of New Technologies in Patent Text: Code, Data, and New Measures","authors":["Sam Arts","Jianan Hou","Juan Carlos Gomez"],"llm_authors":"Sam Arts, Jianan Hou, Juan Carlos Gomez","author_string":"Sam Arts","year":2021,"abstract":"","llm_abstract":"We develop natural language processing techniques to identify the creation and impact of new technologies in the population of U.S. patents. We validate the new techniques and their improvement over traditional metrics based on patent classification and citations in two case-control studies. First, we collect patents linked to awards such as the Nobel prize and the National Inventor Hall of Fame. These patents likely cover radically new technologies with a major impact on technological progress and patenting. Second, we identify patents granted by the United States Patent and Trademark Office but simultaneously rejected by both the European and Japanese patent office. Such patents arguably lack novelty or cover small incremental advances over prior art and should have little impact on technological progress. We provide open access to code, data, and new measures for all utility patents granted by the USPTO up to May 2018 (see https://zenodo.org/record/3515985, DOI: 10.5281/zenodo.3515985).","llm_keywords":["Natural language processing","Patent","Novelty","Impact","Breakthrough","Award"],"classifications":["Information Extraction","Classification","Resources"],"num_cited_by":229,"num_cited_by_title_only":229,"num_pages":14},{"id":"269eae4e657b9c4136069b153292a5e77c8c02a7cce9f040358bbe07309346e854ea02c2e62ac58574aba20102af535162765dc3a0542ff9c42b94261bdf17f8","file_path":"legal-nlp-survey-20250328-002/original/Matthews_2022_0583.pdf","title":"","llm_title":"Experimenting with ensembles of pre-trained language models for classification of custom legal datasets","authors":["Tamara Matthews","David Lillis"],"llm_authors":"Tamara Matthews and David Lillis","author_string":"","year":2022,"abstract":"","llm_abstract":"Document corpora owned by law and regulatory firms pose significant challenges for text classification; being multi-labelled, highly imbalanced, often having a relatively small number of instances and a large word count per instance. Deep learning ensemble methods can improve generalization and performance for multi-label text classification but using pre-trained language models as base learners leads to high computational costs. To tackle the imbalance problem and improve generalization we present a fast, pseudo-stratified sub-sampling method that we use to extract diverse data subsets to create base models for deep ensembles based on fine-tuned models from pre-trained transformers with moderate computational cost such as BERT, RoBERTa, XLNet and Albert. A key feature of the sub-sampling method is that it preserves the characteristics of the entire dataset (particularly the labels’ frequency distribution) while extracting subsets. This sub-sampling method is also used to extract smaller size custom datasets from the freely available LexGLUE legal text corpora. We discuss approaches used and classification performance results with deep learning ensembles, illustrating the effectiveness of our approach on the above custom datasets.","llm_keywords":["pre-trained language models","multi-label classification","legal datasets","deep learning ensembles","text classification","pseudo-stratified sub-sampling","BERT","RoBERTa","XLNet","ALBERT"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":10},{"id":"1790e5fca2f0a06e3898304beba3dd8499f831bc89cc01ca259fb2798f33d4c7041b49387e84dad793f4412721a2f2c76478fb922949dc8b57390a6a50f6c69b","file_path":"legal-nlp-survey-20250328-002/original/Savelka_2019_0250.pdf","title":"200_Savelka.pdf","llm_title":"Improving Sentence Retrieval from Case Law for Statutory Interpretation","authors":["Jaromir Savelka","Huihui Xu","Kevin D. Ashley"],"llm_authors":"Jaromir Savelka, Huihui Xu, Kevin D. Ashley","author_string":"","year":2019,"abstract":"","llm_abstract":"Statutory texts employ vague terms that are difficult to understand. Here we study and evaluate methods for retrieving useful sentences from court opinions that elaborate on the meaning of a vague statutory term. Retrieving sentences instead of whole cases may spare a user the need to review long lists of cases in search of useful explanations. We assembled a data set of 4,635 sentences that were responses to three statutory queries and labeled them in terms of their usefulness for interpretation. We have run a series of experiments on this data set, which we have made public, assessing different techniques to solve the task. These include techniques that measure the similarity between the sentence and the query, utilize the context of a sentence, expand queries, or assess the novelty of a sentence with respect to a statutory provision from which the interpreted term comes. Based on a detailed error analysis we propose a specialized sentence retrieval framework that mitigates the challenges of retrieving case law sentences for interpreting statutory terms. The results of evaluating different implementations of the framework are promising (.725 for NDGC at 10, .662 at 100).","llm_keywords":["Information retrieval","statutory interpretation","case-law analysis","relevant sentences","similarity measures"],"classifications":["Information Retrieval"],"num_cited_by":29,"num_cited_by_title_only":29,"num_pages":10},{"id":"6327c003c8cf7917339fb6341d2e0e1dd682bedd71cbf9a5acb8edad81c1adc914f346dae10791c55a6184cb1d8faa70ad22c63dd4fa5bae433207adc244b4b2","file_path":"legal-nlp-survey-20250328-002/original/Au_2022_0548.pdf","title":"","llm_title":"E-NER — An Annotated Named Entity Recognition Corpus of Legal Text","authors":["Ting Wai Terence Au","Vasileios Lampos","Ingemar J. Cox"],"llm_authors":"Ting Wai Terence Au, Vasileios Lampos, Ingemar J. Cox","author_string":"","year":2022,"abstract":"","llm_abstract":"Identifying named entities such as a person, location or organization, in documents can highlight key information to readers. Training Named Entity Recognition (NER) models requires an annotated data set, which can be a time-consuming labour-intensive task. Nevertheless, there are publicly available NER data sets for general English. Recently there has been interest in developing NER for legal text. However, prior work and experimental results reported here indicate that there is a significant degradation in performance when NER methods trained on a general English data set are applied to legal text. We describe a publicly available legal NER data set, called E-NER, based on legal company filings available from the US Securities and Exchange Commission’s EDGAR data set. Training a number of different NER algorithms on the general English CoNLL-2003 corpus but testing on our test collection confirmed significant degradations in accuracy, as measured by the F1-score, of between 29.4% and 60.4%, compared to training and testing on the E-NER collection.","llm_keywords":["Named Entity Recognition","Legal Text","E-NER Corpus","Annotated Data Set","Domain-Specific NLP","Transfer Learning","Performance Degradation","Securities and Exchange Commission","EDGAR Database"],"classifications":["Resources","Information Extraction"],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":10},{"id":"3261f01e6ae65de8cf79b2cdbffe2bf97a3ecd08686b7ce4c11be15c91f8f1dfd5422aacc2d518350ce61625b84194e4b25cbd09b2cf3574624e3f5b1d1f694b","file_path":"legal-nlp-survey-20250328-002/original/Wang_2019_0210.pdf","title":"A novelty detection patent mining approach for analyzing technological opportunities","llm_title":"A novelty detection patent mining approach for analyzing technological opportunities","authors":["Juite Wang","Yi-Jing Chen"],"llm_authors":"Juite Wang, Yi-Jing Chen","author_string":"Juite Wang","year":2019,"abstract":"","llm_abstract":"Early opportunity identification is critical for technology-based firms seeking to develop technology or product strategies for competitive advantage in the future. This research develops a patent mining approach based on the novelty detection statistical technique to identify unusual patents that may provide a fresh idea for potential opportunities. A natural language processing technique, latent semantic analysis, is applied to extract hidden relations between words in patent documents for alleviating the vocabulary mismatch problem and reducing the cumbersome efforts of keyword selection by experts. The angle-based outlier detection method, a novelty detection statistical technique, is used to determine outlier patents that are distinct from the majority of collected patent documents in a high-dimensional data space. Finally, visualization tools are developed to analyze the identified outlier patents for exploring potential technological opportunities. The developed methodology is applied in the telehealth industry and research findings can help telehealth firms formulate their technology strategies.","llm_keywords":["Technological opportunity analysis","Patent analysis","Novelty detection","Text mining","Telehealth"],"classifications":["Information Extraction"],"num_cited_by":93,"num_cited_by_title_only":93,"num_pages":11},{"id":"6404c6f599e066b780fed46e897c6f4d45c8027f8f90d3877deac38e1a5b431e7cac37cb3ad4f4df00197df26043aab1a411308f570d35bc19e6a8a4142babd8","file_path":"legal-nlp-survey-20250328-002/original/Wenger_2021_0395.pdf","title":"Automated Extraction of Sentencing Decisions from Court Cases in the Hebrew Language","llm_title":"Automated Extraction of Sentencing Decisions from Court Cases in the Hebrew Language","authors":["Mohr Wenger","Tom Kalir","Noga Berger","Carmit Klar Chalamish","Renana Keydar","Gabriel Stanovsky"],"llm_authors":"Mohr Wenger, Tom Kalir, Noga Berger, Carmit Klar Chalamish, Renana Keydar, Gabriel Stanovsky","author_string":"Mohr Wenger ; Tom Kalir ; Noga Berger ; Carmit Klar Chalamish ; Renana Keydar ; Gabriel Stanovsky","year":2021,"abstract":"","llm_abstract":"We present the task of Automated Punishment Extraction (APE) in sentencing decisions from criminal court cases in Hebrew. Addressing APE will enable the identification of sentencing patterns and constitute an important stepping stone for many follow-up legal NLP applications in Hebrew, including the prediction of sentencing decisions. We curate a dataset of sexual assault sentencing decisions and a manually-annotated evaluation dataset, and implement rule-based and supervised models. We find that while supervised models can identify the sentence containing the punishment with good accuracy, rule-based approaches outperform them on the full APE task. We conclude by presenting a first analysis of sentencing patterns in our dataset and analyze common models' errors, indicating avenues for future work, such as distinguishing between probation and actual imprisonment punishment. We will make all our resources available upon request, including data, annotation, and first benchmark models.","llm_keywords":["Automated Punishment Extraction","sentencing decisions","Hebrew language","legal NLP","sexual assault cases","rule-based models","supervised models","punishment extraction","court cases"],"classifications":["Information Extraction","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":10},{"id":"b0164915778a7e9aaa8c5fcc9d2fe99498e1cb163bf5d68bb6838e3aa1c9d94628c47abadc259302d1f1b5858287bae1fafceb5d6dc2bb3460049926baf35e00","file_path":"legal-nlp-survey-20250328-002/original/Bansal_2019_0213.pdf","title":"A Review on the Application of Deep Learning in Legal Domain","llm_title":"A Review on the Application of Deep Learning in Legal Domain","authors":["Neha Bansal","Arun Sharma","R. K. Singh"],"llm_authors":"Neha Bansal, Arun Sharma, R. K. Singh","author_string":"Neha Bansal","year":2019,"abstract":"","llm_abstract":"The Amount of legal information that is being produced on a daily basis in the law courts is increasing enormously and nowadays this information is available in electronic form also. The application of various machine learning and deep learning methods for processing of legal documents has been receiving considerate attention over the last few years. Legal document classification, translation, summarization, contract review, case prediction and information retrieval are some of the tasks that have received concentrated efforts from the research community. In this survey, we have performed a comprehensive study of various deep learning methods applied in the legal domain and classified various legal tasks into three broad categories, viz. legal data search, legal text analytics and legal intelligent interfaces. The proposed study suggests that deep learning models like CNNs, RNNs, LSTM and GRU, and multi-task deep learning models are being used actively to solve wide variety of legal tasks and are giving state-of-the-art performance.","llm_keywords":["Deep learning","Legal text analytics","Classification","Prediction systems","Legal domain","Machine learning","Legal documents","Artificial Intelligence","Neural networks"],"classifications":["Classification","Machine Summarization","Information Retrieval"],"num_cited_by":44,"num_cited_by_title_only":44,"num_pages":8},{"id":"21f3e8a10a46ad749c9d81ddbd8967a34630e66a0bf71bc08ab49f00d6c689a805b133cb3796d81a23d9c0304bcbeda38f11ee049e1711c5c4d2ff196be71d07","file_path":"legal-nlp-survey-20250328-002/original/Sugathadasa_2018_0188.pdf","title":"Legal Document Retrieval using Document Vector Embeddings and Deep Learning","llm_title":"Legal Document Retrieval using Document Vector Embeddings and Deep Learning","authors":["Keet Sugathadasa","Buddhi Ayesha","Nisansa de Silva","Amal Shehan Perera","Vindula Jayawardana","Dimuthu Lakmal","Madhavi Perera"],"llm_authors":"Keet Sugathadasa, Buddhi Ayesha, Nisansa de Silva, Amal Shehan Perera, Vindula Jayawardana, Dimuthu Lakmal, Madhavi Perera","author_string":"Keet Sugathadasa,Buddhi Ayesha,Nisansa de Silva,Amal Shehan Perera,Vindula Jayawardana,Dimuthu Lakmal,Madhavi Perera","year":2018,"abstract":"","llm_abstract":"Domain specific information retrieval process has been a prominent and ongoing research in the field of natural language processing. Many researchers have incorporated different techniques to overcome the technical and domain specificity and provide a mature model for various domains of interest. The main bottleneck in these studies is the heavy coupling of domain experts, that makes the entire process to be time consuming and cumbersome. In this study, we have developed three novel models which are compared against a golden standard generated via the online repositories provided, specifically for the legal domain. The three different models incorporated vector space representations of the legal domain, where document vector generation was done in two different mechanisms and as an ensemble of the above two. This study contains the research being carried out in the process of representing legal case documents into different vector spaces, whilst incorporating semantic word measures and natural language processing techniques. The ensemble model built in this study, shows a significantly higher accuracy level, which indeed proves the need for incorporation of domain specific semantic similarity measures into the information retrieval process. This study also shows, the impact of varying distribution of the word similarity measures, against varying document vector dimensions, which can lead to improvements in the process of legal information retrieval.","llm_keywords":["Document Embedding","Deep Learning","Information Retrieval","Legal Documents","Natural Language Processing","Semantic Similarity"],"classifications":["Information Retrieval","Resources"],"num_cited_by":23,"num_cited_by_title_only":92,"num_pages":9},{"id":"e0260994296fbf90a1946ba40933408e5e38e3ee7eb2a6bf817ba2bf5acf726abc80cef4ba8c2864898c8a2ce0d70a371f46e8ab30b21101a3a72f7cba121a56","file_path":"legal-nlp-survey-20250328-002/original/Friedrich_2020_0321.pdf","title":"","llm_title":"Entropy in Legal Language","authors":["Roland Friedrich","Mauro Luzzatto","Elliott Ash"],"llm_authors":"Roland Friedrich, Mauro Luzzatto, Elliott Ash","author_string":"","year":2020,"abstract":"","llm_abstract":"We introduce a novel method to measure word ambiguity, i.e. local entropy, based on a neural language model. We use the measure to investigate entropy in the written text of opinions published by the U.S. Supreme Court (SCOTUS) and the German Bundesgerichtshof (BGH), representative courts of the common-law and civil-law court systems respectively. We compare the local (word) entropy measure with a global (document) entropy measure constructed with a compression algorithm. Our method uses an auxiliary corpus of parallel English and German to adjust for persistent differences in entropy due to the languages. Our results suggest that the BGH’s texts are of lower entropy than the SCOTUS’s. Investigation of low- and high-entropy features suggests that the entropy differential is driven by more frequent use of technical language in the German court.","llm_keywords":["entropy","legal language","neural language model","common law","civil law","U.S. Supreme Court","German Bundesgerichtshof","word ambiguity","information theory","judiciary analysis"],"classifications":["Information Extraction","Resources"],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":12},{"id":"86dad1dc4e0eaaff2e48345fdba3584861b3f0a0b5750b5861550adb2b29d401fd9f30a5b3f75b4a7a35a650f55c1f2e5bf78a0629a1c6d1fa7b3eeb733ca7c3","file_path":"legal-nlp-survey-20250328-002/original/Oger-Vihikan_2021_0398.pdf","title":"Automatic Resolution of Domain Name Disputes","llm_title":"Automatic Resolution of Domain Name Disputes","authors":["Wayan Oger Vihikan","Meladel Mistica","Inbar Levy","Andrew F. Christie","Timothy Baldwin"],"llm_authors":"Wayan Oger Vihikan, Meladel Mistica, Inbar Levy, Andrew F. Christie, Timothy Baldwin","author_string":"Wayan Oger Vihikan ; Meladel Mistica ; Inbar Levy ; Andrew Christie ; Timothy Baldwin","year":2021,"abstract":"","llm_abstract":"We introduce the new task of domain name dispute resolution (DNDR), that predicts the outcome of a process for resolving disputes about legal entitlement to a domain name. The ICANN UDRP establishes a mandatory arbitration process for a dispute between a trademark owner and a domain name registrant pertaining to a generic Top-Level Domain (gTLD) name (one ending in .COM, .ORG, .NET, etc). The nature of the problem leads to a very skewed data set, which stems from being able to register a domain name with extreme ease, very little expense, and no need to prove an entitlement to it. In this paper, we describe the task and associated data set. We also present benchmarking results based on a range of models, which show that simple baselines are in general difficult to beat due to the skewed data distribution, but in the specific case of the respondent having submitted a response, a fine-tuned BERT model offers considerable improvements over a majority-class model.","llm_keywords":["Domain Name Dispute Resolution","Cybersquatting","ICANN UDRP","Arbitration","Legal NLP","Trademark Disputes","BERT Model","Data Skewness","Litigation Alternative","Legal Judgment Prediction"],"classifications":["Classification","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"3c846d54ba52021695b0e97d256a1188bdfa9993795fbff7e1580b608a1d4179bcc3659ceb899fdaf26f01cc5132327fa9f6c30edd4192eb0317035250c17723","file_path":"legal-nlp-survey-20250328-002/original/Waltl_2017_0116.pdf","title":"","llm_title":"Classifying Legal Norms with Active Machine Learning","authors":["Bernhard Waltl","Johannes Muhr","Ingo Glaser","Georg Bonczek","Elena Scepankova","Florian Matthes"],"llm_authors":"Bernhard Waltl, Johannes Muhr, Ingo Glaser, Georg Bonczek, Elena Scepankova, Florian Matthes","author_string":"","year":2017,"abstract":"","llm_abstract":"This paper describes an extended machine learning approach to classify legal norms in German statutory texts. We implemented an active machine learning (AML) framework based on open-source software. Within the paper we discuss different query strategies to optimize the selection of instances during the learning phase to decrease the required training data. The approach was evaluated within the domain of tenancy law. Thereby, we manually labeled the 532 sentences into eight different functional types and achieved an average F1 score of 0.74. Comparing three different classifiers and four query strategies the classification performance F1 varies from 0.60 to 0.93. We could show that in norm classification tasks AML is more efficient than conventional supervised machine learning approaches.","llm_keywords":["norm classification","active machine learning","text mining","legal norms","AML","machine learning","tenancy law","query strategies"],"classifications":["Classification"],"num_cited_by":39,"num_cited_by_title_only":39,"num_pages":10},{"id":"eb26a427a725073e9d49e4ad51b242dc5835fd015697c8c2aa652f4191861002594b4328d1d164f4f04fc325ab32ce4a59cdaee481e1dfd7b27f258860565052","file_path":"legal-nlp-survey-20250328-002/original/Sarica_2020_0365.pdf","title":"Microsoft Word - manuscript_technet_revision_20190909_arxiv.docx","llm_title":"TechNet: Technology Semantic Network Based on Patent Data","authors":["Serhad Sarica","Jianxi Luo","Kristin L. Wood"],"llm_authors":"Serhad Sarica, Jianxi Luo, Kristin L. Wood","author_string":"","year":2019,"abstract":"","llm_abstract":"The growing developments in general semantic networks, knowledge graphs and ontology databases have motivated us to build a large-scale comprehensive semantic network of technology-related data for engineering knowledge discovery, technology search and retrieval, and artificial intelligence for engineering design and innovation. Specially, we constructed a technology semantic network (TechNet) that covers the elemental concepts in all domains of technology and their semantic associations by mining the complete U.S. patent database from 1976. To derive the TechNet, natural language processing techniques were utilized to extract terms from massive patent texts and recent word embedding algorithms were employed to vectorize such terms and establish their semantic relationships. We report and evaluate the TechNet for retrieving terms and their pairwise relevance that is meaningful from a technology and engineering design perspective. The TechNet may serve as an infrastructure to support a wide range of applications, e.g., technical text summaries, search query predictions, relational knowledge discovery, and design ideation support, in the context of engineering and technology, and complement or enrich existing semantic databases. To enable such applications, the TechNet is made public via an online interface and APIs for public users to retrieve technology-related terms and their relevancies.","llm_keywords":["knowledge discovery","word embedding","technology semantic network","knowledge representation"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":199,"num_cited_by_title_only":199,"num_pages":34},{"id":"c71e34ededf20d0734ca4baeac6d4e2edb1f009bf1c843b51c6aa218e6385ff053bc79a5a42c895a86e645e547bcc55173d8b32e681bc651e96ef0c9a00201cb","file_path":"legal-nlp-survey-20250328-002/original/Galletta_2021_0446.pdf","title":"Measuring Judicial Sentiment: Methods and Application to U.S. Circuit Courts","llm_title":"Measuring Judicial Sentiment: Methods and Application to U.S. Circuit Courts","authors":["Sergio Galletta","Elliott Ash","Daniel L. Chen"],"llm_authors":"Sergio Galletta, Elliott Ash, Daniel L. Chen","author_string":"Sergio Galletta, Elliott Ash, Daniel L. Chen","year":2022,"abstract":"","llm_abstract":"This paper provides a general method for analyzing the sentiments expressed in the language of judicial rulings. We apply natural language processing tools to the text of U.S. appellate court opinions to extrapolate judges’ sentiments (positive/good vs. negative/bad) toward a number of target social groups. We explore descriptively how these sentiments vary over time and across types of judges. In addition, we provide a method for using random assignment of judges in an instrumental variables framework to estimate causal effects of judges’ sentiments. In an empirical application, we show that more positive sentiment influences future judges by increasing the likelihood of reversal but also increasing the number of forward citations.","llm_keywords":["judicial sentiment","natural language processing","U.S. Circuit Courts","instrumental variables","sentiment analysis","judicial opinions","empirical legal studies","machine learning","biases","preferences"],"classifications":["Classification","Information Extraction"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":28},{"id":"29aa913443b80e150bcbae88de7d042db78e4436383fcff68d8ba515570bbec67bd9dba62358a876f85e8b0de62c6183eb998e7a246cdc72b1e48fb11e97b02a","file_path":"legal-nlp-survey-20250328-002/original/Chen_2022_0584.pdf","title":"","llm_title":"Knowledge is Power: Understanding Causality Makes Legal judgment Prediction Models More Generalizable and Robust","authors":["Haotian Chen","Lingwei Zhang","Fanchao Chen","Yang Yu"],"llm_authors":"Haotian Chen, Lingwei Zhang, Fanchao Chen, Yang Yu","author_string":"","year":2022,"abstract":"","llm_abstract":"Legal judgment Prediction (LJP), aiming to predict a judgment based on fact descriptions, serves as legal assistance to mitigate the great work burden of limited legal practitioners. Most existing methods apply various large-scale pre-trained language models (PLMs) finetuned in LJP tasks to obtain consistent improvements. However, we discover the fact that the state-of-the-art (SOTA) model makes judgment predictions according to wrong (or non-casual) information, which not only weakens the model’s generalization capability but also results in severe social problems like discrimination. Here, we analyze the causal mechanism misleading the LJP model to learn the spurious correlations, and then propose a framework to guide the model to learn the underlying causality knowledge in the legal texts. Specifically, we first perform open information extraction (OIE) to refine the text having a high proportion of causal information, according to which we generate a new set of data. Then, we design a model learning the weights of the refined data and the raw data for LJP model training. The extensive experimental results show that our model is more generalizable and robust than the baselines and achieves a new SOTA performance on two commonly used legal-specific datasets.","llm_keywords":["Legal judgment prediction","Causality","Machine learning","Pre-trained language models","Generalization capability","Robustness","Legal AI","Spurious correlations"],"classifications":["Information Extraction","Pre-Processing","Classification","Text Generation"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":10},{"id":"f40e3b06ee9d900965c237eaa98fa0d490bb07b0a192e984cbcff182352563267d6f7b9f82c684651a0915c650b74ec2d1565fbb39d9a83aee9b6ccd5dd60cfa","file_path":"legal-nlp-survey-20250328-002/original/Shaffer_2019_0260.pdf","title":"Proceedings of the Natural Legal Language Processing Workshop 2019","llm_title":"Legal Linking: Citation Resolution and Suggestion in Constitutional Law","authors":["Robert Shaffer","Stephen Mayhew"],"llm_authors":"Robert Shaffer, Stephen Mayhew","author_string":"Association for Computational Linguistics","year":2021,"abstract":"","llm_abstract":"This paper describes a dataset and baseline systems for linking paragraphs from court cases to clauses or amendments in the US Constitution. We implement a rule-based system, a linear model, and a neural architecture for matching pairs of paragraphs, taking training data from online databases in a distantly-supervised fashion. In experiments on a manually-annotated evaluation set, we find that our proposed neural system outperforms a rules-driven baseline. Qualitatively, this performance gap seems largest for abstract or indirect links between documents, which suggests that our system might be useful for answering political science and legal research questions or discovering novel links. We release the dataset along with the manually-annotated evaluation set to foster future work.","llm_keywords":["legal linking","citation resolution","US Constitution","neural architecture","distant supervision"],"classifications":["Information Retrieval","Resources"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":7},{"id":"7433f89ebb551283be10b5792a1c1d20edca9e59e4809e545b3813d96630b9db376f3672a14ead830de1109b237e61e543d5135c01ea5fbde806e35291bb29ed","file_path":"legal-nlp-survey-20250328-002/original/Hammami_2019_0235.pdf","title":"","llm_title":"Deep Learning for French Legal Data Categorization","authors":["Eya Hammami","Imen Akermi","Rim Faiz","Mohand Boughanem"],"llm_authors":"Eya Hammami, Imen Akermi, Rim Faiz, and Mohand Boughanem","author_string":"","year":2019,"abstract":"","llm_abstract":"In current years, deep learning has showed promising results when used in the field of natural language processing (NLP). Neural Networks (NNs) such as convolutional neural network (CNN) and recurrent neural network (RNN) have been utilized for different NLP tasks like information retrieval, sentiment analysis and document classification. In this paper, we explore the use of NNs-based method for legal text classification. In our case, the results show that NN models with a fixed input length outperforms baseline methods.","llm_keywords":["Natural Language Processing","Deep learning","Convolutional Neural Networks","Document categorization","Legal domain"],"classifications":["Classification","Information Retrieval"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":10},{"id":"3eaa576524dc479a6c324d02a1330648cfbab3fcdad6876f2a6c1ef77ed706054b156d9962cf43bff0580d48a7991b9bd3becb0e49370df29662ad03f5f6122a","file_path":"legal-nlp-survey-20250328-002/original/Lesmo_2013_0025.pdf","title":"","llm_title":"TULSI: an NLP system for extracting legal modificatory provisions","authors":["Leonardo Lesmo","Alessandro Mazzei","Monica Palmirani","Daniele P. Radicioni"],"llm_authors":"Leonardo Lesmo, Alessandro Mazzei, Monica Palmirani, Daniele P. Radicioni","author_string":"","year":2013,"abstract":"","llm_abstract":"In this work we present the TULSI system (so named after Turin University Legal Semantic Interpreter), a system to produce automatic annotations of normative documents through the extraction of modificatory provisions. TULSI relies on a deep syntactic analysis and a shallow semantic interpreter that are illustrated in detail. We report the results of an experimental evaluation of the system and discuss them, also suggesting future directions for further improvement.","llm_keywords":["Natural language processing","Information extraction","Law","Semantic interpretation","Legal text annotation","Artificial intelligence","Legal language"],"classifications":["Information Extraction"],"num_cited_by":25,"num_cited_by_title_only":25,"num_pages":34},{"id":"72b94c7919a1d59c0c6be7c8004c5b0352e07b723f39062771f185dc0264d396950c805c36ee0dbff519638e43e10a555e23a801ee1cb1f31928f73a17f42ad3","file_path":"legal-nlp-survey-20250328-002/original/Tang_2016_0096.pdf","title":"","llm_title":"Matching law cases and reference law provision with a neural attention model.","authors":["Guoyu Tang","Honglei Guo","Zhili Guo","Song Xu"],"llm_authors":"Guoyu Tang, Honglei Guo, Zhili Guo, Song Xu","author_string":"","year":2016,"abstract":"","llm_abstract":"With the development of Internet and social media, large-scale legal resources are available now and are very helpful for legal professionals. Although many law application solutions can provide information management and search services, it is still a big challenge to find the relevant law provisions to the complex law cases. Due to the semantic complex of various law provisions and law cases, traditional methods cannot precisely characterize the deep semantic distribution of legal cases. In this paper, we propose a neural attention model for automatically matching reference law provisions. In this proposed model, we employ word by word attention mechanism to calculate pairwise comparisons between cases and law provisions and then an output LSTM layer is used to summarize the comparisons and output the labels. The experimental results show that our model performs better than both traditional SVM classification algorithm and LSTM representation model.","llm_keywords":["legal text matching","neural attention model","natural language processing","deep learning","semantic compliance","RNN","LSTM"],"classifications":[],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":4},{"id":"0fd2552b96ba1c1b84087489bba47d991bc5a3544ba7e14642520d92046a49e283b558d9ea083d64e16cec259fd93efd97f7bdfeeb14210a3633e7cc78cf421e","file_path":"legal-nlp-survey-20250328-002/original/França_2020_0342.pdf","title":"Legal Judgment Prediction in the Context of Energy Market using Gradient Boosting","llm_title":"Legal Judgment Prediction in the Context of Energy Market using Gradient Boosting","authors":["Joao V. F. Franca","Jose M. C. Boaro","Pedro T. C. dos Santos","Fernando Henrique","Venicius Garcia","Caio Manfredini","Domingos A. D. Junior","Francisco Y. C. de Oliveira","Carlos E. P. Castro","Geraldo Braz Junior","Aristofanes C. Silva","Anselmo C. Paiva","Milton S. L. de Oliveira","Renato U. Moreira e Moraes","Erika W. B. A. L. Alves","Jose S. Sobral Neto"],"llm_authors":"Joao V. F. França, Jose M. C. Boaro, Pedro T. C. dos Santos, Fernando Henrique, Venicius Garcia, Caio Manfredini, Domingos A. D. Junior, Francisco Y. C. de Oliveira, Carlos E. P. Castro, Geraldo Braz Junior, Aristofanes C. Silva, Anselmo C. Paiva, Milton S. L. de Oliveira, Renato U. Moreira e Moraes, Erika W. B. A. L. Alves, Jose S. Sobral Neto","author_string":"","year":2020,"abstract":"","llm_abstract":"A recurring problem for energy supply companies is the guarantee of the quality of services, which is regulated in many cases. Even so, there are many lawsuits against energy distribution companies, for several reasons, increasing the operating costs of these companies, in many situations with cases that could be resolved via negotiation. This work proposes a method to predict legal judgment outcome regarding the chance of being won or lost by the company. The idea is to understand in which lawsuits more effort should be made to negotiate with the court. The methodology is divided into five stages: feature extraction, sampling with Borderline SMOTE, feature encoding with Target Encoding, classification with XGBoost, and evaluation. The proposed method was evaluated in a database with more than seventy thousand lawsuits, with different outcomes and types, reaching an accuracy of 78.13%, F1 of 74.34%, and AUC of 77.59%.","llm_keywords":["Legal Judgment Prediction","Machine Learning","XGBoost","Feature Extraction","Gradient Boosting","Energy Market","Court Outcomes","Bayesian Optimization","LegalAI","Litigation"],"classifications":["Classification","Information Extraction"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":6},{"id":"ed8a1f4b7107f6774ab3d02591a2c0f9d2f3d4cf537f28d754aa252d3c200b7e31f0bc6a524fe1cef18eb7cba9402cd310de61ffc9df72cf47301f7f85b61385","file_path":"legal-nlp-survey-20250328-002/original/Li_2019_0238.pdf","title":"Element-Aware Legal Judgment Prediction for Criminal Cases with Confusing Charges","llm_title":"Element-aware Legal Judgment Prediction for Criminal Cases with Confusing Charges","authors":["Shang Li","Boyang Liu","Lin Ye","Hongli Zhang","Binxing Fang"],"llm_authors":"Shang Li, Boyang Liu, Lin Ye, Hongli Zhang, and Binxing Fang","author_string":"Shang Li (Harbin Institute of Technology), Boyang Liu (Harbin Institute of Technology), Lin Ye (Harbin Institute of Technology), Hongli Zhang (Harbin Institute of Technology), Binxing Fang (Harbin Institute of Technology)","year":2019,"abstract":"","llm_abstract":"Legal judgment prediction (LJP) plays an important role in legal assistant systems and aims to provide feasible judgment suggestions, including the charges, applicable law articles, and prison term. In practice, there exist many confusing charges which result in the decline of LJP performance of the existing works. To address this issue, we introduce the legal constitutive elements as the discriminative features to distinguish confusing charges. We propose an element-driven attentive neural network model, EDA-NN, which takes the textual description of a criminal case as the input and learns both element-free and element-aware case representations. Moreover, the element-driven attention mechanism is incorporated with the hierarchical sequence encoders, to generate crucial representations oriented to the legal constitutive elements at both the word and sentence levels. With the concatenation of element-free and element-aware representations, the EDA-NN can jointly predict the legal constitutive elements and judgment results. The experiments are conducted on a real-world dataset of criminal cases in mainland China. The experimental results demonstrate that our approach significantly outperforms all the baseline models on the LJP task for criminal cases with confusing cases.","llm_keywords":["legal judgment prediction","neural networks","attention mechanism","legal intelligence","criminal cases","artificial intelligence","confusing charges","element-aware representations"],"classifications":["Classification","Information Extraction"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":8},{"id":"2584e0e500a30eb569ba09fd1fa486aecda1bd4733d038476bdc230d6548e1b9a097487e7390e4994ca9a0e70851ea86f6d45037cc0e97a8e2c39a023851ee43","file_path":"legal-nlp-survey-20250328-002/original/Bennett_2017_0108.pdf","title":"Proceedings Template - WORD","llm_title":"A scalable approach to legal question answering","authors":["Zachary Bennett","Tony Russell-Rose","Kate Farmer"],"llm_authors":"Zachary Bennett, Tony Russell-Rose, Kate Farmer","author_string":"End User Computing Services","year":2017,"abstract":"","llm_abstract":"Lexis Answers is a question answering service deployed within a live production system. In this paper we provide an overview of the system, an insight into some of the key AI challenges, and a brief description of current evaluation techniques.","llm_keywords":["legal question answering","Lexis Answers","machine learning","artificial intelligence","question answering","information retrieval","semantic retrieval","text mining","legal research"],"classifications":["Resources","Information Retrieval"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":3},{"id":"19defeae58dab367036356ee422d20a3c313dace8c2016a04118cd0bb0e9c446664cc80cdcd85453c52c8c749f217a36ec45c90c071ee8b04726503a7374f0f4","file_path":"legal-nlp-survey-20250328-002/original/Keszocze_2020_0296.pdf","title":"","llm_title":"(Semi-)Automatic Translation of Legal Regulations to Formal Representations: Expanding the Horizon of EDA Applications","authors":["Oliver Keszocze","Betina Keiner","Matthias Richter","Gottfried Antpohler","Robert Wille"],"llm_authors":"Oliver Keszocze, Betina Keiner, Matthias Richter, Gottfried Antpohler, Robert Wille","author_string":"","year":2014,"abstract":"","llm_abstract":"Caused by the challenges in the design of today’s hardware and software systems, tools for Electronic Design Automation (EDA) became impressively powerful. However, these accomplishments can also be exploited in other domains. In fact, the steps of formalizing and checking legal regulations shares many similarities with established EDA design steps. In this work, this is demonstrated by proposing the application of EDA tools in the domain of law processing. We propose a (semi-)automatic translation of real rules and regulations into a formal representation. Afterwards, we discuss how – similar to the hardware/software design – these formalization can be utilized in the respective domain.","llm_keywords":["Electronic Design Automation","legal regulations","formal representation","natural language processing","German Regulations on Scales of Fees for Medical Doctors","Uniform Assessment Standard","software systems","law processing","formalization","EDA tools"],"classifications":["Pre-Processing","Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"65c93af7b249eff1f5520169f305083bfd18d2ba2d318b431dad90f4add9bcf0ccf39e5fc856c0bda95ee2c6159b91b787db6a73dd6b6e6929008f0fbdc4d59e","file_path":"legal-nlp-survey-20250328-002/original/Poplavska_2020_0326.pdf","title":"","llm_title":"From Prescription to Description: Mapping the GDPR to a Privacy Policy Corpus Annotation Scheme","authors":["Ellen Poplavska","Thomas B. Norton","Shomir Wilson","Norman Sadeh"],"llm_authors":"Ellen POPLAVSKA, Thomas B. NORTON, Shomir WILSON, Norman SADEH","author_string":"","year":2020,"abstract":"","llm_abstract":"The European Union’s General Data Protection Regulation (GDPR) has compelled businesses and other organizations to update their privacy policies to state specific information about their data practices. Simultaneously, researchers in natural language processing (NLP) have developed corpora and annotation schemes for extracting salient information from privacy policies, often independently of specific laws. To connect existing NLP research on privacy policies with the GDPR, we introduce a mapping from GDPR provisions to the OPP-115 annotation scheme, which serves as the basis for a growing number of projects to automatically classify privacy policy text. We show that assumptions made in the annotation scheme about the essential topics for a privacy policy reflect many of the same topics that the GDPR requires in these documents. This suggests that OPP-115 continues to be representative of the anatomy of a legally compliant privacy policy, and that the legal assumptions behind it represent the elements of data processing that ought to be disclosed within a policy for transparency. The correspondences we show between OPP-115 and the GDPR suggest the feasibility of bridging existing computational and legal research on privacy policies, benefiting both areas.","llm_keywords":["GDPR","privacy policies","corpus annotation","natural language processing","data protection"],"classifications":[],"num_cited_by":25,"num_cited_by_title_only":25,"num_pages":4},{"id":"de6001a099df4d959ecb872817f5151456d3f6dda2a1732d4a9dd2779fb0f3a39c69a611ba5714862c142249d7cc104f7d0780b04f7887e379c080816c313c6b","file_path":"legal-nlp-survey-20250328-002/original/Xiao_2017_0143.pdf","title":"Multi-Task CNN for Classification of Chinese Legal Questions","llm_title":"The Fourteenth IEEE International Conference on e-Business Engineering","authors":["Guangyi Xiao","Jiqian Mo","Even Chow","Hao Chen","Jingzhi Guo","Zhiguo Gong"],"llm_authors":"","author_string":"Guangyi Xiao, Jiqian Mo, Even Chow, Hao Chen, Jingzhi Guo, Zhiguo Gong","year":2017,"abstract":"","llm_abstract":"","llm_keywords":[],"classifications":[],"num_cited_by":11,"num_cited_by_title_only":392,"num_pages":7},{"id":"5db2aa48977a931268f4ab3b3233f02e3bf9a352f4b24b88252bdfc7673ec828420e04cdd5e14e1a72ef48f60b619cead1a41e1cf0c3008410efe02bfd9d8f44","file_path":"legal-nlp-survey-20250328-002/original/Garofalakis_2019_0218.pdf","title":"","llm_title":"Application of an Ecosystem Methodology Based on Legal Language Processing for the Transformation of Court Decisions and Legal Opinions into Open Data","authors":["John Garofalakis","Konstantinos Plessas","Athanasios Plessas","Panoraia Spiliopoulou"],"llm_authors":"John Garofalakis, Konstantinos Plessas, Athanasios Plessas, Panoraia Spiliopoulou","author_string":"","year":2019,"abstract":"","llm_abstract":"Regulation of modern societies requires the generation of large sets of heterogeneous legal documents: bills, acts, decrees, administrative decisions, court decisions, legal opinions, circulars, etc. More and more legal publishing bodies publish these documents online, although usually in formats that are not machine-readable and without following Open Data principles. Until an open by default generation and publication process is employed, ex-post transformation of legal documents into Legal Open Data is required. Since manual transformation is a time-consuming and costly process, automated methods need to be applied. While some research efforts toward the automation of the transformation process exist, the alignment of such approaches with proposed Open Data methodologies in order to promote data exploitation is still an open issue. In this paper, we present a methodology aligned to the Open Data ecosystem approach for the automated transformation of Greek court decisions and legal opinions into Legal Open Data that builds on legal language processing methods and tools. We show that this approach produces Legal Open Data of satisfying quality while highly reducing the need for manual intervention.","llm_keywords":["Akoma Ntoso","legal open data","legal big data","open data ecosystem","natural language processing","domain specific language","legal parsing"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":30},{"id":"291ff53a9cfd650ccb1afb8236086272f220d0fdc1c9316acd5a88bb51ba4140862c48a58b08c0db833b7103e10cf59fba2f185a22b40180cafb7bbe718362b9","file_path":"legal-nlp-survey-20250328-002/original/Coupette_2021_0466.pdf","title":"","llm_title":"Simplify Your Law: Using Information Theory to Deduplicate Legal Documents","authors":["Corinna Coupette","Jyotsna Singh","Holger Spamann"],"llm_authors":"Corinna Coupette, Jyotsna Singh, Holger Spamann","author_string":"","year":2021,"abstract":"","llm_abstract":"Textual redundancy is one of the main challenges to ensuring that legal texts remain comprehensible and maintainable. Drawing inspiration from the refactoring literature in software engineering, which has developed methods to expose and eliminate duplicated code, we introduce the duplicated phrase detection problem for legal texts and propose the DUPEX algorithm to solve it. Leveraging the Minimum Description Length principle from information theory, DUPEX identifies a set of duplicated phrases, called patterns, that together best compress a given input text. Through an extensive set of experiments on the Titles of the United States Code, we confirm that our algorithm works well in practice: DUPEX will help you simplify your law.","llm_keywords":["law","information theory","minimum description length","text mining","sequence mining"],"classifications":["Information Extraction","Pre-Processing"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":8},{"id":"670c0a184dd82c2baf50bdcd220fae66165a676020ef470a7a6cbe43af05b904b4eb43e92e0ab4af596b75382819c996e9f8c5900f47968747b4b4c8f7a4d341","file_path":"legal-nlp-survey-20250328-002/original/Ramakrishna_2015_0064.pdf","title":"KR4IPLaw Judgment Miner - Case-Law Mining for Legal Norm Annotation","llm_title":"KR4IPLaw Judgment Miner - Case-Law Mining for Legal Norm Annotation","authors":["Shashishekar Ramakrishna","Łukasz Górski","Adrian Paschke"],"llm_authors":"Shashishekar Ramakrishna, Łukasz Górski, Adrian Paschke","author_string":"Shashishekar Ramakrishna","year":2018,"abstract":"","llm_abstract":"The use of pragmatics in applying the law is hard to deal with for a legal knowledge engineer who needs to model it in a precise KR for (semi-)automated legal reasoning systems. The negative aspects of pragmatics is due to the difficulty involved in separating their concerns. When representing a legal norm for (semi-)automated reasoning, an important step/aspect is the annotation of legal sections under consideration. Annotation in the context of this paper refers to identification, segregation and thereafter representation of the content and its associated context. In this paper we present an approach and provide a proof-of-concept implementation for automatizing the process of identifying the most relevant judgment pertaining to a legal section and further transforming them into a formal representation format. The annotated legal section and its related judgments can then be mapped into a decision model for further down the line processing.","llm_keywords":["LegalDocML","Case-law mining","Legal norms","Topic modeling","Pragmatics","Intellectual property","Information retrieval","Natural language processing","Text mining"],"classifications":["Information Extraction","Information Retrieval","Machine Summarization","Pre-Processing","Resources","Text Generation"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":12},{"id":"c7169327bfc0816b777a83cd1131658207466e2c11a449a406985b9825e6fdb28af242c0b5715dc868535d5a2a0f63e304dfea1af462448af9e490912d2ad798","file_path":"legal-nlp-survey-20250328-002/original/Slingerland_2018_0164.pdf","title":"","llm_title":"Analysing the Impact of Legal Change through Case Classification","authors":["Roos Slingerland","Alexander Boer","Radboud Winkels"],"llm_authors":"Roos SLINGERLAND, Alexander BOER & Radboud WINKELS","author_string":"","year":2018,"abstract":"","llm_abstract":"In this paper an automated solution for analysing the impact of legal change is proposed and the results are analysed with the help of a legal expert. It focuses on the automatic classification of cases for civil law. We investigated to what extent several machine learning algorithms were able to classify cases ‘correctly’. This was done with accuracies around 70%. However, the data were scarce and the initial labelling not perfect, so further research should focus on these aspects to improve the analysis of the impact of legal change.","llm_keywords":["Automatic classification","case-law","law changes","Brussels I Regulation","machine learning","legal domain","text classification","European Union","legal language"],"classifications":["Classification"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":10},{"id":"3c7792d2d0102a4176ea02d62b60cd15a952a5e900597b0d0e68289cddd92d8a21c515795d882b81010d8491aeebb69f715f3a8de59ca51813ef3511b84d6361","file_path":"legal-nlp-survey-20250328-002/original/Garneau_2021_0456.pdf","title":"","llm_title":"Plum2Text: A French Plumitifs–Descriptions Data-to-Text Dataset for Natural Language Generation","authors":["Nicolas Garneau","Eve Gaumond","Luc Lamontagne","Pierre-Luc Déziel"],"llm_authors":"Nicolas Garneau, Eve Gaumond, Luc Lamontagne, Pierre-Luc Déziel","author_string":"","year":2021,"abstract":"","llm_abstract":"In this paper, we introduce a new French Data-to-Text (D2T) dataset in the legal domain: Plum2Text1. It is made out of plumitifs (docket files) – descriptions pairs that are derived from publicly available documents issued by Canadian criminal courts. The development of Plum2Text is primarily intended to train statistical natural language generation algorithms, in order to make the plumitifs more easily understandable for Canadian citizens. The inputs and outputs of the dataset are unique: on the data side, the values of the table contain long pieces of textual utterance, and on the text side (or reference), it most often consists of a paraphrase of the table values. We describe how we curated the plumitif–description associations by introducing an annotation tool and a methodology specific to the D2T natural language generation task. We do so by using simple yet efficient text classifiers to help the annotator leverage annotated examples during the annotation process. As a matter of privacy, we also illustrate how we are decontextualizing the descriptions.","llm_keywords":["Legal Language Resource","Natural Language Generation","Annotation Methodology"],"classifications":["Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"399e4af540d6c4e85ddcaeae7aa7e07f97283114c56e5f96adcd261184dd48fdbb15e5ef627bd5b7415f9535f61238d30faec3776d00e0b557efba07cbafbc5f","file_path":"legal-nlp-survey-20250328-002/original/Le_2013_0026.pdf","title":"","llm_title":"Unsupervised Keyword Extraction for Japanese Legal Documents","authors":["Tho Thi Ngoc Le","Minh Le Nguyen","Akira Shimazu"],"llm_authors":"Tho Thi Ngoc Le, Minh Le Nguyen, Akira Shimazu","author_string":"","year":2013,"abstract":"","llm_abstract":"This study proposes a novel unsupervised approach for extracting keywords from Japanese legal documents by applying knowledge of Japanese syntax. Japanese keywords usually occur in chunks; the task of extracting Japanese keywords is treated as a matter of finding chunks that yield documents’ important content. To find these chunks, all chunks in a given document are assigned weights to indicate their importance. Highly weighted chunks are recognized as candidate keywords, which are post-processed to obtain keywords. Although the proposed method employs simple techniques, the experimental results on Japanese legal documents show that the proposed chunk-based approach achieves better performance (10.5% higher on F1-score) than the graph-based ranking approach, the most popular unsupervised method.","llm_keywords":["Japanese keyword extraction","legal documents","unsupervised approach","chunk-based approach","Natural Language Processing"],"classifications":["Information Extraction","Pre-Processing","Classification"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":11},{"id":"92e2978d58f68edac5cb300b0cfd7672c531a55d3bd5521b363e577ca6f9d83993f3cae79c3024bedb2b4705fdac9092d2e8a3f1994928542c3891d4e5a87b1a","file_path":"legal-nlp-survey-20250328-002/original/Agnoloni_2014_0036.pdf","title":"","llm_title":"Legal keyword extraction and decision categorization: a case study on italian civil case law","authors":["Tommaso Agnoloni","Lorenzo Bacci","Maria Teresa Sagri"],"llm_authors":"Tommaso Agnoloni, Lorenzo Bacci, Maria Teresa Sagri","author_string":"simonetta","year":2014,"abstract":"","llm_abstract":"","llm_keywords":["legal keyword extraction","decision categorization","Italian civil case law","semantic processing","text mining","legal informatics"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":33},{"id":"3bd57e62915b68db07c65014c76add6d0028110b579bb1920dacaef3092902968e0aed37e4daa9433494bee11bae988b3c4181fd8ae1f86134d55ae8ec685905","file_path":"legal-nlp-survey-20250328-002/original/Oksanen_2019_0217.pdf","title":"","llm_title":"Anoppi: A Pseudonymization Service for Finnish Court Documents","authors":["Arttu Oksanen","Minna Tamper","Jouni Tuominen","Aki Hietanen","Eero Hyvönen"],"llm_authors":"Arttu Oksanen, Minna Tamper, Jouni Tuominen, Aki Hietanen, Eero Hyvönen","author_string":"","year":2019,"abstract":"","llm_abstract":"To comply with the EU General Data Protection Regulation (GDPR) publishing court judgments online requires that personal data contained in them must be disguised. However, anonymizing the documents manually is a costly and time-consuming procedure. This paper presents Anoppi service for automatic and semi-automatic pseudonymization of Finnish court judgments. Utilizing both statistics- and rule-based named entity recognition methods and morphological analysis, Anoppi is able to automatically pseudonymize documents written in Finnish preserving their readability and layout. The service is currently still in development but pilot tests are going to be carried out in Finnish courts in 2020.","llm_keywords":["automatic pseudonymization","case law","named entity recognition","GDPR","Finnish court documents"],"classifications":["Information Extraction","Pre-Processing"],"num_cited_by":29,"num_cited_by_title_only":29,"num_pages":4},{"id":"e452b4768a8706c134602f5008b3c5e8d47be678e4ae661bff4eaafccb2f5e59b989dc2c440022d961a9ea49a0523d89411bdd86059cb9bb1a6eeba6ddb68475","file_path":"legal-nlp-survey-20250328-002/original/Shaheen_2022_0546.pdf","title":"","llm_title":"Zero-Shot Cross-Lingual Transfer in Legal Domain using Transformer Models","authors":["Zein Shaheen","Gerhard Wohlgenannt","Dmitry Mouromtsev"],"llm_authors":"Zein Shaheen, Gerhard Wohlgenannt, Dmitry Mouromtsev","author_string":"","year":2021,"abstract":"","llm_abstract":"Zero-shot cross-lingual transfer is an important feature in modern NLP models and architectures to support low-resource languages. In this work, we study zero-shot cross-lingual transfer from English to French and German under Multi-Label Text Classification, where we train a classifier using English training set, and we test using French and German test sets. We extend EURLEX57K dataset, the English dataset for topic classification of legal documents, with French and German official translation. We investigate the effect of using some training techniques, namely Gradual Unfreezing and Language Model finetuning, on the quality of zero-shot cross-lingual transfer. We find that Language model finetuning of multi-lingual pre-trained model (M-DistilBERT, M-BERT) leads to 32.0-34.94%, 76.15-87.54% relative improvement on French and German test sets correspondingly. Also, Gradual unfreezing of pre-trained model’s layers during training results in relative improvement of 38-45% for French and 58-70% for German. Compared to training a model in Joint Training scheme using English, French and German training sets, zero-shot BERT-based classification model reaches 86% of the performance achieved by jointly-trained BERT-based classification model.","llm_keywords":["Zero-shot classification","cross-lingual transfer","NLP","Transformer Models","legal documents","multi-label text classification","EURLEX57K","language model finetuning","Multilingual BERT","Gradual unfreezing"],"classifications":["Classification"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":7},{"id":"92ae60b1dbfd32b8b4d62d98445f18d310107a5f7d8cef364c962ccbcc72f6b62a50085a94d7ff63bf870b0f835242b5f93f823cc0c6ccb19e8b3ec113296ac9","file_path":"legal-nlp-survey-20250328-002/original/Hausladen_2020_0366.pdf","title":"Text classification of ideological direction in judicial opinions","llm_title":"Text classification of ideological direction in judicial opinions","authors":["Carina I. Hausladen","Marcel H. Schubert","Elliott Ash"],"llm_authors":"Carina I. Hausladen, Marcel H. Schubert, Elliott Ash","author_string":"Carina I. Hausladen","year":2020,"abstract":"","llm_abstract":"This paper draws on machine learning methods for text classification to predict the ideological direction of decisions from the associated text. Using a 5% hand-coded sample of cases from U.S. Circuit Courts, we explore and evaluate a variety of machine classifiers to predict “conservative decision” or “liberal decision” in held-out data. Our best classifier is highly predictive (F1 = .65) and allows us to extrapolate ideological direction to the full sample. We then use these predictions to replicate and extend Landes and Posner’s (2009) analysis of how the party of the nominating president influences circuit judge’s votes.","llm_keywords":["Judge ideology","Circuit courts","Text data","NLP","Machine learning","Ideological direction","Legal studies","Text classification","Judicial decision-making"],"classifications":[],"num_cited_by":52,"num_cited_by_title_only":52,"num_pages":19},{"id":"79b2d0d11ce3d23e8dbacbbf2d99a5fa64e2cae49be13424a3f3cbc4b17d7b8b2e09570fceaed3797605818b846958095f158476fc6249a6849802f8e26ebe7c","file_path":"legal-nlp-survey-20250328-002/original/Sugisaki_2016_0084.pdf","title":"","llm_title":"Building a Corpus of Multi-lingual and Multi-format International Investment Agreements","authors":["Kyoko Sugisaki","Martin Volk","Rodrigo Polanco","Wolfgang Alschner","Dmitriy Skougarevskiy"],"llm_authors":"Kyoko SUGISAKI, Martin VOLK, Rodrigo POLANCO, Wolfgang ALSCHNER, Dmitriy SKOUGAREVSKIY","author_string":"","year":2016,"abstract":"","llm_abstract":"In this paper, we present an on-going research project whose aim is to develop a new database of international investment agreements that complements existing endeavors. In particular, this paper describes our efforts to build a standardized corpus of multi-lingual and multi-format agreement texts in order to enable researchers in the fields of international law and economics systematically investigate investment treaties.","llm_keywords":["Natural language processing","Annotation of International investment agreements","OCR","Language identification","International investment agreements","Database","Textual analysis"],"classifications":["Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":5},{"id":"d6efd644b5bd63bf7ed73bcf4b0fd949a3dc13ee201934815cfe98cb3dfdb7e882f315620261cbe9d01349e0ca37e0aff1fd316628545af631f2c76744d936b2","file_path":"legal-nlp-survey-20250328-002/original/Bhattacharya_2021_0412.pdf","title":"DeepRhole: deep learning for rhetorical role labeling of sentences in legal case documents","llm_title":"DeepRhole: deep learning for rhetorical role labeling of sentences in legal case documents","authors":["Paheli Bhattacharya"],"llm_authors":"Paheli Bhattacharya, et al.","author_string":"Paheli Bhattacharya","year":2021,"abstract":"","llm_abstract":"The task of rhetorical role labeling is to assign labels (such as Fact, Argument, Final Judgement, etc.) to sentences of a court case document. Rhetorical role labeling is an important problem in the field of Legal Analytics, since it can aid in various downstream tasks as well as enhances the readability of lengthy case documents. The task is challenging as case documents are highly various in structure and the rhetorical labels are often subjective. Previous works for automatic rhetorical role identification (i) mainly used Conditional Random Fields over manually handcrafted features, and (ii) focused on certain law domains only (e.g., Immigration cases, Rent law), and a particular jurisdiction/country (e.g., US, Canada, India). In this work, we improve upon the prior works on rhetorical role identification by proposing novel Deep Learning models for automatically identifying rhetorical roles, which substantially outperform the prior methods. Additionally, we show the effectiveness of the proposed models over documents from five different law domains, and from two different jurisdictions—the Supreme Court of India and the Supreme Court of the UK. Through extensive experiments over different variations of the Deep Learning models, including Transformer models based on BERT and LegalBERT, we show the robustness of the methods for the task. We also perform an extensive inter-annotator study and analyse the agreement of the predictions of the proposed model with the annotations by domain experts. We find that some rhetorical labels are inherently hard/subjective and both law experts and neural models frequently get confused in predicting them correctly.","llm_keywords":["rhetorical role labeling","legal document segmentation","court case documents","Hierarchical BiLSTM","BERT","LegalBERT","machine learning","deep learning","legal analytics","inter-annotator agreement"],"classifications":["Classification"],"num_cited_by":43,"num_cited_by_title_only":43,"num_pages":38},{"id":"73805368929d44d388e2b0e9bcc9d5e0ea85035215576aaf27251c36bd9ecc45c4ebf4013c7c20573bde04af65d5945d3eed496881755533bd64a2e5f211c3ba","file_path":"legal-nlp-survey-20250328-002/original/Bartalan_2022_0544.pdf","title":"","llm_title":"Using attention methods to predict judicial outcomes","authors":["Vithor Gomes Ferreira Bertalan","Evandro Eduardo Seron Ruiz"],"llm_authors":"Vithor Gomes Ferreira Bertalan, Evandro Eduardo Seron Ruiz","author_string":"","year":2022,"abstract":"","llm_abstract":"Legal Judgment Prediction is one of the most acclaimed fields for the combined area of NLP, AI, and Law. By legal prediction we mean an intelligent system capable to predict specific judicial characteristics, such as judicial outcome, a judicial class, predict a specific case. In this research, we have used AI classifiers to predict judicial outcomes in the Brazilian legal system. For this purpose, we developed a text crawler to extract data from the official Brazilian electronic legal systems. These texts formed a dataset of second-degree murder and active corruption cases. We applied different classifiers, such as Support Vector Machines and Neural Networks, to predict judicial outcomes by analyzing textual features from the dataset. Our research showed that Regression Trees, Gated Recurring Units and Hierarchical Attention Networks presented higher metrics for different subsets. As a final goal, we explored the weights of one of the algorithms, the Hierarchical Attention Networks, to find a sample of the most important words used to absolve or convict defendants.","llm_keywords":["Legal Prediction","Hierarchical Attention Networks","Natural Language Processing","Machine Learning","Judicial Outcomes","Brazilian Legal System","AI Classifiers","Textual Analysis"],"classifications":["Classification"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":40},{"id":"b8e51d85d2f6abca206a890bf9409f674a995eb3464d8626b033e70bf093fffc9173a3e41c99f6e5a25b8192345c52a6fca176c536ad33f89eeb4f51ae8d6a36","file_path":"legal-nlp-survey-20250328-002/original/Boella_2015_0067.pdf","title":"","llm_title":"Linking Legal Open Data: Breaking the Accessibility and Language Barrier in European Legislation and Case Law","authors":["Anne Gardner","Guido Boella","Luigi Di Caro","Michele Graziadei","Loredana Cupi","Carlo Emilio Salaroglio","Llio Humphreys","Hristo Konstantinov","Kornel Marko","Livio Robaldo","Claudio Ruffini","Kiril Simov","Andrea Violato","Veli Stroetmann"],"llm_authors":"Guido Boella, Luigi Di Caro, Michele Graziadei, Loredana Cupi, Carlo Emilio Salaroglio, Llio Humphreys, Hristo Konstantinov, Kornel Marko, Livio Robaldo, Claudio Ruffini, Kiril Simov, Andrea Violato, Veli Stroetmann","author_string":"Anne Gardner","year":2015,"abstract":"","llm_abstract":"In this paper we describe how the EUCases FP7 project is addressing the problem of lifting Legal Open Data to Linked Open Data to develop new applications for the legal information provision market by enriching structurally the documents (first of all with navigable references among legal texts) and semantically (with concepts from ontologies and classification). First we describe the social and economic need for breaking the accessibility barrier in legal information in the EU, then we describe the technological challenges and finally we explain how the EUCases project is addressing them by a combination of Human Language Technologies.","llm_keywords":["Legal Open Data","Linked Open Data","European Legislation","Case Law","Human Language Technologies","Multilingual Access","Legal Informatics","EU Law","EUCases Project","Accessibility in Law"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":53,"num_cited_by_title_only":53,"num_pages":5},{"id":"c4ceaf401000d4e253fa0eb97dad16c9c522175ea1fc09e76ac2f1cab963a519430b5b8e73ceb201720f30def49fa6f7bda8a8f938ff088e19ed3c7cb411bf1d","file_path":"legal-nlp-survey-20250328-002/original/Ahmad_2020_0371.pdf","title":"Understanding Legal Documents: Classification of Rhetorical Role of Sentences Using Deep Learning and Natural Language Processing","llm_title":"Understanding Legal Documents: Classification of Rhetorical Role of Sentences Using Deep Learning and Natural Language Processing","authors":["Rameel Ahmad","Deborah Harris","Mohammad Ibrahim Sahibzada"],"llm_authors":"Rameel Ahmad, Deborah Harris, Mohammad Ibrahim Sahibzada","author_string":"","year":2020,"abstract":"","llm_abstract":"Automatically extracting the patterns of reasoning from complex legal documents can make legal systems more effective by increasing on-time case processing and the case clearance rate. The crucial task to achieve this is to automatically classify sentences in legal documents into categories based on their content. In this paper, a deep learning model is proposed that breaks down legal documents and classifies the rhetorical types of sentences. A hypothesis is tested, that using a small set of labelled data, deeper and more accurate models for the processing of legal documents can be constructed. This will automate the processing of legal documents hence decreasing, and ultimately eliminating the backlog that currently exists throughout various legal systems. This work can be generalized for legal appeals cases in diverse fields. The various configurations used to train the Bidirectional Long Short-Term Memory (Bi-LSTM) model will be compared along with a variety of embeddings. The experiments obtained their highest accuracy using the Bi-LSTM model with 300-dimensional GloVe embeddings compared to the previous techniques used for the semantic understanding of law related documents.","llm_keywords":["Bi-LSTM","Classification","Embeddings","Rhetorical Role","Deep Learning","Natural Language Processing","Legal Documents","Semantic Understanding","Machine Learning","PTSD Claims"],"classifications":["Classification"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":4},{"id":"24b934740cf1663a7e7cf402b02bbddd91262ce26b258bcd1b4c4ce783812e0e4f0a20660c892ac2e03a3332231bbd9885f64d57fcb5fc55f97642a6c3dfba61","file_path":"legal-nlp-survey-20250328-002/original/Matthews_2022_0512.pdf","title":"Gender and Racial Stereotype Detection in Legal Opinion Word Embeddings","llm_title":"Gender and Racial Stereotype Detection in Legal Opinion Word Embeddings","authors":["Sean Matthews","Dawn Sepehr","John Hudzina"],"llm_authors":"Sean Matthews, John Hudzina, Dawn Sepehr","author_string":"Sean Matthews, Dawn Sepehr, John Hudzina","year":2021,"abstract":"","llm_abstract":"Studies have shown that some Natural Language Processing (NLP) systems encode and replicate harmful biases with potential adverse ethical effects in our society. In this article, we propose an approach for identifying gender and racial stereotypes in word embeddings trained on judicial opinions from U.S. case law. Embeddings containing stereotype information may cause harm when used by downstream systems for classification, information extraction, question answering, or other machine learning systems used to build legal research tools. We first explain how previously proposed methods for identifying these biases are not well suited for use with word embeddings trained on legal opinion text. We then propose a domain adapted method for identifying gender and racial biases in the legal domain. Our analyses using these methods suggest that racial and gender biases are encoded into word embeddings trained on legal opinions. These biases are not mitigated by exclusion of historical data, and appear across multiple large topical areas of the law. Implications for downstream systems that use legal opinion word embeddings and suggestions for potential mitigation strategies based on our observations are also discussed.","llm_keywords":["gender bias","racial bias","word embeddings","legal opinions","NLP","stereotype detection","AI biases","machine learning","judicial opinions"],"classifications":["Pre-Processing","Resources"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":8},{"id":"db7433fb2c645dd4973d20942e1dc5c0005e0bfb037e0147bccddfe1016c2af0cb9c3f5b66c4f90c49952ae61e2056749bd0ee8ab3c2583a6aca37e9751a7494","file_path":"legal-nlp-survey-20250328-002/original/ZHong_2019_0226.pdf","title":"181_Zhong.pdf","llm_title":"Automatic Summarization of Legal Decisions using Iterative Masking of Predictive Sentences","authors":["Linwu Zhong","Ziyi Zhong","Zinian Zhao","Siyuan Wang","Kevin D. Ashley","Matthias Grabmair"],"llm_authors":"Linwu Zhong, Ziyi Zhong, Zinian Zhao, Siyuan Wang, Kevin D. Ashley, Matthias Grabmair","author_string":"","year":2019,"abstract":"","llm_abstract":"We report on a pilot experiment in automatic, extractive summarization of legal cases concerning Post-traumatic Stress Disorder from the US Board of Veterans’ Appeals. We hypothesize that length-constrained extractive summaries benefit from choosing among sentences that are predictive for the case outcome. We develop a novel train-attribute-mask pipeline using a CNN classifier to iteratively select predictive sentences from the case, which measurably improves prediction accuracy on partially masked decisions. We then select a subset for the summary through type classification, maximum marginal relevance, and a summarization template. We use ROUGE metrics and a qualitative survey to evaluate generated summaries along with expert-extracted and expert-drafted summaries. We show that sentence predictiveness does not reliably cover all decision-relevant aspects of a case, illustrate that lexical overlap metrics are not well suited for evaluating legal summaries, and suggest that future work should focus on case-aspect coverage.","llm_keywords":["automatic summarization","legal decisions","iterative masking","predictive sentences","CNN classifier","ROUGE metrics","case outcome prediction","extractive summarization","legal case analysis","Post-traumatic Stress Disorder"],"classifications":["Machine Summarization","Classification"],"num_cited_by":75,"num_cited_by_title_only":75,"num_pages":10},{"id":"fb89dc2961d8ee8cbb7af8ceaec970271f9d766fe609d5cb446ec2fe2e253f767d49c70646f5fbb50d12f390f4109212dcd70642a1c042e02a782b8169d05107","file_path":"legal-nlp-survey-20250328-002/original/Yin_2022_0577.pdf","title":"","llm_title":"Privacy-Preserving Models for Legal Natural Language Processing","authors":["Ying Yin","Ivan Habernal"],"llm_authors":"Ying Yin, Ivan Habernal","author_string":"","year":2022,"abstract":"","llm_abstract":"Pre-training large transformer models with in-domain data improves domain adaptation and helps gain performance on the domain-specific downstream tasks. However, sharing models pre-trained on potentially sensitive data is prone to adversarial privacy attacks. In this paper, we asked to which extent we can guarantee privacy of pre-training data and, at the same time, achieve better downstream performance on legal tasks without the need of additional labeled data. We extensively experiment with scalable self-supervised learning of transformer models under the formal paradigm of differential privacy and show that under specific training configurations we can improve downstream performance without sacrificing privacy protection for the in-domain data. Our main contribution is utilizing differential privacy for large-scale pre-training of transformer language models in the legal NLP domain, which, to the best of our knowledge, has not been addressed before.","llm_keywords":["privacy-preserving","legal NLP","transformer models","differential privacy","domain adaptation","self-supervised learning","pre-training","natural language processing"],"classifications":["Pre-Processing","Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":13},{"id":"29ac1d26bd64444d78e72c5b8044c3f110ae9ac2a293e02dfc8eeefbdb844ee2b1c637f9faac323b906b40dbcfdb42a080479cff28c63972ca5e09d449b82201","file_path":"legal-nlp-survey-20250328-002/original/Wyner_2017_0145.pdf","title":"","llm_title":"On Annotation of the Textual Contents of Scottish Legal Instruments","authors":["Adam Wyner","Fraser Gough","Francois Levy","Matt Lynch","Adeline Nazarenko"],"llm_authors":"Adam WYNER, Fraser GOUGH, Francois LEVY, Matt LYNCH, Adeline NAZARENKO","author_string":"","year":2017,"abstract":"","llm_abstract":"LegalRuleML is a developing standard for representing the fine-grained semantic contents of legal texts. Such a representation would be highly useful for Semantic Web applications, but deriving formal rules from the textual source is problematic; there is currently little in the way of methodology to systematically transform language to LegalRuleML. To address this, we outline the purposes, processes, and outputs of a pilot study on the annotation of the contents of Scottish legal instruments, using key LegalRuleML elements as annotations. The resulting annotated corpus is assessed in terms of how well it answers the users' queries.","llm_keywords":["semantic annotation","legal text processing","markup language","LegalRuleML","XML","semantic web","legal documents","methodology"],"classifications":["Pre-Processing","Information Extraction","Resources"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":6},{"id":"9f9cccb93f2707eb45798cf1bb8ef15236889d18086020b6137dbf31f0a56bd2d0b764fa4c89251863e816666a8007cb92df106908363d8dca974034dc4ea854","file_path":"legal-nlp-survey-20250328-002/original/Ostendorff_2021_0417.pdf","title":"","llm_title":"Evaluating Document Representations for Content-based Legal Literature Recommendations","authors":["Malte Ostendorff","Elliott Ash","Terry Ruas","Bela Gipp","Julian Moreno-Schneider","Georg Rehm"],"llm_authors":"Malte Ostendorff, Elliott Ash, Terry Ruas, Bela Gipp, Julian Moreno-Schneider, Georg Rehm","author_string":"","year":2021,"abstract":"","llm_abstract":"Recommender systems assist legal professionals in finding relevant literature for supporting their case. Despite its importance for the profession, legal applications do not reflect the latest advances in recommender systems and representation learning research. Simultaneously, legal recommender systems are typically evaluated in small-scale user study without any public available benchmark datasets. Thus, these studies have limited reproducibility. To address the gap between research and practice, we explore a set of state-of-the-art document representation methods for the task of retrieving semantically related US case law. We evaluate text-based (e.g., fastText, Transformers), citation-based (e.g., DeepWalk, Poincaré), and hybrid methods. We compare in total 27 methods using two silver standards with annotations for 2,964 documents. The silver standards are newly created from Open Case Book and Wikisource and can be reused under an open license facilitating reproducibility. Our experiments show that document representations from averaged fastText word vectors (trained on legal corpora) yield the best results, closely followed by Poincaré citation embeddings. Combining fastText and Poincaré in a hybrid manner further improves the overall result. Besides the overall performance, we analyze the methods depending on document length, citation count, and the coverage of their recommendations.","llm_keywords":["Legal literature","document embeddings","recommender systems","document similarity","Transformers"],"classifications":["Information Retrieval","Resources"],"num_cited_by":25,"num_cited_by_title_only":25,"num_pages":10},{"id":"d412df54aacea369775f7cfffba7b26001b7e5b21a530e6449d53332a09fd9eb1fbc64b54abdd93afb0dd1574e520bed5c3b50999c102a0f3ad99039b506cf44","file_path":"legal-nlp-survey-20250328-002/original/Mukherjee_2021_0414.pdf","title":"","llm_title":"Determining Standard Occupational Classification Codes from Job Descriptions in Immigration Petitions","authors":["Sourav Mukherjee","David Widmark","Vince DiMascio","Tim Oates"],"llm_authors":"Sourav Mukherjee, David Widmark, Vince DiMascio, Tim Oates","author_string":"","year":2021,"abstract":"","llm_abstract":"Accurate specification of standard occupational classification (SOC) code is critical to the success of many U.S. work visa applications. Determination of correct SOC code relies on careful study of job requirements and comparison to definitions given by the U.S. Bureau of Labor Statistics, which is often a tedious activity. In this paper, we apply methods from natural language processing (NLP) to computationally determine SOC code based on job description. We implement and empirically evaluate a broad variety of predictive models with respect to quality of prediction and training time, and identify models best suited for this task.","llm_keywords":["SOC codes","natural language processing","work visa applications","predictive models","job descriptions"],"classifications":["Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":6},{"id":"85e8c245460e0a0e44b129f947b050a590d10c109cb25970176f704133f0d225da7c63a3802150c63d48aa9b499a5ad16c730ee89a7b4ac3a659659170231ed6","file_path":"legal-nlp-survey-20250328-002/original/Salaün_2021_0435.pdf","title":"","llm_title":"Labels distribution matters in performance achieved in legal judgment prediction tasks","authors":["Olivier Salaün","Philippe Langlais","Karim Benyekhlef"],"llm_authors":"Olivier Salaün, Philippe Langlais, and Karim Benyekhlef","author_string":"","year":2021,"abstract":"","llm_abstract":"","llm_keywords":["legal judgment prediction","multilabel text classification","legal articles","natural language processing","transformer models","BERT","CamemBERT","landlord-tenant disputes","court rulings"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":2},{"id":"5246770703cbeb261d4ae591930302ac7ca5a2d2161f124b6fcefe0877bd0c453fe1f4761b53fdf9217293520b6176d8c75b55c00a395b0b7d9e4bf08b2c0a8f","file_path":"legal-nlp-survey-20250328-002/original/Cardellino_2015_0062.pdf","title":"Improvements in Information Extraction in Legal Text by Active Learning","llm_title":"Improvements in Information Extraction in Legal Text by Active Learning","authors":["Cristian Cardellino","Laura Alonso Alemany","Serena Villata","Elena Cabrio"],"llm_authors":"Cristian Cardellino, Laura Alonso Alemany, Serena Villata, Elena Cabrio","author_string":"Cristian Cardellino, Laura Alonso Alemany, Serena Villata, Elena Cabrio","year":2022,"abstract":"","llm_abstract":"Managing licensing information and data rights is becoming a crucial issue in the Linked (Open) Data scenario. An open problem in this scenario is how to associate machine-readable licenses specifications to the data, so that automated approaches to treat such information can be fruitfully exploited to avoid data misuse. This means that we need a way to automatically extract from a natural language document specifying a certain license a machine-readable description of the terms of use and reuse identified in such license. Ontology-based Information Extraction is crucial to translate natural language documents into Linked Data. This connection supports consumers in navigating documents and semantically related data. However, the performances of automated information extraction systems are far from being perfect, and rely heavily on human intervention, either to create heuristics, to annotate examples for inferring models, or to interpret or validate patterns emerging from data. In this paper, we apply different Active Learning strategies to Information Extraction (IE) from licenses in English, with highly repetitive text, few annotated or unannotated examples available, and very fine precision needed. We show that the most popular approach to active learning, i.e., uncertainty sampling for instance selection, does not provide a good performance in this setting. We show that we can obtain a similar effect to that of density-based methods using uncertainty sampling, by just reversing the ranking criterion, and choosing the most certain instead of the most uncertain instances.","llm_keywords":["Information Extraction","Active Learning","Legal Text","Licensing Information","Linked Data","Ontology-based Extraction","Machine-readable Licenses"],"classifications":["Information Extraction"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":11},{"id":"2971d4e1993447316de4f65fea037fd259bdcaa169154ceddf9994f5b8d8c393758c1417e8edf45cd9cfd6dad6beecbc7a916fa33cc92d673bceedcacf41d1be","file_path":"legal-nlp-survey-20250328-002/original/Yan_2014_0039.pdf","title":"","llm_title":"Personal Legal Counselor and Interpreter of the Law via Machine Learning","authors":["Derek Yan","Tianyi Wang","Patrick Chase"],"llm_authors":"Derek Yan, Tianyi Wang, Patrick Chase","author_string":"","year":2014,"abstract":"","llm_abstract":"The goal of this project was to predict the likelihood of winning a new legal dispute based on results of past cases. We collected over 5000 legal proceedings in the form of case briefs from the internet and used various language processing techniques to parse the raw text into feature vectors. We then used this feature vectors to train several binary classification algorithms, including Naive Bayes, Random Forest, logistic regression and an SVM. The SVM model achieved the highest test set accuracy of 62%, which was an improvement over the random 50% baseline. In this paper, we explained the details of how we transformed the raw text of the case briefs into feature vectors, and how we used them to build several models for prediction. We then discussed the results obtained by each of the models and suggested future work that could be done in the area.","llm_keywords":["law","machine learning","case briefs","court cases","binary classification","feature vectors","SVM","Naive Bayes","Random Forest","logistic regression"],"classifications":["Pre-Processing","Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"28525f40ee9b1d7eb5706f378930a560a5dcb88325d5e189d26aaff94a43dd5823dab98ad7d4a66441c0e976cc95f4369c6d673db5221b265110860a0f518c29","file_path":"legal-nlp-survey-20250328-002/original/Sugisaki_2016_0104.pdf","title":"","llm_title":"Towards Data-Driven Style Checking: An Example for Law Texts","authors":["Kyoko Sugisaki"],"llm_authors":"Kyoko Sugisaki","author_string":"","year":2022,"abstract":"","llm_abstract":"We present a novel approach to detecting syntactic structures that are inadequate for their domain context. We define writing style in terms of the choices between alternatives, and conducted an experiment in the legislative domain on the syntactic choice of nominalization in German, i.e. complex noun phrase vs. relative clause. In order to infer the stylistic choices that are conventional in the domain, we capture the contexts that affect the syntactic choice. Our results showed that a data-driven binary classifier can be a viable method for modelling syntactic choices in a style-checking tool.","llm_keywords":["Natural language processing","style checking","law texts","syntactic structures","nominalization","German language","binary classifier","style-checking tool","legislative domain"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":9},{"id":"04fa10e4a793f54dc59e533e3cdda0edd09e2f46e842fb1b43ff036e81ca0b59f8bf9f906e0b7349627e9df1ee0ffc44b4b9b970e87017a764096a8adc528cdf","file_path":"legal-nlp-survey-20250328-002/original/Luo_2017_0131.pdf","title":"Learning to Predict Charges for Criminal Cases with Legal Basis","llm_title":"Learning to Predict Charges for Criminal Cases with Legal Basis","authors":["Bingfeng Luo","Yansong Feng","Jianbo Xu","Xiang Zhang","Dongyan Zhao"],"llm_authors":"Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang Zhang, Dongyan Zhao","author_string":"Bingfeng Luo ; Yansong Feng ; Jianbo Xu ; Xiang Zhang ; Dongyan Zhao","year":2017,"abstract":"","llm_abstract":"The charge prediction task is to determine appropriate charges for a given case, which is helpful for legal assistant systems where the user input is fact description. We argue that relevant law articles play an important role in this task, and therefore propose an attention-based neural network method to jointly model the charge prediction task and the relevant article extraction task in a unified framework. The experimental results show that, besides providing legal basis, the relevant articles can also clearly improve the charge prediction results, and our full model can effectively predict appropriate charges for cases with different expression styles.","llm_keywords":["charge prediction","legal assistant systems","neural network","multi-label classification","law articles"],"classifications":[],"num_cited_by":339,"num_cited_by_title_only":339,"num_pages":10},{"id":"cf97f10b3bee38f69fac10b4aa75b3ce0cf35525c03d9ddfccad07e1485125495239c629707811ce6156a00940e35952426803ae0191f55434da188443ed0cc2","file_path":"legal-nlp-survey-20250328-002/original/Undavia_2018_0158.pdf","title":"A Comparative Study of Classifying Legal Documents with Neural Networks","llm_title":"A Comparative Study of Classifying Legal Documents with Neural Networks","authors":["Samir Undavia","Adam Meyers","John E. Ortega"],"llm_authors":"Samir Undavia, Adam Meyers, John E. Ortega","author_string":"Samir Undavia, Adam Meyers, John Ortega","year":2018,"abstract":"","llm_abstract":"In recent years, deep learning has shown promising results when used in the field of natural language processing (NLP). Neural networks (NNs) such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have been used for various NLP tasks including sentiment analysis, information retrieval, and document classification. In this paper, we present the Supreme Court Classifier (SCC), a system that applies these methods to the problem of document classification of legal court opinions. We compare methods using traditional machine learning with recent NN-based methods. We also present a CNN used with pre-trained word vectors which shows improvements over the state-of-the-art applied to our dataset. We train and evaluate our system using the Washington University School of Law Supreme Court Database (SCDB). Our best system (word2vec + CNN) achieves 72.4% accuracy when classifying the court decisions into 15 broad SCDB categories and 31.9% accuracy when classifying among 279 finer-grained SCDB categories.","llm_keywords":["neural networks","document classification","natural language processing","Supreme Court Classifier","convolutional neural networks","recurrent neural networks","machine learning","legal documents","Supreme Court Database"],"classifications":["Classification","Pre-Processing","Resources"],"num_cited_by":72,"num_cited_by_title_only":72,"num_pages":9},{"id":"05f1620fe51f5589df31ac0d241f46bee8406944e795a35cdfc139323c80871fa73b52f703bda02e2d3025c9224927badffcbf908b35f5eb887711ab480c4a72","file_path":"legal-nlp-survey-20250328-002/original/Glaser_2021_0424.pdf","title":"","llm_title":"Generation of Legal Norm Chains: Extracting the Most Relevant Norms from Court Rulings","authors":["Ingo Glaser","Sebastian Moser","Florian Matthes"],"llm_authors":"Ingo Glaser, Sebastian Moser, Florian Matthes","author_string":"","year":2021,"abstract":"","llm_abstract":"Various online databases exist to make judgments accessible in the digital age. Before a legal practitioner can utilize state-of-the-art information retrieval features to retrieve relevant court rulings, the textual document must be processed. More importantly, many verdicts lack crucial semantic information which can be utilized within the search process. One piece of information that is frequently missed, as the judge is not adding it during the publication process within the court, is the so-called norm chain. This list contains the most relevant norms for the underlying decision. Therefore this paper investigates the feasibility of automatically extracting the most relevant norms of a court ruling. A dataset constituting over 42k labeled court rulings was used in order to train different classifiers. While our models provide F1 performances of up to 0.77, they can undoubtedly be utilized within the editorial publication process to provide helpful suggestions.","llm_keywords":["natural legal language processing","norm chains","legal court rulings","multi-label classification","information retrieval","semantic information","machine learning","court verdicts","legal research","data processing"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":11},{"id":"44b73ece4bbd9ed40ba7641f5655d278ba989d1fc4678a2738ff6068652628cba60d8b3f476ed216836d952e506a6d3ddf020b68ea2a1da56a17e8fe4208d574","file_path":"legal-nlp-survey-20250328-002/original/Duan_2019_0264.pdf","title":"Legal Summarization for Multi-role Debate Dialogue  via Controversy Focus Mining and Multi-task Learning","llm_title":"Legal Summarization for Multi-role Debate Dialogue via Controversy Focus Mining and Multi-task Learning","authors":["Xinyu Duan","Yating Zhang","Lin Yuan","Xin Zhou","Xiaozhong Liu","Tianyi Wang","Ruocheng Wang","Qiong Zhang","Changlong Sun","Fei Wu"],"llm_authors":"Xinyu Duan, Yating Zhang, Lin Yuan, Xin Zhou, Xiaozhong Liu, Tianyi Wang, Ruocheng Wang, Qiong Zhang, Changlong Sun, Fei Wu","author_string":"Xinyu Duan*2, Yating Zhang*1, Lin Yuan2, Xin Zhou1, Xiaozhong Liu3Tianyi Wang1, Ruocheng Wang2, Qiong Zhang1, Changlong Sun1, Fei Wu2","year":2019,"abstract":"","llm_abstract":"Multi-role court debate is a critical component in a civil trial where parties from different camps (plaintiff, defendant, witness, judge, etc.) actively involved. Unlike other types of dialogue, court debate can be lengthy, and important information, with respect to the controversy focus(es), often hides within the redundant and colloquial dialogue data. Summarizing court debate can be a novel but significant task to assist judge to effectively make the legal decision for the target trial. In this work, we propose an innovative end-to-end model to address this problem. Unlike prior summarization efforts, the proposed model projects the multi-role debate into the controversy focus space, which enables high-quality essential utterance(s) extraction in terms of legal knowledge and judicial factors. An extensive set of experiments with a large civil trial dataset shows that the proposed model can provide more accurate and readable summarization against several alternatives in the multi-role court debate scene.","llm_keywords":["legal summarization","multi-role debate dialogue","controversy focus","multi-task learning","court debate","legal intelligence","trial debate","utterance extraction"],"classifications":["Machine Summarization"],"num_cited_by":46,"num_cited_by_title_only":46,"num_pages":10},{"id":"804e01ea7a99735375cde723f95ea42c0b16134596ba262c3914f24073a44d4fcc32d0a92c14c2d05e5f739c33cdbf133a30d3399142e370af6196c476e1982b","file_path":"legal-nlp-survey-20250328-002/original/Livermore_2018_0184.pdf","title":"","llm_title":"LAW SEARCH AS PREDICTION","authors":["Michael A. Livermore","Faraz Dadgosari","Mauricio Guim","Peter A. Beling","Daniel N. Rockmore"],"llm_authors":"Michael A. Livermore, Faraz Dadgosari, Mauricio Guim, Peter A. Beling, Daniel N. Rockmore","author_string":"Michael Livermore","year":2018,"abstract":"","llm_abstract":"The process of searching for relevant legal materials is fundamental to legal reasoning. However, despite its enormous practical and theoretical importance, law search has been given inadequate attention by scholars. In this Article, we define the problem of law search, examine its normative and empirical dimensions, and investigate one particularly promising computationally based approach. We implement a model of law search based on a notion of search space and search strategies and apply that model to the corpus of U.S. Supreme Court opinions. We test the success of the model against both citation information and hand-coded legal relevance determinations.","llm_keywords":["law search","legal reasoning","computational model","U.S. Supreme Court","search strategies","legal materials","citation information","empirical analysis","computational approach"],"classifications":["Information Retrieval"],"num_cited_by":11,"num_cited_by_title_only":49,"num_pages":59},{"id":"680a88286ab5b0dd10316dd8df98c421bc5970f9aa5acdab5fc5489870c8e336b7f4ce208057674c298d80fb52b17a8bfbe566a3a2ab20e9409babf7f8883af6","file_path":"legal-nlp-survey-20250328-002/original/Haney_2020_0304.pdf","title":"Microsoft Word - Haney_Manuscript_Final_Edit_5-29 copy.docx","llm_title":"APPLIED NATURAL LANGUAGE PROCESSING FOR LAW PRACTICE","authors":["Brian S. Haney"],"llm_authors":"BRIAN S. HANEY","author_string":"","year":2020,"abstract":"","llm_abstract":"Scholars, lawyers, and commentators are predicting the end of the legal profession, citing specific examples of artificial intelligence (AI) systems out-performing lawyers in certain legal tasks. Yet, technology’s role in the practice of law is nothing new. The Internet, email, and databases like Westlaw and Lexis have been altering legal practice for decades. Despite technology’s evolution across other industries, in many ways the practice of law remains static in its essential functions. The dynamics of legal technology are defined by the organization and quality of data, rather than innovation. This Article explores the state of the art in AI applications in law practice, offering three main contributions to legal scholarship. First, this Article explores various methods of natural language database generation and normalization. Second, this Article provides the first analysis of two types of machine learning models in law practice, deep reinforcement learning and the Transformer. Third, this Article introduces a novel natural language processing algorithm for legal writing.","llm_keywords":["Natural Language Processing","Law Practice","Artificial Intelligence","Machine Learning","Legal Technology","Data Organization","Deep Reinforcement Learning","Transformer Models","Legal Writing","AI in Law"],"classifications":["Pre-Processing","Information Retrieval","Text Generation","Resources"],"num_cited_by":27,"num_cited_by_title_only":27,"num_pages":44},{"id":"b506b524959ec5f59c84ee41e9435ed57c4d7f7c162ce3d662f97129c95236af2cf6e38e424151e6d988b0e4142d375b887eec5d0e9652998265b0671f6ac2e9","file_path":"legal-nlp-survey-20250328-002/original/Ghosh_2020_0357.pdf","title":"","llm_title":"Retrieval of Prior Court Cases Using Witness Testimonies","authors":["Kripabandhu Ghosh","Sachin Pawar","Girish Palshikar","Pushpak Bhattacharyya","Vasudeva Varma"],"llm_authors":"Kripabandhu Ghosh, Sachin Pawar, Girish Palshikar, Pushpak Bhattacharyya, Vasudeva Varma","author_string":"","year":2020,"abstract":"","llm_abstract":"Witness testimonies are important constituents of a court case description and play a significant role in the final decision. We propose two techniques to identify sentences representing witness testimonies. The first technique employs linguistic rules whereas the second technique applies distant supervision where training set is constructed automatically using the output of the first technique. We then represent the identified witness testimonies in a more meaningful structure – event verb (predicate) along with its arguments corresponding to semantic roles A0 and A1 [1]. We demonstrate effectiveness of such representation in retrieving semantically similar prior relevant cases. To the best of our knowledge, this is the first paper to apply NLP techniques to extract witness information from court judgements and use it for retrieving prior court cases.","llm_keywords":["Prior Case Retrieval","Witness Testimonies","Natural Language Processing","Semantic Roles","Court Cases","Event Frames","Testimony Sentence Identification","Linguistic Rules","Distant Supervision","Legal Argumentation"],"classifications":["Information Extraction","Information Retrieval"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":9},{"id":"862fcc2069d14e818d1928c2f69e2d2654450e70c9bae1da8a83fb55868586343136775ca7370210bf4e47f8b5ecb31c579f0233d0c83bb647d0865649e191c6","file_path":"legal-nlp-survey-20250328-002/original/Samarawickrama_2022_0526.pdf","title":"","llm_title":"Legal Party Extraction from Legal Opinion Texts Using Recurrent Deep Neural Networks","authors":["Chamodi Samarawickrama","Melonie de Almeida","Nisansa de Silva","Gathika Ratnayaka","Amal Shehan Perera"],"llm_authors":"Chamodi Samarawickrama, Melonie de Almeida, Nisansa de Silva, Gathika Ratnayaka, and Amal Shehan Perera","author_string":"","year":2022,"abstract":"","llm_abstract":"Since the advent of deep learning based Natural Language Processing (NLP), diverse domains of human society have benefited from automation and the resultant increment in efficiency. Law and order are, undoubtedly, crucial for the proper functioning of society; for without law there would be chaos, failing to offer equality to everyone. The legal domain being such a vital field, the incorporation of NLP into its workings has drawn attention in many research studies. This study attempts to leverage NLP into the task of extracting legal parties from legal opinion text documents. This task is of high importance given the significance of existing legal cases on contemporary cases under the legal practice, case law. This study proposes a novel deep learning methodology which can be effectively used to resolve the problem of identifying legal party members in legal documents. We present two models here, where the first is a BRNN model to detect whether an entity is a legal party or not, and a second, a modification of the same neural network, to classify the thus identified entities into petitioner and defendant classes. Furthermore, in this study, we introduce a novel data set which is annotated with legal party information by an expert in the legal domain. With the use of the said dataset, we have trained and evaluated our models where the experiments carried out support satisfactory performance of our solution. The deep learning model we hereby propose, provides a benchmark for the legal party identification task on this data set. Evaluations for the solution presented in the paper show that our system has 90.89% precision and 91.69% recall for legal party extraction from an unseen paragraph from a legal document. As for the classification of petitioners and defendants, we show that GRU-512 obtains the highest F1 score.","llm_keywords":["Legal party identification","Recurrent Neural Networks","Natural Language Processing","coreference resolution","NER","deep learning","case law","legal documents"],"classifications":[],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":17},{"id":"7e6b540e7e5c6dc426352d28a4fb4eac602140dd5fb52c86c14625831c0ab8403274f9d8ad7229f00098709b6a5bf847333685bc751873a9b86e09d0801aab63","file_path":"legal-nlp-survey-20250328-002/original/Sulis_2022_0507.pdf","title":"","llm_title":"Exploiting Textual Similarity Techniques in Harmonization of Laws","authors":["Emilio Sulis","Llio Bryn Humphreys","Davide Audrito","Luigi Di Caro"],"llm_authors":"Emilio Sulis, Llio Bryn Humphreys, Davide Audrito, Luigi Di Caro","author_string":"","year":2022,"abstract":"","llm_abstract":"This paper describes an application of textual similarity techniques in the Legal Informatics domain. In European law, a relevant interest relates to the transposition of EU directives by the Member States, which can be complete, partial, or eventually absent. As part of a European project, legal experts annotated transpositions of six directives on a per-article basis. Following an established NLP pipeline, we explore a similarity-based technique to identify correspondences between transpositions of national implementations. Early results are promising and show the role that Artificial Intelligence may play within the process of harmonization and standardization of domestic legal systems as a result of the adoption of EU legislation.","llm_keywords":["Legal informatics","Text similarity","Harmonization of laws","Natural language processing","EU directives","Transposition","Artificial Intelligence"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":13},{"id":"71092db3f01c078790325e399afdbf7171037b23c5fff9502b691abce664a1df3473d64787a179ccfc126655e92fbb5f03c6827a49b0c12eaec30b3f125f0c64","file_path":"legal-nlp-survey-20250328-002/original/de-Almeida_2021_0428.pdf","title":"","llm_title":"Identifying Legal Party Members from Legal Opinion Texts Using Natural Language Processing","authors":["Chamodi Samarawickrama","Melonie de Almeida","Amal Shehan Perera","Nisansa de Silva","Gathika Ratnayaka"],"llm_authors":"Chamodi Samarawickrama, Melonie de Almeida, Amal Shehan Perera, Nisansa de Silva and Gathika Ratnayaka","author_string":"","year":2021,"abstract":"","llm_abstract":"Law and order is a field that can highly benefit from the contribution of Natural Language Processing (NLP) to its betterment. An area in which NLP can be of immense help is for information retrieval from legal documents which function as legal databases. The extraction of legal parties from the aforementioned legal documents can be identified as a task of high importance since it has a significant impact on the proceeding contemporary legal cases. This study proposes a novel deep learning methodology that can be effectively used to find a solution to the problem of identifying legal party members in legal documents. In addition to that, in this paper, we introduce a novel dataset which was created by an expert in the legal domain. Evaluations for the solution presented in the paper show that our system has 90.89% precision and 91.69% recall for an unseen paragraph from a legal document, thus conforming the success of our attempt.","llm_keywords":["Legal party identification","Recurrent Neural Networks","Coreference resolution","NER","Natural Language Processing","Legal domain","Information extraction","Legal documents","Artificial intelligence","Deep learning"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":13},{"id":"5e1bb61c116ad1d4fe374fd23e23b5606c1d861cb8abd09242b6082837f1adce84c68233940fbc925ef9fde22da735b4e4f4aa35c11336f4a6c8f805b81decf6","file_path":"legal-nlp-survey-20250328-002/original/Yang_2013_0001.pdf","title":"A Natural Language Processing and Semantic-Based System for Contract Analysis","llm_title":"A Natural Language Processing and Semantic-based System for Contract Analysis","authors":["Dan Yang","Christina Leber","Luis Tari","Aravind Chandramouli","Andrew Crapo","Richard Messmer","Steven Gustafson"],"llm_authors":"Dan Yang, Christina Leber, Luis Tari, Andrew Crapo, Richard Messmer, Steven Gustafson, Aravind Chandramouli","author_string":"Dan Yang; Christina Leber; Luis Tari; Aravind Chandramouli; Andrew Crapo; Richard Messmer; Steven Gustafson","year":2013,"abstract":"","llm_abstract":"The Contract Search Tool is a semantic search platform that enables effective analysis of complex, long-term contractual service agreement for machines such as gas turbines. The approach we developed can effectively identify paragraphs of text for specific legal concepts. Then the key content can be decomposed and organized by the semantics model that captures key elements of the concepts and links to specific paragraphs. This is achieved by performing semantic text analysis to capture implicitly-stated provisions and the definitions of provisions, and relevant information is returned in an organized manner. The tool can be applied to increase productivity of legal review, share legal knowledge with service managers, and reduce legal risk in contract review process.","llm_keywords":["Natural language processing","information retrieval","information extraction","semantics","contract analysis"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":6},{"id":"79f98f3324c952e29e493b9f4fb23d812eb45e5343c18c8fe70c00fbcdffb209b7ba0e0da5fddd616f2eb72fbf2c337053310d68f7fd0602c44847bb57ce110a","file_path":"legal-nlp-survey-20250328-002/original/Hong_2021_0437.pdf","title":"Learning from Limited Labels for Long Legal Dialogue","llm_title":"Learning from Limited Labels for Long Legal Dialogue","authors":["Jenny Hong","Derek Chong","Christopher D. Manning"],"llm_authors":"Jenny Hong, Derek Chong, Christopher D. Manning","author_string":"Jenny Hong ; Derek Chong ; Christopher Manning","year":2021,"abstract":"","llm_abstract":"We study attempting to achieve high accuracy information extraction of case factors from a challenging dataset of parole hearings, which, compared to other legal NLP datasets, has longer texts, with fewer labels. On this corpus, existing work directly applying pretrained neural models has failed to extract all but a few relatively basic items with little improvement over rule-based extraction. We address two challenges posed by existing work: training on long documents and reasoning over complex speech patterns. We use a similar approach to the two-step open-domain question answering approach by using a Reducer to extract relevant text segments and a Producer to generate both extractive answers and non-extractive classifications. In a context like ours, with limited labeled data, we show that a superior approach for strong performance within limited development time is to use a combination of a rule-based Reducer and a neural Producer. We study four representative tasks from the parole dataset. On all four, we improve extraction from the previous benchmark of 0.41–0.63 to 0.83–0.89 F1.","llm_keywords":["legal NLP","information extraction","parole hearings","limited labels","rule-based systems","neural models","speech patterns","open-domain question answering","machine learning","natural language processing"],"classifications":["Information Extraction","Information Retrieval","Classification","Machine Summarization"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":15},{"id":"2fa79d6fee98dd6f54e2baad89acad8a9dca9dc204613ba32d22cae5d12b8b23fab67b4f7fa70cce4a7bc9e43da85ac2454217c2b5689dd9f8d299ca9543528d","file_path":"legal-nlp-survey-20250328-002/original/Ray_2020_0362.pdf","title":"","llm_title":"Summarisation with Majority Opinion","authors":["Oliver Ray","Amy Conroy","Rozano Imansyah"],"llm_authors":"Oliver RAY, Amy CONROY, and Rozano IMANSYAH","author_string":"","year":2020,"abstract":"","llm_abstract":"This paper introduces a method called SUmmarisation with Majority Opinion (SUMO) that integrates and extends two prior approaches for abstractively and extractively summarising UK House of Lords cases. We show how combining two previously distinct lines of work allows us to better address the challenges resulting from this court’s unusual tradition of publishing the opinions of multiple judges with no formal statement of the reasoning (if any) agreed by a majority. We do this by applying natural language processing and machine learning, Conditional Random Fields (CRFs), to a data set we created by fusing together expert-annotated sentence labels from the HOLJ corpus of rhetorical role summary relevance with the ASMO corpus of agreement statement and majority opinion. By using CRFs and a bespoke summary generator on our enriched data set, we show a significant quantitative F1-score improvement in rhetorical role and relevance classification of 10-15% over the state-of-the-art SUM system; and we show a significant qualitative improvement in the quality of our summaries, which closely resemble gold-standard multi-judge abstracts according to a proof-of-principle user study.","llm_keywords":["Legal Summarisation","UK House of Lords","Machine Learning","SUMO","Natural Language Processing","Conditional Random Fields","Majority Opinion","Rhetorical Role","Agreement Statements","Summarisation"],"classifications":["Machine Summarization","Classification","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":4},{"id":"a9707c83d1d8da09ace90703014fc2bf9904be23b0854155033b9bd7d3f8be6a40b1371838b15d3b123fd813fce1299939c797f5f44504ea7f2404f86026609e","file_path":"legal-nlp-survey-20250328-002/original/Sovrano_2022_0497.pdf","title":"Combining shallow and deep learning approaches against data scarcity in legal domains","llm_title":"Combining shallow and deep learning approaches against data scarcity in legal domains","authors":["Francesco Sovrano","Monica Palmirani","Fabio Vitali"],"llm_authors":"Francesco Sovrano, Monica Palmirani, Fabio Vitali","author_string":"Francesco Sovrano","year":2022,"abstract":"","llm_abstract":"We are recently witnessing a radical shift towards digitisation in many aspects of our daily life, including law, public administration and governance. This has sometimes been done with the aim of reducing costs and human errors by improving data analysis and management, but not without raising major technological challenges. One of these challenges is certainly the need to cope with relatively small amounts of data, without sacrificing performance. Indeed, cutting-edge approaches to (natural) language processing and understanding are often data-hungry, especially those based on deep learning. With this paper we seek to address the problem of data scarcity in automatic Legalese (or legal English) processing and understanding. What we propose is an ensemble of shallow and deep learning techniques called SyntagmTuner, designed to combine the accuracy of deep learning with the ability of shallow learning to work with little data. Our contribution is based on the assumption that Legalese differs from its spoken language in the way the meaning is encoded by the structure of the text and the co-occurrence of words. As result, we show with SyntagmTuner how we can perform important tasks for e-governance, as multi-label classification of the United Nations General Assembly (UNGA) Resolutions or legal question answering, with data-sets of roughly 100 samples or even less.","llm_keywords":["data scarcity","deep learning","TF-IDF","syntagmatic relations","law","legal domains","natural language processing","e-governance","Legalese"],"classifications":["Classification"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":13},{"id":"db1fd69ef3d08de98482e0d11b8302a5748d5ff450bead4e9e3d9e6d2a365a754476149a5d61cba29e28094afcb41049b537766e97c5c4ef732ec2df44616249","file_path":"legal-nlp-survey-20250328-002/original/Shimazu_2014_0035.pdf","title":"AISC 244 - Legal Engineering and Its Natural Language Processing","llm_title":"Legal Engineering and Its Natural Language Processing","authors":["Akira Shimazu","Minh Le Nguyen"],"llm_authors":"Akira Shimazu and Minh Le Nguyen","author_string":"Akira Shimazu and Minh Le Nguyen","year":2013,"abstract":"","llm_abstract":"Our society is regulated by a lot of laws which are related mutually. When we view a society as a system, laws can be viewed as the specifications for the society. Such a system-oriented aspect of laws have not been studied well so far. In the upcoming e-Society, laws have more important roles in order to achieve a trustworthy society and we expect a methodology which treats a system-oriented aspect of laws. Legal Engineering is the new field that studies the methodology and applies information science, software engineering and artificial intelligence to laws in order to support legislation and to implement laws using computers. So far, as studies on Legal Engineering, Shimazu group of JAIST proposed the logical structure model of law paragraphs, the coreference model of law texts, the editing model of law texts and so on, and implemented their models. Tojo group of JAIST verified whether several related ordinances of Toyama prefecture in Japan contains contradictions or not. Ochimizu group of JAIST studied the model for designing a law-implementation system and proposed the accountability model for the law-implementation system. Futatsugi group of JAIST proposed the formal description and the verification method of legal domains. As laws are written in natural language, natural language processing is essential for Legal Engineering. In this talk, after the aim, the approach and the problems of Legal Engineering are introduced, studies on natural language processing for Legal Engineering are introduced.","llm_keywords":["Legal Engineering","Natural Language Processing","Artificial Intelligence","Law Implementation","System-Oriented Aspect","Information Science","Software Engineering","Legislation Support"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":1},{"id":"12ea8a539725525b9fa3d440bbd81961361d9907f2155b4930e608ab54973e8977e12accc443b039262312cf682818e8c90257209481b46bd0390f37c8a359cd","file_path":"legal-nlp-survey-20250328-002/original/Sancheti_2022_0551.pdf","title":"","llm_title":"Agent-Specific Deontic Modality Detection in Legal Language","authors":["Abhilasha Sancheti","Aparna Garimella","Balaji Vasan Srinivasan","Rachel Rudinger"],"llm_authors":"Abhilasha Sancheti, Aparna Garimella, Balaji Vasan Srinivasan, Rachel Rudinger","author_string":"","year":2022,"abstract":"","llm_abstract":"Legal documents are typically long and written in legalese, which makes it particularly difficult for laypeople to understand their rights and duties. While natural language understanding technologies can be valuable in supporting such understanding in the legal domain, the limited availability of datasets annotated for deontic modalities in the legal domain, due to the cost of hiring experts and privacy issues, is a bottleneck. To this end, we introduce, LEXDEMOD, a corpus of English contracts annotated with deontic modality expressed with respect to a contracting party or agent along with the modal triggers. We benchmark this dataset on two tasks: (i) agent-specific multi-label deontic modality classification, and (ii) agent-specific deontic modality and trigger span detection using Transformer-based (Vaswani et al., 2017) language models. Transfer learning experiments show that the linguistic diversity of modal expressions in LEXDEMOD generalizes reasonably from lease to employment and rental agreements. A small case study indicates that a model trained on LEXDEMOD can detect red flags with high recall. We believe our work offers a new research direction for deontic modality detection in the legal domain1.","llm_keywords":["deontic modality","legal language","contracts","agent-specific classification","transformer models","modal triggers","natural language understanding"],"classifications":["Classification","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":17},{"id":"dfcdf076a8818bddbb87c9f7a9b97fc4560a0542c4632736df392240b8cc86304986ae9d188eff5370f78f33058ec5dcf95aad138acd9497b12215ab2252565d","file_path":"legal-nlp-survey-20250328-002/original/Licari_2022_0573.pdf","title":"ITALIAN-LEGAL-BERT: A Pre-trained Transformer Language Model for Italian Law","llm_title":"ITALIAN-LEGAL-BERT: A Pre-trained Transformer Language Model for Italian Law","authors":["Daniele Licari","Giovanni Comandè"],"llm_authors":"Daniele Licari, Giovanni Comandè","author_string":"","year":2022,"abstract":"","llm_abstract":"The state of the art in natural language processing is based on transformer models that are pre-trained on general knowledge and enable efficient transfer learning in a wide variety of downstream tasks even with limited data sets. However, these models significantly decrease performance when operating in specific and sectoral domains. This is problematic in the Italian legal context, as there are many discrepancies between the language found in generic open source corpora (e.g., Wikipedia and news articles) and legal language, which can be cryptic, Latin-based, and domain idiolectal formulas. In this paper, we introduce the ITALIAN-LEGAL-BERT model with additional pre-training of the Italian BERT model on Italian civil law corpora. It achieves better results than the ‘general-purpose’ Italian BERT in different domain-specific tasks.","llm_keywords":["Legal artificial intelligence","Pre-trained language model","Italian Legal BERT","NLP","Legal domain","Transformer models","Italian civil law","Domain-specific tasks"],"classifications":["Resources","Pre-Processing"],"num_cited_by":54,"num_cited_by_title_only":54,"num_pages":16},{"id":"f3325b4493e77d902af3d9b56a91b91ea3c87bc3f8126e30d3183a8570534b5c4523c964559d9e9ac2ebd9084c709de16703a8601c91e90650ba6fdd0ccca6d5","file_path":"legal-nlp-survey-20250328-002/original/Sarkar_2021_0420.pdf","title":"Few-shot and Zero-shot Approaches to Legal Text Classification: A Case Study in the Financial Sector","llm_title":"Few-shot and Zero-shot Approaches to Legal Text Classification: A Case Study in the Financial Sector","authors":["Rajdeep Sarkar","Atul Kr. Ojha","Jay Megaro","John Mariano","Vall Herard","John P. McCrae"],"llm_authors":"Rajdeep Sarkar, Atul Kr. Ojha, Jay Megaro, John Mariano, Vall Herard, John P. McCrae","author_string":"Rajdeep Sarkar ; Atul Kr. Ojha ; Jay Megaro ; John Mariano ; Vall Herard ; John P. McCrae","year":2021,"abstract":"","llm_abstract":"The application of predictive coding techniques to legal texts has the potential to greatly reduce the cost of legal review of documents, however, there is such a wide array of legal tasks and continuously evolving legislation that it is hard to construct sufficient training data to cover all cases. In this paper, we investigate few-shot and zero-shot approaches that require substantially less training data and introduce a triplet architecture, which for promissory statements produces performance close to that of a supervised system. This method allows predictive coding methods to be rapidly developed for new regulations and markets.","llm_keywords":["Legal Text Classification","Few-shot Learning","Zero-shot Learning","Predictive Coding","NLP","Financial Sector","Regulatory Compliance","Triplet Architecture","Text Classification","Legal AI"],"classifications":["Classification"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":5},{"id":"d992418f9504ce8030b8b05b65825bb564ddd2d20c994639e73e891bb245ac93edd1d4bae85e69fa6824d944738050f8dfc423bd76a0d42b85d7344b680615f4","file_path":"legal-nlp-survey-20250328-002/original/Kim_2017_0156.pdf","title":"Microsoft Word - Kim_Goebel_camera_ready_ICAIL2017.docx","llm_title":"Two-step Cascaded Textual Entailment for Legal Bar Exam Question Answering","authors":["Mi-Young Kim","Randy Goebel"],"llm_authors":"Mi-Young Kim and Randy Goebel","author_string":"","year":2017,"abstract":"","llm_abstract":"Our legal question answering system combines legal information retrieval and textual entailment, and exploits semantic information using a logic-based representation. We have evaluated our system using the data from the competition on legal information extraction/entailment (COLIEE)-2017. The competition focuses on the legal information processing required to answer yes/no questions from Japanese legal bar exams, and it consists of two phases: ad hoc legal information retrieval (Phase 1), and textual entailment (Phase 2). Phase 1 requires the identification of Japan civil law articles relevant to a legal bar exam query. For this phase, we have used an information retrieval approach using TF-IDF combined with a simple language model. Phase 2 requires a yes/no decision for previously unseen queries, which we approach by comparing the approximate meanings of queries with relevant statutes. Our meaning extraction process uses a selection of features based on a kind of paraphrase, coupled with a condition/conclusion/exception analysis of articles and queries. We also extract and exploit negation patterns from the articles. We construct a logic-based representation as a semantic analysis result, and then classify questions into easy and difficult types by analyzing the logic representation. If a question is in our easy category, we simply obtain the entailment answer from the logic representation; otherwise we use an unsupervised learning method to obtain the entailment answer. Experimental evaluation shows that our result ranked highest in the Phase 2 amongst all COLIEE-2017 competitors.","llm_keywords":["Textual entailment","Question answering","Legal text mining","Logic representation","Information retrieval","Legal bar exam","Semantic analysis","TF-IDF","Language model"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":47,"num_cited_by_title_only":47,"num_pages":9},{"id":"537b309cdcc8300fb6cf4fe21380a367392791f3eb6486e18ae11a0b85ba04e68d1b3921607ac41bcf7059960230f923b2713cc0a8905838895f3286e1e73048","file_path":"legal-nlp-survey-20250328-002/original/Do_2017_0137.pdf","title":"","llm_title":"Legal Question Answering using Ranking SVM and Deep Convolutional Neural Network","authors":["Phong-Khac Do","Huy-Tien Nguyen","Chien-Xuan Tran","Minh-Tien Nguyen","Minh-Le Nguyen"],"llm_authors":"Phong-Khac Do, Huy-Tien Nguyen, Chien-Xuan Tran, Minh-Tien Nguyen, and Minh-Le Nguyen","author_string":"","year":2017,"abstract":"","llm_abstract":"This paper presents a study of employing Ranking SVM and Convolutional Neural Network for two missions: legal information retrieval and question answering in the Competition on Legal Information Extraction/Entailment. For the first task, our proposed model used a triple of features (LSI, Manhattan, Jaccard), and is based on paragraph level instead of article level as in previous studies. In fact, each single-paragraph article corresponds to a particular paragraph in a huge multiple-paragraph article. For the legal question answering task, additional statistical features from information retrieval task integrated into Convolutional Neural Network contribute to higher accuracy.","llm_keywords":["Learning to Rank","Ranking SVM","Convolutional Neural Network","Legal Information Retrieval","Legal Question Answering"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":81,"num_cited_by_title_only":81,"num_pages":15},{"id":"d61406182af276be1b5ea7b01b9f9a224dfba28e2d571b53f6416235913aece4146fdb0c7249b40afe61bdb6da40db0bd21e13d64481f8d2efe15e7aab6f1fbc","file_path":"legal-nlp-survey-20250328-002/original/Trappey,-A._2021_0387.pdf","title":"An intelligent patent recommender adopting machine learning approach for natural language processing: A case study for smart machinery technology mining","llm_title":"An intelligent patent recommender adopting machine learning approach for natural language processing: A case study for smart machinery technology mining","authors":["Amy Trappey","Charles V. Trappey","Alex Hsieh"],"llm_authors":"Amy Trappey, Charles V. Trappey, Alex Hsieh","author_string":"Amy Trappey","year":2021,"abstract":"","llm_abstract":"Recommendation systems are widely applied in many fields, such as online customized product searches and customer-centric advertisements. This research develops the methodology for a patent recommender to discover semantically relevant patents for further technology mining and trend analysis. The proposed recommender adopts machine learning (ML) algorithms for natural language processing (NLP) to represent patent documents in vector space and to enable semantic analyses of the patent documents. The ML approach of neural network (NN) language models, trained by domain patent documents (text) as a training set, convert patent documents into vectors and, thus, can identify semantically similar patents using document similarity measures. In particular, the proposed recommender is deployed to in-depth case studies for advanced patent recommendations. The case domain of smart machinery is used to better enable smart manufacturing by incorporating innovative technologies, such as intelligent sensors, intelligent controllers, and intelligent decision making. The research uses six sub-domains in smart machinery technologies as the case studies to verify the superior accuracy and efficacy of the recommender system and methodologies.","llm_keywords":["Natural language processing","Patent recommendation","Word embedding","Technology mining","Trend analysis"],"classifications":["Information Retrieval"],"num_cited_by":54,"num_cited_by_title_only":54,"num_pages":11},{"id":"ade6ad18193feaf5225323f6c1ad1420db532aff3fc71490002472718c6493df891315449ddd744bd185a9e44ae7c6ddaa5f70d2f4ce9a1bbf3e641ec55d4ca4","file_path":"legal-nlp-survey-20250328-002/original/Wehnert_2021_0441.pdf","title":"","llm_title":"Legal Norm Retrieval with Variations of the BERT Model Combined with TF-IDF Vectorization","authors":["Sabine Wehnert","Viju Sudhi","Shipra Dureja","Libin Kutty","Saijal Shahania","Ernesto W. De Luca"],"llm_authors":"Sabine Wehnert, Viju Sudhi, Shipra Dureja, Libin Kutty, Saijal Shahania, Ernesto W. De Luca","author_string":"","year":2021,"abstract":"","llm_abstract":"In this work, we examine variations of the BERT model on the statute law retrieval task of the COLIEE competition. This includes approaches to leverage BERT’s contextual word embeddings, fine-tuning the model, combining it with TF-IDF vectorization, adding external knowledge to the statutes and data augmentation. Our ensemble of Sentence-BERT with two different TF-IDF representations and document enrichment exhibits the best performance on this task regarding the F2 score. This is followed by a fine-tuned LEGAL-BERT with TF-IDF and data augmentation and our third approach with the BERTScore. As a result, we show that there are significant differences between the chosen BERT approaches and discuss several design decisions in the context of statute law retrieval.","llm_keywords":["BERT model","TF-IDF vectorization","legal information retrieval","contextual word embeddings","document enrichment","data augmentation","COLIEE competition","LEGAL-BERT","BERTScore"],"classifications":["Information Retrieval","Pre-Processing","Resources"],"num_cited_by":42,"num_cited_by_title_only":42,"num_pages":10},{"id":"451ad9f2cd54d9b3fbf816cc52262f00bb3425688f3bdaa920bae7508066258ac25c6129be095d1d0799d7aa022061edea9b8aab806ad04c8dd58462a79ec823","file_path":"legal-nlp-survey-20250328-002/original/Gabbard_2015_0076.pdf","title":"","llm_title":"Writing and Reviewing Contracts: don’t you wish to save time, effort, and money?","authors":["Anne Gardner","Jason Gabbard","Jana Z. Sukkarieh","Federico Silva"],"llm_authors":"Jason Gabbard, Jana Z. Sukkarieh, Federico Silva","author_string":"Anne Gardner","year":2015,"abstract":"","llm_abstract":"This extended abstract describes a web-based system that helps lawyers and their clients save time, effort and money. The system automatically reviews a contract, written in English, and points out which components are present and which components are not against a given gold standard. The system also gives users feedback to improve the contract and it is, to some extent, interactive.","llm_keywords":["Contract Review","Legal Technology","Artificial Intelligence","Text Mining","Machine Learning","Contractual Legalese","Knowledge Representation"],"classifications":["Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":2},{"id":"c84a462d6eda5a9112421e74126abf7fc9285d1d1ab87b4017b11ad73fc192f533b382ca24d53eb5eb7f6613eb5db32366a3bb4a027461429924f859a919e906","file_path":"legal-nlp-survey-20250328-002/original/Getman_2014_0027.pdf","title":"","llm_title":"A crowdsourcing approach to building a legal ontology from text","authors":["Anatoly Getman","Volodymyr Karasiuk"],"llm_authors":"Anatoly P. Getman • Volodymyr V. Karasiuk","author_string":"","year":2014,"abstract":"","llm_abstract":"This article focuses on the problems of application of artificial intelligence to represent legal knowledge. The volume of legal knowledge used in practice is unusually large, and therefore the ontological knowledge representation is proposed to be used for semantic analysis, presentation and use of common vocabulary, and knowledge integration of problem domain. At the same time some features of legal knowledge representation in Ukraine have been taken into account. The software package has been developed to work with the ontology. The main features of the program complex, which has a Web-based interface and supports multi-user filling of the knowledge base, have been described. The crowdsourcing method is due to be used for filling the knowledge base of legal information. The success of this method is explained by the self-organization principle of information. However, as a result of such collective work a number of errors are identified, which are distributed throughout the structure of the ontology. The results of application of this program complex are discussed in the end of the article and the ways of improvement of the considered technique are planned.","llm_keywords":["Knowledge representation","Ontology","Legal information","Software implementation","Self-organization","Crowdsourcing"],"classifications":["Information Extraction","Resources"],"num_cited_by":55,"num_cited_by_title_only":55,"num_pages":23},{"id":"e36c595cf9fc3917546187cafd3296b46563943a93933771b1d3e73dfa7a967c5988ea111e8b6f51e1e4ccd33bd4b9a2f6726bd03e150e94b8453c42ef21b6ef","file_path":"legal-nlp-survey-20250328-002/original/Lee_2021_0472.pdf","title":"","llm_title":"Tax Judgment Analysis and Prediction using NLP and BiLSTM","authors":["Yeong-Keun Lee","Koo-Rack Park","Hoo-Young Lee"],"llm_authors":"Yeong-Keun Lee, Koo-Rack Park, Hoo-Young Lee","author_string":"user","year":2021,"abstract":"","llm_abstract":"Research and importance of legal services applied with AI so that it can be easily understood and predictable in difficult legal fields is increasing. In this study, based on the decision of the Tax Tribunal in the field of tax law, a model was built through self-learning through information collection and data processing, and the prediction results were answered to the user's query and the accuracy was verified. The proposed model collects information on tax decisions and extracts useful data through web crawling, and generates word vectors by applying Word2Vec's Fast Text algorithm to the optimized output through NLP. 11,103 cases of information were collected and classified from 2017 to 2019, and verified with 70% accuracy. It can be useful in various legal systems and prior research to be more efficient application.","llm_keywords":["Artificial Intelligence","Legal System","Tax Tribunal","Word2Vec","BiLSTM","NLP"],"classifications":["Classification","Information Extraction","Resources","Information Retrieval"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":8},{"id":"58bd70f0a3c17192497737b2a311a81c673723812cbbd807ede0d0a6ecc5f3c403765fec21d3341d1b0928987c4150cad3cb975ec737ae4bf9157ee95f6972bc","file_path":"legal-nlp-survey-20250328-002/original/Shen_2022_0589.pdf","title":"","llm_title":"Multi-LexSum: Real-World Summaries of Civil Rights Lawsuits at Multiple Granularities","authors":["Zejiang Shen","Kyle Lo","Lauren Yu","Nathan Dahlberg","Margo Schlanger","Doug Downey"],"llm_authors":"Zejiang Shen, Kyle Lo, Lauren Yu, Nathan Dahlberg, Margo Schlanger, Doug Downey","author_string":"","year":2022,"abstract":"","llm_abstract":"With the advent of large language models, methods for abstractive summarization have made great strides, creating potential for use in applications to aid knowledge workers processing unwieldy document collections. One such setting is the Civil Rights Litigation Clearinghouse (CRLC), which posts information about large-scale civil rights lawsuits, serving lawyers, scholars, and the general public. Today, summarization in the CRLC requires extensive training of lawyers and law students who spend hours per case understanding multiple relevant documents in order to produce high-quality summaries of key events and outcomes. Motivated by this ongoing real-world summarization effort, we introduce Multi-LexSum, a collection of 9,280 expert-authored summaries drawn from ongoing CRLC writing. Multi-LexSum presents a challenging multi-document summarization task given the length of the source documents, often exceeding two hundred pages per case. Furthermore, Multi-LexSum is distinct from other datasets in its multiple target summaries, each at a different granularity (ranging from one-sentence “extreme” summaries to multi-paragraph narrations of over five hundred words). We present extensive analysis demonstrating that despite the high-quality summaries in the training data (adhering to strict content and style guidelines), state-of-the-art summarization models perform poorly on this task. We release Multi-LexSum for further research in summarization methods as well as to facilitate development of applications to assist in the CRLC’s mission.","llm_keywords":["abstractive summarization","Civil Rights Litigation Clearinghouse","Multi-LexSum","multi-document summarization","granularity","large language models","dataset","natural language processing","expert-authored summaries"],"classifications":["Machine Summarization","Resources"],"num_cited_by":58,"num_cited_by_title_only":58,"num_pages":37},{"id":"48c0cf87bb289ed9f23c3238ccec714d3451c306ea0db9ab95266103ed89a94636a3aa7ca26683c118c65d84a62eab8a3ad0d3d6f70d06219f141530e35230c3","file_path":"legal-nlp-survey-20250328-002/original/Łukasz_2022_0537.pdf","title":"Polish Court Ruling Classification Using Deep Neural Networks","llm_title":"Polish Court Ruling Classification Using Deep Neural Networks","authors":["Łukasz Kostrzewa","Robert Nowak"],"llm_authors":"Łukasz Kostrzewa and Robert Nowak","author_string":"Łukasz Kostrzewa and Robert Nowak","year":2022,"abstract":"","llm_abstract":"In this work, the problem of classifying Polish court rulings based on their text is presented. We use natural language processing methods and classifiers based on convolutional and recurrent neural networks. We prepared a dataset of 144,784 authentic, anonymized Polish court rulings. We analyze various general language embedding matrices and multiple neural network architectures with different parameters. Results show that such models can classify documents with very high accuracy (>99%). We also include an analysis of wrongly predicted examples. Performance analysis shows that our method is fast and could be used in practice on typical server hardware with 2 Processors (Central Processing Units, CPUs) or with a CPU and a Graphics processing unit (GPU).","llm_keywords":["law text classification","machine learning","natural language processing","artificial neural networks","Polish court rulings"],"classifications":["Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":16},{"id":"fe06e35b604d6319ac9ab27598c91a7b270695c01331accdd61549e95799f5ddd0f98150bc9b16253bc14c5e85055fc103244462fa46c9b05cc57bb17aaf19ea","file_path":"legal-nlp-survey-20250328-002/original/Nanda_2016_0078.pdf","title":"","llm_title":"A Text Similarity Approach for Automated Transposition Detection of European Union Directives","authors":["Rohan Nanda","Luigi Di Caro","Guido Boella"],"llm_authors":"Rohan NANDA, Luigi DI CARO, Guido BOELLA","author_string":"","year":2016,"abstract":"","llm_abstract":"This paper investigates the application of text similarity techniques to automatically detect the transposition of European Union (EU) directives into the national law. Currently, the European Commission (EC) resorts to time consuming and expensive manual methods like conformity checking studies and legal analysis for identifying national transposition measures. We utilize both lexical and semantic similarity techniques and supplement them with knowledge from EuroVoc to identify transpositions. We then evaluate our approach by comparing the results with the correlation tables (gold standard). Our results indicate that both similarity techniques proved to be effective in detecting transpositions. Such systems could be used to identify the transposed provisions by both EC and legal professionals.","llm_keywords":["transposition","text similarity","EU legislation","national implementing measures","European Union directives","cosine similarity","latent semantic analysis","natural language processing"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":6},{"id":"f53708e9e580e244cfeeef640cab2326ba4d6e7fcf36c3739f63ab17315a5b5b2931511975e32640e4199fb56c93841e2297f72a5dcb027dde13ab426b3bf782","file_path":"legal-nlp-survey-20250328-002/original/Roh_2017_0122.pdf","title":"Developing a Methodology of Structuring and Layering Technological Information in Patent Documents through Natural Language Processing","llm_title":"Developing a Methodology of Structuring and Layering Technological Information in Patent Documents through Natural Language Processing","authors":["Taeyeoun Roh","Yujin Jeong","Byungun Yoon"],"llm_authors":"Taeyeoun Roh, Yujin Jeong, Byungun Yoon","author_string":"Taeyeoun Roh, Yujin Jeong and Byungun Yoon","year":2017,"abstract":"","llm_abstract":"Since patents contain various types of objective technological information, they are used to identify the characteristics of technology fields. Text mining in patent analysis is employed in various fields such as trend analysis and technology classification, and knowledge flow among technologies. However, since keyword-based text mining has the limitation whereby, when screening useful keywords, it frequently omits meaningful keywords, analyzers therefore need to repeat the careful scrutiny of the derived keywords to clarify the meaning of keywords. In this research, we structure meaningful keyword sets related to technological information from patent documents; then we layer the keywords, depending on the level of information. This research involves two steps. First, the characteristics of technological information are analyzed by reviewing the patent law and investigating the description of patent documents. Second, the technological information is structured by considering the information types, and the keywords in each type are layered through natural language processing. Consequently, the structured and layered keyword set does not omit useful keywords and the analyzer can easily understand the meaning of each keyword.","llm_keywords":["text mining","NLP","technological information","patent analysis","text structure"],"classifications":["Classification","Information Retrieval","Information Extraction","Resources"],"num_cited_by":26,"num_cited_by_title_only":26,"num_pages":19},{"id":"acc4f7dfb884091fac6cbaa73d65bfa0efb8bda93188582611ba7f5f558eed06dc8560df366fadf3a4291949d3bb7ac6e53672f47d0c7eff044eb943ec8bdbe9","file_path":"legal-nlp-survey-20250328-002/original/Contissa_2018_0166.pdf","title":"","llm_title":"Automated Processing of Privacy Policies Regulation","authors":["Giuseppe Contissa","Koen Docter","Francesca Lagioia","Marco Lippi","Hans-Wolfgang Micklitz","Przemyslaw Palka","Giovanni Sartor","Paolo Torroni"],"llm_authors":"Giuseppe CONTISSA, Koen DOCTER, Francesca LAGIOIA, Marco LIPPI, Hans-Wolfgang MICKLITZ, Przemyslaw PALKA, Giovanni SARTOR, Paolo TORRONI","author_string":"","year":2018,"abstract":"","llm_abstract":"Two years after its entry into force, the EU General Data Protection Regulation became applicable on the 25th May 2018. Despite the long time for preparation, privacy policies of online platforms and services still often fail to comply with information duties and the standard of lawfulness of data processing. In this paper we present a new methodology for processing privacy policies under GDPR’s provisions, and a novel annotated corpus, to be used by machine learning systems to automatically check the compliance and adequacy of privacy policies. Preliminary results confirm the potential of the methodology.","llm_keywords":["GDPR","privacy policies","machine learning","legal text analytics","compliance","online platforms","data protection","automated detection","information duties","lawfulness"],"classifications":["Pre-Processing","Resources","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":10},{"id":"1c6ab689a90b7a2e0ed35dc586456966f491f02aeb441cdbcf7d49f8f42a9d39deab7699dab6b343eb1787b15c98b2b18365ee01c54e9b3092228400f46ffac4","file_path":"legal-nlp-survey-20250328-002/original/Carvalho_2017_0129.pdf","title":"","llm_title":"Improving Legal Information Retrieval by Distributional Composition with Term Order Probabilities","authors":["Danilo Carvalho","Vu Duc Tran","Khanh Van Tran","Minh Nguyen"],"llm_authors":"Danilo S. Carvalho, Vu Duc Tran, Khanh Van Tran, and Minh Le Nguyen","author_string":"","year":2017,"abstract":"","llm_abstract":"Legal professionals worldwide are currently trying to get up-to-pace with the explosive growth in legal document availability through digital means. This drives a need for high efficiency Legal Information Retrieval (IR) and Question Answering (QA) methods. The IR task in particular has a set of unique challenges that invite the use of semantic motivated NLP techniques. In this work, a two-stage method for Legal Information Retrieval is proposed, combining lexical statistics and distributional sentence representations in the context of Competition on Legal Information Extraction/Entailment (COLIEE). The combination is done with the use of disambiguation rules, applied over the rankings obtained through n-gram statistics. After the ranking is done, its results are evaluated for ambiguity, and disambiguation is done if a result is decided to be unreliable for a given query. Competition and experimental results indicate small gains in overall retrieval performance using the proposed approach. Additionally, an analysis of error and improvement cases is presented for a better understanding of the contributions.","llm_keywords":["Legal Information Retrieval","Natural Language Processing","Question Answering","Distributional Semantics","Machine Learning","N-gram statistics","Sentence representations","Semantic similarity"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":15},{"id":"5632167df9401bd5011a287f7b993d8dac1f1f6954f6df19e1e6941f87da2825c53a6d6c7bb2c81487403284f3ae647d93e2d8d9bde00c042fe1791f78d9d482","file_path":"legal-nlp-survey-20250328-002/original/Joshi_2016_0079.pdf","title":"","llm_title":"ALDA : Cognitive Assistant for Legal Document Analytics","authors":["Karuna Joshi","Aditi Gupta","Sudip Mittal","Claudia Pearce","Anupam Joshi","Tim Finin"],"llm_authors":"Karuna P. Joshi, Aditi Gupta, Sudip Mittal, Claudia Pearce, Anupam Joshi, and Tim Finin","author_string":"","year":2016,"abstract":"","llm_abstract":"In recent times, there has been an exponential growth in digitization of legal documents such as case records, contracts, terms of services, regulations, privacy documents and compliance guidelines. Courts have been digitizing their archived cases and also making it available for e-discovery. On the other hand, businesses are now maintaining large data sets of legal contracts that they have signed with their employees, customers and contractors. Large public sector organizations are often bound by complex legal legislation and statutes. Hence, there is a need of a cognitive assistant to analyze and reason over these legal rules and help people make decisions. Today the process of monitoring an ever increasing dataset of legal contracts and ensuring regulations and compliance is still very manual and labour intensive. This can prove to be a bottleneck in the smooth functioning of an enterprise. Automating these digital workflows is quite hard because the information is available as text documents but it is not represented in a machine understandable way. With the advancements in cognitive assistance technologies, it is now possible to analyze these digitized legal documents efficiently. In this paper, we discuss ALDA, a legal cognitive assistant to analyze digital legal documents. We also present some of the preliminary results we have obtained by analyzing legal documents using techniques such as semantic web, text mining and graph analysis.","llm_keywords":["legal documents","digitization","cognitive assistant","compliance","semantic web","text mining","graph analysis","machine learning","information technology","regulatory policies"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":28,"num_cited_by_title_only":28,"num_pages":5},{"id":"84eda867b6c5f18f61d77063c201a04433c87a7438dcd06f3621af8024616c6c48d97475657e082de458aaaa03c549f420cf00f686a54b8182b5685157be0b15","file_path":"legal-nlp-survey-20250328-002/original/El-Hamdani_2021_0378.pdf","title":"","llm_title":"A Combined Rule-Based and Machine Learning Approach for Automated GDPR Compliance Checking","authors":["Rajaa El Hamdani","Majd Mustapha","David Restrepo Amariles","Aurore Troussel","Sébastien Meeùs","Katsiaryna Krasnashchok"],"llm_authors":"Rajaa EL HAMDANI, Majd Mustapha, David Restrepo Amariles, Aurore Troussel, Sébastien Meeùs, Katsiaryna Krasnashchok","author_string":"","year":2021,"abstract":"","llm_abstract":"The General Data Protection Regulation (GDPR) requires data controllers to implement end-to-end compliance. Controllers must therefore ensure that the terms agreed with the data subject and their own obligations under GDPR are respected in the data flows from data subject to controllers, processors and sub processors (i.e. data supply chain). This paper seeks to contribute to bridge both ends of compliance checking through a two-pronged study. First, we conceptualize a framework to implement a document-centric approach to compliance checking in the data supply chain. Second, we develop specific methods to automate compliance checking of privacy policies. We test a two-modules system, where the first module relies on NLP to extract data practices from privacy policies. The second module encodes GDPR rules to check the presence of mandatory information. The results show that the text-to-text approach outperforms local classifiers and enables the extraction of both coarse-grained and fine-grained information with only one model. We implement full evaluation of our system on a dataset of 30 privacy policies annotated by legal experts. We conclude that this approach could be generalized to other documents in the data supply as a means to improve end-to-end compliance.","llm_keywords":["GDPR","compliance checking","privacy policies","machine learning","rule-based approach","NLP","data supply chain","document-centric approach"],"classifications":["Information Extraction","Classification"],"num_cited_by":59,"num_cited_by_title_only":59,"num_pages":10},{"id":"3d2fe59e1c87eac1cc3f80fcbfc44134ca41b731c2a2c4a9919132b8cee63597b017788161643d89e1a4cb52aea3867258c8550c5fc267efed50519824a65153","file_path":"legal-nlp-survey-20250328-002/original/Waltl_2017_0149.pdf","title":"Predicting the Outcome of Appeal Decisions in Germany’s Tax Law","llm_title":"Predicting the Outcome of Appeal Decisions in Germany’s Tax Law","authors":["Bernhard Waltl","Georg Bonczek","Elena Scepankova","Jörg Landthaler","Florian Matthes"],"llm_authors":"Bernhard Waltl, Georg Bonczek, Elena Scepankova, Jörg Landthaler, and Florian Matthes","author_string":"Bernhard Waltl","year":2017,"abstract":"","llm_abstract":"Predicting the outcome or the probability of winning a legal case has always been highly attractive in legal sciences and practice. Hardly any attempt has been made to predict the outcome of German cases, although prior court decisions become more and more important in various legal domains of Germany’s jurisdiction, e.g., tax law. This paper summarizes our research on training a machine learning classifier to determine likelihood ratios and thus predict the outcome of a restricted set of cases from Germany’s jurisdiction. Based on a data set of German tax law cases (44 285 documents from 1945 to 2016) we selected those cases which belong to an appeal decision (5 990 documents). We used the provided meta-data and natural language processing to extract 11 relevant features and trained a Naive Bayes classifier to predict whether an appeal is going to be successful or not. The evaluation (10-fold cross validation) on the data set has shown a performance regarding F1-score between 0.53 and 0.58. This score indicates that there is room for improvement. We expect that the high relevancy for legal practice, the availability of data, and advance machine learning techniques will foster more research in this area.","llm_keywords":["appeal decisions","German tax law","machine learning","Naive Bayes classifier","likelihood ratios","legal predictions","natural language processing","F1-score","legal practice"],"classifications":["Classification","Information Extraction"],"num_cited_by":53,"num_cited_by_title_only":53,"num_pages":11},{"id":"68e5b78f0fac664b6e6ea30852a923f4257585e91b5dfe2dcfa5a882b866c4019da431e39e274b275da7ef6073fddb3afe2d8b172daa99f41e10cd6455a58e4d","file_path":"legal-nlp-survey-20250328-002/original/Bourguet_2017_0151.pdf","title":"","llm_title":"Scoring Judicial Syllabi in Portuguese","authors":["Jean-Rémi Bourguet","Melissa Zorzanelli Costa"],"llm_authors":"Jean-R´emi BOURGUET, Melissa ZORZANELLI COSTA","author_string":"","year":2017,"abstract":"","llm_abstract":"Law professionals generally need to investigate a large number of items to make their decisions. However, the frameworks they use are often limited to a simple full-text search. In this paper, we propose to score the results of such searches investigating ontological and non-ontological solutions. We examine their applicabilities in a real use case dealing with jurisprudences of regional federal courts in Brazil.","llm_keywords":["Jurisprudences","Full-text search","NLP","Portuguese","Similarities"],"classifications":["Information Retrieval"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"659d56a3515eec3cb848ead7b07ab1c43376df31367a0f7fd3f695e40908b20269f01b468b214d07916ae4bccd82da94ca40ac530f9afb30a7d1555589d42210","file_path":"legal-nlp-survey-20250328-002/original/Tang_2021_0461.pdf","title":"Searching for Legal Documents at Paragraph Level: Automating Label Generation and Use of an Extended Attention Mask for Boosting Neural Models of Semantic Similarity","llm_title":"Searching for legal documents at paragraph level: Automating label generation and use of an Extended Attention Mask for boosting neural models of semantic similarity","authors":["Li Tang","Simon Clematide"],"llm_authors":"Li Tang, Simon Clematide","author_string":"Li Tang ; Simon Clematide","year":2021,"abstract":"","llm_abstract":"Searching for legal documents is a specialized Information Retrieval task that is relevant for expert users (lawyers and their assistants) and for non-expert users. By searching previous court decisions (cases), a user can better prepare the legal reasoning of a new case. Being able to search using a natural language text snippet instead of a more artificial query could help to prevent query formulation issues. Also, if semantic similarity could be modeled beyond exact lexical matches, more relevant results can be found even if the query terms don’t match exactly. For this domain, we formulated a task to compare different ways of modeling semantic similarity at paragraph level, using neural and non-neural systems. We compared systems that encode the query and the search collection paragraphs as vectors, enabling the use of cosine similarity for results ranking. After building a German dataset for cases and statutes from Switzerland, and extracting citations from cases to statutes, we developed an algorithm for estimating semantic similarity at paragraph level, using a link-based similarity method. When evaluating different systems in this way, we find that semantic similarity modeling by neural systems can be boosted with an extended attention mask that quenches noise in the inputs.","llm_keywords":["legal document retrieval","semantic similarity","neural systems","information retrieval","natural language processing","automated label generation","attention mask","cosine similarity"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":9},{"id":"cb25eafef84ecb1931b0e0da9ba7d4ea3fc3912daf6d2dbf568cfafb52edb2f3135abaa63fc6096aa5f75219da7b01f217c06b842e5a2a5a960180bcfc967ab2","file_path":"legal-nlp-survey-20250328-002/original/Padigi_2019_0276.pdf","title":"","llm_title":"Precedent Case Retrieval using Wordnet and Deep Recurrent Neural Networks","authors":["Sai Vishwas Padigi","Mohit Mayank","S. Natarajan"],"llm_authors":"Sai Vishwas Padigi, Mohit Mayank, S. Natarajan","author_string":"NnN","year":2019,"abstract":"","llm_abstract":"The slowness of legal proceedings in the common law legal system is a widely known fact. Any tool which could help reduce the time taken for the resolution of a case is invaluable. Common legal systems place a great importance on precedents and retrieving the correct set of precedents is considerably time consuming. Hence, for any case whose proceedings are in progress, if there are suitable prior cases, then the court has to follow the same interpretations that were passed in the prior cases. This is to ensure that similar situations receive similar treatment, thus maintaining uniformity amongst the legal proceedings across all courts at all times. Hence, precedent cases are treated as important as any other written law (a statute) in this legal system. In this paper, we propose two new approaches to solve this information retrieval problem wherein the system accepts the current case document as the query and returns the relevant precedent cases as the result. The first approach is to calculate the document similarity using Wordnet, which is a lexical database that could be leveraged to quantify the semantic relatedness between two documents, using a semantic network. The second approach is the use of a Siamese Manhattan Long Short Term Memory network, which is a supervised model trained to understand the underlying similarity between two documents.","llm_keywords":["Information retrieval","Text similarity","Deep learning","Legal documents","Wordnet","Siamese Manhattan LSTM"],"classifications":["Information Retrieval"],"num_cited_by":2,"num_cited_by_title_only":5,"num_pages":15},{"id":"429b391782b627ace8a7af95d1ffb390611a444f70bec7a02e270030b50e27a59fa39df04ead7bd522655ca816ea7d495068083a7e2987e9df75617f3309321c","file_path":"legal-nlp-survey-20250328-002/original/Wu_2021_0462.pdf","title":"","llm_title":"Semantic Search and Summarization of Judgments Using Topic Modeling","authors":["Tien-Hsuan Wu","Ben Kao","Felix Chan","Anne Sy Cheung","Michael Mk Cheung","Guowen Yuan","Yongxi Chen"],"llm_authors":"Tien-Hsuan WU, Ben KAO, Felix CHAN, Anne SY CHEUNG, Michael MK CHEUNG, Guowen YUAN, Yongxi CHEN","author_string":"","year":2021,"abstract":"","llm_abstract":"Online legal document libraries, such as WorldLII, are indispensable tools for legal professionals to conduct legal research. We study how topic modeling techniques can be applied to such platforms to facilitate searching of court judgments. Specifically, we improve search effectiveness by matching judgments to queries at semantics level rather than at keyword level. Also, we design a system that summarizes a retrieved judgment by highlighting a small number of paragraphs that are semantically most relevant to the user query. This summary serves two purposes: (1) It explains to the user why the machine finds the retrieved judgment relevant to the user’s query, and (2) it helps the user quickly grasp the most salient points of the judgment, which significantly reduces the amount of time needed by the user to go through the returned search results. We further enhance our system by integrating domain knowledge provided by legal experts. The knowledge includes the features and aspects that are most important for a given category of judgments. Users can then view a judgement’s summary focusing on particular aspects only. We illustrate the effectiveness of our techniques with a user evaluation experiment on the HKLII platform. The results show that our methods are highly effective.","llm_keywords":["Topic modeling","Semantic search","Judgment summarization","Legal research","Court judgments"],"classifications":["Information Retrieval","Machine Summarization"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":7},{"id":"4caa7d7c502592974cbbea65e00aa19def82a3fbddda46f2abd495f6db7041cea1075cad8f2d9d9ad12cf4db8aec4bb9dd35e2d57d4f5708e3e817cda5aa4b77","file_path":"legal-nlp-survey-20250328-002/original/Agnoloni_2017_0140.pdf","title":"","llm_title":"Linking European Case Law: BO-ECLI Parser, an Open Framework for the Automatic Extraction of Legal Links","authors":["Tommaso Agnoloni","Lorenzo Bacci","Ginevra Peruginelli","Marc van Opijnen","Jos van den Oever","Monica Palmirani","Luca Cervone","Octavian Bujor","Arantxa Arsuaga Lecuona","Alberto Boada Garcia","Luigi Di Caro","Giovanni Siragusa"],"llm_authors":"Tommaso AGNOLONI, Lorenzo BACCI, Ginevra PERUGINELLI, Marc van OPIJNEN, Jos van den OEVER, Monica PALMIRANI, Luca CERVONE, Octavian BUJOR, Arantxa ARSUAGA LECUONA, Alberto BOADA GARCIA, Luigi DI CARO, Giovanni SIRAGUSA","author_string":"","year":2017,"abstract":"","llm_abstract":"In this paper we present the BO-ECLI Parser, an open framework for the extraction of legal references from case-law issued by judicial authorities of European member States. The problem of automatic legal links extraction from texts is tackled for multiple languages and jurisdictions by providing a common stack which is customizable through pluggable extensions in order to cover the linguistic diversity and specific peculiarities of national legal citation practices. The aim is to increase the availability in the public domain of machine readable references metadata for case-law by sharing common services, a guided methodology and efficient solutions to recurrent problems in legal references extraction, that reduce the effort needed by national data providers to develop their own extraction solution.","llm_keywords":["natural language processing","legal references","case law databases","linked open data","legal information retrieval","ECLI","metadata","EU member States","citation practices","open source software"],"classifications":["Information Extraction","Resources"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":6},{"id":"a8d138f4ff9a72f9543ed840ed4f6b4dfba98c5c97fd8a836e41734245050b32e06cabbc59172043c8c6a43b23d2c42097527adc75279c173f292c1c99938f3e","file_path":"legal-nlp-survey-20250328-002/original/Leone_2019_0287.pdf","title":"Taking stock of legal ontologies: a feature-based comparative analysis","llm_title":"Taking stock of legal ontologies: a feature‑based comparative analysis","authors":["Valentina Leone","Luigi Di Caro","Serena Villata"],"llm_authors":"Valentina Leone, Luigi Di Caro, Serena Villata","author_string":"Valentina Leone","year":2019,"abstract":"","llm_abstract":"Ontologies represent the standard way to model the knowledge about specific domains. This holds also for the legal domain where several ontologies have been put forward to model specific kinds of legal knowledge. Both for standard users and for law scholars, it is often difficult to have an overall view on the existing alternatives, their main features and their interlinking with the other ontologies. To answer this need, in this paper, we address an analysis of the state-of-the-art in legal ontologies and we characterise them along with some distinctive features. This paper aims to guide generic users and law experts in selecting the legal ontology that better fits their needs and in understanding its specificity so that proper extensions to the selected model could be investigated.","llm_keywords":["Legal ontologies","Semantic web","Modelling legal knowledge"],"classifications":["Resources"],"num_cited_by":32,"num_cited_by_title_only":32,"num_pages":29},{"id":"ee5266c3f21d4845c8aeeb9bd8bb0060d7ab72226a82bdd1ec37a9fac9f7ed57ad5c5310c2e607b279fe7a7391f86051a6b7ba337af26f613a3ef55e93c4ca4d","file_path":"legal-nlp-survey-20250328-002/original/Chikkamath_2020_0302.pdf","title":"An Empirical Study on Patent Novelty Detection: A Novel Approach Using Machine Learning and Natural Language Processing","llm_title":"An Empirical Study on Patent Novelty Detection: A Novel Approach Using Machine Learning and Natural Language Processing","authors":["Renukswamy Chikkamath","Markus Endres","Lavanya Bayyapu","Christoph Hewel"],"llm_authors":"Renukswamy Chikkamath, Markus Endres, Lavanya Bayyapu, Christoph Hewel","author_string":"","year":2020,"abstract":"","llm_abstract":"Patent, a form of intellectual property often be in the first place when it comes to securing an invention. The legal boundaries created then will become key stages of turning an invention into a commercial product. In recent years, the unprecedented growth of patent applications has induced a great challenge to patent examiners. Novelty detection is one major step considered before and after filing a patent application to assure claimed inventions are new and non-obvious. This itself is considered as a salient stage of prior art search by patent applicants, patent examiners, patent attorneys, patent agent professionals. Management in terms of critical analysis of such a large scale of documents has become a challenge since missing an optimal, effective, and efficient system. To this end, we come up with a novel experimental case study to foster highly recursive and interactive tasks. We developed and investigated more than 50 machine learning models on the considered dataset. The contributions of this work include: (1) outlined and anticipated the importance of novelty detection in the patent domain, (2) develop various baseline models for novelty detection, (3) utilize immense contributions of deep learning towards NLP to improve baseline models, (4) assess the performance of every model by using different word embeddings like word2vec, glove, fasttext, and domain-specific embeddings, (5) a novel application of NBSVM algorithm on our dataset, and considered as exceptionally good of our models. We articulated the fulfillment of models using training and validation curves to prove seemingly negligible overfit or no overfit, in the hope that effective automation in novelty detection helps in driving down the routine prior art search efforts.","llm_keywords":["patent novelty","prior art","machine learning","deep learning","natural language processing","intellectual property"],"classifications":["Classification","Information Retrieval","Information Extraction"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":7},{"id":"a386ebf3f5c1928e026fdf80f40ca60170a90c98ed02201263cf213423570df244f456e5e8cfe32680493e21ed878483b2f18a3eabf2f2cec9bbccbb3daaa201","file_path":"legal-nlp-survey-20250328-002/original/Drawzeski_2021_0379.pdf","title":"A Corpus for Multilingual Analysis of Online Terms of Service","llm_title":"A Corpus for Multilingual Analysis of Online Terms of Service","authors":["Kasper Drawzeski","Andrea Galassi","Agnieszka Jablonowska","Francesca Lagioia","Marco Lippi","Hans Wolfgang Micklitz","Giovanni Sartor","Giacomo Tagiuri","Paolo Torroni"],"llm_authors":"Kasper Drazewski, Andrea Galassi, Agnieszka Jablonowska, Francesca Lagioia, Marco Lippi, Hans Wolfgang Micklitz, Giovanni Sartor, Giacomo Tagiuri, Paolo Torroni","author_string":"Kasper Drawzeski ; Andrea Galassi ; Agnieszka Jablonowska ; Francesca Lagioia ; Marco Lippi ; Hans Wolfgang Micklitz ; Giovanni Sartor ; Giacomo Tagiuri ; Paolo Torroni","year":2021,"abstract":"","llm_abstract":"We present the first annotated corpus for multilingual analysis of potentially unfair clauses in online Terms of Service. The data set comprises a total of 100 contracts, obtained from 25 documents annotated in four different languages: English, German, Italian, and Polish. For each contract, potentially unfair clauses for the consumer are annotated, for nine different unfairness categories. We show how a simple yet efficient annotation projection technique based on sentence embeddings could be used to automatically transfer annotations across languages.","llm_keywords":["multilingual analysis","Terms of Service","unfair clauses","annotation projection","sentence embeddings","consumer protection","linguistic resources","machine learning"],"classifications":["Information Extraction","Pre-Processing","Resources"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":8},{"id":"3c0c42afa176dd088a1303b2df4357942855610bbd4090dd22ac3de5a94fb7983123e9b4c2e7d10c1f4e0e99db5746df91fdd318cbda478b0104789982e66534","file_path":"legal-nlp-survey-20250328-002/original/Shounak_2022_0528.pdf","title":"A Heterogeneous Graph-based Approach for Automatic Legal Statute Identification from Indian Legal Documents","llm_title":"LeSICiN: A Heterogeneous Graph-based Approach for Automatic Legal Statute Identification from Indian Legal Documents","authors":["Shounak Paul","Pawan Goyal","Saptarshi Ghosh"],"llm_authors":"Shounak Paul, Pawan Goyal, Saptarshi Ghosh","author_string":"","year":2021,"abstract":"","llm_abstract":"The task of Legal Statute Identification (LSI) aims to identify the legal statutes that are relevant to a given description of facts or evidence of a legal case. Existing methods only utilize the textual content of facts and legal articles to guide such a task. However, the citation network among case documents and legal statutes is a rich source of additional information, which is not considered by existing models. In this work, we take the first step towards utilising both the text and the legal citation network for the LSI task. We curate a large novel dataset for this task, including facts of cases from several major Indian Courts of Law, and statutes from the Indian Penal Code (IPC). Modeling the statutes and training documents as a heterogeneous graph, our proposed model LeSICiN can learn rich textual and graphical features, and can also tune itself to correlate these features. Thereafter, the model can be used to inductively predict links between test documents (new nodes whose graphical features are not available to the model) and statutes (existing nodes). Extensive experiments on the dataset show that our model comfortably outperforms several state-of-the-art baselines, by exploiting the graphical structure along with textual features.","llm_keywords":["Legal Statute Identification","graph-based approach","Indian legal documents","heterogeneous graph","legal citation network"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":14,"num_cited_by_title_only":52,"num_pages":8},{"id":"a6065161cfef811f32cf7ff55e61a6e10b866551642bb82113e511fd7aaed2060b306202875795966c82d88e6b7d71c75fae051f8dfeffea23cd1e2176d94b11","file_path":"legal-nlp-survey-20250328-002/original/Bhattacharya_2021_0431.pdf","title":"","llm_title":"Incorporating Domain Knowledge for Extractive Summarization of Legal Case Documents","authors":["Paheli Bhattacharya","Soham Poddar","Koustav Rudra","Kripabandhu Ghosh","Saptarshi Ghosh"],"llm_authors":"Paheli Bhattacharya, Soham Poddar, Koustav Rudra, Kripabandhu Ghosh, Saptarshi Ghosh","author_string":"","year":2021,"abstract":"","llm_abstract":"Automatic summarization of legal case documents is an important and practical challenge. Apart from many domain-independent text summarization algorithms that can be used for this purpose, several algorithms have been developed specifically for summarizing legal case documents. However, most of the existing algorithms do not systematically incorporate domain knowledge that specifies what information should ideally be present in a legal case document summary. To address this gap, we propose an unsupervised summarization algorithm DELSumm which is designed to systematically incorporate guidelines from legal experts into an optimization setup. We conduct detailed experiments over case documents from the Indian Supreme Court. The experiments show that our proposed unsupervised method outperforms several strong baselines in terms of ROUGE scores, including both general summarization algorithms and legal-specific ones. In fact, though our proposed algorithm is unsupervised, it outperforms several supervised summarization models that are trained over thousands of document-summary pairs.","llm_keywords":["legal document summarization","extractive summarization","domain knowledge","unsupervised summarization","legal case documents","optimization","Indian Supreme Court","ROUGE scores"],"classifications":["Machine Summarization"],"num_cited_by":8,"num_cited_by_title_only":81,"num_pages":10},{"id":"7e5224b89e22685cb08889a55703bd998cd80a786b70ea4f808e83379e5fbb5c88255c962ef5d5fb9d84abe7df21a4bfb98d5702cc2e5727327bfb0f36b7bc1a","file_path":"legal-nlp-survey-20250328-002/original/Kruiper_2021_0467.pdf","title":"SPaR.txt, a Cheap Shallow Parsing Approach for Regulatory Texts","llm_title":"SPAR.txt, a cheap Shallow Parsing approach for Regulatory texts","authors":["Ruben Kruiper","Ioannis Konstas","Alasdair J.G. Gray","Farhad Sadeghineko","Richard Watson","Bimal Kumar"],"llm_authors":"Ruben Kruiper, Ioannis Konstas, Alasdair Gray, Farhad Sadeghineko, Richard Watson, Bimal Kumar","author_string":"Ruben Kruiper ; Ioannis Konstas ; Alasdair J.G. Gray ; Farhad Sadeghineko ; Richard Watson ; Bimal Kumar","year":2021,"abstract":"","llm_abstract":"Automated Compliance Checking (ACC) sys\u0002dtems aim to semantically parse building reg\u0002dulations to a set of rules. However, seman\u0002dtic parsing is known to be hard and requires large amounts of training data. The complex\u0002dity of creating such training data has led to re\u0002dsearch that focuses on small sub-tasks, such as shallow parsing or the extraction of a lim\u0002dited subset of rules. This study introduces a shallow parsing task for which training data is relatively cheap to create, with the aim of learning a lexicon for ACC. We annotate a small domain-specific dataset of 200 sen\u00002dtences, SPAR.txt1 , and train a sequence tag\u0002dger that achieves 79,93 F1-score on the test set. We then show through manual evaluation that the model identifies most (89,84%) de\u0002dfined terms in a set of building regulation doc\u0002duments, and that both contiguous and discon\u0002dtiguous Multi-Word Expressions (MWE) are discovered with reasonable accuracy (70,3%).","llm_keywords":["Automated Compliance Checking","Shallow parsing","Semantic parsing","Building regulations","Sequence tagging","Multi-Word Expressions","Regulatory texts","Information Extraction","Lexicon learning","Natural Language Processing"],"classifications":["Information Extraction","Pre-Processing"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":15},{"id":"9d48fe92b18a5ed92b462bd9634dd0500149b00e90d6636093263f37d847f4d62e1e0b938c30db351933f46be25bee31f02c7ffed70ac2566d8a12060f0660a2","file_path":"legal-nlp-survey-20250328-002/original/Castano_2019_0233.pdf","title":"187_Castano.pdf","llm_title":"Crime Knowledge Extraction: an Ontology-driven Approach for Detecting Abstract Terms in Case Law Decisions","authors":["Silvana Castano","Mattia Falduti","Alfo Ferrara","Stefano Montanelli"],"llm_authors":"Silvana Castano, Mattia Falduti, Alfo Ferrara, Stefano Montanelli","author_string":"","year":2019,"abstract":"","llm_abstract":"In this paper, we present CRIKE, a data-science approach to automatically detect concrete applications of legal abstract terms in case-law decisions. To this purpose, CRIKE relies on the use of the LATO ontology where legal abstract terms are properly formalized as concepts and relations among concepts. Using LATO, CRIKE aims at discovering how and where legal abstract terms are applied by judges in their legal argumentation. Moreover, we detect the terminology used in the text of case-law decisions to characterize concrete abstract-term instances. A case-study on a case-law decisions dataset provided by the Court of Milan, Italy, is also discussed.","llm_keywords":["legal ontology","legal-term extraction","case-law analysis","CRIKE","LATO ontology","abstract terms","legal argumentation"],"classifications":["Information Extraction","Classification"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":5},{"id":"8c6435e3fb8ab767543641a628a482efa1a4b5ccf816dab068d78b2e403ecd64dc41e818fb8f8cd54679023240b73de44dca61f003f3f40b05695748666c1210","file_path":"legal-nlp-survey-20250328-002/original/Mickevičius_2015_0056.pdf","title":"Classification of Short Legal Lithuanian Texts","llm_title":"Classification of Short Legal Lithuanian Texts","authors":["Vytautas Mickevicius","Tomas Krilavicius","Vaidas Morkevicius"],"llm_authors":"Vytautas Mickevicius, Tomas Krilavicius, Vaidas Morkevicius","author_string":"Vytautas Mickevicius ; Tomas Krilavicius ; Vaidas Morkevicius","year":2015,"abstract":"","llm_abstract":"Statistical analysis of parliamentary roll call votes is an important topic in political science because it reveals ideological positions of members of parliament (MP) and factions. However, it depends on the issues debated and voted upon. Therefore, analysis of carefully selected sets of roll call votes provides a deeper knowledge about MPs. However, in order to classify roll call votes according to their topic automatic text classifiers have to be employed, as these votes are counted in thousands. It can be formulated as a problem of classification of short legal texts in Lithuanian (classification is performed using only headings of roll call vote). We present results of an ongoing research on thematic classification of roll call votes of the Lithuanian Parliament. The problem differs significantly from the classification of long texts, because feature spaces are small and sparse, due to the short and formulaic texts. In this paper we investigate performance of 3 feature representation techniques (bag-of-words, n-gram and tf-idf) in combination with Support Vector Machines (with different kernels) and Multinomial Logistic Regression. The best results were achieved using tf-idf with SVM with linear and polynomial kernels.","llm_keywords":["parliamentary voting analysis","automatic text classification","Lithuanian Parliament","support vector machines","multinomial logistic regression"],"classifications":["Classification"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":6},{"id":"1cb3a992c13a96bfe2171ca7b3d4d561b5f77bc899cb2130fa0292f2595eec2582ecc440435eb34b258a745549932398f7cc43f3393ba3996b78da529b5d3073","file_path":"legal-nlp-survey-20250328-002/original/Munshi_2022_0494.pdf","title":"","llm_title":"Automated Islamic Jurisprudential Legal Opinions Generation Using Artificial Intelligence","authors":["Amr Abdullah Munshi","Wesam Hasan AlSabban","Abdullah Tarek Farag","Omar Essam Rakha","Ahmad Al Sallab","Majid Alotaibi"],"llm_authors":"Amr Abdullah Munshi, Wesam Hasan AlSabban, Abdullah Tarek Farag, Omar Essam Rakha, Ahmad Al Sallab, Majid Alotaibi","author_string":"","year":2022,"abstract":"","llm_abstract":"Islam is the second-largest and fastest-growing religion. The Islamic Law, Sharia, represents a profound component of the day-to-day lives of Muslims. While sources of Sharia are available for anyone, it often requires a highly qualified person, the Mufti, to provide Fatwa. With Islam followers representing almost 25% of the planet earth population, generating many queries, and the sophistication of the Mufti qualification process, creating a shortage in them, we have a supply-demand problem, calling for Automation solutions. This scenario motivates the application of Artificial Intelligence (AI) to Automated Islamic Fatwa in a scalable way that can adapt to various sources like social media. In this work, the potential of AI, Machine Learning, and Deep Learning, with technologies like Natural Language Processing (NLP), paving the way to help the Automation of Islam Fatwa are explored. The work started by surveying the State-of-The-Art (SoTA) of NLP and exploring the potential use-cases to solve the problems of Question answering and Text Classification in the Islamic Fatwa Automation. The first and major enabler component for AI application for Islamic Fatwa, the data were presented by building the largest dataset for Islamic Fatwa, spanning the widely used websites for Fatwa. Moreover, the baseline systems for Topic Classification, Topic Modeling, and Retrieval-based Question-Answering are presented to set the future research and benchmark on the dataset. Finally, the dataset is released and baselines to the public domain to help advance future research in the area.","llm_keywords":["Artificial intelligence","Islamic fatwa","machine learning","natural language processing","question answering","text classification"],"classifications":["Classification","Information Retrieval","Resources"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":22},{"id":"02ae3c8028fbc9e04b8075f15ce262d2d1514ed8795f14ab9ceaa2cd96a66c4442a13f21e1772686ca1a5ccaca7ffc627c5e3288ccba2b46e8cedf120d0b1551","file_path":"legal-nlp-survey-20250328-002/original/Hoppe_2021_0477.pdf","title":"Towards Intelligent Legal Advisors for Document Retrieval and Question-Answering in German Legal Documents","llm_title":"Towards Intelligent Legal Advisors for Document Retrieval and Question-Answering in German Legal Documents","authors":["Christoph Hoppe","David Pelkmann","Nico Migenda","Daniel Hotte","Wolfram Schenck"],"llm_authors":"Christoph Hoppe, David Pelkmann, Nico Migenda, Daniel Hotte, Wolfram Schenck","author_string":"Christoph Hoppe; David Pelkmann; Nico Migenda; Daniel Hotte; Wolfram Schenck","year":2022,"abstract":"","llm_abstract":"The legal system is one of the most important pillars of human society. While digitization is integrated into many areas of everyday life, the legal system is still very traditionally positioned. Recent advances in storing and processing large number of documents initiated the work of intelligent legal advisors. While first approaches in the English language suggest an enormous potential to generate knowledge from legal documents, there are no approaches in the German legal system. We present an intelligent legal advisor based on semantic document retrieval, to improve knowledge extraction from German legal documents. In addition, we set up a question-answering system. We implemented a BERT and a BM25-model for German document retrieval in legal documents. The approach is validated on a data set consisting of German question-answer pairs.","llm_keywords":["NLP","knowledge extraction","question-answering","semantic search","document retrieval","German language","legal documents","BERT","BM25"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":7,"num_cited_by_title_only":13,"num_pages":4},{"id":"8d578e25fb3f0f46e2686a2e94368af37d57ce19d67ae47a4704aa866a810e691f86f36e8f7733bb7fe3c04431d95e6f4e8c2f1320d7d20090df9ea947f76215","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2021_0449.pdf","title":"","llm_title":"MultiEURLEX – A multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer","authors":["Ilias Chalkidis","Manos Fergadiotis","Ion Androutsopoulos"],"llm_authors":"Ilias Chalkidis, Manos Fergadiotis, Ion Androutsopoulos","author_string":"","year":2022,"abstract":"","llm_abstract":"We introduce MULTI-EURLEX, a new multilingual dataset for topic classification of legal documents. The dataset comprises 65k European Union (EU) laws, officially translated in 23 languages, annotated with multiple labels from the EUROVOC taxonomy. We highlight the effect of temporal concept drift and the importance of chronological, instead of random splits. We use the dataset as a testbed for zero-shot cross-lingual transfer, where we exploit annotated training documents in one language (source) to classify documents in another language (target). We find that fine-tuning a multilingually pretrained model (XLM-ROBERTA, MT5) in a single source language leads to catastrophic forgetting of multilingual knowledge and, consequently, poor zero-shot transfer to other languages. Adaptation strategies, namely partial fine-tuning, adapters, BITFIT, LNFIT, originally proposed to accelerate fine-tuning for new end-tasks, help retain multilingual knowledge from pretraining, substantially improving zero-shot cross-lingual transfer, but their impact also depends on the pretrained model used and the size of the label set.","llm_keywords":["multilingual learning","legal document classification","zero-shot transfer","cross-lingual transfer","EU laws","EUROVOC taxonomy","transformer models","adaptation strategies","temporal concept drift"],"classifications":["Classification","Resources"],"num_cited_by":3,"num_cited_by_title_only":115,"num_pages":23},{"id":"92f6945271cc83938baa2ada91c03d21bb523e7b89add01807201736841b24b40c6ea05ed08740ded8dd886b6d1a3f5e5544d7cd2f5e16c62bebc10f26316036","file_path":"legal-nlp-survey-20250328-002/original/Bordino_2021_0423.pdf","title":"GarNLP: A Natural Language Processing Pipeline for Garnishment Documents","llm_title":"GarNLP: A Natural Language Processing Pipeline for Garnishment Documents","authors":["Ilaria Bordino","Andrea Ferretti","Francesco Gullo","Stefano Pascolutti"],"llm_authors":"Ilaria Bordino, Andrea Ferretti, Francesco Gullo, Stefano Pascolutti","author_string":"Ilaria Bordino","year":2020,"abstract":"","llm_abstract":"Basic elements of the law, such as statuses and regulations, are embodied in natural language, and strictly depend on linguistic expressions. Hence, analyzing legal contents is a challenging task, and the legal domain is increasingly looking for automatic-processing support. This paper focuses on a specific context in the legal domain, which has so far remained unexplored: automatic processing of garnishment documents. A garnishment is a legal procedure by which a creditor can collect what a debtor owes by requiring to confiscate a debtor’s property (e.g., a checking account) that is hold by a third party, dubbed garnishee. Our proposal, motivated by a real-world use case, is a versatile natural-language-processing pipeline to support a garnishee in the processing of a large-scale flow of garnishment documents. In particular, we mainly focus on two tasks: (i) categorize received garnishment notices onto a predefined taxonomy of categories; (ii) perform an information-extraction phase, which consists in automatically identifying from the text various information, such as identity of involved actors, amounts, and dates. The main contribution of this work is to describe challenges, design, implementation, and performance of the core modules and methods behind our solution. Our proposal is a noteworthy example of how data-science techniques can be successfully applied to a novel yet challenging real-world context.","llm_keywords":["Applied data science","Natural language processing","Legal documents","Garnishment","Categorization","Information extraction","Supervised learning","Word embeddings","Named entity recognition"],"classifications":["Classification","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":14},{"id":"9edc8ecf9ff81ee713da370253d8fd76cfc3f9d5378f70fab7e40b56a4ad7cc31fe094e5b410c628b2789f9008e2bc7963676113320a0d1e254aec335534a30f","file_path":"legal-nlp-survey-20250328-002/original/van-de-Luijtgaarden_2019_0227.pdf","title":"","llm_title":"Automatic Summarization of Legal Text","authors":["N. van de Luijtgaarden","M.P. Schraagen","A.L. Lamprecht","R.W. Lucas"],"llm_authors":"N. van de Luijtgaarden, M.P. Schraagen, A.L. Lamprecht, R.W. Lucas","author_string":"","year":2019,"abstract":"","llm_abstract":"With the legal sector embracing digitalization, the increasing availability of information has led to a need for systems that can automatically summarize one or more documents. Current research on legal text summarization has only focused on extractive methods, which can result in awkward summaries as sentences in legal documents can be very long and detailed. In this study, we argue that due to more data being available, improved hardware and matured algorithms, the time is now right for using abstractive summarization models in the legal field. The main goal of this thesis is to discuss how we can best apply an abstractive summarization model on a legal domain dataset. A five-phased approach was used to evaluate generated summaries based on ROUGE score, abstractiveness and through a human evaluation experiment using law graduates. ROUGE results of our experiments are comparable to state-of-the-art studies that made use of the CNN/Daily Mail dataset. Experiments show that the model excels in rewriting the long and redundant legal sentences to much shorter ones, but does not generate many new words compared to the input document. However, the conducted human evaluation showed that not all elements needed in a summary (background, considerations, judgement) were always present together in a generated summary, and that reference summaries got better relevance scores. Still, students observed that generated summaries did contain key information about cases and preferred it to using reference summaries that only contain keywords. Through this study, we argue that there is a lot of potential for abstractive summarization in the legal field. The quality is not on the same level as the reference summaries, but it can function as a good replacement for reference summaries that only contain keywords. For improving relevance in the generated summaries, an implementation of a network that can recognize the three core elements of a case is needed. For readability, additional post-processing in the decoding function can help recognize when sentences are cut off too early. In general, we also doubt whether ROUGE is still a good metric for evaluating abstractive summarization models, as there exists an inverse relationship between the ROUGE score and the abstractiveness of a document.","llm_keywords":["legal text summarization","digitalization","abstractive summarization","extractive methods","ROUGE score","human evaluation","deep learning","natural language processing"],"classifications":["Machine Summarization"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":65},{"id":"26d30b281cb772534ebb853ca39e66b9da7d08775f126e2cf837a33b0334fec2e370bf2cdf3f26ee1f380a77b7c6f4155d6bedc8ff44be03b52eba61e4b339ac","file_path":"legal-nlp-survey-20250328-002/original/Bouhoula_2022_0581.pdf","title":"","llm_title":"Automated Detection of GDPR Violations in Cookie Notices Using Machine Learning","authors":["Ahmed Bouhoula"],"llm_authors":"Bouhoula, Ahmed","author_string":"","year":2022,"abstract":"","llm_abstract":"Privacy regulations such as the General Data Protection Regulation require websites to inform EU-based users of the collection of their data and to request their consent to use non-essential cookies. This led to a global adaptation of cookie notices. Several studies showed that websites’ implementation of cookie notices tends to violate these regulations. However, most of these studies focused on a limited subset of websites, detected only simple violations using prescribed patterns, or restricted their analysis to only the first layer of cookie notices. This master’s thesis addresses these limitations. Our method automatically navigates through cookie notices using several heuristics, extracts their text, observes declared processing purposes and available consent options with Natural Language Processing, and analyzes websites’ cookies. We find that 47% of websites are highly susceptible of collecting users’ data despite negative consent, and that around 61% of cookie notices do not offer users the option to opt-out of consent.","llm_keywords":["GDPR","cookie notices","machine learning","privacy regulations","consent options","natural language processing","data collection","web compliance"],"classifications":["Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":50},{"id":"e53a22f5bec70ebb5c86401cf56a787261bcad0974423eef216b6f3e677299e19ec2868ea2198ed26ee01fd68609f9fb7345a5a14c511474990288fcfe35a327","file_path":"legal-nlp-survey-20250328-002/original/Andersson_2013_0008.pdf","title":"","llm_title":"Domain Adaptation of General Natural Language Processing Tools for a Patent Claim Visualization System","authors":["Linda Andersson","Mihai Lupu","Allan Hanbury"],"llm_authors":"Linda Andersson, Mihai Lupu, and Allan Hanbury","author_string":"","year":2013,"abstract":"","llm_abstract":"In this study we present a first step towards domain adaptation of Natural Language Processing (NLP) tools, which we use in a pipeline for a system to create a dependency claim graph (DCG). Our system takes advantage of patterns occurring in the patent domain notably of the characteristic of patent claims of containing technical terminology combined with legal rhetorical structure. Such patterns make the sentences generally difficult to understand for people, but can be leveraged by our system to assist the cognitive process of understanding the innovation described in the claim. We present this set of patterns, together with an extensive evaluation showing that the results are, even for this relatively difficult genre, at least 90% correct, as identified by both expert and non-expert users. The assessment of each generated DCG is based upon completeness, connection and a set of pre-defined relations.","llm_keywords":["Graph visualization","domain adaptation","Natural Language Processing","patent claims","dependency claim graph"],"classifications":["Pre-Processing","Information Extraction","Resources"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":18},{"id":"8a8a8ea3f88f14711c39e14d8bcb40c60d8f90b7cfbc21241aa9b60b83ac0d825c6ab4381b9cfec157339f5508edd06bfc9527e4fe55cb93a6073a31e6fa0777","file_path":"legal-nlp-survey-20250328-002/original/Panagis_2017_0128.pdf","title":"","llm_title":"Giving Every Case Its (Legal) Due: The Contribution of Citation Networks and Text Similarity Techniques","authors":["Yannis Panagis","Urska Sadl","Fabien Tarissan"],"llm_authors":"Yannis PANAGIS, Urska ˇ SADL, and Fabien TARISSAN","author_string":"","year":2017,"abstract":"","llm_abstract":"In this article we propose a novel methodology, which uses text similarity techniques to infer precise citations from the judgments of the Court of Justice of the European Union (CJEU), including their content. We construct a complete network of citations to judgments on the level of singular text units or paragraphs. By contrast to previous literature, which takes into account only explicit citations of entire judgments, we also infer implicit citations, meaning the repetitions of legal arguments stemming from past judgments without explicit reference. On this basis we can differentiate between different categories and modes of citations. The latter is crucial for assessing the actual legal importance of judgments in the citation network. Our study is an important methodological step forward in integrating citation network analysis into legal studies, which significantly enhances our understanding of European Union law and the decision making of the CJEU.","llm_keywords":["Network analysis","Citation networks","Text similarity","CJEU","Legal Studies","European Union Law","Implicit citations"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":10},{"id":"dee2290c538eeade0ff1eef5a19e2546581ea5b34ae99f99091ee3ec5920944dac7146f879bb9ff6301a473723afcad0288aa6243e15996ab7b3a4a6103fa9a6","file_path":"legal-nlp-survey-20250328-002/original/Gamage_2018_0179.pdf","title":"Fast Approach to Build an Automatic Sentiment Annotator for Legal Domain using Transfer Learning","llm_title":"Fast Approach to Build an Automatic Sentiment Annotator for Legal Domain using Transfer Learning","authors":["Viraj Salaka Gamage","Menuka Warushavithana","Nisansa de Silva","Amal Shehan Perera","Gathika Ratnayaka","Thejan Rupasinghe"],"llm_authors":"Viraj Salaka Gamage, Menuka Warushavithana, Nisansa de Silva, Amal Shehan Perera, Gathika Ratnayaka, Thejan Rupasinghe","author_string":"Viraj Salaka ; Menuka Warushavithana ; Nisansa de Silva ; Amal Shehan Perera ; Gathika Ratnayaka ; Thejan Rupasinghe","year":2018,"abstract":"","llm_abstract":"This study proposes a novel way of identifying the sentiment of the phrases used in the legal domain. The added complexity of the language used in law, and the inability of the existing systems to accurately predict the sentiments of words in law are the main motivations behind this study. This is a transfer learning approach which can be used for other domain adaptation tasks as well. The proposed methodology achieves an improvement of over 6% compared to the source model’s accuracy in the legal domain.","llm_keywords":["sentiment analysis","transfer learning","legal domain","Recursive Neural Tensor Network","domain adaptation","sentiment classification","legal texts","natural language processing"],"classifications":["Classification"],"num_cited_by":7,"num_cited_by_title_only":10,"num_pages":6},{"id":"6b75febc501e4316f63ca891cb0683d0bed8bc9eb8e81a84acd3426d7407d15a17568260dd389126131956dc2dff0e027df70550d9fe627bde27b41a2dec3951","file_path":"legal-nlp-survey-20250328-002/original/Trompper_2016_0082.pdf","title":"","llm_title":"Automatic Assignment of Section Structure to Texts of Dutch Court Judgments","authors":["Maarten Trompper","Radboud Winkels"],"llm_authors":"Maarten Trompper and Radboud Winkels","author_string":"","year":2017,"abstract":"","llm_abstract":"A growing number of Dutch court judgments is openly distributed on Rechtspraak.nl. Currently, many documents are not marked up or marked up only very sparsely, hampering our ability to process these documents automatically. In this paper, we explore the problem of automatic assignment of a section structure to these texts. We experiment with Linear-Chain Conditional Random Fields to label text elements with their roles in the document (text, title or numbering). In this sub-task, we report F1 scores of around 0.91 for tagging section titles, and around 1.0 for the other types. Given a list of labels, we experiment with Probabilistic Context-Free Grammars to generate a parse tree which represents the section hierarchy of a document. In this task, we report an F1 score of 0.92.","llm_keywords":["Automatic Markup","Conditional Random Fields","Probabilistic Context-Free Grammars","Court Judgments","Semantic Markup","Text Processing","Legal Documents","Dutch Judgments","Rechtspraak.nl"],"classifications":["Pre-Processing","Classification","Text Generation"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":7},{"id":"5af0769671175c998b4c9320f4c82a73e6deee9a065637a18d8cba074ce7df5a39afcc2afe388009370a77c6ab41c0220fe0eec2b8ae64eff840fcffefbce768","file_path":"legal-nlp-survey-20250328-002/original/Vu_2019_0265.pdf","title":"","llm_title":"Legal Text Generation from Abstract Meaning Representation","authors":["Sinh Trong Vu","Minh Le Nguyen","Ken Satoh"],"llm_authors":"Sinh Trong Vu, Minh Le Nguyen, Ken Satoh","author_string":"","year":2019,"abstract":"","llm_abstract":"Generating from Abstract Meaning Representation (AMR) is a non-trivial problem, as many syntactic decisions are not constrained by the semantic graph. Current deep learning approaches in AMR generation almost depend on a large amount of “silver data” in general domains. While the text in the legal domain is often structurally complicated, and contain specific terminologies that are rarely seen in training data, making text generated from those deep learning models usually become awkward with lots of “out of vocabulary” tokens. In our paper, we propose some modifications in the training and decoding phase of the state of the art AMR generation model to have a better text realization. Our model is tested using a human-annotated legal dataset, showing an improvement compared to the baseline model.","llm_keywords":["AMR Generation","Deep Learning","Legal Text","Semantic Annotation","Natural Language Processing","Graph-to-sequence Model","Legal Domain","Out of Vocabulary Tokens","Negation Sentences","Conditional Sentences"],"classifications":["Text Generation","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"f69b3f017a69619d2fb6495c756f85e3cb01e7e97e2751a0df41bebb70a20e8e5a919d30f741e0e0e0659c1ffb147550b4997220863ee7d7cc17b437d3592456","file_path":"legal-nlp-survey-20250328-002/original/Holzenberger_2020_0298.pdf","title":"A Dataset for Statutory Reasoning in Tax Law Entailment and Question Answering","llm_title":"A Dataset for Statutory Reasoning in Tax Law Entailment and Question Answering","authors":["Nils Holzenberger","Andrew Blair-Stanek","Benjamin Van Durme"],"llm_authors":"Nils Holzenberger, Andrew Blair-Stanek, Benjamin Van Durme","author_string":"Nils Holzenberger, Andrew Blair-Stanek, and Benjamin Van Durme","year":2020,"abstract":"","llm_abstract":"Legislation can be viewed as a body of prescriptive rules expressed in natural language. The application of legislation to facts of a case we refer to as statutory reasoning, where those facts are also expressed in natural language. Computational statutory reasoning is distinct from most existing work in machine reading, in that much of the information needed for deciding a case is declared exactly once (a law), while the information needed in much of machine reading tends to be learned through distributional language statistics. To investigate the performance of natural language understanding approaches on statutory reasoning, we introduce a dataset, together with a legal-domain text corpus. Straightforward application of machine reading models exhibits low out-of-the-box performance on our questions, whether or not they have been fine-tuned to the legal domain. We contrast this with a hand-constructed Prolog-based system, designed to fully solve the task. These experiments support a discussion of the challenges facing statutory reasoning moving forward, which we argue is an interesting real-world task that can motivate the development of models able to utilize prescriptive rules specified in natural language.","llm_keywords":["Law","NLP","Reasoning","Prolog","Statutory reasoning","Tax law","Question answering","Machine reading","Natural language processing","Knowledge representation"],"classifications":["Resources"],"num_cited_by":81,"num_cited_by_title_only":81,"num_pages":8},{"id":"ddeaa1203085c8b5982a33f7b31cdde22c954f9be3320716f6f35332b6d03a4d451a6164a058b76a40975984d073a36ac07c238dfa7586711c2796770b31ca86","file_path":"legal-nlp-survey-20250328-002/original/Begum_2021_0389.pdf","title":"Analysis of Legal Case Document Automated Summarizer","llm_title":"Analysis of Legal Case Document Automated Summarizer","authors":["Naimoonisa Begum","Ankur Goyal"],"llm_authors":"Naimoonisa Begum, Ankur Goyal","author_string":"Naimoonisa Begum; Ankur Goyal","year":2021,"abstract":"","llm_abstract":"The Legal case documents available after judgements are lengthy in size and need to be summarized for future reference by the legal experts, professionals and clients who need help for reference to similar cases. In the Common Law system of India, the legal case documents summary is done manually by specially appointed legal attorneys and is referred to as Gold Summaries. This process is time consuming as the legal case documents are very voluminous in size. We endeavor the survey of different automated legal domain based automated summarization techniques using artificial intelligence. We try to compare some extraction based legal case documents summarizers. The paper initiates with general introduction to legal domain text summarization techniques, different metrics to measure the performance of automated summaries generated by various legal domain-based text summarization methodologies. The conclusion finally suggests some directions for future research.","llm_keywords":["Text-based summarization","Evaluation metrics","Legal-domain text-based summarization","Artificial Intelligence","Common Law system","Legal case documents","Automated summarization","Extractive summarization","Abstractive summarization"],"classifications":["Machine Summarization"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":6},{"id":"6f2e9f6cdbe300967c6eab55137af07fab0712a873579f201c642ec019dc8aec7d9c47ac945e6193eec70fcd0fe10f21780bd1c6b3dc71007c3b2ae2afe42baf","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2020_0345.pdf","title":"LEGAL-BERT: The Muppets straight out of Law School","llm_title":"LEGAL-BERT: The Muppets straight out of Law School","authors":["Ilias Chalkidis","Manos Fergadiotis","Prodromos Malakasiotis","Nikolaos Aletras","Ion Androutsopoulos"],"llm_authors":"Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, Ion Androutsopoulos","author_string":"Ilias Chalkidis ; Manos Fergadiotis ; Prodromos Malakasiotis ; Nikolaos Aletras ; Ion Androutsopoulos","year":2020,"abstract":"","llm_abstract":"BERT has achieved impressive performance in several NLP tasks. However, there has been limited investigation on its adaptation guidelines in specialised domains. Here we focus on the legal domain, where we explore several approaches for applying BERT models to downstream legal tasks, evaluating on multiple datasets. Our findings indicate that the previous guidelines for pre-training and fine-tuning, often blindly followed, do not always generalize well in the legal domain. Thus we propose a systematic investigation of the available strategies when applying BERT in specialised domains. These are: (a) use the original BERT out of the box, (b) adapt BERT by additional pre-training on domain-specific corpora, and (c) pre-train BERT from scratch on domain-specific corpora. We also propose a broader hyper-parameter search space when fine-tuning for downstream tasks and we release LEGAL-BERT, a family of BERT models intended to assist legal NLP research, computational law, and legal technology applications.","llm_keywords":["BERT","Legal domain","NLP","Pre-training","Fine-tuning","Domain adaptation","LEGAL-BERT","Transformer models"],"classifications":["Resources"],"num_cited_by":999,"num_cited_by_title_only":999,"num_pages":7},{"id":"563e55280acccd2277475faa3aa5601f2b3324b97cb92b99689a6a2efb63c069baf0697305e34036ea64fba036e53b8345c400da95b150735c0e45701bec0a4c","file_path":"legal-nlp-survey-20250328-002/original/Mok_2019_0261.pdf","title":"201_Mok.pdf","llm_title":"Legal Machine-Learning Analysis: First Steps towards A.I. Assisted Legal Research","authors":["Wai Yin Mok","Jonathan R. Mok"],"llm_authors":"Wai Yin Mok, Jonathan R. Mok","author_string":"","year":2019,"abstract":"","llm_abstract":"","llm_keywords":["machine learning","legal research","contract law","natural language processing","ontology","court decisions","precedent analysis","case law","spaCy"],"classifications":[],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":2},{"id":"7e2ec509eb29388939b42ee1f84e21053662d4da77083920ac695b44df43581a0ac7ccbe47be2d66fffe64bf508f9040b9d52b5ed48118f4dd2f8daf08dd6e1f","file_path":"legal-nlp-survey-20250328-002/original/Bhattacharya_2019_0209.pdf","title":"A Comparative Study of Summarization Algorithms Applied to Legal Case Judgments","llm_title":"A Comparative Study of Summarization Algorithms Applied to Legal Case Judgments","authors":["Paheli Bhattacharya","Kaustubh Hiware","Subham Rajgaria","Nilay Pochhi","Kripabandhu Ghosh","Saptarshi Ghosh"],"llm_authors":"Paheli Bhattacharya, Kaustubh Hiware, Subham Rajgaria, Nilay Pochhi, Kripabandhu Ghosh, Saptarshi Ghosh","author_string":"Paheli Bhattacharya","year":2019,"abstract":"","llm_abstract":"Summarization of legal case judgments is an important problem because the huge length and complexity of such documents make them difficult to read as a whole. Many summarization algorithms have been proposed till date, both for general text documents and a few specifically targeted to summarizing legal documents of various countries. However, to our knowledge, there has not been any systematic comparison of the performances of different algorithms in summarizing legal case documents. In this paper, we perform the first such systematic comparison of summarization algorithms applied to legal judgments. We experiment on a large set of Indian Supreme Court judgments, and a large variety of summarization algorithms including both unsupervised and supervised ones. We assess how well domain-independent summarization approaches perform on legal case judgments, and how approaches specifically designed for legal case documents of other countries (e.g., Canada, Australia) generalize to Indian Supreme Court documents. Apart from quantitatively evaluating summaries by comparing with gold standard summaries, we also give important qualitative insights on the performance of different algorithms from the perspective of a law expert.","llm_keywords":["Summarization","Legal case judgment","Supervised","Unsupervised","Indian Supreme Court","Algorithm comparison","Domain-independent summarization","Legal text summarization"],"classifications":["Machine Summarization"],"num_cited_by":160,"num_cited_by_title_only":160,"num_pages":16},{"id":"4b04580d9423007a3c093b60939cdac64a45f6076242bfc7e8376fda386a7e08e458527420b716e345f272c373cad2b48d5d081a51973dbbf9c5960af0522683","file_path":"legal-nlp-survey-20250328-002/original/Sancheti_2022_0563.pdf","title":"","llm_title":"What to Read in a Contract? Party-Specific Summarization of Important Obligations, Entitlements, and Prohibitions in Legal Documents","authors":["Abhilasha Sancheti","Aparna Garimella","Balaji Vasan Srinivasan","Rachel Rudinger"],"llm_authors":"Abhilasha Sancheti, Aparna Garimella, Balaji Vasan Srinivasan, Rachel Rudinger","author_string":"","year":2022,"abstract":"","llm_abstract":"Legal contracts, such as employment or lease agreements, are important documents as they govern the obligations and entitlements of the various contracting parties. However, these documents are typically long and written in legalese resulting in lots of manual hours spent in understanding them. In this paper, we address the task of summarizing legal contracts for each of the contracting parties, to enable faster reviewing and improved understanding of them. Specifically, we collect a dataset consisting of pairwise importance comparison annotations by legal experts for ∼ 293K sentence pairs from lease agreements. We propose a novel extractive summarization system to automatically produce a summary consisting of the most important obligations, entitlements, and prohibitions in a contract. It consists of two modules: (1) a content categorizer to identify sentences containing each of the categories (i.e., obligation, entitlement, and prohibition) for a party, and (2) an importance ranker to compare the importance among sentences of each category for a party to obtain a ranked list. The final summary is produced by selecting the most important sentences of a category for each of the parties. We demonstrate the effectiveness of our proposed system by comparing it against several text ranking baselines via automatic and human evaluation.","llm_keywords":["legal contracts","summarization","obligations","entitlements","prohibitions","extractive summarization","content categorizer","importance ranker","legal domain","TL;DRLegal"],"classifications":["Machine Summarization","Classification","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":16},{"id":"517ed0f0698a64948f0c555e1ffc5a8f553824ca2f93053af00875b2a3b41cf495aa36ffe008b47070fba1571a6be1ffd2e0b3482e24eccaae60756fb4b4daf1","file_path":"legal-nlp-survey-20250328-002/original/Tian_2018_0183.pdf","title":"","llm_title":"K-means Clustering for Controversial Issues Merging in Chinese Legal Texts","authors":["Xin Tian","Yin Fang","Yang Weng","Yawen Luo","Huifang Cheng","Zhu Wang"],"llm_authors":"Xin Tian, Yin Fang, Yang Weng, Yawen Luo, Huifang Cheng, Zhu Wang","author_string":"","year":2018,"abstract":"","llm_abstract":"In the face of a growing number of cases, Chinese courts have gradually formed a trial mode to improve the efficiency of trials by conducting trials around the controversial issues. However, identifying the controversy issue in specific cases is not only affected by the uncertainty of facts and laws, but also by the discretion of the judges and extra-case factors, and cannot be expressed as a standard format, which lead to the controversial issues based case retrieval a challenging problem. In this paper, we propose a controversial issues merging algorithm based on K-means clustering for Chinese legal texts. The proposed algorithm can determine the number of clusters of the given cause of action automatically and merge the controversial issues semantically, which makes the case information retrieval more accurate and effective.","llm_keywords":["information retrieval","K-means clustering","controversial issues","Chinese legal texts","machine learning","semantic vectorization","unsupervised learning","factual issues","legal issues"],"classifications":["Information Retrieval"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":5},{"id":"40e5043f26438873979cb385ce275aecf9baacb069faed2b6fe3fc201f0cdfc2bc02289928843b0623f48978cdc4cbeff65c5c9802e3cd69eb0585cbbc8ba02b","file_path":"legal-nlp-survey-20250328-002/original/Petrova_2020_0324.pdf","title":"","llm_title":"Extracting Outcomes from Appellate Decisions in US State Courts","authors":["Alina Petrova","John Armour","Thomas Lukasiewicz"],"llm_authors":"Alina PETROVA, John ARMOUR, Thomas LUKASIEWICZ","author_string":"","year":2020,"abstract":"","llm_abstract":"Predicting the outcome of a legal process has recently gained considerable research attention. Numerous attempts have been made to predict the exact outcome, judgment, charge, and fines of a case given the textual description of its facts and metadata. However, most of the effort has been focused on Chinese and European law, for which there exist annotated datasets. In this paper, we introduce CASELAW4 — a new dataset of 350k common law judicial decisions from the U.S. Caselaw Access Project, of which 250k have been automatically annotated with binary outcome labels of AFFIRM or REVERSE by our hybrid learning system. To our knowledge, it is the first attempt to perform outcome extraction (a) on such a large volume of English-language judicial opinions, (b) on the Caselaw Access Project data, and (c) on US State Courts of Appeal cases, and it paves the way to large-scale outcome prediction and advanced legal analytics using U.S. Case Law. We set up baseline results for the outcome extraction task on the new dataset, achieving an F-measure of 82.32%.","llm_keywords":["legal analytics","outcome extraction","legal reasoning","outcome prediction","US Case Law"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":10},{"id":"ca27e85b14a27d3f1d8011c76e1bd069adc245acf4aaad4048160d1dce0bbc0180ac55819a14b8f69bd80a2a95220e4666c73d0063a24270553dcd2dbd6c0ca7","file_path":"legal-nlp-survey-20250328-002/original/Wehnert_2019_0239.pdf","title":"","llm_title":"ERST: Leveraging Topic Features for Context-Aware Legal Reference Linking","authors":["Sabine Wehnert","Gabriel Campero Durand","Gunter Saake"],"llm_authors":"Sabine WEHNERT, Gabriel CAMPERO DURAND and Gunter SAAKE","author_string":"","year":2019,"abstract":"","llm_abstract":"As legal regulations evolve, companies and organizations are tasked with quickly understanding and adapting to regulation changes. Tools like legal knowledge bases can facilitate this process, by either helping users navigate legal information or become aware of potentially relevant updates. At their core, these tools require legal references from many sources to be unified, e.g., by legal entity linking. This is challenging since legal references are often implicitly expressed, or combined via a context. In this paper, we prototype a machine learning approach to link legal references and retrieve combinations for a given context, based on standard features and classifiers, as used in entity resolution. As an extension, we evaluate an enhancement of those features with topic vectors, aiming to capture the relevant context of the passage containing a reference. We experiment with a repository of authoritative sources on German law for building topic models and extracting legal references and report that topic models do indeed contribute in improving supervised entity linking and reference retrieval.","llm_keywords":["reference linking","entity resolution","topic models","information retrieval","legal regulations","machine learning","context-aware","German law"],"classifications":["Classification","Information Extraction","Information Retrieval"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":10},{"id":"bd08af5ac8e2511b26c98ff1ece669ca3e64313f67e1ff512dfc67435a7b5b122524224406687398620717ba9ab4a484363c814bdb6f70c8e30a1fd5c49c3e59","file_path":"legal-nlp-survey-20250328-002/original/Shen_2018_0187.pdf","title":"Microsoft Word - CSAE23286","llm_title":"Legal Article-Aware End-To-End Memory Network for Charge Prediction","authors":["Yatian Shen","Jun Sun","Xiaopeng Li","Lei Zhang","Yan Li","Xiajiong Shen"],"llm_authors":"Yatian Shen, Jun Sun, Xiaopeng Li, Lei Zhang, Yan Li, Xiajiong Shen","author_string":"Administrator","year":2018,"abstract":"","llm_abstract":"The1 task of charge prediction is to decide accurate charges for a given case of crime. The relevant law texts play an important role in the work of charge prediction, and therefore we used an end-to-end memory network to perform the charge prediction. We combine the supportive law articles from the statutory laws and regulations with the large external memory, which can be trained without requiring significantly more supervision. Several experimental results demostrate that neural networks taking the Position Embeddings (pF), Part-of-speech tag Embeddings (POSF), the WordNet (WN) and bigram information as input can get better result than previous other methods.","llm_keywords":["Charge prediction","End-to-end memory network","Neural network","Deep learning","Legal assistant systems","Text classification","Supportive law articles","Law texts","Machine intelligence","External memory"],"classifications":["Classification"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":5},{"id":"0c1ddcbd2ace8dd95ffdab22fe735e7afe560c0a8d5b642b9b622630959e2332144bf5d6e63f57619a63963add9e218b5599bfe8355a499d1d079c2147adcd67","file_path":"legal-nlp-survey-20250328-002/original/Correia_2022_0510.pdf","title":"Fine-grained legal entity annotation: A case study on the Brazilian Supreme Court","llm_title":"Fine-grained legal entity annotation: A case study on the Brazilian Supreme Court","authors":["Fernando Correia","Alexandre Almeida","José Nunes","Kaline Santos","Ivar Hartmann","Felipe Silva","Hélio Lopes"],"llm_authors":"Fernando A. Correia, Alexandre A.A. Almeida, José Luiz Nunes, Kaline G. Santos, Ivar A. Hartmann, Felipe A. Silva, Hélio Lopes","author_string":"Fernando A. Correia","year":2021,"abstract":"","llm_abstract":"The exploration of legal documents in the Brazilian Judiciary context lacks reliable annotated corpus to support the development of new Natural Language Process (NLP) applications. Therefore, this paper presents a step toward exploring legal decisions with Named Entity Recognition (NER) in the Brazilian Supreme Court (STF) context. We aim to present a case study on the fine-grained annotation task of legal decisions, performed by law students as annotators where two levels of nested legal entities were annotated. Nested entities mapped in a preliminary study composed of four coarser legal named entities and twenty-four nested ones (fine-grained). The final result is a corpus of 594 decisions published by the STF annotated by the 76 law students, those with the highest average inter-annotator agreement score. We also present two baselines for NER based on Conditional Random Fields (CRFs) and Bidirectional Long-Short Term Memory Networks (BiLSTMs). This corpus is the first of its kind, the most extensive corpus known in Portuguese dedicated for legal named entity recognition, open and available to better support further research studies in a similar context.","llm_keywords":["Named Entity Recognition","Legal documents","Manual annotation task","Annotated corpus in Portuguese","Brazilian Supreme Court"],"classifications":["Information Extraction","Resources"],"num_cited_by":3,"num_cited_by_title_only":33,"num_pages":21},{"id":"0537b85e4798fb7f94e35ebc332ec9b65a34544d7183aacd63e87a6d81678039a6d3b8c984c904aff7c6e30585c5496254fa126bc9f5a4b2ec8e983868490903","file_path":"legal-nlp-survey-20250328-002/original/Kore_2020_0340.pdf","title":"","llm_title":"Legal Document Summarization Using Nlp and Ml Techniques","authors":["Rahul Kore","Prachi Ray","Priyanka Lade","Amit Nerurkar"],"llm_authors":"Rahul C Kore, Prachi Ray, Priyanka Lade, Amit Nerurkar","author_string":"IJETAE","year":2020,"abstract":"","llm_abstract":"Reading legal documents are tedious and sometimes it requires domain knowledge related to that document. It is hard to read the full legal document without missing the key important sentences. With increasing number of legal documents it would be convenient to get the essential information from the document without having to go through the whole document. The purpose of this study is to understand a large legal document within a short duration of time. Summarization gives flexibility and convenience to the reader. Using vector representation of words, text ranking algorithms, similarity techniques, this study gives a way to produce the highest ranked sentences. Summarization produces the result in such a way that it covers the most vital information of the document in a concise manner. The paper proposes how the different natural language processing concepts can be used to produce the desired result and give readers the relief from going through the whole complex document. This study definitively presents the steps that are required to achieve the aim and elaborates all the algorithms used at each and every step in the process.","llm_keywords":["Natural Language Processing","Word Embeddings","Page Rank Algorithm","Text Rank Algorithm","Document Summarization","Extractive Summarization","Abstractive Summarization","Semantic Similarity","Keyword Extraction"],"classifications":["Machine Summarization"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":7},{"id":"292666b539f0075af5666bc7b8eacfebca779459c0d5c14a70930760d1322ca622558dce1704b79ec83457c89ed4a2f4f2039b9f5ba9dab415490377e28c9656","file_path":"legal-nlp-survey-20250328-002/original/Henderson_2022_0566.pdf","title":"","llm_title":"Pile of Law: Learning Responsible Data Filtering from the Law and a 256GB Open-Source Legal Dataset","authors":["Peter Henderson","Mark S. Krass","Lucia Zheng","Neel Guha","Christopher D. Manning","Dan Jurafsky","Daniel E. Ho"],"llm_authors":"Peter Henderson, Mark S. Krass, Lucia Zheng, Neel Guha, Christopher D. Manning, Dan Jurafsky, Daniel E. Ho","author_string":"","year":2022,"abstract":"","llm_abstract":"One concern with the rise of large language models lies with their potential for significant harm, particularly from pretraining on biased, obscene, copyrighted, and private information. Emerging ethical approaches have attempted to filter pretraining material, but such approaches have been ad hoc and failed to take context into account. We offer an approach to filtering grounded in law, which has directly addressed the tradeoffs in filtering material. First, we gather and make available the Pile of Law, a ∼256GB (and growing) dataset of open-source English-language legal and administrative data, covering court opinions, contracts, administrative rules, and legislative records. Pretraining on the Pile of Law may help with legal tasks that have the promise to improve access to justice. Second, we distill the legal norms that governments have developed to constrain the inclusion of toxic or private content into actionable lessons for researchers and discuss how our dataset reflects these norms. Third, we show how the Pile of Law offers researchers the opportunity to learn such filtering rules directly from the data, providing an exciting new research direction in model-based processing. Warning: this paper contains quotations that may be offensive or upsetting.","llm_keywords":["large language models","data filtering","legal dataset","ethical AI","privacy","bias","access to justice","legal norms"],"classifications":["Resources"],"num_cited_by":106,"num_cited_by_title_only":106,"num_pages":43},{"id":"2f880be48d63a8075080cc42e150d77a64b8435f4ece66f778c2a0691f9eee5182d30080f404ad84b9b7aeedc7744a30a151842736b86f71581ee14da5c2f913","file_path":"legal-nlp-survey-20250328-002/original/Garneau_2021_0407.pdf","title":"","llm_title":"CriminelBART: A French Canadian Legal Language Model Specialized in Criminal Law","authors":["Nicolas Garneau","Eve Gaumond","Luc Lamontagne","Pierre-Luc Déziel"],"llm_authors":"Nicolas Garneau, Eve Gaumond, Luc Lamontagne, Pierre-Luc Déziel","author_string":"","year":2021,"abstract":"","llm_abstract":"","llm_keywords":["Criminal Law","Language Model","Cloze Tests","Text Generation","Neural networks","CriminelBART","French Canadian","Legal Language Model","Criminal Code","Artificial Intelligence"],"classifications":[],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":2},{"id":"825af7f62778cd6a0493875628e11e7a6d654601a94de6f428a3c8254224ee3fa247e8dbb8dcfe1b0d7599dde96eb80999b8ba463cd4193a348e6238c2df2f49","file_path":"legal-nlp-survey-20250328-002/original/Sert_2021_0480.pdf","title":"Using Artificial Intelligence to Predict Decisions of the Turkish Constitutional Court","llm_title":"Using Artificial Intelligence to Predict Decisions of the Turkish Constitutional Court","authors":["Mehmet Fatih Sert","Engin Yıldırım","İrfan Haşlak"],"llm_authors":"Mehmet Fatih Sert, Engin Yıldırım, İrfan Haşlak","author_string":"Mehmet Fatih Sert, Engin Yıldırım, and İrfan Haşlak","year":2021,"abstract":"","llm_abstract":"This article draws on an artificial intelligence (AI) technique to predict whether an individual application regarding the Turkish Constitutional Court’s public morality and freedom of expression cases leading to a “violation” or a “nonviolation” decision. To this end, four different data sets have been composed, preclassification and fundamental word embeddings steps have been made on each data set. Multilayer perceptron, which is based on artificial neural networks, has been used for the prediction of the case decisions. We have predicted the court’s decisions on these cases with the high success rates (average accuracy of 90%) by using the subject or reasoning sections of texts of the cases as data. The subject section of the cases constituting only a very small part of the data has yielded the highest accuracy. The article has demonstrated that a basic AI technique can be successful in achieving accurate predictions even with relatively small data sets derived from well-structured court rulings.","llm_keywords":["artificial intelligence","multilayer perceptron","text mining","Turkish Constitutional Court","individual application"],"classifications":["Classification","Pre-Processing"],"num_cited_by":37,"num_cited_by_title_only":37,"num_pages":20},{"id":"8dc5a220b1671054ce9bf4dd3ab9070234ce491b942c2d19f5f9a7a2e747792f391da1b6b443fa7c0c9a4cfc983f9b6b2b0a0bd5f0c73d2e7f17d193f0def489","file_path":"legal-nlp-survey-20250328-002/original/Humphreys_2015_0069.pdf","title":"jurix-recitals-CReady","llm_title":"Mapping Recitals to Normative Provisions in EU Legislation to Assist Legal Interpretation","authors":["Llio Humphreys","Cristiana Santos","Luigi di Caro","Guido Boella","Leon van der Torre","Livio Robaldo"],"llm_authors":"Llio Humphreys, Cristiana Santos, Luigi di Caro, Guido Boella, Leon van der Torre, Livio Robaldo","author_string":"Cristiana","year":2015,"abstract":"","llm_abstract":"This paper looks at the use of recitals in the interpretation of EU legislation, and mechanisms for connecting them to normative provisions. The purposive approach to the interpretation of EU legislation taken by the European Court of Justice makes frequent references to recitals as helping to establish the purpose of normative provisions. Our research uses a cosine similarity based approach to link articles with relevant provisions to help legal professionals and lay end-users interpret the law. Such support can be used in legal knowledge-based systems.","llm_keywords":["recitals","EU legislation","purposive interpretation","semantic similarity","legal interpretation"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":9},{"id":"1232d39901ee9c12186a4e0c6832d7003763414cda16720707edc3b4a40293c4c14f2277ffbd9cc2d3efb86a171a15ac2f00d826e7e5290510986dad15ce4d10","file_path":"legal-nlp-survey-20250328-002/original/Quemy_2017_0120.pdf","title":"Data Science Techniques for Law and Justice: Current State of Research and Open Problems","llm_title":"Data Science Techniques for Law and Justice: Current State of Research and Open Problems","authors":["Alexandre Quemy"],"llm_authors":"Alexandre Quemy","author_string":"Alexandre Quemy","year":2017,"abstract":"","llm_abstract":"By comparing the state of research in Legal Analysis to the needs of legal agents, we extract four fundamental problems and discuss how they are covered by the current best approaches. In particular, we review the recent statistical models, relying on Machine Learning coupled to Natural Language Processing techniques, and the Abstract Argumentation applied to the legal domain before giving some new perspectives of research.","llm_keywords":["Legal analysis","Abstract Argumentation","Case-Based Reasoning","Machine Learning","Natural Language Processing","Statistical models","Legal domain","Research challenges"],"classifications":["Information Extraction"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":11},{"id":"2b2d86675a343a7627e3bb3ab7e6d0f63940bd10d2487fc10b2fe0a6f32e618eba0c6f2f1ca797cb9155d5a2c466c03c53f196ad498076ffc6b531dce95669a2","file_path":"legal-nlp-survey-20250328-002/original/Tagarelli_2021_0479.pdf","title":"Unsupervised law article mining based on deep pre-trained language representation models with application to the Italian civil code","llm_title":"Unsupervised law article mining based on deep pre‑trained language representation models with application to the Italian civil code","authors":["Andrea Tagarelli","Andrea Simeri"],"llm_authors":"Andrea Tagarelli, Andrea Simeri","author_string":"Andrea Tagarelli","year":2021,"abstract":"","llm_abstract":"Modeling law search and retrieval as prediction problems has recently emerged as a predominant approach in law intelligence. Focusing on the law article retrieval task, we present a deep learning framework named LamBERTa, which is designed for civil-law codes, and specifically trained on the Italian civil code. To our knowledge, this is the first study proposing an advanced approach to law article prediction for the Italian legal system based on a BERT (Bidirectional Encoder Representations from Transformers) learning framework, which has recently attracted increased attention among deep learning approaches, showing outstanding effectiveness in several natural language processing and learning tasks. We define LamBERTa models by fine-tuning an Italian pre-trained BERT on the Italian civil code or its portions, for law article retrieval as a classification task. One key aspect of our LamBERTa framework is that we conceived it to address an extreme classification scenario, which is characterized by a high number of classes, the few-shot learning problem, and the lack of test query benchmarks for Italian legal prediction tasks. To solve such issues, we define different methods for the unsupervised labeling of the law articles, which can in principle be applied to any law article code system. We provide insights into the explainability and interpretability of our LamBERTa models, and we present an extensive experimental analysis over query sets of different type, for single-label as well as multi-label evaluation tasks. Empirical evidence has shown the effectiveness of LamBERTa, and also its superiority against widely used deep-learning text classifiers and a few-shot learner conceived for an attribute-aware prediction task.","llm_keywords":["law article retrieval","deep learning","BERT","Italian civil code","text classification"],"classifications":["Information Retrieval","Classification","Text Generation","Pre-Processing"],"num_cited_by":54,"num_cited_by_title_only":54,"num_pages":57},{"id":"9d574d02498572f7c835a4053d48d6a787d1e9c722108700497ff3d06a03bd61cdfcab86ed03f37cb932d25695b30c29af5994f0827e8e0494e9bc201ca19d55","file_path":"legal-nlp-survey-20250328-002/original/Chen_2022_0500.pdf","title":"Construction and Evaluation of a High-Quality Corpus for Legal Intelligence Using Semiautomated Approaches","llm_title":"Construction and Evaluation of a High-Quality Corpus for Legal Intelligence Using Semiautomated Approaches","authors":["Haihua Chen","Lavinia F. Pieptea","Junhua Ding"],"llm_authors":"Haihua Chen, Lavinia F. Pieptea, and Junhua Ding","author_string":"Haihua Chen; Lavinia F. Pieptea; Junhua Ding","year":2022,"abstract":"","llm_abstract":"A high-quality corpus is essential for building an effective legal intelligence system. The quality of a corpus includes both the quality of original data and the quality of its corresponding labeling. The major quality dimensions of a legal corpus include comprehensiveness, freshness, and correctness. However, building a comprehensive, correct, and fresh legal corpus is a grand challenge. In this article, we propose a semiautomated machine learning framework to address the challenge. We first created an initial corpus with 4937 instances that were manually labeled. Several strategies were implemented to assure its quality. The initial results showed that class imbalance and insufficiency of training data are the two major quality issues that negatively impacted the quality of the system that was built on the data. We experimented and compared three class-imbalance-handling techniques and found that the mixed-sampling method, which combines upsampling and downsampling, was the most effective way to address the issue. In order to address the insufficiency of training data, we experimented several machine learning methods for automated data augmentation including pseudolabeling, co-training, expectation-maximization, and generative adversarial network (GAN). The results showed that GAN with deep learning models achieved the best performance. Finally, ensemble learning of different classifiers was proposed and experimented with for the construction of a legal corpus, which achieves higher quality in comprehensiveness, freshness, and correctness compared to existing work. The semiautomated machine learning framework and the data quality evaluation method developed in this research can be used for data augmentation and quality evaluation of a large dataset as well as a reference for the selection of machine learning methods for data augmentation and generation. The machine learning models, the training data, and the legal corpus are published and publicly accessible at [Online]. Available: https://github.com/haihua0913/legalArgumentmining.","llm_keywords":["legal corpus","machine learning","data augmentation","legal intelligence","class imbalance","generative adversarial network","deep learning","ensemble learning","natural language processing"],"classifications":[],"num_cited_by":19,"num_cited_by_title_only":19,"num_pages":17},{"id":"0bcb9b127bfc668d1b9bc1c88d01e70eb114709a3f2129f72973efed49879e57cdf628fc82ba04e03d53e25dbc7cd9c0a525dca4a9a04c680c61bde31ea88d20","file_path":"legal-nlp-survey-20250328-002/original/Savelka_2018_0204.pdf","title":"","llm_title":"Segmenting U.S. Court Decisions into Functional and Issue Specific Parts","authors":["Jaromír Savelka","Kevin D. Ashley"],"llm_authors":"Jaromír Savelka and Kevin D. Ashley","author_string":"","year":2018,"abstract":"","llm_abstract":"In common law jurisdictions, legal research often involves an analysis of relevant case law. Court opinions comprise several high-level parts with different functions. A statement’s membership in one of the parts is a key factor influencing how the statement should be understood. In this paper we present a number of experiments in automatically segmenting court opinions into the functional and the issue specific parts. We defined a set of seven types including Background, Analysis, and Conclusions. We used the types to annotate a sizable corpus of US trade secret and cyber crime decisions. We used the data set to investigate the feasibility of recognizing the parts automatically. The proposed framework based on conditional random fields proved to be very promising in this respect. To support research in automatic case law analysis we plan to release the data set to the public.","llm_keywords":["case law","legal analysis","information retrieval","text segmentation","conditional random fields","natural language processing","machine learning","court opinions","issue specific parts","US court decisions"],"classifications":[],"num_cited_by":58,"num_cited_by_title_only":58,"num_pages":10},{"id":"12b709e1536987e9e2256e0d39977bd6386111aba7ef5bc74dba597da203517bc34922fe0d200b33bf4c31c6e067638204f147cd6084d36618fc4bcbceccf618","file_path":"legal-nlp-survey-20250328-002/original/Sanchez_2019_0283.pdf","title":"Proceedings of the Natural Legal Language Processing Workshop 2019","llm_title":"Sentence Boundary Detection in Legal Text","authors":["George Sanchez"],"llm_authors":"George Sanchez","author_string":"Association for Computational Linguistics","year":2021,"abstract":"","llm_abstract":"In this paper, we examined several algorithms to detect sentence boundaries in legal text. Legal text presents challenges for sentence tokenizers because of the variety of punctuations, linguistic structure, and syntax of legal text. Out-of-the-box algorithms perform poorly on legal text affecting further analysis of the text. A novel and domain-specific approach is needed to detect sentence boundaries to further analyze legal text. We present the results of our investigation in this paper.","llm_keywords":["Sentence Boundary Detection","Legal Text","Natural Language Processing","Punkt Model","Conditional Random Field","Deep Learning","Supervised Approach","Tokenization","Linguistic Structure","Text Analysis"],"classifications":["Pre-Processing"],"num_cited_by":55,"num_cited_by_title_only":55,"num_pages":9},{"id":"8b319605386fe725f3323307fce480ae64546085120ee4197d084bfa54ee3bb3af561cb89db6f02814bb1b37d59b70d12eb0df654535ac1d32485ca3423b366c","file_path":"legal-nlp-survey-20250328-002/original/Khaltarkhuu_2022_0578.pdf","title":"","llm_title":"Text Classification of Modern Mongolian Documents using BERT models","authors":["Garmaabazar Khaltarkhuu","Biligsaikhan Batjargal","Akira Maeda"],"llm_authors":"Garmaabazar Khaltarkhuu, Biligsaikhan Batjargal, Akira Maeda","author_string":"","year":2022,"abstract":"","llm_abstract":"This paper investigates the application of state-of-the-art deep-learning-based natural language processing techniques in modern Mongolian documents. In particular, we explore several methods that apply Bidirectional Encoder Representations from Transformers (BERT) models for classifying modern Mongolian legal documents. Based on our findings, we propose BERT-based models called LEGAL-BERT-Mongolian. We demonstrated two variants of LEGAL-BERT-Mongolian, i.e., uncased-LEGAL-BERT-Mongolian and cased-LEGAL-BERT-Mongolian, for classifying modern Mongolian legal documents. The uncased-LEGAL-BERT-Mongolian model achieved the best results, with a precision of 0.91, recall of 0.87, and F1 score of 0.89, whereas the cased-LEGAL-BERT-Mongolian model achieved a precision of 0.87, recall of 0.83, and F1 score of 0.85. Moreover, because the LEGAL-BERT-Mongolian models demonstrated a certain degree of confusion among the “legal,” “economy,” and “politics” categories, some distinct deep features need to be explored to properly distinguish these classification categories. Furthermore, the proposed LEGAL-BERT-Mongolian models need to be evaluated on larger datasets.","llm_keywords":["Document classification","Deep learning","Mongolian legal documents","Legal document analysis"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":6},{"id":"3d82a1bdbcd7e7ac9bcf0b3f0a9134de0a859759b5e5bf0cef43212c1964d2a4915deb9917a276ddd34f3067c8c0b823f6882939f1446edca4ca83a140bfc951","file_path":"legal-nlp-survey-20250328-002/original/Chen_2013_0004.pdf","title":"A text mining approach to assist the general public in the retrieval of legal documents","llm_title":"A Text Mining Approach to Assist the General Public in the Retrieval of Legal Documents","authors":["Yen-Liang Chen","Yi-Hung Liu","Wu-Liang Ho"],"llm_authors":"Yen-Liang Chen, Yi-Hung Liu, Wu-Liang Ho","author_string":"","year":2013,"abstract":"","llm_abstract":"Applying text mining techniques to legal issues has been an emerging research topic in recent years. Although some previous studies focused on assisting professionals in the retrieval of related legal documents, they did not take into account the general public and their difficulty in describing legal problems in professional legal terms. Because this problem has not been addressed by previous research, this study aims to design a text-mining-based method that allows the general public to use everyday vocabulary to search for and retrieve criminal judgments. The experimental results indicate that our method can help the general public, who are not familiar with professional legal terms, to acquire relevant criminal judgments more accurately and effectively.","llm_keywords":["text mining","legal documents","general public","information retrieval","legal issues","search engines","database search","criminal judgments","automated legal systems"],"classifications":["Information Retrieval"],"num_cited_by":59,"num_cited_by_title_only":59,"num_pages":11},{"id":"8a021252b0cb131aed186e38566d5f1df6bbcb67a6efe1013748d1d40b1ac97cb676e050dea9af3c57b39373b2ca52433babc77682eb7af36d73bcfc47e499a2","file_path":"legal-nlp-survey-20250328-002/original/Agarwal_2022_0579.pdf","title":"","llm_title":"Extractive Summarization of Legal Decisions using Multi-task Learning and Maximal Marginal Relevance","authors":["Abhishek Agarwal","Shanshan Xu","Matthias Grabmair"],"llm_authors":"Abhishek Agarwal, Shanshan Xu, Matthias Grabmair","author_string":"","year":2022,"abstract":"","llm_abstract":"Summarizing legal decisions requires the expertise of law practitioners, which is both time and cost-intensive. This paper presents techniques for extractive summarization of legal decisions in a low-resource setting using limited expert annotated data. We test a set of models that locate relevant content using a sequential model and tackle redundancy by leveraging maximal marginal relevance to compose summaries. We also demonstrate an implicit approach to help train our proposed models generate more informative summaries. Our multi-task learning model variant leverages rhetorical role identification as an auxiliary task to further improve the summarizer. We perform extensive experiments on datasets containing legal decisions from the US Board of Veterans’ Appeals and conduct quantitative and expert-ranked evaluations of our models. Our results show that the proposed approaches can achieve ROUGE scores vis-à-vis expert extracted summaries that match those achieved by inter-annotator comparison.","llm_keywords":["extractive summarization","legal decisions","multi-task learning","maximal marginal relevance","rhetorical role identification","low-resource setting","transformers","domain-specific BERT","redundancy reduction"],"classifications":["Machine Summarization","Pre-Processing","Text Generation","Resources"],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":16},{"id":"c99b0718eadaaa867ec177afdcc1454328a5b7a4bb81586077da20dbc82272cc0d9a97ba5cbf1ed541eefc149ffc0b90e7c07aa295b4d9d1848222a4445fd4ff","file_path":"legal-nlp-survey-20250328-002/original/Leone_2020_0368.pdf","title":"","llm_title":"The Role of Vocabulary Mediation to Discover and Represent Relevant Information in Privacy Policies","authors":["Valentina Leone","Luigi Di Caro"],"llm_authors":"Valentina LEONE, Luigi DI CARO","author_string":"","year":2020,"abstract":"","llm_abstract":"To date, the effort made by existing vocabularies to provide a shared representation of the data protection domain is not fully exploited. Different natural language processing (NLP) techniques have been applied to the text of privacy policies without, however, taking advantage of existing vocabularies to provide those documents with a shared semantic superstructure. In this paper we show how a recently released domain-specific vocabulary, i.e. the Data Privacy Vocabulary (DPV), can be used to discover, in privacy policies, the information that is relevant with respect to the concepts modelled in the vocabulary itself. We also provide a machine-readable representation of this information to bridge the unstructured textual information to the formal taxonomy modelled in it. This is the first approach to the automatic processing of privacy policies that relies on the DPV, fuelling further investigation on the applicability of existing semantic resources to promote the reuse of information and the interoperability between systems in the data protection domain.","llm_keywords":["legal vocabularies","ontology population","text similarity","data protection","natural language processing","semantic resources","privacy policies","Data Privacy Vocabulary","machine-readable representation"],"classifications":["Information Extraction"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":10},{"id":"35946cc4620d299b036c326c1e68ed86275be2b022f24c24a3af26ce825f2856a53b0ac1c310deea93da4acb5211d1d9fb68b55d85a5806917d7de5fcef891e4","file_path":"legal-nlp-survey-20250328-002/original/Landthaler_2016_0092.pdf","title":"","llm_title":"Extending Full Text Search for Legal Document Collections using Word Embeddings","authors":["Jorg Landthaler","Bernhard Waltl","Patrick Holl","Florian Matthes"],"llm_authors":"Jorg LANDTHALER, Bernhard WALTL, Patrick HOLL, Florian MATTHES","author_string":"","year":2016,"abstract":"","llm_abstract":"Traditional full text search allows fast search for exact matches. However, full text search is not optimal to deal with synonyms or semantically related terms and phrases. In this paper we explore a novel method that provides the ability to find not only exact matches, but also semantically similar parts for arbitrary length search queries. We achieve this without the application of ontologies, but base our approach on Word Embeddings. Recently, Word Embeddings have been applied successfully for many natural language processing tasks. We argue that our method is well suited for legal document collections and examine its applicability for two different use cases: We conduct a case study on a stand-alone law, in particular the EU Data Protection Directive 94/46/EC (EU-DPD) in order to extract obligations. Secondly, from a collection of publicly available templates for German rental contracts we retrieve similar provisions.","llm_keywords":["information retrieval","full text search","relatedness search","recommender systems","text mining","word embeddings","EU-DSGVO","rental contracts"],"classifications":["Information Retrieval"],"num_cited_by":43,"num_cited_by_title_only":43,"num_pages":10},{"id":"340dea42ec9876c36ef03a35590b07f7bca24494843dc5c3235a3ed234f1b1011852751c86a89fbbaf57d7dc1eea9b9037154c1c5652b7d135571065205b96f1","file_path":"legal-nlp-survey-20250328-002/original/Smywinski-Pohl_2019_0223.pdf","title":"180_Smywinski-Pohl.pdf","llm_title":"Automatic Construction of a Polish Legal Dictionary with Mappings to Extra-Legal Terms Established via Word Embeddings","authors":["Aleksander Smywiński-Pohl","Karol Lasocki","Krzysztof Wróbel","Marek Strzała"],"llm_authors":"Aleksander Smywiński-Pohl, Karol Lasocki, Krzysztof Wróbel, Marek Strzała","author_string":"","year":2019,"abstract":"","llm_abstract":"The primary objective of this research is finding correspondence between legal and extra-legal terms in Polish by employing unsupervised methods, such as statistics and word embeddings. We investigate the possibility to construct a legal dictionary automatically by employing statistical methods for identifying the legal terms (including multi-word entities) and then finding correspondence between these terms and extra-legal terminology used by laymen, by employing word embeddings inducing algorithms. We compare two popular libraries word2vec and GloVe in a synthetic experiment showing the superiority of word2vec CBOW negative sampling variant in the described problem.","llm_keywords":["legal terms","multi-word entities","word embeddings","terminology extraction","conversational systems"],"classifications":["Pre-Processing","Information Extraction","Resources","Text Generation"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":5},{"id":"a95a4caaa979a7e3165c9423bd2b29620702b822547511175c8360f024eaba6348c1efbd714084c46a9c06c5cfbcfe9875c9c7cac5450af6fde46abe8a429bcb","file_path":"legal-nlp-survey-20250328-002/original/Çetiner_2021_0447.pdf","title":"Mevzuat Verisetinde Soru Cevaplama Uygulamasi Question Answering Application on Legalisation Dataset","llm_title":"Mevzuat Verisetinde Soru Cevaplama Uygulaması","authors":["Meltem Çetiner","Ahmet Yıldırım","Bahadır Onay","Cüneyt Öksüz"],"llm_authors":"Meltem Çetiner, Ahmet Yıldırım, Bahadır Onay, Cüneyt Öksüz","author_string":"Meltem Cetiner; Ahmet Yildirim; Cuneyt Oksuz; Bahadir Onay","year":2021,"abstract":"","llm_abstract":"Question Answering is a widely studied sub-field of Natural Language Processing (NLP). It studies information retrieval techniques that locate the answer in a corpus for a given query. Recently, deep learning techniques are widely employed in this field. This work uses a transfer learning method on Turkish Tax legislation documents. Experts in Tax-Law domain created 355 question-answer pairs in SQuAD 1.1 (Stanford Question Answering Dataset) format using law documents in UYAP (National Judiciary Informatics System). BERT (Bidirectional Encoder Representations from Transformers) contextual word embedding vectors are used to create a representation that can capture different meanings in word representations. Using both these embeddings and the model obtained from SQuAD 1.1 dataset, a system was deployed. Also, using the failing answers retrieved from the application of this model, a SQuAD 2.0 dataset were created that includes impossible-to-answer questions. New models were obtained by training with this dataset. Our observation is that the most successful model of SQuAD 2.0 dataset outperforms that of SQuAD 1.1 by 11% in exact matching measure and by 5% in F1.","llm_keywords":["Question-Answering","Legalisation","BERT","SQuAD","Natural Language Processing","Deep Learning","Transfer Learning"],"classifications":["Information Extraction","Resources","Information Retrieval"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":5},{"id":"6f05787a173bc8cce8807c3485230a81ae7dea918bc99137c18b586ea5b7934657c4a456e2647de2748fcb9b9ad46c880d3ca1d39b20e18c1129863bd05f4f83","file_path":"legal-nlp-survey-20250328-002/original/Mandal_2021_0430.pdf","title":"","llm_title":"Improving Legal Case Summarization Using Document-Specific Catchphrases","authors":["Arpan Mandal","Paheli Bhattacharya","Sekhar Mandal","Saptarshi Ghosh"],"llm_authors":"Arpan Mandal, Paheli Bhattacharya, Sekhar Mandal, Saptarshi Ghosh","author_string":"","year":2021,"abstract":"","llm_abstract":"Legal case summarization is an important problem, and several domain-specific summarization algorithms have been applied for this task. These algorithms generally use domain-specific legal dictionaries to estimate the importance of sentences. However, none of the popular summarization algorithms use document-specific catchphrases, which provide a unique amalgamation of domain-specific and document-specific information. In this work, we assess the performance of two legal document summarization algorithms, when two different types of catchphrases are incorporated in the summarization process. Our experiments confirm that both the summarization algorithms show improvement across all performance metrics, with the incorporation of document-specific catchphrases.","llm_keywords":["Legal case document","Summarization","Catchphrases","Domain-specific dictionaries","Document-specific importance"],"classifications":["Machine Summarization"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":6},{"id":"3dc51302036f57b36909e747079718417138d04244938029f0752ee91b4a62f490ab40f3ff1175db2ad67652dbbba3c1d2e1df9e48d301221bc45fd610b172e7","file_path":"legal-nlp-survey-20250328-002/original/Markovich_2015_0058.pdf","title":"","llm_title":"Elliptical Lists in Legislative Texts","authors":["Anne Gardner","Réka Markovich","Eötvös Loránd","Gábor Hamp"],"llm_authors":"Réka Markovich, Eötvös Loránd, Gábor Hamp","author_string":"Anne Gardner","year":2015,"abstract":"","llm_abstract":"Legal texts consist of hierarchically ordered and labeled (numbered) structural units (sections, subsections, paragraphs, etc.). Using the ordered layout and the labels the different parts of structural units can be easily localized and clearly referred. Nearly one-third of the structural units in the statutes we have examined are list items that can be considered as elliptical. In such cases the list items—each with unique identifying label (number)—are not complete propositions. We have trained the computer to recognize these lists and the different units and elements in them, and to create complete sentences from these. We will introduce some logical considerations that have to be reckoned with if we intend to use these complete sentences to create logical assignments to the legal regulation’s content: we show how this technique influences the logical description of norms.","llm_keywords":["elliptical lists","text structure","logical analysis","deontic logic"],"classifications":["Text Generation","Information Extraction"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":4},{"id":"b4d08937f0b0ee469011fdbbb4ad64586b2d0f949ff02b4941b8b1b4714739a2eabedb0d5d695f0fb44a7d0f3024c7ef33919e185a8130986b5c3dcf18ac264a","file_path":"legal-nlp-survey-20250328-002/original/Yang_2019_0257.pdf","title":"","llm_title":"Legal Judgment Prediction via Multi-Perspective Bi-Feedback Network","authors":["Wenmian Yang","Weijia Jia","Xiaojie Zhou","Yutao Luo"],"llm_authors":"Wenmian Yang, Weijia Jia, Xiaojie Zhou, Yutao Luo","author_string":"","year":2019,"abstract":"","llm_abstract":"The Legal Judgment Prediction (LJP) is to determine judgment results based on the fact descriptions of the cases. LJP usually consists of multiple subtasks, such as applicable law articles prediction, charges prediction, and the term of the penalty prediction. These multiple subtasks have topological dependencies, the results of which affect and verify each other. However, existing methods use dependencies of results among multiple subtasks inefficiently. Moreover, for cases with similar descriptions but different penalties, current methods cannot predict accurately because the word collocation information is ignored. In this paper, we propose a Multi-Perspective Bi-Feedback Network with the Word Collocation Attention mechanism based on the topology structure among subtasks. Specifically, we design a multi-perspective forward prediction and backward verification framework to utilize result dependencies among multiple subtasks effectively. To distinguish cases with similar descriptions but different penalties, we integrate word collocations features of fact descriptions into the network via an attention mechanism. The experimental results show our model achieves significant improvements over baselines on all prediction tasks.","llm_keywords":["Legal Judgment Prediction","Multi-Perspective Bi-Feedback Network","Word Collocation Attention","multi-task learning","charge prediction","penalty prediction","law article prediction","natural language processing"],"classifications":["Classification"],"num_cited_by":171,"num_cited_by_title_only":171,"num_pages":7},{"id":"2642d66bb4d79a1c1f9effad01bb1ed6491670cf88d370ef6ab75f5b56dff65bbfc00a3e492b391926db534ba3981173580e5b8c6ffc76532c0e9c35506a8e32","file_path":"legal-nlp-survey-20250328-002/original/Glaser_2021_0391.pdf","title":"","llm_title":"Anonymization of German Legal Court Rulings","authors":["Ingo Glaser","Tom Schamberger","Florian Matthes"],"llm_authors":"Ingo Glaser, Tom Schamberger, Florian Matthes","author_string":"","year":2021,"abstract":"","llm_abstract":"In the legal domain, many legal documents such as court decisions and contracts are regularly anonymized. This process requires text sequences with high sensitivity to be identified and neutralized to secure sensitive information from third parties. Usually, this process is performed manually by trained employees. Therefore, anonymization is generally considered an expensive and inefficient process. This work proposes a machine learning approach for the automatic identification of sensitive text elements in German legal court decisions and provides an implementation. For this task, different deep neural network architectures based on generally pre-trained contextual embeddings as well as trained word embeddings are evaluated. Because of the lack of non-anonymized data sets, an approach to create pseudonymized data sets is proposed as well.","llm_keywords":["anonymization","legal documents","machine learning","German court rulings","neural networks","pre-trained embeddings","named entity recognition","sensitive information","legal technology","pseudonymized data sets"],"classifications":["Classification","Information Extraction"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":5},{"id":"38bc7804b511342e8cdb7f31cd69ff091376961eadc4ec46f75f7f928c46af26925cf7b1bda3c9bdb7e5a09f554593920c52e05458b38cf02690badb9d990d18","file_path":"legal-nlp-survey-20250328-002/original/Yan_2019_0253.pdf","title":"Law Article Prediction Based on Deep Learning","llm_title":"Law Article Prediction Based on Deep Learning","authors":["Ge Yan","Yu Li","Siyuan Shen","Shu Zhang","Jia Liu"],"llm_authors":"Ge Yan, Yu Li, Siyuan Shen, Shu Zhang, Jia Liu","author_string":"","year":2019,"abstract":"","llm_abstract":"Analysing judicial documents is a significant task in the field of legal intelligence, of which the prediction of law articles can help ordinary people better comprehend basic legal knowledge. It can be seen as a multi-label classification problem. Our work uses description of the cases as the input and views law articles as labels. After word segmentation and feature extraction, the classifier model TextCNN is used to train and predict the results. Results of comparative experiments show that our approach can achieve competitive results.","llm_keywords":["Law Articles Prediction","Multi-label Classification","TextCNN","Deep Learning","Judicial Documents","Legal Intelligence","Text Mining","Feature Extraction"],"classifications":["Classification"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":4},{"id":"1e39a4a75b4c40412b100507b4150b14e87ac5f6c195ab93d280471f6be0ae46dc7d10092a87cf48c318444adf6c1b91a182c3c4be2ffb03375ccd7bb8603680","file_path":"legal-nlp-survey-20250328-002/original/Ash_2018_0169.pdf","title":"","llm_title":"Case Vectors: Spatial Representations of the Law using Document Embeddings","authors":["Elliott Ash","Daniel L. Chen"],"llm_authors":"Elliott Ash and Daniel L. Chen","author_string":"","year":2018,"abstract":"","llm_abstract":"Recent work in natural language processing represents language objects (words and documents) as dense vectors that encode the relations between those objects. This paper explores the application of these methods to legal language, with the goal of understanding judicial reasoning and the relations between judges. In an application to federal appellate courts, we show that these vectors encode information that distinguishes courts, time, and legal topics. The vectors do not reveal spatial distinctions in terms of political party or law school attended, but they do highlight generational differences across judges. We conclude the paper by outlining a range of promising future applications of these methods.","llm_keywords":["legal language","document embeddings","judicial reasoning","federal appellate courts","natural language processing","semantic vectors","computational legal studies"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":26,"num_cited_by_title_only":26,"num_pages":25},{"id":"68613b0c424fcfb90507ced22db18271c91b188130b035bef75d7782412a5959b614f462a7ee006d7717f7f6452f8d25d9e86c9f7ab9df83a21c7dec68dbf9b8","file_path":"legal-nlp-survey-20250328-002/original/Savelka_2015_0075.pdf","title":"","llm_title":"Transfer of Predictive Models for Classification of Statutory Texts in Multi-jurisdictional Settings","authors":["Anne Gardner","Jaromír Šavelka","Kevin D. Ashley"],"llm_authors":"Jaromír Šavelka, Kevin D. Ashley","author_string":"Anne Gardner","year":2015,"abstract":"","llm_abstract":"In this paper we use statistical machine learning to classify statutory texts in terms of highly specific functional categories. We focus on regulatory provisions from multiple US state jurisdictions, all dealing with the same general topic of public health system emergency preparedness and response. In prior work we have established that one can improve classification performance on one jurisdiction’s statutory texts using texts from another jurisdiction. Here we describe a framework facilitating transfer of predictive models for classification of statutory texts among multiple state jurisdictions. Our results show that the classification performance improves as we employ an increasing number of models trained on data coming from different states.","llm_keywords":["text categorization","statutory texts","public health system","multiple jurisdictions","transfer learning"],"classifications":["Classification"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":5},{"id":"8ac8fe0ddb4763db829e9adacec7facf186997a65a8bd437951ded33fc417bf9ecd776868483fc2eb1f956295c25242bb9f26a0f8d91307620f80a86a674b700","file_path":"legal-nlp-survey-20250328-002/original/van-Opijnen_2015_0055.pdf","title":"Proceedings Template - WORD","llm_title":"Beyond the Experiment: the eXtendable Legal Link eXtractor","authors":["Marc van Opijnen","Nico Verwer","Jan Meijer"],"llm_authors":"Marc van Opijnen, Nico Verwer, Jan Meijer","author_string":"End User Computing Services","year":2015,"abstract":"","llm_abstract":"In this paper we describe a software framework for detecting and resolving references to (national and EU) legislation, case law, parliamentary documents and official gazettes. Meant to function in a large-scale production environment, performance, flexibility and maintainability are essential requirements. This led us to some noteworthy choices: within the pipeline architecture of Apache Cocoon we use the trie data structure for named entity recognition and a parsing expression grammar for pattern recognition, the latter having significant advantages over the use of regular expressions. Additional attention is paid to some substantive maintainability issues.","llm_keywords":["Legal semantic web","Natural Language Processing","Parsing expression grammar","Pipeline processing","Named entity recognition","Pattern recognition","Automation","Linked data","Dutch legal data","Legal references"],"classifications":["Information Extraction","Pre-Processing","Resources"],"num_cited_by":26,"num_cited_by_title_only":26,"num_pages":9},{"id":"c1823c256132e3ff4bd1dfe3adb6b893b7d99a017f6bdc77bb9b79b0711930832983a1303a2c5a3c9cbbe2bf395c366ae8b26b5d9080ac071ddb6b42480dabac","file_path":"legal-nlp-survey-20250328-002/original/De-Martino_2022_0540.pdf","title":"PRILJ: an efficient two-step method based on embedding and clustering for the identification of regularities in legal case judgments","llm_title":"PRILJ: an efcient two‑step method based on embedding and clustering for the identifcation of regularities in legal case judgments","authors":["Graziella De Martino","Gianvito Pio","Michelangelo Ceci"],"llm_authors":"Graziella De Martino, Gianvito Pio, Michelangelo Ceci","author_string":"Graziella De Martino","year":2021,"abstract":"","llm_abstract":"In an era characterized by fast technological progress that introduces new unpredictable scenarios every day, working in the law field may appear very difficult, if not supported by the right tools. In this respect, some systems based on Artificial Intelligence methods have been proposed in the literature, to support several tasks in the legal sector. Following this line of research, in this paper we propose a novel method, called PRILJ, that identifies paragraph regularities in legal case judgments, to support legal experts during the redaction of legal documents. Methodologically, PRILJ adopts a two-step approach that first groups documents into clusters, according to their semantic content, and then identifies regularities in the paragraphs for each cluster. Embedding-based methods are adopted to properly represent documents and paragraphs into a semantic numerical feature space, and an Approximated Nearest Neighbor Search method is adopted to efficiently retrieve the most similar paragraphs with respect to the paragraphs of a document under preparation. Our extensive experimental evaluation, performed on a real-world dataset provided by EUR-Lex, proves the effectiveness and the efficiency of the proposed method. In particular, its ability of modeling different topics of legal documents, as well as of capturing the semantics of the textual content, appear very beneficial for the considered task, and make PRILJ very robust to the possible presence of noise in the data.","llm_keywords":["Legal information retrieval","Embedding","Clustering","Approximate nearest neighbor search","Artificial Intelligence","Legal case judgments","Natural Language Processing"],"classifications":["Classification","Information Retrieval","Information Extraction"],"num_cited_by":25,"num_cited_by_title_only":25,"num_pages":32},{"id":"2a1241de76f5d927a2a9e98b13cfc5eed5c00012f74524c5d5603f969798c356259a18c23901c4dee1d9ad3a7259c35b27b66e3fcd4d4ebd714d8de7dc8e0789","file_path":"legal-nlp-survey-20250328-002/original/He_2019_0280.pdf","title":"","llm_title":"SECaps: A Sequence Enhanced Capsule Model for Charge Prediction","authors":["Congqing He","Li Peng","Yuquan Le","Jiawei He","Xiangyu Zhu"],"llm_authors":"Congqing He, Li Peng, Yuquan Le, Jiawei He, Xiangyu Zhu","author_string":"","year":2019,"abstract":"","llm_abstract":"Automatic charge prediction aims to predict appropriate final charges according to the fact descriptions for a given criminal case. Automatic charge prediction plays a critical role in assisting judges and lawyers to improve the efficiency of legal decisions, and thus has received much attention. Nevertheless, most existing works on automatic charge prediction perform adequately on high-frequency charges but are not yet capable of predicting few-shot charges with limited cases. In this paper, we propose a Sequence Enhanced Capsule model, dubbed as SECaps model, to relieve this problem. Specifically, following the work of capsule networks, we propose the seq-caps layer, which considers sequence information and spatial information of legal texts simultaneously. Then we design an attention residual unit, which provides auxiliary information for charge prediction. In addition, our SECaps model introduces focal loss, which relieves the problem of imbalanced charges. Comparing the state-of-the-art methods, our SECaps model obtains 4.5% and 6.4% absolutely considerable improvements under Macro F1 in Criminal-S and Criminal-L respectively. The experimental results consistently demonstrate the superiorities and competitiveness of our proposed model.","llm_keywords":["Charge prediction","Capsule networks","Few-shot","Focal loss"],"classifications":[],"num_cited_by":39,"num_cited_by_title_only":39,"num_pages":13},{"id":"80e6b1bf3f1fdef2de32c904eac5ca90f5050ae69542049da96aaf0619c80ad680606a0e4ae0d7d08601e33eb3650f0e2735eb77abcd03553733af5d967df340","file_path":"legal-nlp-survey-20250328-002/original/Heylen_2014_0043.pdf","title":"TermWise: Leveraging Big Data for Terminological Support in Legal Translation","llm_title":"TermWise: Leveraging Big Data for Terminological Support in Legal Translation","authors":["Kris Heylen","Stephen Bond","Dirk de Hertog","Hendrik Kockaert","Frieda Steurs","Ivan Vulić"],"llm_authors":"Kris Heylen, Stephen Bond, Dirk de Hertog, Hendrik Kockaert, Frieda Steurs, Ivan Vulić","author_string":"Kris Heylen, Stephen Bond, Dirk de Hertog, Hendrik Kockaert, Frieda Steurs, Ivan Vulić","year":2022,"abstract":"","llm_abstract":"Increasingly, large bilingual document collections are being made available online, especially in the legal domain. This type of Big Data is a valuable resource that specialized translators exploit to search for informative examples of how domain-specific expressions should be translated. However, general purpose search engines are not optimized to retrieve previous translations that are maximally relevant to a translator. In this paper, we report on the TermWise project, a cooperation of terminologists, corpus linguists and computer scientists, that aims to leverage big online translation data for terminological support to legal translators at the Belgian Federal Ministry of Justice. The project developed dedicated knowledge extraction algorithms and a server-based tool to provide translators with the most relevant previous translations of domain-specific expressions relative to the current translation assignment. In the paper, we give an overview of the system, give a demo of the user interface and then discuss, more in general, the possibilities of mining big data to support specialized translation.","llm_keywords":["Legal Terminology","Automatic Knowledge acquisition","Big Data","Context Sensitive Suggestion","Specialized Translation","Translation Tools","Bilingual Corpora","Terminological Support"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"1e9dfd7967ab3d5abcad5617e0bd136bd8d39f8e92463d73ce0b31899d2c4948f7804c380531767c6141b87fa523729569fecf9bf8767b40ae6b27d3f1e14f35","file_path":"legal-nlp-survey-20250328-002/original/Gan_2021_0432.pdf","title":"Judgment Prediction via Injecting Legal Knowledge into Neural Networks","llm_title":"Judgment Prediction via Injecting Legal Knowledge into Neural Networks","authors":["Leilei Gan","Kun Kuang","Yi Yang","Fei Wu"],"llm_authors":"Leilei Gan, Kun Kuang, Yi Yang, and Fei Wu","author_string":"Leilei Gan, Kun Kuang, Yi Yang, Fei Wu","year":2021,"abstract":"","llm_abstract":"Legal Judgment Prediction (LJP) is a key problem in legal artificial intelligence, which aims to predict a law case’s judgment based on a given text describing the facts of the law case. Most of previous works treat LJP as a text classification task and generally adopt deep neural networks (DNNs) based methods to solve it. However, existing DNNs based models are data thirsty and hard to explain which legal knowledge is based on to make such a prediction. Thus, injecting legal knowledge into neural networks to interpret the model and improve performance remains a significant problem. In this paper, we propose to represent declarative legal knowledge as a set of first-order logic rules and integrate these logic rules into a co-attention network-based model explicitly. The use of logic rules enhances neural networks with direct logical reasoning capabilities and makes the model more interpretable. We take private loan scenario as a case study and demonstrate the effectiveness of the proposed method through comprehensive experiments and analyses conducted on the collected dataset.","llm_keywords":["Legal Judgment Prediction","Neural Networks","Legal Knowledge","Interpretable AI","First-Order Logic","Text Classification","Deep Learning","Artificial Intelligence","Private Loan Scenarios"],"classifications":["Classification","Information Extraction"],"num_cited_by":62,"num_cited_by_title_only":62,"num_pages":9},{"id":"4fa2ea6c1ff2f089c9bdc531fb497e2316e9171974486d9c7801c91da0ea4d38e1712d4fbcff772961d719d1e1ee6b81383256c88936a72b20cc04bd323037d1","file_path":"legal-nlp-survey-20250328-002/original/Souza_2021_0386.pdf","title":"","llm_title":"An Information Retrieval Pipeline for Legislative Documents from the Brazilian Chamber of Deputies","authors":["Ellen Souza","Douglas Vitorio","Gyovana Moriyama","Luiz Santos","Lucas Martins","Mariana Souza","Marcio Fonseca","Nadia Felix","Andre C. P. L. F. Carvalho","Hidelberg O. Albuquerque","Adriano L. I. Oliveira"],"llm_authors":"Ellen SOUZA, Douglas VITORIO, Gyovana MORIYAMA, Luiz SANTOS, Lucas MARTINS, Mariana SOUZA, Marcio FONSECA, Nadia FELIX, Andre C. P. L. F. CARVALHO, Hidelberg O. ALBUQUERQUE, Adriano L. I. OLIVEIRA","author_string":"","year":2021,"abstract":"","llm_abstract":"This work investigates information retrieval methods to address the existing difficulties on the Preliminary Search, part of the law making process from the Brazilian Chamber of Deputies. For such, different preprocessing approaches, stemmers, language models, and BM25 variants were compared. Two legislative corpora from Chamber were used to build and validate the pipeline. All texts were converted to lowercase and had stopwords, accentuation, and punctuation removed. Words were represented by their stem combined with word unigram and bigram language models. Retrieving the bill that was originated from a specific job request, the BM25L with Savoy stemmer reached a R@20 of 0.7356. After removing queries with inconsistencies or which made reference exclusively to attachments, to other job requests, or to bills, the R@20 increased to 0.94.","llm_keywords":["Legal Information Retrieval","Legislative Document Retrieval","Brazilian Portuguese","BM25","Preliminary Search","Information Retrieval Pipeline"],"classifications":["Information Retrieval","Pre-Processing"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":8},{"id":"7332f51934e343aee2cc66ad103ec8eb6fdc2c9ba0e161dae1e95f02281f629566344402e88ea5a5a0ef1958f2cf32a544c1025d2ba888e379df240f34adfcb8","file_path":"legal-nlp-survey-20250328-002/original/Kalouli_2018_0171.pdf","title":"","llm_title":"CoUSBi: A Structured and Visualized Legal Corpus of US State Bills","authors":["Aikaterini-Lida Kalouli","Leo Vrana","Vigile Marie Fabella","Luna Bellani","Annette Hautli-Janisz"],"llm_authors":"Aikaterini-Lida Kalouli, Leo Vrana, Vigile Marie Fabella, Luna Bellani, Annette Hautli-Janisz","author_string":"","year":2018,"abstract":"","llm_abstract":"This paper reports on an approach to automatically transform semi-structured and public databases of US state-level legislative bills into a structured, legal corpus, namely the Corpus of US Bills (CoUSBi). Our work has resulted in a methodology and a corpus that makes this data usable for natural language processing applications. It thus also lays important groundwork for work in the social sciences, particularly in the fields of political science and economics where there is a growing interest in the relationship between legislative policy-making and economic behavior. Against the backdrop of eventually contributing to a Legal Knowledge Graph, the paper shows that the corpus we provide already fulfills the requirements to be connected to other resources: We automatically extract correspondences between individual state bills and model bills from independent organizations, generating interesting insights into the legislative process. We furthermore use NEREx, a Visual Analytics framework, that allows us to capture important content of the bills at a glance.","llm_keywords":["Resource development","US state bills","model bills","Visual Analytics","legal corpus","NLP","Legislative Knowledge Graph"],"classifications":["Information Extraction"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":8},{"id":"7b6118af45d8766e7bc33f0dfe14ff8f8247c36609e01ad76a4f01b08868c2f4b6574fef7b72d99f00efa4eb66a5fcaf21160998d0e18a71020caf735a8b15fb","file_path":"legal-nlp-survey-20250328-002/original/John_2017_0138.pdf","title":"","llm_title":"Legalbot: a Deep Learning-Based Conversational Agent in the Legal Domain","authors":["Adebayo Kolawole John","Luigi Di Caro","Livio Robaldo","Guido Boella"],"llm_authors":"Adebayo Kolawole John, Luigi Di Caro, Livio Robaldo, and Guido Boella","author_string":"","year":2017,"abstract":"","llm_abstract":"This paper present a deep learning-based dialogue system which has been trained to answer user queries posed as questions during conversation. The proposed system, though generative, takes advantage of domain specific knowledge for generating valid answers. The evaluation analysis shows that the proposed system obtained a promising result.","llm_keywords":["Recurrent Neural Networks","Long Short-Term Memory","Chatbot","Conversational agent","Dialogue Systems","Machine Learning","Legal Domain","Seq2Seq model"],"classifications":["Text Generation"],"num_cited_by":26,"num_cited_by_title_only":26,"num_pages":6},{"id":"5c239f59238a6364ec133dabb6204921ff9b7b8a7138eac83b556378fdd5ef724f1f65e30c2dbcb381380a9c121146a848760ba70d2f7b7463f0417fed730bf7","file_path":"legal-nlp-survey-20250328-002/original/Kien_2020_0303.pdf","title":"Answering Legal Questions by Learning Neural Attentive Text Representation","llm_title":"Answering Legal Questions by Learning Neural Attentive Text Representation","authors":["Phi Manh Kien","Ha-Thanh Nguyen","Ngo Xuan Bach","Vu Tran","Minh Le Nguyen","Tu Minh Phuong"],"llm_authors":"Phi Manh Kien, Ha-Thanh Nguyen, Ngo Xuan Bach, Vu Tran, Minh Le Nguyen, Tu Minh Phuong","author_string":"Phi Manh Kien ; Ha-Thanh Nguyen ; Ngo Xuan Bach ; Vu Tran ; Minh Le Nguyen ; Tu Minh Phuong","year":2020,"abstract":"","llm_abstract":"Text representation plays a vital role in retrieval-based question answering, especially in the legal domain where documents are usually long and complicated. The better the question and the legal documents are represented, the more accurate they are matched. In this paper, we focus on the task of answering legal questions at the article level. Given a legal question, the goal is to retrieve all the correct and valid legal articles, that can be used as the basic to answer the question. We present a retrieval-based model for the task by learning neural attentive text representation. Our text representation method first leverages convolutional neural networks to extract important information in a question and legal articles. Attention mechanisms are then used to represent the question and articles and select appropriate information to align them in a matching process. Experimental results on an annotated corpus consisting of 5,922 Vietnamese legal questions show that our model outperforms state-of-the-art retrieval-based methods for question answering by large margins in terms of both recall and NDCG.","llm_keywords":["neural attentive text representation","retrieval-based question answering","legal questions","convolutional neural networks","attention mechanisms","deep neural networks","text representation","legal domain"],"classifications":["Information Retrieval"],"num_cited_by":65,"num_cited_by_title_only":65,"num_pages":11},{"id":"2060e13310ffd4e11b3b1d48e1d2b802e6a8f3025ce6dad3bc9a535b7f257939ca259e30e43e4334c72876dd2ed90c8e707f628ed8fe6cf8ceeac2c95756c97f","file_path":"legal-nlp-survey-20250328-002/original/Panagis_2016_0098.pdf","title":"","llm_title":"On top of topics: leveraging topic modeling to study the dynamic case-law of international courts","authors":["Yannis Panagis","Martin Lolle Christensen","Urška Šadl"],"llm_authors":"Yannis PANAGIS, Martin Lolle CHRISTENSEN, Urška ŠADL","author_string":"","year":2017,"abstract":"","llm_abstract":"Legal scholars study international courts by analyzing only a fraction of available material, which leaves doubts as to whether their accounts correctly capture the dynamics of international law. In this paper we use dynamic topic modeling, a family of unsupervised machine learning techniques, to gauge the shifts in the content of the case-law of international courts over longer time spans. Our results indicate that dynamic topic modeling is a powerful and reliable tool to systematically and accurately track legal change over time and enhance our understanding of courts and their influence on the law.","llm_keywords":["Machine Learning","Topic modeling","Case-law","Court of Justice of the EU","European Court of Human Rights"],"classifications":["Classification","Information Retrieval","Information Extraction","Resources"],"num_cited_by":1,"num_cited_by_title_only":19,"num_pages":6},{"id":"5c5d45b80a64278fb13475b6e44990b61df04f1706545947c98bf935cea0368904c8d8c55cb66bb7ee34c6e9386bfcab444587bde0f72a57cecfce2225b95045","file_path":"legal-nlp-survey-20250328-002/original/Simonson_2021_0470.pdf","title":"Supervised Identification of Participant Slots in Contracts","llm_title":"Supervised Identification of Participant Slots in Contracts","authors":["Dan Simonson"],"llm_authors":"Dan Simonson","author_string":"Dan Simonson","year":2021,"abstract":"","llm_abstract":"This paper presents a technique for the identification of participant slots in English language contracts. Taking inspiration from unsupervised slot extraction techniques, the system presented here uses a supervised approach to identify terms used to refer to a genre-specific slot in novel contracts. We evaluate the system in multiple feature configurations to demonstrate that the best performing system in both genres of contracts omits the exact mention form from consideration—even though such mention forms are often the name of the slot under consideration—and is instead based solely on the dependency label and parent; in other words, a more reliable quantification of a party’s role in a contract is found in what they do rather than what they are named.","llm_keywords":["participant slots","contracts","supervised learning","legal language processing","NLP","slot identification"],"classifications":["Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":9},{"id":"0a6e1151d4847ed3e9bf49f1b2b0d0c2879cb66ae3042076468894b32f7290f3759ca0b28354f075d83c09c7fd20a17afbd6dcec45980252909bf8e459b508ef","file_path":"legal-nlp-survey-20250328-002/original/Merchant_2018_0198.pdf","title":"NLP Based Latent Semantic Analysis for Legal Text Summarization","llm_title":"NLP Based Latent Semantic Analysis for Legal Text Summarization","authors":["Kaiz Merchant","Yash Pande"],"llm_authors":"Kaiz Merchant, Yash Pande","author_string":"","year":2018,"abstract":"","llm_abstract":"It is very essential for lawyers and ordinary citizens to do an exhaustive research related to their case before they answer questions in court. For quite some time they have had to read extremely long judgements and try to pick out the useful information from them or hire legal editors to create summaries. We propose an automated text summarization system that generates short and useful summaries from lengthy judgements. We make use of a natural language processing technique called latent semantic analysis (LSA) to capture concepts within a single document. We use two approaches- a single document untrained approach and a multi-document trained approach depending on the type of input case (criminal or civil). Our data was collected from official government sites that included Supreme Court, high court and district court cases and our model achieved an average ROGUE-1 score of 0.58. Finally, our system was approved by professional lawyers. In the future we aim to provide better continuity within our generated summaries and evaluate our system more accurately.","llm_keywords":["Latent semantic analysis","legal","text summarization","natural language processing","automated text summarization","legal text processing"],"classifications":["Machine Summarization"],"num_cited_by":128,"num_cited_by_title_only":128,"num_pages":5},{"id":"0209e6c2fc920d824f2ba9485890bb872009fd2eb4be484ee0185ac4fffe72bf3b9551baa84cdf92b57557b37324280e9e7edbd4c5300c90f830e2223ee7fc0f","file_path":"legal-nlp-survey-20250328-002/original/Joshi_2022_0564.pdf","title":"","llm_title":"Investigating Strategies for Clause Recommendation","authors":["Sagar Joshi","Sumanth Balaji","Jerrin Thomas","Aparna Garimella","Vasudeva Varma"],"llm_authors":"Sagar JOSHI, Sumanth BALAJI, Jerrin THOMAS, Aparna GARIMELLA, Vasudeva VARMA","author_string":"","year":2022,"abstract":"","llm_abstract":"Clause recommendation is the problem of recommending a clause to a legal contract, given the context of the contract in question and the clause type to which the clause should belong. With not much prior work being done toward the generation of legal contracts, this problem was proposed as a first step toward the bigger problem of contract generation. As an open-ended text generation problem, the distinguishing characteristics of this problem lie in the nature of legal language as a sublanguage and the considerable similarity of textual content within the clauses of a specific type. This similarity aspect in legal clauses drives us to investigate the importance of similar contracts’ representation for recommending clauses. In our work, we experiment with generating clauses for 15 commonly occurring clause types in contracts expanding upon the previous work on this problem and analyzing clause recommendations in varying settings using information derived from similar contracts.","llm_keywords":["Clause recommendation","Legal contracts","Legal NLP","AI-driven assistance","Contract drafting"],"classifications":["Text Generation","Resources","Information Retrieval"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":10},{"id":"9c5df8ba11b8da93e65b8af0922a2db8940d8f673635626f97e7c34b1e963a0ee804a729ec3d855965ce9d2dcac2cc64a3ba99b776dd6ea99a79f7180096e1ef","file_path":"legal-nlp-survey-20250328-002/original/Bergam_2022_0569.pdf","title":"","llm_title":"Legal and Political Stance Detection of SCOTUS Language","authors":["Noah Bergam","Emily Allaway","Kathleen McKeown"],"llm_authors":"Noah Bergam, Emily Allaway, Kathleen McKeown","author_string":"","year":2022,"abstract":"","llm_abstract":"We analyze publicly available US Supreme Court documents using automated stance detection. In the first phase of our work, we investigate the extent to which the Court’s public-facing language is political. We propose and calculate two distinct ideology metrics of SCOTUS justices using oral argument transcripts. We then compare these language-based metrics to existing social scientific measures of the ideology of the Supreme Court and the public. Through this cross-disciplinary analysis, we find that justices who are more responsive to public opinion tend to express their ideology during oral arguments. This observation provides a new kind of evidence in favor of the attitudinal change hypothesis of Supreme Court justice behavior. As a natural extension of this political stance detection, we propose the more specialized task of legal stance detection with our new dataset SC-stance, which matches written opinions to legal questions. We find competitive performance on this dataset using language adapters trained on legal documents.","llm_keywords":["stance detection","Supreme Court","ideology metrics","public opinion","attitudinal change hypothesis","oral arguments","legal stance detection","SC-stance dataset","language adapters"],"classifications":["Classification"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":11},{"id":"7a144e4fd7a144b1a0dc0f79bf6421136cd3a002ad95d953139026ea40936c7c20f2363fe89f86d5a97b31462353809499f864cac60f0fdbf27645d73f73776f","file_path":"legal-nlp-survey-20250328-002/original/Xiao_2021_0436.pdf","title":"Lawformer: A pre-trained language model for Chinese legal long documents","llm_title":"Lawformer: A pre-trained language model for Chinese legal long documents","authors":["Chaojun Xiao","Xueyu Hu","Zhiyuan Liu","Cunchao Tu","Maosong Sun"],"llm_authors":"Chaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, Maosong Sun","author_string":"Chaojun Xiao","year":2021,"abstract":"","llm_abstract":"Legal artificial intelligence (LegalAI) aims to benefit legal systems with the technology of artificial intelligence, especially natural language processing (NLP). Recently, inspired by the success of pre-trained language models (PLMs) in the generic domain, many LegalAI researchers devote their effort to applying PLMs to legal tasks. However, utilizing PLMs to address legal tasks is still challenging, as the legal documents usually consist of thousands of tokens, which is far longer than the length that mainstream PLMs can process. In this paper, we release the Longformer-based pre-trained language model, named as Lawformer, for Chinese legal long documents understanding. We evaluate Lawformer on a variety of LegalAI tasks, including judgment prediction, similar case retrieval, legal reading comprehension, and legal question answering. The experimental results demonstrate that our model can achieve promising improvement on tasks with long documents as inputs. The code and parameters are available at https://github.com/thunlp/LegalPLMs.","llm_keywords":["Pre-trained language model","Legal artificial intelligence","Natural language processing","Long documents","Judgment prediction","Case retrieval","Reading comprehension","Question answering","Chinese legal documents"],"classifications":["Resources","Information Retrieval","Classification"],"num_cited_by":256,"num_cited_by_title_only":256,"num_pages":6},{"id":"1ee2c4a2710e8c9629758ab72f83338bc3b6b4546ba8af0eb29b3af83d7e21fc0db9e9c2dfe4332dd233e85c74401c382f58297a2f78dd21e5cadff90d3e4893","file_path":"legal-nlp-survey-20250328-002/original/Zhang_2021_0439.pdf","title":"TALLIP2103-55","llm_title":"Legal Judgment Elements Extraction Approach with Law Article-aware Mechanism","authors":["Hu Zhang","Bangze Pan","Ru Li"],"llm_authors":"HU ZHANG, BANGZE PAN, RU LI","author_string":"","year":2021,"abstract":"","llm_abstract":"Legal judgment elements extraction (LJEE) aims to identify the different judgment features from the fact description in legal documents automatically, which helps to improve the accuracy and interpretability of the judgment results. In real court rulings, judges usually need to scan both the fact descriptions and the law articles repeatedly to find out the relevant information, and it is hard to acquire the key judgment features quickly, so legal judgment elements extraction is a crucial and challenging task for legal judgment prediction. However, most existing methods follow the text classification framework, which fails to model the attentive relations of the law articles and the legal judgment elements. To address this issue, we simulate the working process of human judges, and propose a legal judgment elements extraction method with a law article-aware mechanism, which captures the complex semantic correlations of the law article and the legal judgment elements. Experimental results show that our proposed method achieves significant improvements than other state-of-the-art baselines on the element recognition task dataset. Compared with the BERT-CNN model, the proposed “All labels Law Articles Embedding Model (ALEM)” improves the accuracy, recall, and F1 value by 0.5, 1.4 and 1.0, respectively.","llm_keywords":["Legal judgment elements extraction","Law article-aware mechanism","Natural language processing","Intelligent justice","Artificial intelligence"],"classifications":["Information Extraction"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":15},{"id":"070f391bb909b0d5531618507f7492decc144fba5894dbfc075f3f5fa2aba0efc33e83f4f5ac4a00a70928a08fb340316391303af36246be63b2dc8e2ce6ee56","file_path":"legal-nlp-survey-20250328-002/original/Ash_2019_0292.pdf","title":"","llm_title":"The Making of International Tax Law: Empirical Evidence from Natural Language Processing","authors":["Elliott Ash","Omri Marian"],"llm_authors":"Elliott Ash & Omri Marian","author_string":"Omri Marian","year":2018,"abstract":"","llm_abstract":"We offer the first attempt at empirically testing the level of transnational consensus on the legal language controlling international tax matters. We also investigate the institutional framework of such consensus-building. We build a dataset of 4,052 bilateral income tax treaties, as well as 16 model tax treaties published by the United Nations (UN), Organisation for Economic Co-operation and Development (OECD) and the United States. We use natural language processing to perform pair-wise comparison of all treaties in effect at any given year. We identify clear trends of convergence of legal language in bilateral tax treaties since the 1960s, particularly on the taxation of cross-border business income. To explore the institutional source of such consensus, we compare all treaties in effect at any given year to the model treaties in effect during that year. We also explore whether newly concluded treaties converge towards legal language in newly introduced models. We find the OECD Model Tax Convention (OECD Model) to have a significant influence. In the years following the adoption of a new OECD Model there is a clear trend of convergence in newly adopted bilateral tax treaties towards the language of the new OECD Model. We also find that model treaties published by the UN (UN Model) have little immediate observable effect, though UN treaty policies seem to have a delayed, yet lasting effect. We conclude that such findings support the argument that a trend towards international legal consensus on certain tax matters exists, and that the OECD is the institutional source of the consensus building process.","llm_keywords":["International Tax Law","Natural Language Processing","Bilateral Tax Treaties","OECD Model","UN Model","Consensus Building","Cross-Border Transactions","Legal Language Convergence","International Institutions"],"classifications":["Information Retrieval"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":47},{"id":"9548a2e99701da0a828b3a51b9184afc119bc90f51f75f803462b8a925f110055e53993be6679dc451ea4e055e1adaf3640582c638ef82ef390ce4cddd419b1a","file_path":"legal-nlp-survey-20250328-002/original/Anglin_2019_0247.pdf","title":"","llm_title":"Gather-Narrow-Extract: A Framework for Studying Local Policy Variation Using Web-Scraping and Natural Language Processing","authors":["Kylie L. Anglin"],"llm_authors":"Kylie L. Anglin","author_string":"","year":2020,"abstract":"","llm_abstract":"Education researchers have traditionally faced severe data limitations in studying local policy variation; administrative data sets capture only a fraction of districts’ policy decisions, and it can be expensive to collect more nuanced implementation data from teachers and leaders. Natural language processing and web-scraping techniques can help address these challenges by assisting researchers in locating and processing policy documents located online. School district policies and practices are commonly documented in student and staff manuals, school improvement plans, and meeting minutes that are posted for the public. This article introduces an end-to-end framework for collecting these sorts of policy documents and extracting structured policy data: The researcher gathers all potentially relevant documents from district websites, narrows the text corpus to spans of interest using a text classifier, and then extracts specific policy data using additional natural language processing techniques. Through this framework, a researcher can describe variation in policy implementation at the local level, aggregated across state- or nationwide populations even as policies evolve over time.","llm_keywords":["NLP","web-scraping","machine learning","implementation","Districts of Innovation"],"classifications":["Information Retrieval","Classification","Information Extraction","Pre-Processing"],"num_cited_by":14,"num_cited_by_title_only":31,"num_pages":23},{"id":"80bc7452b12e8904d20b71da8c967e0b7cddb5ab6ba004be39e91482c3a73d1d662923668df880754c596cec10d35857f63985eeab13f0215e5565711332122b","file_path":"legal-nlp-survey-20250328-002/original/Gheewala_2019_0225.pdf","title":"","llm_title":"Automatic Extraction of Legal Citations using Natural Language Processing","authors":["Akshita Gheewala","Chris Turner","Jean-Rémi de Maistre"],"llm_authors":"Akshita Gheewala, Chris Turner, Jean-Rémi de Maistre","author_string":"","year":2019,"abstract":"","llm_abstract":"The accessibility of legal documents to the different actors of the judicial system needs to be ensured for the implementation of a strong international rule of law. The gap of such accessibility is being addressed by the Jus Mundi multilingual search-engine for International Law. The data updated on this platform is qualified by skilled lawyers. However, the interconnection of references within such documents, is a key feature for lawyers since, a major part of the legal research is analysing such citations to support their arguments. The process of interconnecting such references can prove to be expensive as well as time-consuming, if completed manually. Hence, the purpose of this research is to automatically extract such legal citations within international law, using Natural Language Processing (NLP), enabling the interconnectivity of documents on Jus Mundi. This study also discusses and addresses research gaps within this subject, especially in the domain specific to International Law. The method followed to achieve the automation is building an adaptable model through Regular-Expression based annotation language named JAPE (Java Annotation Patterns Engine). This set of automatically extracted links are then to be integrated with the search engine, having direct implication in the enablement of smoother navigation, making the law more accessible. This research also contributes to the state of the art bringing closer the eventual use of NLP in applications used to interact with International Law documents.","llm_keywords":["Natural Language Processing","International Law","Legal Citations","Java Annotation Patterns Engine","Jus Mundi","automation","legal documents","search engine","regular-expression","pattern recognition"],"classifications":["Information Extraction","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":9},{"id":"c4ba0de91c7b0a33a6783172344bb0fb8d09ba7f80a9b179e5515dd0ffead770462934ebf3439f86432f054166d356042e22774044fac0b1f707e21ae86d3efc","file_path":"legal-nlp-survey-20250328-002/original/Jallan_2019_0220.pdf","title":"Application of Natural Language Processing and Text Mining to Identify Patterns in Construction-Defect Litigation Cases","llm_title":"Application of Natural Language Processing and Text Mining to Identify Patterns in Construction-Defect Litigation Cases","authors":["Yashovardhan Jallan","Elizabeth Brogan","Baabak Ashuri","Caroline M. Clevenger"],"llm_authors":"Yashovardhan Jallan, Elizabeth Brogan, Baabak Ashuri, Caroline M. Clevenger","author_string":"https://orcid.org/0000-0002-2076-0133Yashovardhan Jallan, S.M.ASCE1; Elizabeth Brogan, P.E., A.M.ASCE2; Baabak Ashuri, Ph.D., M.ASCE3; and https://orcid.org/0000-0003-2265-8447Caroline M. Clevenger, Ph.D., P.E., M.ASCE41Ph.D. Student, School of Civil and Environmental Engineering, Georgia Institute of Technology, Atlanta, GA 30332. ORCID: https://orcid.org/0000-0002-2076-0133. Email: yjallan@gatech.edu2Ph.D. Student, Construction Engineering and Management, Dept. of Civil Engineering, Univ. of Colorado Denver, 1200 Larimer, Denver, CO 80204. Email: elizabeth.brogan@ucdenver.edu3Associate Professor, School of Building Construction and School of Civil and Environmental Engineering, Georgia Institute of Technology, Atlanta, GA 30332. Email: baabak.ashuri@coa.gatech.edu4Associate Professor, Construction Engineering and Management, Dept. of Civil Engineering, Univ. of Colorado Denver, 1200 Larimer, Denver, CO 80204 (corresponding author). ORCID: https://orcid.org/0000-0003-2265-8447. Email: caroline.clevenger@ucdenver.edu","year":2019,"abstract":"","llm_abstract":"Recently, construction-defect litigation has upsurged across the United States. Disputes arise due to a variety of reasons, and result in a range of negative impacts on construction projects, such as increased cost, delay, profit loss, and inconvenience. Although the majority of these disputes settle out of court, a public trail of legal records exists. Previous research has generally been limited to exploring a small subset of such cases based on restricted access to records and data. This ongoing research automates systematic exploration of construction-defect lawsuits in the public domain by using modern computational capabilities of natural language processing and text mining to conduct a comprehensive survey of legal cases over the last 10 years. The approach of this research is to use coded text mining to automatically identify and analyze thousands of publicly available construction-defect cases. To perform such research, the authors developed a program that trolls the national legal database, LexisNexis. Key contributions include the development of a model that can find the frequencies of keywords in the cases and apply a statistical algorithm called Latent Dirichlet Allocation (LDA) to identify important topics and themes in order to classify the case data. The research demonstrates new methods for exploring publicly available construction-defect cases. Major challenges are identified and discussed. As exploratory research, the findings are intended to inform and motivate future study, which may lead to identification of broad-based trends in construction-defect litigation.","llm_keywords":["natural language processing","text mining","construction-defect litigation","LexisNexis","Latent Dirichlet Allocation","public legal filings","patterns","themes","legal records"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":71,"num_cited_by_title_only":71,"num_pages":6},{"id":"22928b025ea38970830948302aaeb962932edcd3391ef1c0ea75411d6cd3a05c4c8f27152785f35313f1d9c6b0f67a53079f811a8d07d6dc14a57c8f7a96e997","file_path":"legal-nlp-survey-20250328-002/original/Boella_2014_0033.pdf","title":"","llm_title":"Learning from syntax generalizations for automatic semantic annotation","authors":["Guido Boella","Luigi Di Caro","Alice Ruggeri","Livio Robaldo"],"llm_authors":"Guido Boella, Luigi Di Caro, Alice Ruggeri, Livio Robaldo","author_string":"","year":2014,"abstract":"","llm_abstract":"Nowadays, there is a huge amount of textual data coming from on-line social communities like Twitter or encyclopedic data provided by Wikipedia and similar platforms. This Big Data Era created novel challenges to be faced in order to make sense of large data storages as well as to efficiently find specific information within them. In a more domain-specific scenario like the management of legal documents, the extraction of semantic knowledge can support domain engineers to find relevant information in more rapid ways, and to provide assistance within the process of constructing application-based legal ontologies. In this work, we face the problem of automatically extracting structured knowledge to improve semantic search and ontology creation on textual databases. To achieve this goal, we propose an approach that first relies on well-known Natural Language Processing techniques like Part-Of-Speech tagging and Syntactic Parsing. Then, we transform these information into generalized features that aim at capturing the surrounding linguistic variability of the target semantic units. These new featured data are finally fed into a Support Vector Machine classifier that computes a model to automate the semantic annotation. We first tested our technique on the problem of automatically extracting semantic entities and involved objects within legal texts. Then, we focus on the identification of hypernym relations and definitional sentences, demonstrating the validity of the approach on different tasks and domains.","llm_keywords":["Ontology learning","Automatic annotation","Information extraction","Semantic search","Natural Language Processing","Legal documents","Structured knowledge","Syntactic parsing","Support Vector Machine","Semantic annotation"],"classifications":["Information Extraction","Classification"],"num_cited_by":47,"num_cited_by_title_only":47,"num_pages":16},{"id":"f1ae7b8cf4625cb910249bf021c088fac254ea2384e033dbab477e29624249937feea5ffa02a21e82892d96ab2cac6d5a812532b1f09e15afd36012c47029fdc","file_path":"legal-nlp-survey-20250328-002/original/Zhong_2020_0332.pdf","title":"Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction","llm_title":"Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction","authors":["Haoxi Zhong","Yuzhong Wang","Cunchao Tu","Tianyang Zhang","Zhiyuan Liu","Maosong Sun"],"llm_authors":"Haoxi Zhong, Yuzhong Wang, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun","author_string":"Haoxi Zhong,Yuzhong Wang,Cunchao Tu,Tianyang Zhang,Zhiyuan Liu,Maosong Sun","year":2020,"abstract":"","llm_abstract":"Legal Judgment Prediction (LJP) aims to predict judgment results according to the facts of cases. In recent years, LJP has drawn increasing attention rapidly from both academia and the legal industry, as it can provide references for legal practitioners and is expected to promote judicial justice. However, the research to date usually suffers from the lack of interpretability, which may lead to ethical issues like inconsistent judgments or gender bias. In this paper, we present QAjudge, a model based on reinforcement learning to visualize the prediction process and give interpretable judgments. QAjudge follows two essential principles in legal systems across the world: Presumption of Innocence and Elemental Trial. During inference, a Question Net will select questions from the given set, and an Answer Net will answer the question according to the fact description. Finally, a Predict Net will produce judgment results based on the answers. Reward functions are designed to minimize the number of questions asked. We conduct extensive experiments on several real-world datasets. Experimental results show that QAjudge can provide interpretable judgments while maintaining comparable performance with other state-of-the-art LJP models.","llm_keywords":["Legal Judgment Prediction","LJP","Interpretability","Reinforcement Learning","QAjudge","Presumption of Innocence","Elemental Trial","Ethical Issues","Deep Learning"],"classifications":["Classification","Text Generation"],"num_cited_by":135,"num_cited_by_title_only":135,"num_pages":8},{"id":"0635be1c69add090b6b028cfaf9fbc3075a274fa9c4266601f62acc0e673e53600f53a5c01094bbb1528baf07a17e95c0cf86ad83db90cfbcdef46f643affad1","file_path":"legal-nlp-survey-20250328-002/original/Wagh_2017_0113.pdf","title":"untitled","llm_title":"Application of Citation Network Analysis for Improved Similarity Index Estimation of Legal Case Documents : A study","authors":["Rupali Wagh","Deepa Anand"],"llm_authors":"Rupali Wagh, Deepa Anand","author_string":"","year":2018,"abstract":"","llm_abstract":"With the availability of information in online databases, information retrieval has become back bone of many processes today. Significant share of this online data comprises of unstructured and textual data. There are many domains like legal domain which rely solely on information stored in various legal documents. Legal domain is considered to be very complex and its processes are largely dependent on knowledge interpretation by human expert. Establishing relevance and similarity between two cases based on expositions in various legal documents is the most common but non trivial task performed by a legal expert. This paper discusses application of network analysis to compare two approaches for finding legal document similarity – a) Cosine similarity b) Citation based similarity. Results show that citation based similarity measure is more robust in determining parallel among cases.","llm_keywords":["Document similarity","Legal documents","Citation network","tf-idf scoring","Cosine similarity"],"classifications":[],"num_cited_by":21,"num_cited_by_title_only":25,"num_pages":5},{"id":"2d5751ff6c69ef57782f8a4bf95ba6e6a53da3a8b4f625203ee5d625137024323de63eca629092faf48648ca3963e0ff08f38ede76b40b933509485c055404b1","file_path":"legal-nlp-survey-20250328-002/original/Monroy_2013_0019.pdf","title":"LNCS 7817 - Computational Linguistics and Intelligent Text Processing","llm_title":"Link Analysis for Representing and Retrieving Legal Information","authors":["Alfredo López Monroy","Hiram Calvo","Alexander Gelbukh","Georgina García Pacheco"],"llm_authors":"Alfredo López Monroy, Hiram Calvo, Alexander Gelbukh, Georgina García Pacheco","author_string":"Alexander Gelbukh (ed.)","year":2018,"abstract":"","llm_abstract":"Legal texts consist of a great variety of texts, for example laws, rules, statutes, etc. This kind of documents has as an important feature, that they are strongly linked among them, since they include references from one part to another. This makes it difficult to consult them, because in order to satisfy an information request, it is necessary to gather several references and rulings from a single text, and even with other texts. The goal of this work is to help in the process of consulting legal rulings through their retrieval from a request expressed as a question in natural language. For this, a formal model is proposed; this model is based on a weighted, non-directed graph; nodes represent the articles that integrate each document, and its edges represent references between articles and their degree of similarity. Given a question, this is added to the graph, and by combining a shortest-path algorithm with edge weight analysis, a ranked list of articles is obtained. To evaluate the performance of the proposed model we gathered 8,987 rulings and evaluated the answer to 40 test-questions as correct, incorrect or partial. A lawyer validated the answer to these questions. We compared results with other systems such as Lucene and JIRS (Java Information Retrieval System)","llm_keywords":["legal information retrieval","link analysis","natural language processing","weighted graphs","shortest-path algorithm","legal texts","information request","document references","question answering","legal rulings"],"classifications":["Information Retrieval"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":15},{"id":"77372d55863e93aed0598f18bcebdbd46695de7ca3c0560de1a39dbf9fa269019e1676c9872508426887bd098e4484f1a8a2094e3846fd28167d9197cafc40ba","file_path":"legal-nlp-survey-20250328-002/original/Nanda_2017_0119.pdf","title":"","llm_title":"Concept Recognition in European and National Law","authors":["Rohan Nanda","Giovanni Siragusa","Luigi Di Caro","Martin Theobald","Guido Boella","Livio Robaldo","Francesco Costamagna"],"llm_authors":"Rohan NANDA, Giovanni SIRAGUSA, Luigi DI CARO, Martin THEOBALD, Guido BOELLA, Livio ROBALDO, Francesco COSTAMAGNA","author_string":"","year":2017,"abstract":"","llm_abstract":"This paper presents a concept recognition system for European and national legislation. Current named entity recognition (NER) systems do not focus on identifying concepts which are essential for interpretation and harmonization of European and national law. We utilized the IATE (Inter-Active Terminology for Europe) vocabulary, a state-of-the-art named entity recognition system and Wikipedia to generate an annotated corpus for concept recognition. We applied conditional random fields (CRF) to identify concepts on a corpus of European directives and Statutory Instruments (SIs) of the United Kingdom. The CRF-based concept recognition system achieved an F1 score of 0.71 over the combined corpus of directives and SIs. Our results indicate the usability of a CRF-based learning system over dictionary tagging and state-of-the-art methods.","llm_keywords":["Concept Recognition","European Law","Information Retrieval","Named Entity Recognition","Conditional Random Fields","Legal Texts","Harmonization","Integration","Vocabulary","Ontology"],"classifications":["Information Extraction","Classification"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":6},{"id":"f182be1dbfcb1c48787108c057cf4e766858911e5e4cabc828a9667a98e18f9d35f07c9617c2190987f5d60f1bdbd37d76e65c3ceeb118aa1c931227854b5e87","file_path":"legal-nlp-survey-20250328-002/original/Shankar_2018_0173.pdf","title":"","llm_title":"Deep Ensemble Learning for Legal Query Understanding","authors":["Arunprasath Shankar","Venkata Nagaraju Buddarapu"],"llm_authors":"Arunprasath Shankar, Venkata Nagaraju Buddarapu","author_string":"","year":2019,"abstract":"","llm_abstract":"Legal query understanding is a complex problem that involves two natural language processing (NLP) tasks that needs to be solved together: (i) identifying intent of the user and (ii) recognizing entities within the queries. The problem equates to decomposing a legal query into its individual components and deciphering the underlying differences that can occur due to pragmatics. Identifying the desired intent and recognizing correct entities helps us return back relevant results to the user. Deep Neural Networks (DNNs) have recently achieved great success surpassing traditional statistical approaches. In this work, we experiment with several DNN architectures towards legal query intent classification and entity recognition. Deep Neural architectures like Recurrent Neural Networks (RNNs), Long Short Term Memory (LSTM), Convolutional Neural Networks (CNNs) and Gated Recurrent Units (GRU) were applied and compared against one another both individually and as combinations. The models were also compared against machine learning (ML) and rule-based approaches. In this paper, we describe a methodology that integrates posterior probabilities produced by the best DNN models and create a stacked framework for combining the different predictors to improve prediction accuracy and F-measure for legal intent classification and entity recognition.","llm_keywords":["Legal Query Understanding","Deep Neural Networks","Intent Classification","Entity Recognition","Recurrent Neural Networks","Convolutional Neural Networks","Machine Learning","Legal Search","Natural Language Processing"],"classifications":["Classification","Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":14,"num_pages":10},{"id":"519610553ca6edff8026e0e2bfeb264763edd709dbcc01184d0704e1f9a678746801d4de77e5bd8cd4685630d7c3123b1b8e20e25fcbe442027edea5ed5e3df3","file_path":"legal-nlp-survey-20250328-002/original/Sheik_2021_0411.pdf","title":"","llm_title":"Deep Learning Techniques for Legal Text Summarization","authors":["Reshma Sheik","S. Jaya Nirmala"],"llm_authors":"Reshma Sheik, Dr. S. Jaya Nirmala","author_string":"","year":2022,"abstract":"","llm_abstract":"Summarizing Legal Text data is a significant problem due to the extensive length and complexity involved in analyzing it. The advent of deep neural networks and their demanding application in Natural Language Processing(NLP) paves the way to conquer the legal domain text data. This paper proposes a systematic comparison of various deep learning strategies applied in summarizing Legal Texts. We begin the study with the introduction and evolution of different deep learning models used in text summarization. Through the work, we have identified the importance of various preparation mechanisms within deep learning to enhance the legal text summarization process. The work also focuses on reviewing existing deep learning models used recently in the legal domain for different types of summarization. Models employing the sequence to sequence neural network architecture with attention framework gained popularity and widened the scope of legal text summarization. It progressed with transfer learning to fine-tune the state of the art pre-trained language models, leading to better accuracy in summarization.","llm_keywords":["Deep learning","Legal Text Summarization","Natural Language Processing","Neural Networks","Transfer Learning","Sequence to Sequence","Attention Framework","Pre-trained Language Models","Summarization Techniques","Legal Domain"],"classifications":["Machine Summarization","Pre-Processing","Resources"],"num_cited_by":26,"num_cited_by_title_only":26,"num_pages":6},{"id":"0386e7f858c107d51fcd43ee4d3addabe82dd2b76cc724f84105d321ec3b3c3ff7002872b5a314cddaf1eb9434bb3de2ac52f09f95bf4512193ef91d661848f6","file_path":"legal-nlp-survey-20250328-002/original/Jayasinghe_2022_0552.pdf","title":"","llm_title":"Legal Case Winning Party Prediction With Domain Specific Auxiliary Models","authors":["Sahan Jayasinghe","Lakith Rambukkanage","Ashan Silva","Nisansa de Silva","Amal Shehan Perera"],"llm_authors":"Sahan Jayasinghe, Lakith Rambukkanage, Ashan Silva, Nisansa de Silva, Amal Shehan Perera","author_string":"","year":2022,"abstract":"","llm_abstract":"Sifting through hundreds of old case documents to obtain information pertinent to the case in hand has been a major part of the legal profession for centuries. However, with the expansion of court systems and the compounding nature of case law, this task has become more and more intractable with time and resource constraints. Thus automation by Natural Language Processing presents itself as a viable solution. In this paper, we discuss a novel approach for predicting the winning party of a current court case by training an analytical model on a corpus of prior court cases which is then run on the prepared text on the current court case. This will allow legal professionals to efficiently and precisely prepare their cases to maximize the chance of victory. The model is built with and experimented using legal domain specific sub-models to provide more visibility to the final model, along with other variations. We show that our model with critical sentence annotation with a transformer encoder using RoBERTa based sentence embedding is able to obtain an accuracy of 75.75%, outperforming other models.","llm_keywords":["Natural Language Processing","Legal Domain","Case Law","Transformer Encoders"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":9},{"id":"eeba4daa801e85a10309932f9c7964a39ee95c0b0e162a46fe99a706f9b6bdc34d1f7dafe2085d55f771cd9c98b5c9cddffbb9a587bd853e6dded9484aec125b","file_path":"legal-nlp-survey-20250328-002/original/Ashley_2022_0541.pdf","title":"Prospects for Legal Analytics: Some Approaches to Extracting More Meaning from Legal Texts","llm_title":"Prospects for Legal Analytics: Some Approaches to Extracting More Meaning from Legal Texts","authors":["Kevin D. Ashley"],"llm_authors":"Kevin D. Ashley","author_string":"Kevin D. Ashley","year":2022,"abstract":"","llm_abstract":"","llm_keywords":["Legal Analytics","Text Mining","Artificial Intelligence","Natural Language Processing","Machine Learning","Legal Reasoning","Argument Mining","Legal Texts","Legal Practice","Computational Models"],"classifications":[],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":35},{"id":"991661876670d90d31f3651bce8d1ef3327d6038085761be1d85e5a7a24046d767e16a5a2627a886a7ab13061d01b4c5862988bb04654a6bf5f1eed9f54b96cb","file_path":"legal-nlp-survey-20250328-002/original/Branting_2015_0063.pdf","title":"AI Approaches to the Complexity of Legal Systems","llm_title":"Inducing Predictive Models for Decision Support in Administrative Adjudication","authors":["Ugo Pagallo","L. Karl Branting","Alexander Yeh","Brandy Weiss","Elizabeth Merkhofer","Bradford Brown"],"llm_authors":"L. Karl Branting, Alexander Yeh, Brandy Weiss, Elizabeth Merkhofer, Bradford Brown","author_string":"Ugo Pagallo","year":2021,"abstract":"","llm_abstract":"Administrative adjudications are the most common form of legal decisions in many countries, so improving the efficiency, accuracy, and consistency of administrative processes could significantly benefit agencies and citizens alike. We explore the hypothesis that predictive models induced from previous administrative decisions can improve subsequent decision-making processes. This paper describes three datasets for exploring this hypothesis: motion-rulings, Board of Veterans Appeals (BVA) decisions; and World Intellectual Property Organization (WIPO) domain name dispute decisions. Three different approaches for prediction in these domains were tested: maximum entropy over token n-grams; SVM over token n-grams; and a Hierarchical Attention Network (HAN) applied to the full text. Each approach was capable of predicting outcomes, with the simpler WIPO cases appearing to be much more predictable than BVA or motion-ruling cases. We explore several approaches to using predictive models to identify salient phrases in the predictive texts (i.e., motion or contentions and factual background) and propose a design for incorporating this information into a decision-support tool.","llm_keywords":["predictive models","administrative adjudication","legal systems","case management","decision-support tool","machine learning","text analysis","SVM","maximum entropy","Hierarchical Attention Network"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":103,"num_cited_by_title_only":29,"num_pages":13},{"id":"6e7ef00e0c3c8d76eabfc216369390ffa4228d964fbff198812f96e6d68064403980c73866f6d80d87a63472045204e6d0252b016b69a794d93b13baa752da0b","file_path":"legal-nlp-survey-20250328-002/original/Branting_2019_0214.pdf","title":"173_Branting.pdf","llm_title":"ADEPT: Automated Directive Extraction from Policy Texts","authors":["K. Branting","S. Petersen","D. Shin","J. Finegan","C. Balhana","A. Lyte","C. Pfeifer"],"llm_authors":"K. Branting, S. Petersen, D. Shin, J. Finegan, C. Balhana, A. Lyte, C. Pfeifer","author_string":"","year":2019,"abstract":"","llm_abstract":"","llm_keywords":["directive sentences","policy documents","automated extraction","machine learning","text processing","legal text","sentence classification","U.S. Executive-branch policy directives"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":2},{"id":"13ce405d4824bfe9124fdedd96d3644815176cd453e4e7a65d1ea30002dbdaf0f2081fae9fdec6ecb6c669e0e6680570af95896d5ef3619f37b87a24668c9d0a","file_path":"legal-nlp-survey-20250328-002/original/Pothong_2022_0501.pdf","title":"Coreference Resolution and Meaning Representation in a Legislative Corpus","llm_title":"Coreference Resolution and Meaning Representation in a Legislative Corpus","authors":["Surawat Pothong","Nuttanart Facundes"],"llm_authors":"Surawat Pothong, Nuttanart Facundes","author_string":"Surawat Pothong; Nuttanart Facundes","year":2022,"abstract":"","llm_abstract":"This paper addresses the application and integration of coreferences resolution tasks in a legislative corpus by using SpanBERT, which is an improvement of the BERT (Bidirectional Encoder Representations from Transformers) model and semantic extraction by Abstract Meaning Representation (AMR) for reducing text complexity, meaning preservation and further applications. Our main processes are divided into four subparts: legal text pre-processing, coreference resolution, AMR, evaluation for meaning preservation, and complexity reduction. Smatch evaluation tool and Bilingual Evaluation Understudy (BLEU) scores are applied to evaluate overlapped meaning between resolved and unresolved coreference sentences. The AMR graphs after complexity have been reduced can be applied for further processing tasks with Neural Network such as legal inferencing and legal engineering tasks.","llm_keywords":["Coreference Resolution","Meaning Representation","SpanBERT","Abstract Meaning Representation","Natural Language Processing","Deep Learning","Machine Learning","Legal Text Processing"],"classifications":["Pre-Processing","Information Extraction","Resources","Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":6},{"id":"2b25374c379dfc66d9616cec426778ea0e9b3b7222af84b9f76a9876de4f4155fc91203e7777811608ac41204fb3d089a4b1a830728c949b4b998723b30ffb6f","file_path":"legal-nlp-survey-20250328-002/original/Sovrano_2020_0343.pdf","title":"","llm_title":"Legal Knowledge Extraction for Knowledge Graph Based Question-Answering","authors":["Francesco Sovrano","Monica Palmirani","Fabio Vitali"],"llm_authors":"Francesco Sovrano, Monica Palmirani, Fabio Vitali","author_string":"","year":2020,"abstract":"","llm_abstract":"This paper presents the Open Knowledge Extraction (OKE) tools combined with natural language analysis of the sentence in order to enrich the semantic of the legal knowledge extracted from legal text. In particular the use case is on international private law with specific regard to the Rome I Regulation EC 593/2008, Rome II Regulation EC 864/2007, and Brussels I bis Regulation EU 1215/2012. A Knowledge Graph (KG) is built using OKE and Natural Language Processing (NLP) methods jointly with the main ontology design patterns defined for the legal domain (e.g., event, time, role, agent, right, obligations, jurisdiction). Using critical questions, underlined by legal experts in the domain, we have built a question answering tool capable to support the information retrieval and to answer to these queries. The system should help the legal expert to retrieve the relevant legal information connected with topics, concepts, entities, normative references in order to integrate his/her searching activities.","llm_keywords":["Legal Knowledge Extraction","Question-Answering","Ontology Design Pattern Alignment","Knowledge Graph","Natural Language Processing","International Private Law","Rome I Regulation","Rome II Regulation","Brussels I bis Regulation","Semantic Enrichment"],"classifications":[],"num_cited_by":54,"num_cited_by_title_only":54,"num_pages":11},{"id":"c6b0db84b6bbd298b98e49934ee052333ee7ceb6877dde7d1c6e42ee36d091675576d78665753a14af7e06122dfc7dd8f666a7008f193dd64b11c752b7f6a43f","file_path":"legal-nlp-survey-20250328-002/original/Babafemi_2020_0354.pdf","title":"","llm_title":"Predicting and Analyzing Law-Making in Kenya","authors":["Oyinlola Babafemi","Adewale Akinfaderin"],"llm_authors":"Oyinlola Babafemi, Adewale Akinfaderin","author_string":"","year":2020,"abstract":"","llm_abstract":"Modelling and analyzing parliamentary legislation, roll-call votes and order of proceedings in developed countries has received significant attention in recent years. In this paper, we focused on understanding the bills introduced in a developing democracy, the Kenyan bicameral parliament. We developed and trained machine learning models on a combination of features extracted from the bills to predict the outcome - if a bill will be enacted or not. We observed that the texts in a bill are not as relevant as the year and month the bill was introduced and the category the bill belongs to.","llm_keywords":["Kenyan parliament","law-making","machine learning models","bills","legislation analysis","bicameral parliament","bill enactment prediction"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":4},{"id":"16dcc6292469a4630c03ffa5cbb1c8f811e70cc56f3036d4da5f35512042fc48bc3025a34ce654a4acb70a751a29529e432e66b6676cb4d9aca31512aefeb42d","file_path":"legal-nlp-survey-20250328-002/original/Araskiewicz_2022_0499.pdf","title":"","llm_title":"Computational Legal Problem Solving. What can Legal Tech Learn from AI and Law Research, and Beyond?","authors":["Michał Araszkiewicz"],"llm_authors":"Michał Araszkiewicz","author_string":"","year":2022,"abstract":"","llm_abstract":"","llm_keywords":["LegalTech","natural language processing","machine learning","legal reasoning","AI","legal interpretation","algorithmic legal reasoning","law-making","legal argumentation","digital transformation"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":30},{"id":"0ba644052c0aa2875bf59a92d342d86aed2876b7be01d83a2e7ba052b08c46d8e2e07b66b77266c343d2a86edcfefa4f5ba225d1d4a92cca2284e3e1d83e01d0","file_path":"legal-nlp-survey-20250328-002/original/Obanda_2022_0554.pdf","title":"Using Natural Language Processing for Case Brief Generation and Verdict Support in the Kenyan Court System","llm_title":"USING NATURAL LANGUAGE PROCESSING FOR CASE BRIEF GENERATION AND VERDICT SUPPORT IN THE KENYAN COURT SYSTEM","authors":["Sharon Obanda"],"llm_authors":"SHARON OBANDA","author_string":"Obanda Sharon","year":2022,"abstract":"","llm_abstract":"The National Council for Law Reporting publishes judgements in an online searchable database, enabling large-scale machine learning and statistical analysis in the legal domain. This is the culmination of the transformation that had been going on in the Judiciary inspired by the new requirements of public service delivery under the 2010 Constitution and the increased awareness and demand for legal information by the citizens. The Kenyan Judiciary is now continually seeking to apply creative, innovative, appropriate and integrated technological solutions that enable efficient service delivery. This research focuses on how to integrate Natural Language Processing (NLP) systems and Artificial Intelligence (AI) in document review, legal writing and legal case predictions in Kenya leveraging on NLP’s major purpose which is converting informal textual structures into formal representations for analysis. The aim is to demonstrate that NLP and Machine Learning (ML) algorithms can be exploited to provide a viable means of solving the problems bedeviling the Kenyan judicial system such as the increasing complexity of cases and huge backlog of cases in Kenyans courts. Using selected lawyers and advocates to provide expert labeling of the downloaded cases and sample legal case briefs to fine tune and evaluate the outcome of the summary models, NLP and AI algorithms were used to automatically generate case briefs with relevant precedent cases and the likely outcome of the verdict associated with the case submitted to the Kenyan Judiciary. The toolkit developed is a trained NLP and AI model that can generate case briefs and predetermined verdicts of the specific case with 88% and 83.7% levels of accuracy respectively. Considering the huge backlog of cases in Kenyans courts, coupled with the complexity of the cases, this research has demonstrated that NLP and ML can augment human abilities and provide a viable means of automating some aspects of the legal process such as case brief generation and verdict prediction. The toolkit developed, when fully implemented, will result in improving service delivery through facilitating speedier trials and enhancing the efficiency and effectiveness of administrative processes.","llm_keywords":["Kenya Judiciary","Case Briefs","Verdict Prediction","Legal Case Prediction","Natural Language Processing","Machine Learning"],"classifications":["Machine Summarization","Information Extraction","Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":43},{"id":"c52147c189198a5a72f880e00c9e91e710bf997dbb82a09bb63b8556ac287e2c071a81c71ccbf8e65b2155812f69dcbeee0cbd300a3d0c431387736ef952af94","file_path":"legal-nlp-survey-20250328-002/original/Surdeanu_2013_0014.pdf","title":"Identifying patent monetization entities","llm_title":"Identifying Patent Monetization Entities","authors":["Mihai Surdeanu","Sara Jeruss"],"llm_authors":"Mihai Surdeanu, Sara Jeruss","author_string":"Mihai Surdeanu, Sara Jeruss","year":2013,"abstract":"","llm_abstract":"The United States has seen an explosion in patent litigation lawsuits in recent years. Recent studies indicate that a large proportion of these lawsuits, increasing from 22% in 2007 to 40% in 2011, were filed by patent monetization entities (PMEs), i.e., companies that hold patents, license patents, and file patent lawsuits, but do not sell products or provide services practicing the technologies described in their patents. We introduce a classifier that identifies which patent litigation lawsuits are initiated by PMEs. Using features extracted from the entities’ litigation behavior, the patents they asserted, and their presence on the web, the proposed classifier correctly separates PMEs from operating companies with a F1 score of 85%. We believe that such a classifier will be a useful tool to policy makers and patent litigators, allowing them to gain a clearer picture of the 37,000+ patent lawsuits filed to date and assessing newly filed cases in real time.","llm_keywords":["patent monetization entities","PMEs","patent litigation","classifier","operating companies","intellectual property","patent licensing","litigation behavior"],"classifications":["Classification","Information Extraction"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":9},{"id":"2ebaf5311ee03e7a4ba64804a3248f716e11926800794b401281bde94e0f75a3d8f101f737a324864a928fc4c48d5119fad8238cc69fea228d66ce8afb0376d4","file_path":"legal-nlp-survey-20250328-002/original/Zhong_2018_0200.pdf","title":"","llm_title":"Overview of CAIL2018: Legal Judgment Prediction Competition","authors":["Haoxi Zhong","Chaojun Xiao","Zhipeng Guo","Cunchao Tu","Zhiyuan Liu","Maosong Sun","Yansong Feng","Xianpei Han","Zhen Hu","Heng Wang","Jianfeng Xu"],"llm_authors":"Haoxi Zhong, Chaojun Xiao, Zhipeng Guo, Cunchao Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng, Xianpei Han, Zhen Hu, Heng Wang, Jianfeng Xu","author_string":"","year":2018,"abstract":"","llm_abstract":"In this paper, we give an overview of the Legal Judgment Prediction (LJP) competition at Chinese AI and Law challenge (CAIL2018). This year’s competition focuses on LJP which aims to predict the judgment results according to the given facts. Specifically, in CAIL2018, we proposed three subtasks of LJP for the contestants, i.e., predicting relevant law articles, charges and prison terms given the fact descriptions. CAIL2018 has attracted several hundreds participants (601 teams, 1,144 contestants from 269 organizations). In this paper, we provide a detailed overview of the task definition, related works, outstanding methods and competition results in CAIL2018.","llm_keywords":["Legal Judgment Prediction","CAIL2018","artificial intelligence","law articles","charges","prison terms","machine learning","deep learning","natural language processing","criminal dataset"],"classifications":["Classification"],"num_cited_by":37,"num_cited_by_title_only":37,"num_pages":6},{"id":"e38853dcbc7f84842fe8ba15d25f2876d61e0a3cb275a762a2b5c4d639aaa3c0de298b6d45357966ddd8e610879df41cc053ad251041230965c52f67e01a88ee","file_path":"legal-nlp-survey-20250328-002/original/Mezghanni_2016_0093.pdf","title":"","llm_title":"Information Retrieval from Unstructured Arabic Legal Data","authors":["Imen Bouaziz Mezghanni","Faiez Gargouri"],"llm_authors":"Imen Bouaziz Mezghanni and Faiez Gargouri","author_string":"","year":2016,"abstract":"","llm_abstract":"Given the steady increase of published and stored information in the form of Arabic unstructured texts, current Information Retrieval (IR) systems must be able to suit the nature and requirements of this language for an accurate and efficient search. This paper sheds light on the challenges in Arabic IR (AIR) and proposes an approach for enhancing the process of AIR based on transforming these texts into structured documents in XML format through a document ontology as well as a set of linguistic grammars. The IR system hence is done on the XML documents. The aim of such system is to incorporate the knowledge on the document structure and on specific content elements in computing the relevance of an information element. A query expansion module mainly based on domain ontology as well as user profile is proposed for the enhancement of the search results.","llm_keywords":["Information retrieval","Arabic information retrieval","Unstructured data","Structured data"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"af81e738e42f355895c692331ab0952bc87b9a7b2c0007c87a52fff984e82adf162b83ee14fd3c56dffaaa0022aec786e2be7daa780292ab5fa7c72296e57615","file_path":"legal-nlp-survey-20250328-002/original/Keymanesh_2020_0370.pdf","title":"Toward Domain-Guided Controllable Summarization of Privacy Policies","llm_title":"Toward Domain-Guided Controllable Summarization of Privacy Policies","authors":["Moniba Keymanesh","Micha Elsner","Srinivasan Parthasarathy"],"llm_authors":"Moniba Keymanesh, Micha Elsner, Srinivasan Parthasarathy","author_string":"Moniba Keymanesh, Micha Elsner, and Srinivasan Parthasarathy","year":2020,"abstract":"","llm_abstract":"Companies’ privacy policies are often skipped by the users as they are too long, verbose, and difficult to comprehend. Identifying the key privacy and security risk factors mentioned in these unilateral contracts and effectively incorporating them in a summary can assist users in making a more informed decision when asked to agree to the terms and conditions. However, existing summarization methods fail to integrate domain knowledge into their framework or rely on a large corpus of annotated training data. We propose a hybrid approach to identify sections of privacy policies with a high privacy risk factor. We incorporate these sections into summaries by selecting the riskiest content from different privacy topics. Our approach enables users to select the content to be summarized within a controllable length. Users can view a summary that captures different privacy factors or a summary that covers the riskiest content. Our approach outperforms the domain-agnostic baselines by up to 27% in ROUGE-1 score and 50% in METEOR score using plain English reference summaries while relying on significantly less training data in comparison to abstractive approaches.","llm_keywords":["Privacy Policies","Summarization","Domain-Guided","Controllable Summarization","Privacy Risk","Extractive Summarization","Natural Language Processing","Legal Contracts"],"classifications":["Machine Summarization","Information Extraction"],"num_cited_by":30,"num_cited_by_title_only":30,"num_pages":7},{"id":"d09dd13a973e9cafe2f6850f1cf4dbb945f935fd25b10c4d20b6b4bb2a8f4b05968494d8bf29867c99ab2ac5b3e2c80c06e43348799998d119a7ad62a6da9c64","file_path":"legal-nlp-survey-20250328-002/original/Chen_2022_0532.pdf","title":"","llm_title":"Mulan: A Multiple Residual Article-Wise Attention Network for Legal Judgment Prediction","authors":["Junyi Chen","Lan Du","Ming Liu","Xiabing Zhou"],"llm_authors":"Junyi Chen, Lan Du, Ming Liu, Xiabing Zhou","author_string":"","year":2022,"abstract":"","llm_abstract":"","llm_keywords":["Legal judgment prediction","neural networks","multiple label learning","article-wise attention","deep learning","law articles","charges prediction","CAIL2018 datasets"],"classifications":[],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":15},{"id":"48d6ab3c9af971041e04624b96eb5654b02a3bf348993b8db4af8899042693ff8d3c9d2cfa1aa08f3b8d63450dd7d1c2c04d067a6cd4f02cc005931b50d28a25","file_path":"legal-nlp-survey-20250328-002/original/Liu_2021_0418.pdf","title":"Everything Has a Cause: Leveraging Causal Inference in Legal Text Analysis","llm_title":"Everything Has a Cause: Leveraging Causal Inference in Legal Text Analysis","authors":["Xiao Liu","Da Yin","Yansong Feng","Yuting Wu","Dongyan Zhao"],"llm_authors":"Xiao Liu, Da Yin, Yansong Feng, Yuting Wu, Dongyan Zhao","author_string":"Xiao Liu ; Da Yin ; Yansong Feng ; Yuting Wu ; Dongyan Zhao","year":2021,"abstract":"","llm_abstract":"Causal inference is the process of capturing cause-effect relationship among variables. Most existing works focus on dealing with structured data, while mining causal relationship among factors from unstructured data, like text, has been less examined, but is of great importance, especially in the legal domain. In this paper, we propose a novel Graph-based Causal Inference (GCI) framework, which builds causal graphs from fact descriptions without much human involvement and enables causal inference to facilitate legal practitioners to make proper decisions. We evaluate the framework on a challenging similar charge disambiguation task. Experimental results show that GCI can capture the nuance from fact descriptions among multiple confusing charges and provide explainable discrimination, especially in few-shot settings. We also observe that the causal knowledge contained in GCI can be effectively injected into powerful neural networks for better performance and interpretability. Code and data are available at https://github.com/xxxiaol/GCI/.","llm_keywords":["Causal Inference","Legal Text Analysis","Graph-based Causal Inference","Unstructured Data","Legal AI System","Similar Charge Disambiguation","Explainable AI"],"classifications":["Classification"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":14},{"id":"ee6ae8e1b737c208247451a1113af80a192905d70230a2ba44e0be3d06c3ac7849fe4693be3089aac61a529a0c7355a59775ab96988c83291823cd53f98f0a9f","file_path":"legal-nlp-survey-20250328-002/original/Liu_2019_0255.pdf","title":"","llm_title":"Legal Cause Prediction with Inner Descriptions and Outer Hierarchies","authors":["Zhiyuan Liu","Cunchao Tu","Maosong Sun"],"llm_authors":"Zhiyuan Liu, Cunchao Tu, Zhiyuan Liu, Maosong Sun","author_string":"","year":2019,"abstract":"","llm_abstract":"Legal Cause Prediction (LCP) aims to determine the charges in criminal cases or types of disputes in civil cases according to the fact descriptions. The research to date takes LCP as a text classification task and fails to consider the outer hierarchical dependencies and inner text information of causes. However, this information is critical for understanding causes and is expected to benefit LCP. To address this issue, we propose the Hierarchical Legal Cause Prediction (HLCP) model to incorporate this crucial information within the seq2seq framework. Specifically, we employ an attention-based seq2seq model to predict the cause path and utilize the inner text information to filter out noisy information in fact descriptions. We conduct experiments on 4 real-world criminal and civil datasets. Experimental results show that our model achieves significant and consistent improvements over all baselines.","llm_keywords":["Legal Cause Prediction","Hierarchical Model","Seq2Seq Framework","Text Classification","Deep Learning","Attention Mechanism","Legal Documents Analysis"],"classifications":["Classification","Information Extraction"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":14},{"id":"9b6601a12f43cdd15100b5dc8bd8c44f0cb8a55a89f5bd053033f434bd63858cdb5742c809cd20dc9d12fa1dcc5987820a2d5dd0459987e36b09d9b55cd100d2","file_path":"legal-nlp-survey-20250328-002/original/Ordoñez,-H.-A._2020_0336.pdf","title":"Jurisprudence search in Colombia based on natural language processing (NLP) and Lynked Data","llm_title":"Jurisprudence search in Colombia based on Natural Language Processing (NLP) and Lynked Data","authors":["Cristian Camilo Ordoñez","Jose Armando Ordoñez","Hugo Armando Ordoñez Eraso","Franco Arturo Urbano"],"llm_authors":"Cristian Camilo Ordoñez, Jose Armando Ordoñez, Hugo Armando Ordoñez Eraso, Franco Arturo Urbano","author_string":"Ordoñez","year":2021,"abstract":"","llm_abstract":"Objective— To develop a search model for judicial \ndecisions supported by natural language process¬ing that allows analyzing the text of jurispruden¬tial sentences. Additionally, link-data is used to \ntake advantage of the interrelation of content in \nrelated court decisions and improve search pro¬cesses. Methodology— The search model was built in two \nphases: the first is the training phase to generate \nthe models required to create an index, and sec¬ond, a search phase where the user enters a search \nstring that is used to find the documents (court \ndecisions) more related to the search. The model \nwas compared with other existing search engines \nof the Supreme Court of Justice of Colombia. The \nevaluation was divided into 2 steps. 1) Evaluation \nof the results obtained in each search, 2) User sat¬isfaction with the results obtained in the searches \nsolution. Results— The developed platform outperforms the \nexisting search system of the court regarding user \nsatisfaction and precision. Conclusions— The designed model for judicial \nsentences based on Natural Language Processing \n(NLP) and linked contributes to improving the \nuser experience and the precision of the jurispru¬dence search.","llm_keywords":["Jurisprudence","retrieval","natural language processing","system evaluation","automated summary"],"classifications":["Information Retrieval"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":9},{"id":"a34cadc9eebda52dd331dd142658088a72a44aa3caa31ec1d49e6ae75c6420957adf03303f7fdcd27d502e8a97a2cc2342e6da5d3be28a33461b05f1b8e0b305","file_path":"legal-nlp-survey-20250328-002/original/Pandey_2021_0478.pdf","title":"","llm_title":"Towards Reducing the Pendency of Cases at Court: Automated Case Analysis of Supreme Court Judgments in India","authors":["Shubham Pandey","Ayan Chandra","Sudeshna Sarkar","Uday Shankar"],"llm_authors":"Shubham PANDEY, Ayan CHANDRA, Sudeshna SARKAR, Uday SHANKAR","author_string":"","year":2021,"abstract":"","llm_abstract":"The Indian court system generates huge amounts of data relating to administration, pleadings, litigant behaviour, and court decisions on a regular basis. But the existing Judiciary is incapable of managing these vast troves of data efficiently that causes delays and pendency of a large volume of cases in the courts. Some of these time-consuming tasks involve case briefing, examining the legal issues, facts, legal principles, observations, and other significant aspects submitted by the contending parties in the court. In other words, computational methods to understand the underlying structure of a case document will directly aid the lawyers to perform these tasks efficiently and improve the overall efficiency of the Justice delivery system. Application of Computational techniques (such as Natural Language Processing) can help to gather and sift through these vast troves of information, identify patterns, extract the document structure, draft documents and make the information available online. Traditionally lawyers are trained to examine cases using the Case Law Analysis approach for case briefing. In this article, the authors aim to establish the importance and relevance of the automated case analysis problem in the legal domain. They introduce a novel case analysis structure for the supreme court judgment documents and define twelve different case law labels that are used by legal professionals to identify the structure. Finally the authors propose a method for automated case analysis, which will directly aid the lawyers to prepare speedy and efficient case briefs and drastically reduce the time taken by them in litigation.","llm_keywords":["Law and Technology","AI in Law","Natural Language Processing","Legal Document Analysis","Case Analysis"],"classifications":["Pre-Processing","Information Extraction","Text Generation","Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":8},{"id":"b9ee20fa2c3613944e50d524db3f736a039c1ae23f9ba004f9e2eb30aa5cc30ccaf5bc33dc263dfa1c8afd2c1a9d2f3a19433de49f81fe9ebce6f382111c61ad","file_path":"legal-nlp-survey-20250328-002/original/Savelka_2017_0121.pdf","title":"","llm_title":"Detecting Agent Mentions in U.S. Court Decisions","authors":["Jaromír Savelka","Kevin D. Ashley"],"llm_authors":"Jaromír Savelka, Kevin D. Ashley","author_string":"","year":2017,"abstract":"","llm_abstract":"Case law analysis is a significant component of research on almost any legal issue and understanding which agents are involved and mentioned in a decision is integral part of the analysis. In this paper we present a first experiment in detecting mentions of different agents in court decisions automatically. We defined a light-weight and easily extensible hierarchy of agents that play important roles in the decisions. We used the types from the hierarchy to annotate a corpus of US court decisions. The resulting data set enabled us to test the hypothesis that the mentions of agents in the decisions could be detected automatically. Conditional random fields models trained on the data set were shown to be very promising in this respect. To support research in automatic case-law analysis we release the agent mentions data set with this paper.","llm_keywords":["case law","legal analysis","agent mentions","named entity recognition","conditional random fields"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":10},{"id":"791ccab8bdf4371f37f191406ab1bbda4a813b84955a3fd39d6005aa142a54dfd286375f2b08c74ccc10975333a4a9ed4b30b8600ec1fde6fcfdc2255e8bb476","file_path":"legal-nlp-survey-20250328-002/original/Clavie_2021_0474.pdf","title":"","llm_title":"The Unreasonable Effectiveness of the Baseline: Discussing SVMs in Legal Text Classification","authors":["Benjamin Clavie","Marc Alphonsus"],"llm_authors":"Benjamin CLAVIE and Marc ALPHONSUS","author_string":"","year":2021,"abstract":"","llm_abstract":"We aim to highlight an interesting trend to contribute to the ongoing debate around advances within legal Natural Language Processing. Recently, the focus for most legal text classification tasks has shifted towards large pre-trained deep learning models such as BERT. In this paper, we show that a more traditional approach based on Support Vector Machine classifiers reaches competitive performance with deep learning models. We also highlight that error reduction obtained by using specialised BERT-based models over baselines is noticeably smaller in the legal domain when compared to general language tasks. We discuss some hypotheses for these results to support future discussions.","llm_keywords":["Natural Language Processing","Text Classification","Machine Learning","Support Vector Machine","BERT","Legal Domain","Deep Learning","Domain Specific Tasks"],"classifications":["Classification"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":4},{"id":"af0f84942b818cb26e6ff1c7cac32b1f0748cea9c3cc3a690621417abc1435c7dc0f5338c6020201cbf0b14d5aeb03f57e77ebf4b930afe36d6b4bc33d264fec","file_path":"legal-nlp-survey-20250328-002/original/Nanda_2020_0347.pdf","title":"","llm_title":"Multilingual Legal Information Retrieval System for Mapping Recitals and Normative Provisions","authors":["Rohan Nanda","Llio Humphreys","Lorenzo Grossio","Adebayo Kolawole John"],"llm_authors":"Rohan NANDA, Llio HUMPHREYS, Lorenzo GROSSIO, Adebayo KOLAWOLE JOHN","author_string":"","year":2020,"abstract":"","llm_abstract":"This paper presents a multilingual legal information retrieval system for mapping recitals to articles in European Union (EU) directives and normative provisions in national legislation. Such a system could be useful for purposive interpretation of norms. A previous work on mapping recitals and normative provisions was limited to EU legislation in English and only one lexical text similarity technique. In this paper, we develop state-of-the-art text similarity models to investigate the interplay between directive recitals, directive (sub-)articles and provisions of national implementing measures (NIMs) on a multilingual corpus (from Ireland, Italy and Luxembourg). Our results indicate that directive recitals do not have a direct influence on NIM provisions, but they sometimes contain additional information that is not present in the transposed directive sub-article, and can therefore facilitate purposive interpretation.","llm_keywords":["legal information retrieval","recitals","European legislation","interpretation","normative provisions","EU directives","national implementing measures","text similarity"],"classifications":["Information Retrieval"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":10},{"id":"efe8467b6ebc297e456c2d414ad5aa239fda5d2dbbbd557cf6b6f4c32884a779150b99748329f847b1ab228e2b1151b90a072c5e3e1916f8194340866912179e","file_path":"legal-nlp-survey-20250328-002/original/Luz-de-Araujo_2020_0369.pdf","title":"","llm_title":"Topic Modelling Brazilian Supreme Court Lawsuits","authors":["Pedro Henrique Luz De Araujo","Teófilo De Campos"],"llm_authors":"Pedro Henrique Luz De Araujo, Teófilo De Campos","author_string":"","year":2020,"abstract":"","llm_abstract":"The present work proposes the use of Latent Dirichlet Allocation to model Extraordinary Appeals received by Brazil’s Supreme Court. The data consist of a corpus of 45,532 lawsuits manually annotated by the Court’s experts with theme labels, a multi-class and multi-label classification task. We initially train models with 10 and 30 topics and analyze their semantics by examining each topic’s most relevant words and their most representative texts, aiming to evaluate model interpretability and quality. We also train models with 30, 100, 300 and 1,000 topics, and quantitatively evaluate their potential using the topics to generate feature vectors for each appeal. These vectors are then used to train a lawsuit theme classifier. We compare traditional bag-of-words approaches (word counts and tf-idf values) with the topic-based text representation to assess topic relevancy. Our topics semantic analysis demonstrate that our models with 10 and 30 topics were capable of capturing some of the legal matters discussed by the Court. In addition, our experiments show that the model with 300 topics was the best text vectoriser and that the interpretable, low dimensional representations it generates achieve good classification results.","llm_keywords":["topic models","legal domain","document analysis","Latent Dirichlet Allocation","Brazilian Supreme Court","multi-label classification","natural language processing","text representation","feature vectors","bag-of-words"],"classifications":["Classification","Information Retrieval"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":10},{"id":"7829de869c921660591417a23d4ca7e3dd7fc4e24ce2af7275a6e2eea45c17935bec70f87053be968f4639e66ae1a1ea0cca2a9a5a8434cb861a63021789f029","file_path":"legal-nlp-survey-20250328-002/original/Shankar_2019_0262.pdf","title":"Legal Query Reformulation using Deep Learning","llm_title":"Legal Query Reformulation using Deep Learning","authors":["Arunprasath Shankar","Venkata Nagaraju Buddarapu"],"llm_authors":"Arunprasath Shankar, Venkata Nagaraju Buddarapu","author_string":"Arunprasath Shankar and Venkata Nagaraju Buddarapu","year":2019,"abstract":"","llm_abstract":"Query reformulation is the process of iteratively modifying a query to improve the quality of search engine results. In recent years, the task of reformulating natural language (NL) queries has received considerable diligence from both industry and academic communities. Traditionally, query reformulation has been mostly approached by using the noisy channel model. Since legal queries are diverse and multi-faceted, these traditional approaches cannot effectively handle low frequency and out-of-vocabulary (OOV) words. Motivated by these issues, we rethink the task of legal query reformulation as a type of monolingual neural machine translation (NMT) problem, where the input (source) query is potentially erroneous and the output (target) query is its corrected form. We propose a unified and principled framework with multiple levels of granularity. Specifically, (i) an encoder with character attention which augments the subword representation; (ii) a decoder with attentions that enable the representations from different levels of granularity to control the translation cooperatively and (iii) a semi-supervised methodology to extract and augment a large-scale dataset of NL query pairs combining syntactic and semantic operations. We establish the effectiveness of our methodology using an internal dataset, where the training data is automatically obtained from user query logs. We further demonstrate that training deep neural networks on additional data with synthesized errors can improve performance for translation.","llm_keywords":["query reformulation","deep learning","neural machine translation","legal queries","natural language processing","encoder-decoder framework","attention learning"],"classifications":["Information Retrieval"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":10},{"id":"f1b40c2327b3bcb6dfd8bdb84f2efe0d43d927bfa8c28d94a68aa1fe2f10781a042dd9298581fd09e932f28c6e4fd6886f5f4d73bcb98daf5a78ecade4d1dd63","file_path":"legal-nlp-survey-20250328-002/original/Vold_2021_0482.pdf","title":"","llm_title":"Using Transformers to Improve Answer Retrieval for Legal Questions","authors":["Andrew Vold","Jack G. Conrad"],"llm_authors":"Andrew Vold, Jack G. Conrad","author_string":"","year":2021,"abstract":"","llm_abstract":"Transformer architectures such as BERT, XLNet, and others are frequently used in the field of natural language processing. Transformers have achieved state-of-the-art performance in tasks such as text classification, passage summarization, machine translation, and question answering. Efficient hosting of transformer models, however, is a difficult task because of their large size and high latency. In this work, we describe how we deploy a RoBERTa Base question answer classification model in a production environment. We also compare the answer retrieval performance of a RoBERTa Base classifier against a traditional machine learning model in the legal domain by measuring the performance difference between a trained linear SVM on the publicly available PRIVACYQA dataset. We show that RoBERTa achieves a 31% improvement in F1-score and a 41% improvement in Mean Reciprocal Rank over the traditional SVM.","llm_keywords":["Transformers","Answer Retrieval","Legal Questions","Machine Learning","BERT","RoBERTa","Question Answering","Natural Language Processing","Deep Learning","Information Retrieval"],"classifications":["Classification","Information Retrieval"],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":5},{"id":"643124c27aed454f5374b68ad9225b5d3fab4460724e14b2d86f74158a6dc1b712d5b0007a2ab02f6565cc52eca4dcbfd9cb10c70af37dad7fd6ed029dddb72b","file_path":"legal-nlp-survey-20250328-002/original/Walker_2017_0152.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"Semantic Types for Computational Legal Reasoning: Propositional Connectives and Sentence Roles in the Veterans’ Claims Dataset","authors":["Vern R. Walker","Ji Hae Han","Xiang Ni","Kaneyasu Yoseda"],"llm_authors":"Vern R. Walker, Ji Hae Han, Xiang Ni and Kaneyasu Yoseda","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"This paper announces the creation and public availability of a dataset of annotated decisions adjudicating claims by military veterans for disability compensation in the United States. This is intended to initiate a collaborative, transparent approach to semantic analysis for argument mining from legal documents. The dataset is being used in the LUIMA argument-mining project. We address two major sub-tasks for making legal reasoning computable. First, we report the semantic types of propositional connective we use to extract information about legal rules from sentences in statutes, regulations, and appellate court decisions, and to represent those rules as integrated systems. Second, we report the semantic types of sentence role we use to extract and represent the fact-finding reasoning found in adjudicatory decisions, with the goal of identifying successful and unsuccessful patterns of evidentiary argument. For each type system, we provide explanations and examples. Thus, we hope to stimulate a shared effort to create diverse datasets in law, to empirically evolve optimal sets of semantic types for argument mining, and to refine protocols for accurately applying those types to texts.","llm_keywords":["Semantic data","inference role","propositional-connective type system","sentence-role type system","ontology","legal rule","argument mining","computational argumentation"],"classifications":["Information Extraction","Resources"],"num_cited_by":6,"num_cited_by_title_only":36,"num_pages":10},{"id":"4f23989428d1613a8846d2f489a1ac27452850fce430b4835cecd24bcc90f4c5c4b905ea68ee289c062c7ec7445b88a0242345733a98962dddd595dc63b7d6aa","file_path":"legal-nlp-survey-20250328-002/original/Soh_2019_0254.pdf","title":"","llm_title":"Legal Area Classification: A Comparative Study of Text Classifiers on Singapore Supreme Court Judgments","authors":["Jerrold Soh Tsin Howe","Lim How Khang","Ian Ernst Chai"],"llm_authors":"Jerrold Soh Tsin Howe, Lim How Khang, Ian Ernst Chai","author_string":"","year":2019,"abstract":"","llm_abstract":"This paper conducts a comparative study on the performance of various machine learning ('ML') approaches for classifying judgments into legal areas. Using a novel dataset of 6,227 Singapore Supreme Court judgments, we investigate how state-of-the-art NLP methods compare against traditional statistical models when applied to a legal corpus that comprised few but lengthy documents. All approaches tested, including topic model, word embedding, and language model-based classifiers, performed well with as little as a few hundred judgments. However, more work needs to be done to optimize state-of-the-art methods for the legal domain.","llm_keywords":["legal area classification","machine learning","text classification","Singapore Supreme Court judgments","natural language processing","topic model","word embedding","language model","traditional statistical models"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":89,"num_pages":11},{"id":"1bce2b6340bb01b1ac15778296466b5b050ee79b057721fa2ba800879c59b35bc3e8b91bbdca229fffdb0630018f70c768f373ea0e32e9dc9bbb14517d852776","file_path":"legal-nlp-survey-20250328-002/original/Lepp_2020_0352.pdf","title":"Pardon the Interruption: An Analysis of Gender and Turn-Taking in U.S. Supreme Court Oral Arguments","llm_title":"Pardon the Interruption: An Analysis of Gender and Turn-Taking in U.S. Supreme Court Oral Arguments","authors":["Haley Lepp","Gina-Anne Levow"],"llm_authors":"Haley Lepp, Gina-Anne Levow","author_string":"Haley Lepp, Gina-Anne Levow","year":2020,"abstract":"","llm_abstract":"This study presents a corpus of turn changes between speakers in U.S. Supreme Court oral arguments. Each turn change is labeled on a spectrum of “cooperative” to “competitive” by a human annotator with legal experience in the United States. We analyze the relationship between speech features, the nature of exchanges, and the gender and legal role of the speakers. Finally, we demonstrate that the models can be used to predict the label of an exchange with moderate success. The automatic classification of the nature of exchanges indicates that future studies of turn-taking in oral arguments can rely on larger, unlabeled corpora.","llm_keywords":["gender","turn-taking","U.S. Supreme Court","oral arguments","speech features","competitive exchanges","cooperative exchanges","legal role","gender bias"],"classifications":["Classification","Resources"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"cf6d762d73d3838d2ba7f747295c321dbc37b34d72d9a877132aa68ead469b2b9e3a3a789f9789833a9f1501d0219e7d144456f38a304da19199fc9daa833797","file_path":"legal-nlp-survey-20250328-002/original/Trias_2021_0450.pdf","title":"Named Entity Recognition in Historic Legal Text: A Transformer and State Machine Ensemble Method","llm_title":"Named Entity Recognition in Historic Legal Text: A Transformer and State Machine Ensemble Method","authors":["Fernando Trias","Hongming Wang","Sylvain Jaume","Stratos Idreos"],"llm_authors":"Fernando Trias, Hongming Wang, Sylvain Jaume, Stratos Idreos","author_string":"Fernando Trias ; Hongming Wang ; Sylvain Jaume ; Stratos Idreos","year":2021,"abstract":"","llm_abstract":"Older legal texts are often scanned and digitized via Optical Character Recognition (OCR), which results in numerous errors. Although spelling and grammar checkers can correct much of the scanned text automatically, Named Entity Recognition (NER) is challenging, making correction of names difficult. To solve this, we developed an ensemble language model using a transformer neural network architecture combined with a finite state machine to extract names from English-language legal text. We use the US-based English language Harvard Caselaw Access Project for training and testing. Then, the extracted names are subjected to heuristic textual analysis to identify errors, make corrections, and quantify the extent of problems. With this system, we are able to extract most names, automatically correct numerous errors and identify potential mistakes that can later be reviewed for manual correction.","llm_keywords":["Named Entity Recognition","Transformer Neural Network","Finite State Machine","Historic Legal Text","Optical Character Recognition","Heuristic Textual Analysis","Harvard Caselaw Access Project"],"classifications":["Pre-Processing","Information Extraction","Resources"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":8},{"id":"8e350382a90640cee9a5dc93d6cde7c56d5cf63168f279b8dd162805f3f2bc6e03a75874fb3146f27df4b0bdc0d1558bc12bdc9ea3ab7805e3ed3cd6562f826f","file_path":"legal-nlp-survey-20250328-002/original/Sevim_2022_0513.pdf","title":"","llm_title":"Gender bias in legal corpora and debiasing it","authors":["Nurullah Sevim","Furkan Sahinuç","Aykut Koç"],"llm_authors":"Nurullah Sevim, Furkan ¸Sahinuç and Aykut Koç","author_string":"","year":2022,"abstract":"","llm_abstract":"Word embeddings have become important building blocks that are used profoundly in natural language processing (NLP). Despite their several advantages, word embeddings can unintentionally accommodate some gender- and ethnicity-based biases that are present within the corpora they are trained on. Therefore, ethical concerns have been raised since word embeddings are extensively used in several high-level algorithms. Studying such biases and debiasing them have recently become an important research endeavor. Various studies have been conducted to measure the extent of bias that word embeddings capture and to eradicate them. Concurrently, as another subfield that has started to gain traction recently, the applications of NLP in the field of law have started to increase and develop rapidly. As law has a direct and utmost effect on people’s lives, the issues of bias for NLP applications in legal domain are certainly important. However, to the best of our knowledge, bias issues have not yet been studied in the context of legal corpora. In this article, we approach the gender bias problem from the scope of legal text processing domain. Word embedding models that are trained on corpora composed by legal documents and legislation from different countries have been utilized to measure and eliminate gender bias in legal documents. Several methods have been employed to reveal the degree of gender bias and observe its variations over countries. Moreover, a debiasing method has been used to neutralize unwanted bias. The preservation of semantic coherence of the debiased vector space has also been demonstrated by using high-level tasks. Finally, overall results and their implications have been discussed in the scope of NLP in legal domain.","llm_keywords":["Bias","NLP in law","Legal text processing","Word embeddings","Debiasing","Gender bias","Computational law","Semantic vector spaces"],"classifications":["Resources","Text Generation","Information Extraction","Pre-Processing","Information Retrieval","Classification","Machine Summarization"],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":34},{"id":"e0502f967466bfc76730cae2994ea068c6b506c1e543e87ab44e221d52f628337350544ca04c5dee1ec64685d7551aa0f51be2de396164378aab6305a194dcea","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2019_0272.pdf","title":"","llm_title":"Neural Legal Judgment Prediction in English","authors":["Ilias Chalkidis","Ion Androutsopoulos","Nikolaos Aletras"],"llm_authors":"Ilias Chalkidis, Ion Androutsopoulos, Nikolaos Aletras","author_string":"","year":2019,"abstract":"","llm_abstract":"Legal judgment prediction is the task of automatically predicting the outcome of a court case, given a text describing the case’s facts. Previous work on using neural models for this task has focused on Chinese; only feature-based models (e.g., using bags of words and topics) have been considered in English. We release a new English legal judgment prediction dataset, containing cases from the European Court of Human Rights. We evaluate a broad variety of neural models on the new dataset, establishing strong baselines that surpass previous feature-based models in three tasks: (1) binary violation classification; (2) multi-label classification; (3) case importance prediction. We also explore if models are biased towards demographic information via data anonymization. As a side-product, we propose a hierarchical version of BERT, which bypasses BERT’s length limitation.","llm_keywords":["legal judgment prediction","neural models","European Court of Human Rights","binary violation classification","multi-label classification","case importance prediction","bias","data anonymization","hierarchical BERT"],"classifications":["Classification","Resources"],"num_cited_by":424,"num_cited_by_title_only":424,"num_pages":7},{"id":"51d744cd05f2dd76859dddf3780ec441a0637478ad7be375211b508a71a8501b45acba56f71a5f2551800081fbb6de28ba50f0d92853df34a818e709faab5e2b","file_path":"legal-nlp-survey-20250328-002/original/Collarana_2018_0162.pdf","title":"","llm_title":"A Question Answering System on Regulatory Documents","authors":["Diego Collarana","Timm Heuss","Jens Lehmann","Ioanna Lytra","Gaurav Maheshwari","Rostislav Nedelchev","Thorsten Schmidt","Priyansh Trivedi"],"llm_authors":"Diego COLLARANA, Timm HEUSS, Jens LEHMANN, Ioanna LYTRA, Gaurav MAHESHWARI, Rostislav NEDELCHEV, Thorsten SCHMIDT, Priyansh TRIVEDI","author_string":"","year":2018,"abstract":"","llm_abstract":"In this work, we outline an approach for question answering over regulatory documents. In contrast to traditional means to access information in the domain, the proposed system attempts to deliver an accurate and precise answer to user queries. This is accomplished by a two-step approach which first selects relevant paragraphs given a question; and then compares the selected paragraph with user query to predict a span in the paragraph as the answer. We employ neural network based solutions for each step, and compare them with existing, and alternate baselines. We perform our evaluations with a gold-standard benchmark comprising over 600 questions on the MaRisk regulatory document. In our experiments, we observe that our proposed system outperforms other baselines.","llm_keywords":["Question Answering","Reading Comprehension","Regulatory Domain","Neural Networks","Machine Learning","Information Retrieval","Natural Language Processing","Legal Documents","Transfer Learning","Domain-specific Applications"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":19,"num_cited_by_title_only":19,"num_pages":10},{"id":"bb9c3cee98b390ec1cf2f5b0af31f9cb6163e98221dcd29c748265da61c141f30e29e9cfd35b41331d4badc437482a477d7358d19c5e7cbefb177e70d26a1550","file_path":"legal-nlp-survey-20250328-002/original/de-Araujo_2014_0032.pdf","title":"Information Extraction for legal knowledge representation – a review of approaches and trends","llm_title":"Information extraction for legal knowledge representation – a review of approaches and trends","authors":["Denis Andrei de Araujo","Carolina Müller","Rove Chisman","Sandro José Rigo"],"llm_authors":"Denis Andrei de Araujo, Carolina Müller, Rove Chisman, Sandro José Rigo","author_string":"Denis Andrei de Araujo","year":2014,"abstract":"","llm_abstract":"This work presents an introduction to Information Extraction systems and a survey of the known approaches of Information Extraction in the legal area. This work analyzes with particular attention the techniques that rely on the representation of legal knowledge as a means to achieve better performance, with emphasis on those techniques including ontologies and linguistic support. Some details of the systems implementations are presented, followed by an analysis of the positive and negative points of each approach, aiming at bringing the reader a critical position regarding the solutions studied.","llm_keywords":["Ontologies","Information extraction","Information recovery","Legal knowledge representation","Linguistic analysis","Information Retrieval","Legal reasoning","Legal documents","Automatic processing","Legal text editing"],"classifications":["Information Extraction"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":18},{"id":"37b6b647b00d6865b283ff6ebd9d6acd3937675db76bb38885633df839cd8b5599079e63a4adcbf7b934e21a1f8e99978823bf1155d70e5bfd6062ae9fb54f81","file_path":"legal-nlp-survey-20250328-002/original/Nghiem_2022_0561.pdf","title":"Text Classification and Prediction in the Legal Domain","llm_title":"Text Classification and Prediction in the Legal Domain","authors":["Minh-Quoc Nghiem","Paul Baylis","Andre Freitas","Sophia Ananiadou"],"llm_authors":"Minh-Quoc Nghiem, Paul Baylis, Andre Freitas, Sophia Ananiadou","author_string":"Minh-Quoc Nghiem ; Paul Baylis ; André Freitas ; Sophia Ananiadou","year":2022,"abstract":"","llm_abstract":"We present a case study on the application of text classification and legal judgment prediction for flight compensation. We combine transformer-based classification models to classify responses from airlines and incorporate text data with other data types to predict a legal claim being successful. Our experimental evaluations show that our models achieve consistent and significant improvements over baselines and even outperformed human prediction when predicting a claim being successful. These models were integrated into an existing claim management system, providing substantial productivity gains for handling the case lifecycle, currently supporting several thousands of monthly processes.","llm_keywords":["text classification","legal judgment prediction","flight compensation","NLP","transformer-based models","legal domain","automation","claims management"],"classifications":["Classification"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":6},{"id":"060395bcbd67abe24a2a61068c38dac2f088996a004cea5d2fbb8e6ff45b4a65008f4d867552dd27984eeb7d691a11509ca05d1e0c41fb4f95a8b989b3c6493b","file_path":"legal-nlp-survey-20250328-002/original/Niu_2014_0041.pdf","title":"Rule-based NLP Methodology for Semantic Interpretation of Impact Factors for Construction Claim Cases","llm_title":"Rule-based NLP Methodology for Semantic Interpretation of Impact Factors for Construction Claim Cases","authors":["Jia Niu","Raja R.A. Issa"],"llm_authors":"Jia Niu and Raja R.A. Issa","author_string":"","year":2014,"abstract":"","llm_abstract":"Construction claim analysis largely depends on determining the existence of impact factors. Extensive research has been conducted on the relationships between impact factors and outcomes of construction litigation from various perspectives and using various methodologies. However, only a few of them have taken into consideration the automated semantic interpretation of impact factors contained in a construction litigation case. In this paper, based on previous pilot studies on the domain ontologies of construction contractual semantics, a rule-based NLP (Natural Language Processing) methodology for semantically interpreting impact factors for construction claim cases is proposed. Based on the available NLP techniques and domain ontologies, this methodology utilizes a rule-based mechanism to achieve the mapping from textual elements to ontology entities. In this way, the support of domain ontology is provided to enhance the performance of the impact factor interpretation process in the text. Also, it was found that several software packages can work together to satisfy the demand for the implementation of this methodology. Further, to test the validity of this methodology, several case studies focusing on DSC (Differing Site Conditions) claims are conducted by adopting cases from legal databases as data. The significance of this research is that it provides a more automated functionality to the traditional approach of claim outcome prediction by adding one more semantic factor-interpreting layer to it, and by also exploring the application of ontology-based NLP in the domain of construction claim analysis via text processing.","llm_keywords":["rule-based NLP","semantic interpretation","impact factors","construction claim cases","domain ontology","litigation outcome prediction","construction management","automated functionality","text processing","DSC claims"],"classifications":["Pre-Processing","Information Extraction"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":8},{"id":"e785e24643ec1d823a928099bd0147a10de068f98867885e635496561d4c028f3f158b6d7326718a0e6bc043cbbb86586336c84257f7b426a2cae6f8ec627765","file_path":"legal-nlp-survey-20250328-002/original/Kríz_2016_0088.pdf","title":"","llm_title":"Czech Legal Text Treebank 1.0","authors":["Vincent Kríz","Barbora Hladká","Zdeňka Urešová"],"llm_authors":"Vincent Kríz, Barbora Hladká, Zdeňka Urešová","author_string":"","year":2016,"abstract":"","llm_abstract":"We introduce a new member of the family of Prague dependency treebanks. The Czech Legal Text Treebank 1.0 is a morphologically and syntactically annotated corpus of 1,128 sentences. The treebank contains texts from the legal domain, namely the documents from the Collection of Laws of the Czech Republic. Legal texts differ from other domains in several language phenomena influenced by rather high frequency of very long sentences. A manual annotation of such sentences presents a new challenge. We describe a strategy and tools for this task. The resulting treebank can be explored in various ways. It can be downloaded from the LINDAT/CLARIN repository and viewed locally using the TrEd editor or it can be accessed on-line using the KonText and TreeQuery tools.","llm_keywords":["annotated corpus","legal domain","parsing","dependency treebanks","Czech Legal Text Treebank","semantic relations","RExtractor system","syntactic parsing","morphological annotation","Prague Dependency Treebank"],"classifications":["Resources"],"num_cited_by":3,"num_cited_by_title_only":4,"num_pages":6},{"id":"acb3a07326e7e06e901a4c4ba4279b823371cb26ccad16e9a253310d1352a04a33a7c159b116ee00bb2ff5913116a9d17805a6275bda44d374f1db58c1335c66","file_path":"legal-nlp-survey-20250328-002/original/Cornoiu_2013_0021.pdf","title":"New development for legal information retrieval using the Eurovoc Thesaurus and legal ontology","llm_title":"Full text search in the legal domain is not enough","authors":["S. Cornoiu","H. Valean"],"llm_authors":"S. Cornoiu, H. Valean Valean","author_string":"S. Cornoiu; H. Valean","year":2013,"abstract":"","llm_abstract":"Full text search in the legal domain is not enough, because there is a gap between common sense and legal knowledge. We want to present some possible directions to solve the problem of full text search in legal domain. The gap can be bridged using a model that mixes tags from Eurovoc Thesaurus Schema Ontology and legal ontology in order to enrich information retrieval capabilities in the legal domain.","llm_keywords":["legal ontology","Semantic Web","Eurovoc Thesaurus","information retrieval","legal knowledge"],"classifications":[],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":4},{"id":"412ef7a9110efda1b07988b01648468457e5a9ead3bb026820557fedd60f60cd5be2919b0ef8fb87e2215e0ba1ef9ef458240211d3b7e776e59fdecf41e5dd83","file_path":"legal-nlp-survey-20250328-002/original/Nguyen_2017_0106.pdf","title":"","llm_title":"A Knowledge Representation for Vietnamese Legal Document System","authors":["Ha-Thanh Nguyen","Viet-Ha Nguyen","Viet-Anh Vu"],"llm_authors":"Ha-Thanh Nguyen, Viet-Ha Nguyen, Viet-Anh Vu","author_string":"","year":2017,"abstract":"","llm_abstract":"Legal documents play an important role in the legal systems of every nation. In order to process information automatically and make use of knowledge from legal documents, we need an appropriate knowledge representation for them. In this research, we investigate properties of the Vietnamese legal document system and propose a representation for the documents and their interrelationships. The main challenges for this task are their unstability, limited validity period and complicated interrelationships. Properties and relationships which we design to represent in our knowlege base are selective in order to make use of information within legal documents. In order to represent our knowlege base, we compare three methods: Semantic Network, Production Rules, Frame Language and make use of their advantages in our representation. Moreover, we implement a service-oriented system providing knowledge querying service for other application systems based on our research result.","llm_keywords":["knowledge representation","Vietnamese legal documents","semantic network","production rules","frame language","artificial intelligence","legal system","e-Society","NLP","service-oriented system"],"classifications":["Information Retrieval","Information Extraction","Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":6},{"id":"d0b32738a7fbf8df0d31a619602a0df152724d07c533ebb6db14eaf6ffa5e42d80776e896253aa65572fe867012e61f56a7ba975ea97b1ee71b9c1fcbc2bafe9","file_path":"legal-nlp-survey-20250328-002/original/Glaser_2021_0469.pdf","title":"Summarization of German Court Rulings","llm_title":"Summarization of German Court Rulings","authors":["Ingo Glaser","Sebastian Moser","Florian Matthes"],"llm_authors":"Ingo Glaser, Sebastian Moser, Florian Matthes","author_string":"Ingo Glaser ; Sebastian Moser ; Florian Matthes","year":2021,"abstract":"","llm_abstract":"Historically speaking, the German legal language is widely neglected in NLP research, especially in summarization systems, as most of them are based on English newspaper articles. In this paper, we propose the task of automatic summarization of German court rulings. Due to their complexity and length, it is of critical importance that legal practitioners can quickly identify the content of a verdict and thus be able to decide on the relevance for a given legal case. To tackle this problem, we introduce a new dataset consisting of 100k German judgments with short summaries. Our dataset has the highest compression ratio among the most common summarization datasets. German court rulings contain much structural information, so we create a pre-processing pipeline tailored explicitly to the German legal domain. Additionally, we implement multiple extractive as well as abstractive summarization systems and build a wide variety of baseline models. Our best model achieves a ROUGE-1 score of 30.50. Therefore with this work, we are laying the crucial groundwork for further research on German summarization systems.","llm_keywords":["German legal language","text summarization","German court rulings","pre-processing pipeline","extractive summarization","abstractive summarization","NLP research","ROUGE score","dataset collection","legal domain"],"classifications":["Machine Summarization","Resources","Pre-Processing"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":10},{"id":"d4a81d6e6f24a5cfa89b53fd1283057722ebba3dc8d339b22a3b3b7728ee8eacfea457d68493591843da975dd40b85beed15bcd9db75f2e6330346dafce43932","file_path":"legal-nlp-survey-20250328-002/original/Bruno_2022_0565.pdf","title":"","llm_title":"LawngNLI: A Long-Premise Benchmark for In-Domain Generalization from Short to Long Contexts and for Implication-Based Retrieval","authors":["William Bruno","Dan Roth"],"llm_authors":"William Bruno and Dan Roth","author_string":"","year":2022,"abstract":"","llm_abstract":"Natural language inference has trended toward studying contexts beyond the sentence level. An important application area is law: past cases often do not foretell how they apply to new situations and implications must be inferred. This paper introduces LawngNLI, constructed from U.S. legal opinions with automatic labels with high human-validated accuracy. Premises are long and multigranular. Experiments show two use cases. First, LawngNLI can benchmark for in-domain generalization from short to long contexts. It has remained unclear if large-scale long-premise NLI datasets actually need to be constructed: near-top performance on long premises could be achievable by fine-tuning using short premises. Without multigranularity, benchmarks cannot distinguish lack of fine-tuning on long premises versus domain shift between short and long datasets. In contrast, our long and short premises share the same examples and domain. Models fine-tuned using several past NLI datasets and/or our short premises fall short of top performance on our long premises. So for at least certain domains (such as ours), large-scale long-premise datasets are needed. Second, LawngNLI can benchmark for implication-based retrieval. Queries are entailed or contradicted by target documents, allowing users to move between arguments and evidence. Leading retrieval models perform reasonably zero shot on a LawngNLI-derived retrieval task. We compare different systems for re-ranking, including lexical overlap and cross-encoders fine-tuned using a modified LawngNLI or past NLI datasets. LawngNLI can train and test systems for implication-based case retrieval and argumentation.","llm_keywords":["Natural Language Inference","Legal Opinions","Long-Premise Dataset","Domain Generalization","Implication-Based Retrieval","Case Retrieval","Argumentation","Machine Learning Models","Fine-Tuning","Data-driven Benchmarks"],"classifications":["Information Retrieval"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":25},{"id":"3a9806067f4a3868e4327eb098aa3e8d5771779ea3bea8cc0eba2398ef2dd49f5622aa80a21ac1a7cfdf600ad0fd22393a7528204188a32172c493ba02cf027c","file_path":"legal-nlp-survey-20250328-002/original/Mandal_2017_0141.pdf","title":"Measuring Similarity among Legal Court Case Documents","llm_title":"Measuring Similarity among Legal Court Case Documents","authors":["Arpan Mandal","Raktim Chaki","Sarbajit Saha","Kripabandhu Ghosh","Arindam Pal","Saptarshi Ghosh"],"llm_authors":"Arpan Mandal, Raktim Chaki, Sarbajit Saha, Kripabandhu Ghosh, Arindam Pal, Saptarshi Ghosh","author_string":"Arpan Mandal, Raktim Chaki, Sarbajit Saha, Kripabandhu Ghosh, Arindam Pal, and Saptarshi Ghosh","year":2018,"abstract":"","llm_abstract":"Computing the similarity between two legal documents is an important challenge in the Legal Information Retrieval domain. Efficient calculation of this similarity has useful applications in various tasks such as identifying relevant prior cases for a given case document. Prior works have proposed network-based and text-based methods for measuring similarity between legal documents. However, there are certain limitations in the prior methods. Network-based measures are not always meaningfully applicable since legal citation networks are usually very sparse. On the other hand, only primitive text-based similarity measures, such as TF-IDF based approaches, have been tried till date. In this work, we focus on improving text-based methodologies for computing the similarity between two legal documents. In addition to TF-IDF based measures, we use advanced similarity measures (such as topic modeling) and neural network models (such as word embeddings and document embeddings). We perform extensive experiments on a large dataset of Indian Supreme Court cases, and compare among various methodologies for measuring the textual similarity of legal documents. Our experiments show that embedding based approaches perform better than other approaches. We also demonstrate that the proposed embedding-based methodologies significantly outperforms a baseline hybrid methodology involving both network-based and text-based similarity.","llm_keywords":["Legal Information Retrieval","Legal Document Similarity","Court Cases","Topic Modeling","Word Embeddings"],"classifications":["Information Retrieval"],"num_cited_by":78,"num_cited_by_title_only":108,"num_pages":9},{"id":"2911dc60c98410fcb024d2a9df60840f9e2c38a070df5bc47b777e938ae3b02ecf684208645f88a7d3d1e1056dc22b92d6de2d88248b3d26b6c26aa1d393879f","file_path":"legal-nlp-survey-20250328-002/original/Bommarito-II_2018_0192.pdf","title":"","llm_title":"LexNLP: Natural language processing and information extraction for legal and regulatory texts","authors":["Michael J Bommarito II","Daniel Martin Katz","Eric M Detterman"],"llm_authors":"Michael J Bommarito II, Daniel Martin Katz, Eric M Detterman","author_string":"","year":2018,"abstract":"","llm_abstract":"LexNLP is an open source Python package focused on natural language processing and machine learning for legal and regulatory text. The package includes functionality to (i) segment documents, (ii) identify key text such as titles and section headings, (iii) extract over eighteen types of structured information like distances and dates, (iv) extract named entities such as companies and geopolitical entities, (v) transform text into features for model training, and (vi) build unsupervised and supervised models such as word embedding or tagging models. LexNLP includes pre-trained models based on thousands of unit tests drawn from real documents available from the SEC EDGAR database as well as various judicial and regulatory proceedings. LexNLP is designed for use in both academic research and industrial applications, and is distributed at https://github.com/LexPredict/lexpredict-lexnlp.","llm_keywords":["natural language processing","legal","regulatory","machine learning","segmentation","extraction","open source","Python"],"classifications":["Pre-Processing","Information Extraction","Resources"],"num_cited_by":88,"num_cited_by_title_only":88,"num_pages":7},{"id":"a04462a82981f77710b9e2321cee514e84e38a52e524febfdf5b4410f010e268392cac041fd8386a605fe691e613bcd8894aa645ba367c352e560e5d808e6fc6","file_path":"legal-nlp-survey-20250328-002/original/Alschner_2019_0290.pdf","title":"Microsoft Word - Alschner_computational_analysis_IL_23Sep2019.docx","llm_title":"The Computational Analysis of International Law","authors":["Wolfgang Alschner"],"llm_authors":"Wolfgang Alschner","author_string":"","year":2019,"abstract":"","llm_abstract":"When traditional international law techniques reach their conceptual and methodological limits, we need to look for help in other disciplines. International law scholars have in the past drawn inspirations from economics, political science or sociology to enrich the study and our understanding of international law. Now the time has come to add a new discipline to this list: computer science. The computational analysis of international law renders legal analysis scalable and empowers international lawyers to study international law in unprecedented depth and breadth. In this contribution, I provide an overview of computational techniques for the doctrinal and legal-institutional study of international law highlighting this neglected, but increasingly important field of interdisciplinary study.","llm_keywords":["international law","computer science","computational analysis","big data","legal research","doctrinal study","legal-institutional study","interdisciplinary study","empirical legal scholarship","international treaties"],"classifications":["Resources"],"num_cited_by":27,"num_cited_by_title_only":27,"num_pages":30},{"id":"8ee6996f5013e3d52c15e9027f37b46ad52313b639be1ff8796cb7668508d4a9bcd06118a1cd5ba2aea11e5a0126591c5f533c21cca48237e4c9ce302bf984f1","file_path":"legal-nlp-survey-20250328-002/original/Son_2016_0101.pdf","title":"Recognizing logical parts in legal texts using neural architectures","llm_title":"Recognizing logical parts in legal texts using neural architectures","authors":["Truong Son Nguyen","Le Minh Nguyen","Bao Quoc Ho","Akira Shimazu"],"llm_authors":"Nguyen Truong Son, Nguyen Le Minh, Ho Bao Quoc, Akira Shimazu","author_string":"","year":2016,"abstract":"","llm_abstract":"This paper proposes neural networks approaches to recognize logical parts in Vietnamese legal documents. We utilize four models based on recurrent neural networks including Long Short Term Memory (LSTM), Bidirectional LSTM and their combination with Conditional Random Fields. The experimental results on the Vietnamese Business Law data set shows the promising of this approach. Although, these approaches don’t use any engineering features like traditional approaches, they can produce the state-of-the-art performance.","llm_keywords":["legal text mining","sequence labeling","conditional random fields","long short term memory","recurrent neural networks","Vietnamese legal documents","deep learning","machine learning","natural language processing"],"classifications":["Information Extraction","Classification"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":6},{"id":"c6d5869c2bf7e2a91e24da5604cf6dc48af7abdb2c14178f2892ecf19b5f782b4c69b81cbb52064f7a577abdfb0ff46b37a7f38a6df09841f7c9e52bd6b2c8b1","file_path":"legal-nlp-survey-20250328-002/original/Mamooler_2022_0571.pdf","title":"","llm_title":"An Efficient Active Learning Pipeline for Legal Text Classification","authors":["Sepideh Mamooler","Rémi Lebret","Stephane Massonnet","Karl Aberer"],"llm_authors":"Sepideh Mamooler and Rémi Lebret and Stephane Massonnet and Karl Aberer","author_string":"","year":2022,"abstract":"","llm_abstract":"Active Learning (AL) is a powerful tool for learning with less labeled data, in particular, for specialized domains, like legal documents, where unlabeled data is abundant, but the annotation requires domain expertise and is thus expensive. Recent works have shown the effectiveness of AL strategies for pre-trained language models. However, most AL strategies require a set of labeled samples to start with, which is expensive to acquire. In addition, pre-trained language models have been shown unstable during fine-tuning with small datasets, and their embeddings are not semantically meaningful. In this work, we propose a pipeline for effectively using active learning with pre-trained language models in the legal domain. To this end, we leverage the available unlabeled data in three phases. First, we continue pre-training the model to adapt it to the downstream task. Second, we use knowledge distillation to guide the model’s embeddings to a semantically meaningful space. Finally, we propose a simple, yet effective, strategy to find the initial set of labeled samples with fewer actions compared to existing methods. Our experiments on Contract-NLI, adapted to the classification task, and LEDGAR benchmarks show that our approach outperforms standard AL strategies, and is more efficient. Furthermore, our pipeline reaches comparable results to the fully-supervised approach with a small performance gap, and dramatically reduced annotation cost. Code and the adapted data will be made available.","llm_keywords":["Active Learning","Legal Text Classification","Pre-trained Language Models","Knowledge Distillation","RoBERTa","Unlabeled Data","Text Annotation","Machine Learning","Semantic Embeddings","Legal Domain"],"classifications":["Classification","Pre-Processing","Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":14},{"id":"7f514f5d10a5c0b77f25f7526c8563a211c7fb95228eaa70a52310935fa32ba12b1d9446d73a8d79f8a37cfcd3bd1ef5a01819199e53d6ae26e4e5b34d0c759c","file_path":"legal-nlp-survey-20250328-002/original/Pitis_2017_0142.pdf","title":"Methods for Retrieving Alternative Contract Language Using a Prototype","llm_title":"Methods for Retrieving Alternative Contract Language Using a Prototype","authors":["Silviu Pitis"],"llm_authors":"Silviu Pitis","author_string":"Silviu Pitis","year":2017,"abstract":"","llm_abstract":"This paper addresses the problem of searching for alternative contract language that is similar to, yet different from, a given provision (the prototype). While this is a core task in transactional legal work, generic search solutions do not offer an effective solution. We draw upon modern information retrieval research to propose and validate novel methods for retrieving alternative language using a prototype. Our solution accepts an entire provision as a prototype and retrieves variants on the language from a database of precedent contracts. In designing this solution, we propose two ordered proximity measures and demonstrate their effectiveness relative to existing techniques. Further, we examine the challenge posed by varying definitions of redundant search results and propose to resolve it with a user-tunable, dynamic approach to result clustering.","llm_keywords":["transactional law","contract clause retrieval","information retrieval","novelty detection","search result clustering"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":9},{"id":"b63c48a8a477aa62fc372f4b9e836cfdfe12370184991ab90b76db7a87b2cc049ae4f79d559e6559ffddc6c8a323be841af7ed95bb6f41e6cc45dfe35a911ba3","file_path":"legal-nlp-survey-20250328-002/original/Coupette_2022_0593.pdf","title":"Law Smells","llm_title":"Law Smells: Defining and Detecting Problematic Patterns in Legal Drafting","authors":["Corinna Coupette","Dirk Hartung","Janis Beckedorf","Maximilian Böther","Daniel Martin Katz"],"llm_authors":"Corinna Coupette, Dirk Hartung, Janis Beckedorf, Maximilian Böther, Daniel Martin Katz","author_string":"Corinna Coupette","year":2022,"abstract":"","llm_abstract":"Building on the computer science concept of code smells, we initiate the study of law smells, i.e., patterns in legal texts that pose threats to the comprehensibility and maintainability of the law. With five intuitive law smells as running examples—namely, duplicated phrase, long element, large reference tree, ambiguous syntax, and natural language obsession—, we develop a comprehensive law smell taxonomy. This taxonomy classifies law smells by when they can be detected, which aspects of law they relate to, and how they can be discovered. We introduce text-based and graph-based methods to identify instances of law smells, confirming their utility in practice using the United States Code as a test case. Our work demonstrates how ideas from software engineering can be leveraged to assess and improve the quality of legal code, thus drawing attention to an understudied area in the intersection of law and computer science and highlighting the potential of computational legal drafting.","llm_keywords":["Refactoring","Software engineering","Law","Natural language processing","Network analysis"],"classifications":["Information Extraction","Pre-Processing","Classification"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":34},{"id":"cd134311478145195ace9fe5d76ff0170d2152d36dd647194d2d2c24ed6bcaca71f5718b3cd1d1af6234e2df7895989d578051e82bbe09dfe77753dd82062445","file_path":"legal-nlp-survey-20250328-002/original/Kim_2015_0065.pdf","title":"sv-lncs","llm_title":"Legal Question Answering Using Ranking SVM and Syntactic/Semantic Similarity","authors":["Mi-Young Kim","Ying Xu","Randy Goebel"],"llm_authors":"Mi-Young Kim, Ying Xu, and Randy Goebel","author_string":"Springer-SBM","year":2016,"abstract":"","llm_abstract":"We describe a legal question answering system which combines legal information retrieval and textual entailment. We have evaluated our system using the data from the first competition on legal information extraction/entailment (COLIEE) 2014. The competition focuses on two aspects of legal information processing related to answering yes/no questions from Japanese legal bar exams. The shared task consists of two phases: legal ad-hoc information retrieval and textual entailment. The first phase requires the identification of Japan civil law articles relevant to a legal bar exam query. We have implemented two unsupervised baseline models (tf-idf and Latent Dirichlet Allocation(LDA)-based Information Retrieval(IR)), and a supervised model, Ranking SVM, for the task. The features of the model are a set of words, and scores of an article based on the corresponding baseline models. The results show that the Ranking SVM model nearly doubles the Mean Average Precision compared with both baseline models. The second phase is to answer “Yes” or “No” to previously unseen queries, by comparing the meanings of queries with relevant articles. The features used for phase two are syntactic/semantic similarities and identification of negation/antonym relations. The results show that our method, combined with rule-based model and the unsupervised model, outperforms the SVM-based supervised model.","llm_keywords":["legal text mining","question answering","recognizing textual entailment","information retrieval","ranking SVM","Latent Dirichlet Allocation"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":6,"num_cited_by_title_only":40,"num_pages":17},{"id":"7dae3c5885d79f3d34f9f09f5d897260cc16342d24005c8b34fffc7e26295c2ab36feba71e9dbb400835a28f523f22dac9b3484ba422318da6fe0c341cd369c1","file_path":"legal-nlp-survey-20250328-002/original/Grabmair_2013_0015.pdf","title":"untitled","llm_title":"Introducing LUIMA: An Experiment in Legal Conceptual Retrieval of Vaccine Injury Decisions using a UIMA Type System and Tools","authors":["Anne Gardner","Matthias Grabmair","Kevin D. Ashley","Ran Chen","Preethi Sureshkumar","Chen Wang","Eric Nyberg","Vern R. Walker"],"llm_authors":"Matthias Grabmair, Kevin D. Ashley, Ran Chen, Preethi Sureshkumar, Chen Wang, Eric Nyberg, Vern R. Walker","author_string":"Anne Gardner","year":2015,"abstract":"","llm_abstract":"This paper presents first results from a proof of feasibility experiment in conceptual legal document retrieval in a particular domain (involving vaccine injury compensation). The conceptual markup of documents is done automatically using LUIMA, a law-specific semantic extraction toolbox based on the UIMA framework. The system consists of modules for automatic sub-sentence level annotation, machine learning based sentence annotation, basic retrieval using Apache Lucene and a machine learning based reranking of retrieved documents. In a leave-one-out experiment on a limited corpus, the resulting rankings scored higher for most tested queries than baseline rankings created using a commercial full-text legal information system.","llm_keywords":["legal document retrieval","semantic retrieval","natural language processing","argumentation mining"],"classifications":["Information Extraction","Information Retrieval"],"num_cited_by":80,"num_cited_by_title_only":80,"num_pages":10},{"id":"1b849c5f3910142f45f8587517298098955f2d155508a0596521f28cc4fcd397bfda8ced6bfd67aabad2e179ff90883b016e511d2ff6a78eb4da5c3f111db552","file_path":"legal-nlp-survey-20250328-002/original/Vianna_2022_0536.pdf","title":"Organizing Portuguese Legal Documents through Topic Discovery","llm_title":"Organizing Portuguese Legal Documents through Topic Discovery","authors":["Daniela Vianna","Edleno Silva de Moura"],"llm_authors":"Daniela Vianna, Edleno Silva de Moura","author_string":"Daniela Vianna","year":2022,"abstract":"","llm_abstract":"A significant challenge in the legal domain is to organize and summarize a constantly growing collection of legal documents, uncovering hidden topics, or themes, that later can support tasks such as legal case retrieval and legal judgment prediction. This massive amount of digital legal documents, combined with the inherent complexity of judiciary systems worldwide, presents a promising scenario for Machine Learning solutions, mainly those taking advantage of all the advancements in the area of Natural Language Processing (NLP). It is in this scenario that Jusbrasil, the largest legal tech company in Brazil, is situated. Using a dataset partially curated by the Jusbrasil legal team, we explore topic modeling solutions using state of the art language models, trained with legal Portuguese documents, to automatically organize and summarize this complex collection of documents. Instead of using an entire legal case, which usually is composed of many pages, we show that it is possible to efficiently organize the collection using the syllabus (in Portuguese, ementa jurisprudencial) from each court decision as they concisely summarize the main points presented by the entire decision.","llm_keywords":["law tech","legal cases","topic model","language models","natural language processing","legal documents","machine learning","Portuguese legal system","document organization","topic discovery"],"classifications":["Machine Summarization"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":5},{"id":"c134793037c3fbebc0a1b39e0f13014689106ad8c74b89756f8e418b228bece72b991f38a6f2136229a37ad3c1da5cce5101c109f147adfc4bc041e36ecb16f7","file_path":"legal-nlp-survey-20250328-002/original/Nakamura_2013_0010.pdf","title":"LNAI 8929 - AI Approaches to the Complexity of Legal Systems","llm_title":"Extraction of Legal Definitions and Their Explanations with Accessible Citations","authors":["Pompeu Casanovas","Ugo Pagallo","Monica Palmirani","Giovanni Sartor","Makoto Nakamura","Yasuhiro Ogawa","Katsuhiko Toyama"],"llm_authors":"Makoto Nakamura, Yasuhiro Ogawa, Katsuhiko Toyama","author_string":"Pompeu Casanovas, Ugo Pagallo, Monica Palmirani, and Giovanni Sartor (eds.)","year":2022,"abstract":"","llm_abstract":"The aim of this paper is to produce a Japanese legal terminology consisting of legal terms and their explanations that includes accessible citations. Although we have succeeded in finding over 14,000 terms with high precision, 23.1 percent of the correct explanations included citations that were inaccessible due to context-dependent format. We propose a method for revising explanatory sentences that takes into account XML-tag annotation for context-independent format for all citations. The effectiveness of this method is confirmed by our experimental results.","llm_keywords":["Japanese statutes","Definitions","XML","Citations"],"classifications":["Text Generation","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":15},{"id":"d5c63eed6715b6f024bf3a7610ef667aa8ab99ebc069280b4daa87979bba9750942336f896672fcdf316b4eaa86bdc9d4a5b799b2ef62a6ad61a6bb0fd684226","file_path":"legal-nlp-survey-20250328-002/original/Cardellino_2017_0135.pdf","title":"Legal NERC with ontologies, Wikipedia and curriculum learning","llm_title":"Legal NERC with ontologies, Wikipedia and curriculum learning","authors":["Cristian Cardellino","Milagro Teruel","Laura Alonso Alemany","Serena Villata"],"llm_authors":"Cristian Cardellino, Milagro Teruel, Laura Alonso Alemany, Serena Villata","author_string":"Cristian Cardellino ; Milagro Teruel ; Laura Alonso Alemany ; Serena Villata","year":2017,"abstract":"","llm_abstract":"In this paper, we present a Wikipedia-based approach to develop resources for the legal domain. We establish a mapping between a legal domain ontology, LKIF (Hoekstra et al., 2007), and a Wikipedia-based ontology, YAGO (Suchanek et al., 2007), and through that we populate LKIF. Moreover, we use the mentions of those entities in Wikipedia text to train a specific Named Entity Recognizer and Classifier. We find that this classifier works well in the Wikipedia, but, as could be expected, performance decreases in a corpus of judgments of the European Court of Human Rights. However, this tool will be used as a preprocess for human annotation. We resort to a technique called curriculum learning aimed to overcome problems of overfitting by learning increasingly more complex concepts. However, we find that in this particular setting, the method works best by learning from most specific to most general concepts, not the other way round.","llm_keywords":["Legal domain","Ontologies","Wikipedia","LKIF","YAGO","Named Entity Recognition","Curriculum learning","Information extraction","Ontology mapping"],"classifications":["Pre-Processing","Resources","Classification"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":6},{"id":"f9e2afc7867dd75932409cc28c2f265a2182e7b6af372af1a739616a72b2700bab83301a05ec06ef65ee872e6b7645faab70c0f08f1e8ed6bbd7689722bc1a6b","file_path":"legal-nlp-survey-20250328-002/original/Limsopatham_2021_0416.pdf","title":"Effectively Leveraging BERT for Legal Document Classification","llm_title":"Effectively Leveraging BERT for Legal Document Classification","authors":["Nut Limsopatham"],"llm_authors":"Nut Limsopatham","author_string":"Nut Limsopatham","year":2021,"abstract":"","llm_abstract":"Bidirectional Encoder Representations from Transformers (BERT) has achieved state-of-the-art performances on several text classification tasks, such as GLUE and sentiment analysis. Recent work in the legal domain started to use BERT on tasks, such as legal judgement prediction and violation prediction. A common practise in using BERT is to fine-tune a pre-trained model on a target task and truncate the input texts to the size of the BERT input (e.g. at most 512 tokens). However, due to the unique characteristics of legal documents, it is not clear how to effectively adapt BERT in the legal domain. In this work, we investigate how to deal with long documents, and how is the importance of pre-training on documents from the same domain as the target task. We conduct experiments on the two recent datasets: ECHR Violation Dataset and the Overruling Task Dataset, which are multi-label and binary classification tasks, respectively. Importantly, on average the number of tokens in a document from the ECHR Violation Dataset is more than 1,600. While the documents in the Overruling Task Dataset are shorter (the maximum number of tokens is 204). We thoroughly compare several techniques for adapting BERT on long documents and compare different models pre-trained on the legal and other domains. Our experimental results show that we need to explicitly adapt BERT to handle long documents, as the truncation leads to less effective performance. We also found that pre-training on the documents that are similar to the target task would result in more effective performance on several scenario.","llm_keywords":["BERT","legal document classification","text classification","long documents","pre-training","ECHR Violation Dataset","Overruling Task Dataset","NLP","transfer learning","semantic and syntactic knowledge"],"classifications":["Classification","Pre-Processing","Resources"],"num_cited_by":49,"num_cited_by_title_only":49,"num_pages":7},{"id":"dfd807d081e52e2f7510a2568993b7c5cd0ec38fe4fef69400dc4ae9493c537493565c1b167be93bab9ae29fa659ad8ed844b85d5e1851705c28d7588a97d3a0","file_path":"legal-nlp-survey-20250328-002/original/Carvalho_2015_0066.pdf","title":"","llm_title":"Lexical-Morphological Modeling for Legal Text Analysis","authors":["Danilo Carvalho","Minh-Tien Nguyen","Chien-Xuan Tran","Minh-Le Nguyen"],"llm_authors":"Danilo S. Carvalho, Minh-Tien Nguyen, Chien-Xuan Tran, Minh-Le Nguyen","author_string":"","year":2018,"abstract":"","llm_abstract":"In the context of the Competition on Legal Information Extraction/Entailment (COLIEE), we propose a method comprising the necessary steps for finding relevant documents to a legal question and deciding on textual entailment evidence to provide a correct answer. The proposed method is based on the combination of several lexical and morphological characteristics, to build a language model and a set of features for Machine Learning algorithms. We provide a detailed study on the proposed method performance and failure cases, indicating that it is competitive with state-of-the-art approaches on Legal Information Retrieval and Question Answering, while not needing extensive training data nor depending on expert produced knowledge. The proposed method achieved significant results in the competition, indicating a substantial level of adequacy for the tasks addressed.","llm_keywords":["Legal Text Analysis","Textual Entailment","Machine Learning","Legal Information Retrieval","COLIEE","Lexical Analysis","Morphological Modeling","Natural Language Processing","Legal Question Answering","Distributional Semantics"],"classifications":[],"num_cited_by":28,"num_cited_by_title_only":28,"num_pages":16},{"id":"dc094e051fe4bbddd44fc23b0d62fc83b60345af35413e785aaa51ad63819480a875d00a7283dd42a1df157b2199a24b83697a51dcb3bbcca7cac22c774c55a1","file_path":"legal-nlp-survey-20250328-002/original/Guo_2019_0277.pdf","title":"RnnTd: An Approach Based on LSTM and Tensor Decomposition for Classification of Crimes in Legal Cases","llm_title":"RnnTd: An Approach based on LSTM and Tensor Decomposition for Classification of Crimes in Legal Cases","authors":["Xiaoding Guo","Hongli Zhang","Lin Ye","Shang Li"],"llm_authors":"Xiaoding Guo, Hongli Zhang, Lin Ye, Shang Li","author_string":"","year":2019,"abstract":"","llm_abstract":"With the rapid development of big data and artificial intelligence technology, wisdom justice and wisdom procuratorial services have become an inevitable trend in the development of contemporary courts and procuratorates. As one of the most basic businesses involved, the classification of crimes in legal cases is one of the hot topics of research. This article proposes a classification model of legal cases based on LSTM and tensor decomposition layer, namely RnnTd. We represent different types of legal cases in terms of tensors, and then apply tensor decomposition layer to decompose the original tensors into core tensors. The core tensor represents the primary tensor elements and tensor structure information of its corresponding original tensor. Further, the core tensors are used to train LSTM to construct a legal case classification model. Compared with the classification models which are based on traditional deep learning algorithms, the tensor decomposition layer based LSTM classification model proposed in this article has weak dependence on vocabulary and grammar information in the original legal case data of legal cases, and does not require heavy manual marking work. It is worth mentioning that our model is more scalable and interpretability. Experiments show that the legal case classification algorithm proposed in this article has higher accuracy and faster convergence than traditional neural networks.","llm_keywords":["classification of crimes","LSTM","tensor decomposition","legal cases","artificial intelligence","machine learning","tensor decomposition layer","scalability","accuracy","computational complexity"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":7},{"id":"634a0d3cc2a92aa8f93b07cf5edf160ade7ad4a089a1ec2c081fbe23f9d0ebdbdc19dcff9c9ed96c6d428047512c81d5a6995f4ce80b6f812a26021141b41bf0","file_path":"legal-nlp-survey-20250328-002/original/Coulthard_2022_0559.pdf","title":"Natural language processing to identify case factors in child protection court proceedings","llm_title":"Natural language processing to identify case factors in child protection court proceedings","authors":["Beth Coulthard","Brian J Taylor"],"llm_authors":"Beth Coulthard and Brian J Taylor","author_string":"Beth Coulthard and Brian J Taylor","year":2022,"abstract":"","llm_abstract":"Social work case files hold rich detail about the lives and needs of vulnerable groups. Traditional case-reading studies to gain generalisable knowledge are resource-intensive, however, and sample sizes thereby limited. The advent of ‘big data’ technology, and vast repositories of centrally stored electronic records offer social work researchers novel alternatives, including data linkage and predictive risk modelling using administrative data. Free-text documents, however – including assessments, reports, and case chronologies – remain a largely untapped resource. This paper describes how 5000 social work court statements held by the Child and Family Court Advisory Support Service in England (Cafcass) were analysed using natural language processing (NLP) based on simple rules and mathematical principles. Thirteen factors relating to harm and risk to children involved in care proceedings in England were identified by automated computer techniques, and almost 90% agreement with professional readers achieved when the factors were clear-cut. The study represents an innovative approach for social work research on complex social problems. In conclusion, the paper discusses learning points; practical implications; future research avenues; and the technical and ethical challenges of NLP.","llm_keywords":["Algorithm","automation","big data","child protection","decision-making","natural language processing","NLP","predictive analytics","predictive risk modelling","social work"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":14},{"id":"b3a8c805e50fcb0599e5f7c9d13bd1f7c27f17be50a57fa35131faa6f945572e807e178c53e8dc4c8e40cbe5f695b546880f8b047c9162e5604a823f1ca8b05d","file_path":"legal-nlp-survey-20250328-002/original/Westermann_2021_0410.pdf","title":"","llm_title":"Data-Centric Machine Learning: Improving Model Performance and Understanding Through Dataset Analysis","authors":["Hannes Westermann","Jaromír Savelka","Vern R. Walker","Kevin D. Ashley","Karim Benyekhlef"],"llm_authors":"Hannes Westermann, Jaromír Savelka, Vern R. Walker, Kevin D. Ashley, Karim Benyekhlef","author_string":"","year":2021,"abstract":"","llm_abstract":"Machine learning research typically starts with a fixed data set created early in the process. The focus of the experiments is finding a model and training procedure that result in the best possible performance in terms of some selected evaluation metric. This paper explores how changes in a data set influence the measured performance of a model. Using three publicly available data sets from the legal domain, we investigate how changes to their size, the train/test splits, and the human labelling accuracy impact the performance of a trained deep learning classifier. Our experiments suggest that analyzing how data set properties affect performance can be an important step in improving the results of trained classifiers, and leads to better understanding of the obtained results.","llm_keywords":["Classification","Evaluation","Data-centric Approach","Machine Learning","Legal Texts","Semantic Homogeneity"],"classifications":["Classification","Resources"],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":4},{"id":"14df1e0d259eaed2c8b4094cec557ac1b811c3ae1ca700c3dca8f10fc2d8002307898cd444febd3d44f2b530b2d7d731b2db471918430c68c6158c4a7f15d9fc","file_path":"legal-nlp-survey-20250328-002/original/Varga_2022_0587.pdf","title":"Keyphrase extraction from Slovak court decisions","llm_title":"Keyphrase extraction from Slovak court decisions","authors":["Dávid Varga","Šimon Horvát","Zoltán Szoplák","Ľubomír Antoni","Stanislav Krajči","Peter Gurský","Laura Bachňáková Rózenfeldová"],"llm_authors":"Dávid Varga, Šimon Horvát, Zoltán Szoplák, Ľubomír Antoni, Stanislav Krajči, Peter Gurský and Laura Bachňáková Rózenfeldová","author_string":"","year":2022,"abstract":"","llm_abstract":"Keyphrase extraction is a vital subtask of text summarization and comparison, through which we can obtain the most relevant set of words and phrases that describe the content of a given document. In this paper we test multiple approaches of unsupervised keyword extraction on a set of court decisions. These approaches are TF-IDF, YAKE! and a graph-based weighted PageRank algorithm. We combine these algorithms with a dictionary-based word embedding method in order to capture the semantic relationships between the potential keyphrases. Extracted keyphrases can be used for semantic indexing of court decisions, which can help with finding decisions with similar content.","llm_keywords":["keyphrase","extraction","legal text","word network","embedding","court decision"],"classifications":["Information Extraction","Machine Summarization","Pre-Processing"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":9},{"id":"d6c56c516fc7c2257587fdd96c4d569e27ee88de4ebfa3d96e8e6806e94c7a14e7e9ef78db723e9d1c8c511d72b277ae3d724956dd572ec99ac83b9613a1b720","file_path":"legal-nlp-survey-20250328-002/original/Nguyen_2021_0421.pdf","title":"","llm_title":"Few-Shot Tuning Framework for Automated Terms of Service Generation","authors":["Ha Thanh Nguyen","Kiyoaki Shirai","Le Minh Nguyen"],"llm_authors":"Ha Thanh NGUYEN, Kiyoaki SHIRAI, Le Minh NGUYEN","author_string":"","year":2021,"abstract":"","llm_abstract":"In this paper, we introduce BART2S a novel framework based on BART pretrained models to generate terms of service in high quality. The framework contains two parts: a generator finetuned with multiple tasks and a discriminator finetuned to distinguish the fair and unfair terms. Besides the novelty in design and the implementation contributions, the proposed framework can support drafting terms of service, a growing need in the digital age. Our proposed approach allows the system to reach a balance between automation and the will expression of the service provider. Through experiments, we demonstrate the effectiveness of the method and discuss potential future directions.","llm_keywords":["few-shot tuning","terms of service","generation","BART","framework","automation","natural language generation"],"classifications":["Pre-Processing","Text Generation"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"28752ab6271465c879e59ed7a821b56792862325849cfe6135aa401d3479724f781d1121abcac13fafa4fdb64789d75b9f5abe51d037dd95c7a98e3bf9446603","file_path":"legal-nlp-survey-20250328-002/original/Khazaeli_2021_0381.pdf","title":"A Free Format Legal Question Answering System","llm_title":"A Free Format Legal Question Answering System","authors":["Soha Khazaeli","Janardhana Punuru","Chad Morris","Sanjay Sharma","Bert Staub","Michael Cole","Sunny Chiu-Webster","Dhruv Sakalley"],"llm_authors":"Soha Khazaeli, Janardhana Punuru, Chad Morris, Sanjay Sharma, Bert Staub, Michael Cole, Sunny Chiu-Webster, Dhruv Sakalley","author_string":"Soha Khazaeli ; Janardhana Punuru ; Chad Morris ; Sanjay Sharma ; Bert Staub ; Michael Cole ; Sunny Chiu-Webster ; Dhruv Sakalley","year":2021,"abstract":"","llm_abstract":"We present an information retrieval-based question answer system to answer legal questions. The system is not limited to a predefined set of questions or patterns and uses both sparse vector search and embeddings for input to a BERT-based answer re-ranking system. A combination of general domain and legal domain data is used for training. This natural question answering system is in production and is used commercially.","llm_keywords":["legal question answering","information retrieval","BERT","legal research","machine learning","dense vector","sparse vector"],"classifications":[],"num_cited_by":34,"num_cited_by_title_only":34,"num_pages":7},{"id":"1e8b27bb7665422966c5578f82d1680a0f0555f81f77d47560f1f1f55ffce7322d97e20326a865a9a0dcd29033d165821fda60cadb33cef4b99d88435832cf21","file_path":"legal-nlp-survey-20250328-002/original/Chen_2020_0333.pdf","title":"Joint Entity and Relation Extraction for Legal Documents with Legal Feature Enhancement","llm_title":"Joint Entity and Relation Extraction for Legal Documents with Legal Feature Enhancement","authors":["Yanguang Chen","Yuanyuan Sun","Zhihao Yang","Hongfei Lin"],"llm_authors":"Yanguang Chen, Yuanyuan Sun, Zhihao Yang, Hongfei Lin","author_string":"Yanguang Chen ; Yuanyuan Sun ; Zhihao Yang ; Hongfei LIN","year":2020,"abstract":"","llm_abstract":"In recent years, the plentiful information contained in Chinese legal documents has attracted a great deal of attention because of the large-scale release of the judgment documents on China Judgments Online. It is in great need of enabling machines to understand the semantic information stored in the documents which are transcribed in the form of natural language. The technique of information extraction provides a way of mining the valuable information implied in the unstructured judgment documents. We propose a Legal Triplet Extraction System for drug-related criminal judgment documents. The system extracts the entities and the semantic relations jointly and benefits from the proposed entity feature and multi-task learning framework. Furthermore, we manually annotate a dataset for Named Entity Recognition and Relation Extraction in Chinese legal domain, which contributes to training supervised triplet extraction models and evaluating the model performance. Our experimental results show that the entity feature introduction and multi-task learning framework are feasible and effective for the Legal Triplet Extraction System. The F1 score of triplet extraction finally reaches 0.836 on the legal dataset.","llm_keywords":["Information Extraction","Entity Recognition","Relation Extraction","Legal Documents","Chinese Legal Domain","Neural Networks","Multi-task Learning","Drug-related Crimes","Seq2Seq Model"],"classifications":["Information Extraction","Resources"],"num_cited_by":53,"num_cited_by_title_only":53,"num_pages":11},{"id":"48746855b98089dd6e5fc04808cf042bdab72038226dbe0c6ed0ae50335b4367b794d379ce0c99821bac9af3a6b5b460bf86b8cf0f94704ee5f97c5ea1288e52","file_path":"legal-nlp-survey-20250328-002/original/Hammami_2022_0492.pdf","title":"","llm_title":"A Study of Dynamic Convolutional Neural Network Technique for SCOTUS Legal Opinions Data Classification","authors":["Eya Hammami","Rim Faiz","Sami Ben Slama"],"llm_authors":"Eya Hammami, Rim Faiz, and Sami Ben Slama","author_string":"","year":2022,"abstract":"","llm_abstract":"The quantity of legal information that is being produced on a daily basis in courts is growing enormously. The processing of such data has been gaining considerable attention thanks to their availability in an electronic form and the advancement made in Artificial Intelligence applications. Indeed, deep learning has offered promising results when used in the field of natural language processing (NLP). Neural Networks such as recurrent neural network and convolutional neural networks have been used for different NLP tasks like information retrieval, document classification and sentiment analysis. In this paper, we present a Neural Network based model with a dynamic input length for classifying legal opinions from cases seen by the Supreme Court of the United States (SCOTUS) (https://www.kaggle.com/gqfiddler/scotus-opinions). The proposed model, tested over a real-world legal opinions dataset, by the way, proved better performance than the other baseline methods.","llm_keywords":["Text classification","Natural language processing","Legal text","Artificial intelligence","Deep learning","Neural networks"],"classifications":["Classification"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":13},{"id":"943109fbf48ab6ccdcc2fcfb0856a476de1633586f9165693720a5b99be3911226caba6b824af2ac14943ed1fc20f822e7824943ade154017f2eaa083d8e6eb4","file_path":"legal-nlp-survey-20250328-002/original/Jung_2017_0133.pdf","title":"Proceedings Template - WORD","llm_title":"Legal Information Retrieval System relevant to R&D Projects based on Word-embedding of Core Terms","authors":["HaeMin Jung","Youna Lee","Wooju Kim"],"llm_authors":"HaeMin Jung, Youna Lee, Wooju Kim","author_string":"End User Computing Services","year":2017,"abstract":"","llm_abstract":"Generally, Research and development projects have relationship with statutes. Sometimes, new technologies developed in R&D projects can’t be applied because they are restricted by newly enacted statutes. The situation comes from the fact that researchers don’t know well about statutes that might affect their R&D projects. Therefore, we proposed a methodology to find relevant statutes with the R&D plan, based on cosine similarity of document vectors. R&D plan is a document which is written by researchers before they get into R&D, and it contains the main concepts about the project. In our method, a R&D plan is represented as a vector using network centrality. Then cosine similarity between the vector and TF-IDF vectors of statutes is calculated. After the calculation, statutes are provided with their ranks based on similarity values, so researchers can review and check them with priority. Compared to our previous study, this study differs in that we applied new variants of vectors to enhance the performance of our methodology and find a better representation for documents.","llm_keywords":["Information Retrieval System","Vector Space Model","Cosine Similarity","R&D Projects","Statutes","TF-IDF","Document Vectors","Legal Information"],"classifications":["Information Retrieval"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":3},{"id":"a177f92cbfa14ae61e800c6956945af779bb4589c483a4d40f5ffc09e7ef95a97623b9df7a5e446ea23d3890d10640e755b54d38bc5303c7117bfe1b9695fdd5","file_path":"legal-nlp-survey-20250328-002/original/Noguti_2020_0338.pdf","title":"Legal Document Classification: An Application to Law Area Prediction of Petitions to Public Prosecution Service","llm_title":"Legal Document Classification: An Application to Law Area Prediction of Petitions to Public Prosecution Service","authors":["Mariana Noguti","Eduardo Vellasques","Luiz Oliveira"],"llm_authors":"Mariana Y. Noguti, Eduardo Vellasques, Luiz S. Oliveira","author_string":"","year":2020,"abstract":"","llm_abstract":"In recent years, there has been an increased interest in the application of Natural Language Processing (NLP) to legal documents. The use of convolutional and recurrent neural networks along with word embedding techniques have presented promising results when applied to textual classification problems, such as sentiment analysis and topic segmentation of documents. This paper proposes the use of NLP techniques for textual classification, with the purpose of categorizing the descriptions of the services provided by the Public Prosecutor’s Office of the State of Paraná to the population in one of the areas of law covered by the institution. Our main goal is to automate the process of assigning petitions to their respective areas of law, with a consequent reduction in costs and time associated with such process while allowing the allocation of human resources to more complex tasks. In this paper, we compare different approaches to word representations in the aforementioned task: including document-term matrices and a few different word embeddings. With regards to the classification models, we evaluated three different families: linear models, boosted trees and neural networks. The best results were obtained with a combination of Word2Vec trained on a domain-specific corpus and a Recurrent Neural Network (RNN) architecture (more specifically, LSTM), leading to an accuracy of 90% and F1-Score of 85% in the classification of eighteen categories (law areas).","llm_keywords":["Natural Language Processing","Text Classification","Word Embeddings","Recurrent Neural Networks","Legal Documents","Law Area Prediction","Public Prosecution","Word2Vec","LSTM","Document-term Matrices"],"classifications":["Classification"],"num_cited_by":36,"num_cited_by_title_only":36,"num_pages":8},{"id":"cd63503b911fc0549dc83ec04f04dc3070e8c65ee8314aad884bcb036c791d229c5d27dd2616a0bcdc57eeb9f3414396343b1416b564ebc9b7f485e583e0c5d7","file_path":"legal-nlp-survey-20250328-002/original/Cid_2018_0193.pdf","title":"","llm_title":"Linguistic Legal Concept Extraction in Portuguese","authors":["Alessandra Cid","Alexandre Rademaker","Bruno Cuconato","Valeria de Paiva"],"llm_authors":"Alessandra Cid, Alexandre Rademaker, Bruno Cuconato, Valeria de Paiva","author_string":"","year":2018,"abstract":"","llm_abstract":"This work investigates legal concepts and their expression in Portuguese, concentrating on the 'Order of Attorneys of Brazil' Bar exam. Using a corpus formed by a collection of multiple-choice questions, three norms related to the Ethics part of the OAB exam, language resources (Princeton WordNet and OpenWordNet-PT) and tools (AntConc and Freeling), we began to investigate the concepts and words missing from our repertory of concepts and words in Portuguese, the knowledge base OpenWordNet-PT. We add these concepts and words to OpenWordNet-PT and hence obtain a representation of these texts that is mostly 'contained' in the lexical knowledge base.","llm_keywords":["wordnet","law","legal informatics","lexical resources","Portuguese","natural language processing","legal concepts","OAB exam","OpenWordNet-PT","multiword expressions"],"classifications":["Resources","Information Extraction"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"738828349dfe01ea568b5780b2745797dd772ee58f0e0f9da7e6b5fcb7be1ffffe8dfbff9b977c447169702d4450248447a45bb9c4441575d31ead9f30ca5c6d","file_path":"legal-nlp-survey-20250328-002/original/Walker_2018_0178.pdf","title":"Evidence Types, Credibility Factors, and Patterns or Soft Rules for Weighing Conflicting Evidence: Argument Mining in the Context of Legal Rules Governing Evidence Assessment","llm_title":"Evidence Types, Credibility Factors, and Patterns or Soft Rules for Weighing Conflicting Evidence: Argument Mining in the Context of Legal Rules Governing Evidence Assessment","authors":["Vern R. Walker","Dina Foerster","Julia Monica Ponce","Matthew Rosen"],"llm_authors":"Vern R. Walker, Dina Foerster, Julia Monica Ponce, Matthew Rosen","author_string":"Vern R. Walker ; Dina Foerster ; Julia Monica Ponce ; Matthew Rosen","year":2018,"abstract":"","llm_abstract":"This paper reports on the results of an empirical study of adjudicatory decisions about veterans’ claims for disability benefits in the United States. It develops a typology of kinds of relevant evidence (argument premises) employed in cases, and it identifies factors that the tribunal considers when assessing the credibility or trustworthiness of individual items of evidence. It also reports on patterns or “soft rules” that the tribunal uses to comparatively weigh the probative value of conflicting evidence. These evidence types, credibility factors, and comparison patterns are developed to be inter-operable with legal rules governing the evidence assessment process in the U.S. This approach should be transferable to other legal and non-legal domains.","llm_keywords":["argument mining","adjudicatory decisions","evidence assessment","credibility factors","probative value","legal rules","disability benefits","veterans’ claims"],"classifications":["Classification"],"num_cited_by":23,"num_cited_by_title_only":23,"num_pages":11},{"id":"407af3bbd7253c32f9011b668ee9973b5fdf86a79bbe45dfeebbc81e4dd61df91937040c2c34cc0358fc2bb257605073470bb3c0bf306d5ef2a1afca6b57ed18","file_path":"legal-nlp-survey-20250328-002/original/Eder_2022_0487.pdf","title":"\"Beste Grüße, Maria Meyer\" — Pseudonymization of Privacy-Sensitive Information in Emails","llm_title":"“Beste Gruße, ¨ Maria Meyer” — Pseudonymization of Privacy-Sensitive Information in Emails","authors":["Elisabeth Eder","Michael Wiegand","Ulrike Krieg-Holz","Udo Hahn"],"llm_authors":"Elisabeth Eder, Michael Wiegand, Ulrike Krieg-Holz, Udo Hahn","author_string":"Elisabeth Eder ; Michael Wiegand ; Ulrike Krieg-Holz ; Udo Hahn","year":2022,"abstract":"","llm_abstract":"The exploding amount of user-generated content has spurred NLP research to deal with documents from various digital media formats (tweets, chats, emails, etc.). Using these texts as language resources implies complying with legal data privacy regulations. To protect the personal data of individuals and preclude their identification, we employ pseudonymization. More precisely, we identify those text spans that carry information revealing an individual’s identity (e.g., names of persons, locations, phone numbers, or dates) and subsequently substitute them with synthetically generated surrogates. Based on CODE ALLTAG, a German-language email corpus, we address two tasks. The first task is to evaluate various architectures for the automatic recognition of privacy-sensitive entities in raw data. The second task examines the applicability of pseudonymized data as training data for such systems since models learned on original data cannot be published for reasons of privacy protection. As outputs of both tasks, we, first, generate a new pseudonymized version of CODE ALLTAG compliant with the legal requirements of the General Data Protection Regulation (GDPR). Second, we make accessible a tagger for recognizing privacy-sensitive information in German emails and similar text genres, which is trained on already pseudonymized data.","llm_keywords":["pseudonymization","data privacy","email corpus","German language resources","named entity recognition"],"classifications":["Information Extraction"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":12},{"id":"7deee28bd3a6d0815c2c7ad5d891250ab17fde3a80f4a4cffe9aa8972d24d556142892632aa1fbd654cff354773f24cba8cd225ba6a4d0bbe759cb0a05e0c22e","file_path":"legal-nlp-survey-20250328-002/original/Cardellino_2017_0107.pdf","title":"A Low-cost, High-coverage Legal Named Entity Recognizer, Classifier and Linker","llm_title":"A Low-cost, High-coverage Legal Named Entity Recognizer, Classifier and Linker","authors":["Cristian Cardellino","Milagro Teruel","Laura Alonso Alemany","Serena Villata"],"llm_authors":"Cristian Cardellino, Milagro Teruel, Laura Alonso Alemany, Serena Villata","author_string":"Cristian Cardellino, Milagro Teruel, Laura Alonso Alemany, and Serena Villata","year":2017,"abstract":"","llm_abstract":"In this paper we try to improve Information Extraction in legal texts by creating a legal Named Entity Recognizer, Classifier and Linker. With this tool, we can identify relevant parts of texts and connect them to a structured knowledge representation, the LKIF ontology. More interestingly, this tool has been developed with relatively little effort, by mapping the LKIF ontology to the YAGO ontology and through it, taking advantage of the mentions of entities in the Wikipedia. These mentions are used as manually annotated examples to train the Named Entity Recognizer, Classifier and Linker. We have evaluated the approach on holdout texts from the Wikipedia and also on a small sample of judgments of the European Court of Human Rights, resulting in a very good performance, i.e., around 80% F-measure for different levels of granularity. We present an extensive error analysis to direct further developments, and we expect that this approach can be successfully ported to other legal subdomains, represented by different ontologies.","llm_keywords":["Legal information extraction","legal ontologies","Named Entity Recognition","Information Retrieval","LKIF ontology","YAGO ontology"],"classifications":["Information Extraction","Classification","Resources"],"num_cited_by":79,"num_cited_by_title_only":79,"num_pages":10},{"id":"2b246264a8ec048e050b4137e2dfa40098946c3c2150613634281d8ccd8ad10abfab2a17106bf513ff221e7d34585d8ca45fa4a70423860ce058a1423881cff2","file_path":"legal-nlp-survey-20250328-002/original/Galassi_2020_0313.pdf","title":"Cross-lingual Annotation Projection in Legal Texts","llm_title":"Cross-lingual Annotation Projection in Legal Texts","authors":["Andrea Galassi","Kasper Drazewski","Marco Lippi","Paolo Torroni"],"llm_authors":"Andrea Galassi, Kasper Drazewski, Marco Lippi, Paolo Torroni","author_string":"Andrea Galassi ; Kasper Drazewski ; Marco Lippi ; Paolo Torroni","year":2020,"abstract":"","llm_abstract":"We study annotation projection in text classification problems where source documents are published in multiple languages and may not be an exact translation of one another. In particular, we focus on the detection of unfair clauses in privacy policies and terms of service. We present the first English-German parallel asymmetric corpus for the task at hand. We study and compare several language-agnostic sentence-level projection methods. Our results indicate that a combination of word embeddings and dynamic time warping performs best.","llm_keywords":["Annotation Projection","Legal Texts","Multilinguality","Unfair Clauses","Privacy Policies","Terms of Service","Cross-lingual Analysis","Dynamic Time Warping","Word Embeddings","Natural Language Processing"],"classifications":["Pre-Processing","Resources","Classification"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":12},{"id":"c23c25934e9d94a5cc9d9e0cc017983fd117e3150c1e3859659e9c2d6abf3b2a5d222f20fdf9e190db27c10608f0e772ce2e3a115d4d9035cbbea02b6712ef88","file_path":"legal-nlp-survey-20250328-002/original/Galli_2022_0549.pdf","title":"","llm_title":"Predicting Outcomes of Italian VAT","authors":["Federico Galli","Giulia Grundler","Alessia Fidelangeli","Andrea Galassi","Francesca Lagioia","Elena Palmieri","Federico Ruggeri","Giovanni Sartor","Paolo Torroni"],"llm_authors":"Federico GALLI, Giulia GRUNDLER, Alessia FIDELANGELI, Andrea GALASSI, Francesca LAGIOIA, Elena PALMIERI, Federico RUGGERI, Giovanni SARTOR, Paolo TORRONI","author_string":"","year":2022,"abstract":"","llm_abstract":"This study aims at predicting the outcomes of legal cases based on the textual content of judicial decisions. We present a new corpus of Italian documents, consisting of 226 annotated decisions on Value Added Tax by Regional Tax law commissions. We address the task of predicting whether a request is upheld or rejected in the final decision. We employ traditional classifiers and NLP methods to assess which parts of the decision are more informative for the task.","llm_keywords":["Predictive Justice","Machine Learning","Natural Language Processing","Case Law","Tax Law"],"classifications":["Classification","Resources"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":6},{"id":"9cfffdb7e7224cd490b3e25e1ca08704d1775ffca8de5782115ad593dcf427983d928bdb34c870eeedcab9f7bba683e213d2281138eefa9d80af99813b2fb1de","file_path":"legal-nlp-survey-20250328-002/original/Yamakoshi_2018_0182.pdf","title":"","llm_title":"Japanese Legal Term Correction Using Random Forests","authors":["Takahiro Yamakoshi","Takahiro Komamizu","Yasuhiro Ogawa","Katsuhiko Toyama"],"llm_authors":"Takahiro YAMAKOSHI, Takahiro KOMAMIZU, Yasuhiro OGAWA, Katsuhiko TOYAMA","author_string":"","year":2018,"abstract":"","llm_abstract":"We propose a method that assists legislation officers in finding inappropriate Japanese legal terms in Japanese statutory sentences and suggests corrections. In particular, we focus on sets of similar legal terms whose usages are defined in legislation drafting rules. Our method predicts suitable legal terms in statutory sentences using Random Forest classifiers, each of which is optimized for each set of similar legal terms. Our experiment shows that our method outperformed existing modern word prediction methods using neural language models.","llm_keywords":["Japanese Legal Terms","Legal Term Correction","Random Forest","Legislation Drafting","Statutory Sentences","Language Models","Classifier Optimization","Legal Term Prediction"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"bdc58a1e1479da0b88b93ea12367ec9e95d021ef36c82fec4ed4701d8ea7de4ded98a8ffb733964ae8c2494e2e7f07160ff03644b2f17d52d381c3773c381c74","file_path":"legal-nlp-survey-20250328-002/original/Mathis_2022_0547.pdf","title":"Extracting Proceedings Data from Court Cases with Machine Learning","llm_title":"Extracting Proceedings Data from Court Cases with Machine Learning","authors":["Bruno Mathis"],"llm_authors":"Bruno Mathis","author_string":"Bruno Mathis","year":2022,"abstract":"","llm_abstract":"France is rolling out an open data program for all court cases, but with few metadata attached. Reusers will have to use named-entity recognition (NER) within the text body of the case to extract any value from it. Any court case may include up to 26 variables, or labels, that are related to the proceeding, regardless of the case substance. These labels are from different syntactic types: some of them are rare; others are ubiquitous. This experiment compares different algorithms, namely CRF, SpaCy, Flair and DeLFT, to extract proceedings data and uses the learning model assessment capabilities of Kairntech, an NLP platform. It shows that an NER model can apply to this large and diverse set of labels and extract data of high quality. We achieved an 87.5% F1 measure with Flair trained on more than 27,000 manual annotations. Quality may yet be improved by combining NER models by data type.","llm_keywords":["machine learning","named-entity recognition","information extraction","judicial data","civil procedure"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":16},{"id":"6878e0e3ff7484db3a10855b4ef98eb10c011815292d7c686743d22f3f281e1099228047f4b30cc1c0dee739f18372898e29e29441d4f0e22235be6755073be8","file_path":"legal-nlp-survey-20250328-002/original/Thomas_2020_0356.pdf","title":"Quick Check: A Legal Research Recommendation System","llm_title":"Quick Check: A Legal Research Recommendation System","authors":["Merine Thomas","Thomas Vacek","Xin Shuai","Wenhui Liao","George Sanchez","Paras Sethia","Don Teo","Kanika Madan","Tonya Custis"],"llm_authors":"Merine Thomas, Thomas Vacek, Xin Shuai, Wenhui Liao, George Sanchez, Paras Sethia, Don Teo, Kanika Madan, Tonya Custis","author_string":"Merine Thomas, Thomas Vacek, Xin Shuai, Wenhui Liao, George Sanchez, Paras Sethia, Don Teo, Kanika Madan, and Tonya Custis","year":2020,"abstract":"","llm_abstract":"Finding relevant sources of law that discuss a specific legal issue and support a favorable decision is an onerous and time-consuming task for litigation attorneys. In this paper, we present Quick Check, a system that extracts the legal arguments from a user’s brief and recommends highly relevant case law opinions. Using a combination of full-text search, citation network analysis, clickstream analysis, and a hierarchy of ranking models trained on a set of over 10K annotations, the system is able to effectively recommend cases that are similar in both legal issue and facts. Importantly, the system leverages a detailed legal taxonomy and an extensive body of editorial summaries of case law. We demonstrate how recommended cases from the system are surfaced through a user interface that enables a legal researcher to quickly determine the applicability of a case with respect to a given legal issue.","llm_keywords":["legal research","recommendation system","citation network analysis","learning to rank","legal arguments","case law","full-text search","clickstream analysis"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":4},{"id":"b16b9ee11625ada2c5d7e845595fc9198eb1adb598db936fafe5da51d239faddc344d051b550fd9ed36c24df3c91cea09e12cfed8e66b78baa576839a2cca0fd","file_path":"legal-nlp-survey-20250328-002/original/Bakker_2022_0574.pdf","title":"Extracting Structured Knowledge from Dutch Legal Texts: A Rule-based Approach","llm_title":"Extracting Structured Knowledge from Dutch Legal Texts: A Rule-based Approach","authors":["Roos Bakker","Maaike de Boer","Romy van Drie","Daan Vos"],"llm_authors":"Roos M. Bakker, Maaike H.T. de Boer, Romy A.N. van Drie, Daan Vos","author_string":"","year":2022,"abstract":"","llm_abstract":"Legal texts are difficult to interpret, and its interpretation depends on the knowledge and experience of the legal expert. Formalising interpretations can improve transparency. However, creating formalisations of legal texts is labour-intensive, and automatically creating them is still a challenge. Previous work showed that rule-based systems have mixed success on Dutch legal texts. They use complex rule systems for specific cases, making them hard to compare. Because of the lack of analysis, the success of these methods is also unclear. In this paper, we propose a new rule-based architecture for detecting the different roles of Flint frames, a knowledge representation language which aims to be a generic and less task-dependent language. The rules in this architecture are based on Part-of-Speech tags and universal dependency tags. Our analysis shows that this combination yields more precise extraction of the roles of Flint frames than previous methods, and the use of universal dependency tags allows this method to also be applied to other languages. For further improvement we suggest extending the rules for extracting the recipient role, add rules for recognising complex relative clauses, and testing this framework on English legal texts.","llm_keywords":["Information Extraction","Knowledge Modelling","Legal Interpretation Support","Dutch Legal Texts","Rule-based Systems"],"classifications":["Information Extraction"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":10},{"id":"0e8fcc7d0c0d079993f1e95d4193c31d0f741c50db8fbcb59f33b6de4bef61140fb7ddee6b8530842cc5a82e2384a83bb326d8ef77a5d7ca82bd40ca64b34050","file_path":"legal-nlp-survey-20250328-002/original/Angelidis_2018_0196.pdf","title":"","llm_title":"Named Entity Recognition, Linking and Generation for Greek Legislation","authors":["Iosif Angelidis","Ilias Chalkidis","Manolis Koubarakis"],"llm_authors":"Iosif Angelidis, Ilias Chalkidis and Manolis Koubarakis","author_string":"","year":2018,"abstract":"","llm_abstract":"We investigate named entity recognition in Greek legislation using state-of-the-art deep neural network architectures. The recognized entities are used to enrich the Greek legislation knowledge graph with more detailed information about persons, organizations, geopolitical entities, legislation references, geographical landmarks and public document references. We also interlink the textual references of the recognized entities to the corresponding entities represented in other open public datasets and, in this way, we enable new sophisticated ways of querying Greek legislation. Relying on the results of the aforementioned methods we generate and publish a new dataset of geographical landmarks mentioned in Greek legislation. We make available publicly all datasets and other resources used in our study. Our work is the first of its kind for the Greek language in such an extended form and one of the few that examines legal text in a full spectrum, for both entity recognition and linking.","llm_keywords":["Named Entity Recognition","Entity Linking","Dataset Generation","Deep Learning","Greek Legislation","Legal Text Processing","Knowledge Graph","Artificial Intelligence","Public Datasets","Open Data"],"classifications":["Information Extraction","Resources"],"num_cited_by":67,"num_cited_by_title_only":67,"num_pages":10},{"id":"0b9b89668566e6a98996275843cd5ae96b51ebb841ee50bb2d4165e44aed7c4363054d02001ecd588ac73211513bc5314be8844d54d60b44d62168bfa87f58c3","file_path":"legal-nlp-survey-20250328-002/original/Medvedeva_2020_0374.pdf","title":"Using machine learning to predict decisions of the European Court of Human Rights","llm_title":"Using machine learning to predict decisions of the European Court of Human Rights","authors":["Masha Medvedeva","Michel Vols","Martijn Wieling"],"llm_authors":"Masha Medvedeva, Michel Vols, Martijn Wieling","author_string":"Masha Medvedeva","year":2019,"abstract":"","llm_abstract":"When courts started publishing judgements, big data analysis (i.e. large-scale statistical analysis of case law and machine learning) within the legal domain became possible. By taking data from the European Court of Human Rights as an example, we investigate how natural language processing tools can be used to analyse texts of the court proceedings in order to automatically predict (future) judicial decisions. With an average accuracy of 75% in predicting the violation of 9 articles of the European Convention on Human Rights our (relatively simple) approach highlights the potential of machine learning approaches in the legal domain. We show, however, that predicting decisions for future cases based on the cases from the past negatively impacts performance (average accuracy range from 58 to 68%). Furthermore, we demonstrate that we can achieve a relatively high classification performance (average accuracy of 65%) when predicting outcomes based only on the surnames of the judges that try the case.","llm_keywords":["machine learning","case law","European Court of Human Rights","natural language processing","judicial decisions"],"classifications":["Classification"],"num_cited_by":453,"num_cited_by_title_only":453,"num_pages":30},{"id":"76e8f53e96b3a882c20f1c8d457d394446eb45c64e022bd75b4fb6baf2d5dffe3efcda986b44ac4aeffd11d44e3dfef8b1862cdfbe4c51ff7fc7507bdd99d59e","file_path":"legal-nlp-survey-20250328-002/original/Wrzalik_2021_0425.pdf","title":"GerDaLIR: A German Dataset for Legal Information Retrieval","llm_title":"GerDaLIR: A German Dataset for Legal Information Retrieval","authors":["Marco Wrzalik","Dirk Krechel"],"llm_authors":"Marco Wrzalik and Dirk Krechel","author_string":"Marco Wrzalik ; Dirk Krechel","year":2021,"abstract":"","llm_abstract":"We present GerDaLIR, a German Dataset for Legal Information Retrieval based on case documents from the open legal information platform Open Legal Data. The dataset consists of 123K queries, each labelled with at least one relevant document in a collection of 131K case documents. We conduct several baseline experiments including BM25 and a state-of-the-art neural re-ranker. With our dataset, we aim to provide a standardized benchmark for German LIR and promote open research in this area. Beyond that, our dataset comprises sufficient training data to be used as a downstream task for German or multilingual language models.","llm_keywords":["German dataset","Legal Information Retrieval","GerDaLIR","benchmark","multilingual language models","precedent retrieval","Open Legal Data"],"classifications":["Information Retrieval"],"num_cited_by":17,"num_cited_by_title_only":17,"num_pages":6},{"id":"587a8ef9fec24ff71b76c60afe297b50c0a9c38189f93524b66638f8ef4202d13cc2e35a81daf6c5f4582c93f3b85882d5b0cf1d6269708cf8f2f2e9b98ea038","file_path":"legal-nlp-survey-20250328-002/original/Shang_2022_0560.pdf","title":"","llm_title":"A Computational Intelligence Model for Legal Prediction and Decision Support","authors":["Xuerui Shang"],"llm_authors":"Xuerui Shang","author_string":"","year":2022,"abstract":"","llm_abstract":"","llm_keywords":["Legal judgment prediction","Artificial intelligence","Deep learning","Convolutional neural networks","Neural network model","Process supervision","Machine learning","Natural language processing","Legal decision support","Text classification"],"classifications":[],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":8},{"id":"e30ec34683433760542f40c8829c84615af12a144155a7b86684bb0066bd5e38c92468ab1b093b57b35ca02db162a0a33ccc7846eba38fc639b7c67de6933608","file_path":"legal-nlp-survey-20250328-002/original/Hassan_2020_0305.pdf","title":"Automated Requirements Identification from Construction Contract Documents Using Natural Language Processing","llm_title":"Automated Requirements Identification from Construction Contract Documents Using Natural Language Processing","authors":["Fahad ul Hassan","Tuyen Le"],"llm_authors":"Fahad ul Hassan and Tuyen Le, Ph.D., A.M.ASCE","author_string":"https://orcid.org/0000-0002-2308-2606Fahad ul Hassan1 and https://orcid.org/0000-0002-8606-9214Tuyen Le, Ph.D., A.M.ASCE21Ph.D. Student, Glenn Dept. of Civil Engineering, Clemson Univ., Clemson, SC 29634. ORCID: https://orcid.org/0000-0002-2308-2606. Email: fhassan@g.clemson.edu2Assistant Professor, Glenn Dept. of Civil Engineering, Clemson Univ., Clemson, SC 29634 (corresponding author). ORCID: https://orcid.org/0000-0002-8606-9214. Email: tuyenl@clemson.edu","year":2020,"abstract":"","llm_abstract":"Contract documents are a critical legal component of a construction project that specify all wishes and expectations of the owner toward the design, construction, and handover of a project. Precise comprehension of the contract documents is critical to ensure that all important contractual requirements of the project scope are captured and managed. A contract package typically includes both requirements and other unimportant texts such as instructions and supporting statements; thus, practitioners are required to read and identify texts indicating the requirements. The conventional manual practice of scope comprehension requires much time and effort and may include human errors. Little attention has been paid toward automated identification of requirement texts. This study introduces an effective way to identify contractual requirements by developing an automated framework using natural language processing (NLP) and machine learning techniques. Four different machine learning algorithms, namely Naïve Bayes, support vector machines, logistic regression, and feedforward neural network were used to develop the classification models. The models classified the contractual text into requirement and nonrequirement text. Experiments showed that the support vector machine model outperforms the other models in terms of accuracy, precision, recall, and F1-score. In addition, unigrams yield better results than higher n-gram features. An experimental study including human participants further proves that the developed model is efficient and effective that can help reduce reading time and improve contract scope comprehension. DOI: 10.1061/(ASCE)LA.1943-4170.0000379. © 2020 American Society of Civil Engineers.","llm_keywords":["Construction contracts","Scope comprehension","Project requirements","Natural language processing","Machine learning","Text classification","Project management"],"classifications":["Classification","Information Extraction"],"num_cited_by":120,"num_cited_by_title_only":120,"num_pages":12},{"id":"941b780fdb776135ce8e406b9a293149f756eddb0e70f46f87c55321b4d5c3c389c0be0084cd0bce1d0566ddf62cd8acc0930b03962604cb49a7d4b807a267e7","file_path":"legal-nlp-survey-20250328-002/original/Ashley_2013_0013.pdf","title":"Microsoft Word - Ashley Walker-Jurix2013-2Sep2013.docx","llm_title":"From Information Retrieval (IR) to Argument Retrieval (AR) for Legal Cases: Report on a Baseline Study","authors":["Kevin D. Ashley","Vern R. Walker"],"llm_authors":"Kevin D. Ashley, Vern R. Walker","author_string":"Kevin Ashley","year":2013,"abstract":"","llm_abstract":"Users of commercial legal information retrieval (IR) systems often want argument retrieval (AR): retrieving not merely sentences with highlighted terms, but arguments and argument-related information. Using a corpus of argument-annotated legal cases, we conducted a baseline study of current legal IR systems in responding to standard queries. We identify ways in which they cannot meet the need for AR and illustrate how additional argument-relevant information could address some of those inadequacies. We conclude by indicating our approach to developing an AR system to retrieve arguments from legal decisions.","llm_keywords":["argument retrieval","legal information retrieval","default-logic framework","presuppositional annotation","semantics","pragmatics","AI and Law","text annotation","Bayesian statistical inference"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":39,"num_cited_by_title_only":39,"num_pages":10},{"id":"dd3d9e0bed6975e46d42271c4f698298de7e795457172d495676e336230ab19c748b9e3c4ade5073a32b0d179dcc06c8bd5ade0e682fde1df3c46111968d0f33","file_path":"legal-nlp-survey-20250328-002/original/Nanda_2017_0134.pdf","title":"","llm_title":"Legal Information Retrieval Using Topic Clustering and Neural Networks","authors":["Rohan Nanda","Adebayo Kolawole John","Luigi Di Caro","Guido Boella","Livio Robaldo"],"llm_authors":"Rohan Nanda, Adebayo Kolawole John, Luigi Di Caro, Guido Boella, Livio Robaldo","author_string":"","year":2017,"abstract":"","llm_abstract":"This paper presents a description about our adopted approach for the information retrieval and textual entailment tasks of the COLIEE 2017 competition. We address the information retrieval task by implementing a partial string matching and a topic clustering method. For the textual entailment task, we propose a Long Short-Term Memory (LSTM) - Convolutional Neural Network (CNN) model which utilizes word embeddings trained on the Google News vectors. We evaluated our approach for both tasks on the COLIEE 2017 dataset. The results demonstrate that the topic clustering method outperformed the partial string matching method in the information retrieval task. The performance of LSTM-CNN model was competitive with other textual entailment systems.","llm_keywords":["Legal Information Retrieval","Topic Clustering","Neural Networks","Textual Entailment","LSTM","CNN","Word Embeddings","Partial String Matching","COLIEE 2017"],"classifications":["Text Generation","Resources","Information Retrieval"],"num_cited_by":40,"num_cited_by_title_only":40,"num_pages":11},{"id":"dc8ae0280bdcc57e73e56faee19a88e93bef4ccc892fec2c97a1a0912f00ae96a92de105216c7273ce786b80dc73066bcf8e9cf24bb69c2d9384142c97e45269","file_path":"legal-nlp-survey-20250328-002/original/Lagioia_2019_0234.pdf","title":"","llm_title":"Deep Learning for Detecting and Explaining Unfairness in Consumer Contracts","authors":["Francesca Lagioia","Federico Ruggeri","Kasper Drazewski","Marco Lippi","Hans-Wolfgang Micklitz","Paolo Torroni","Giovanni Sartor"],"llm_authors":"Francesca LAGIOIA, Federico RUGGERI, Kasper DRAZEWSKI, Marco LIPPI, Hans-Wolfgang MICKLITZ, Paolo TORRONI, Giovanni SARTOR","author_string":"","year":2019,"abstract":"","llm_abstract":"Consumer contracts often contain unfair clauses, in apparent violation of the relevant legislation. In this paper we present a new methodology for evaluating such clauses in online Terms of Services. We expand a set of tagged documents (terms of service), with a structured corpus where unfair clauses are liked to a knowledge base of rationales for unfairness, and experiment with machine learning methods on this expanded training set. Our experimental study is based on deep neural networks that aim to combine learning and reasoning tasks, one major example being Memory Networks. Preliminary results show that this approach may not only provide reasons and explanations to the user, but also enhance the automated detection of unfair clauses.","llm_keywords":["unfair clause detection","deep learning","memory networks"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":14,"num_cited_by_title_only":14,"num_pages":10},{"id":"878fe91214c95c3295b5a870924fb292c94df7b83e62fd48da2d3315f4578258ce036650132de3043a51aff06c11098cbc08217c0ea07457d466fdd315238893","file_path":"legal-nlp-survey-20250328-002/original/Sharma_2022_0506.pdf","title":"","llm_title":"eLegalls: Legal Informatics-enabled Legal Tech to Aid Lawyering","authors":["Sugam Sharma","Divya Dwivedi"],"llm_authors":"Sugam Sharma, Divya Dwivedi","author_string":"Sharma Sugam","year":2021,"abstract":"","llm_abstract":"Legal Tech Jurisprudence is not as developed as it was hoped for, compared with other fields of study. As a result, legal tech has not advanced globally as would have been preferred and remains primal in nature. The situation is more disappointing when it comes to developing or underdeveloped countries. While tech is critical in countries like India, which is going through digital transition currently, the justice system is still functioning in centenarian ways. For some reason, the system has not yet begun to fully harness the potential of modern technologies, which may consist of AI, ML, DL, NLP, etc. but not limited to these technologies. A lawyer, who is an integral part of the justice system, still continues to handle most tasks manually or with the help of an assistant, which often becomes challenging and cumbersome while dealing with complex legal issues that involve humongous contracts, for example. It is problems like these that can be very well handled with the help of technologies, being dubbed as legal informatics (LI), to help elevate the quality and quantity of lawyering and the core of jurisprudence. To try and resolve this problem and find an amicable solution to an extent, we have designed and developed an LI-enabled innovative computational system, called eLegalls and this paper illuminates and elaborates its potential, particularly to provide an aid for hassle-free lawyering.","llm_keywords":["eLegalls","Legal","Informatics","Law","Automation","Legal Tech","Jurisprudence","Lawyer"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":16},{"id":"1a5862d3a53d6c2657fa0758f04ea4a2f61f4a35043ca61d86cf873747436211f32d0daab6237441e8fc883613c4bf3580d5d9f7a4993065c40774eedc3e2d0a","file_path":"legal-nlp-survey-20250328-002/original/El-Ghosh_2016_0103.pdf","title":"","llm_title":"Towards a Middle-out Approach for Building Legal Domain Reference Ontology","authors":["M. El Ghosh","H. Naja","H. Abdulrab","M. Khalil"],"llm_authors":"M. El Ghosh, H. Naja, H. Abdulrab, and M. Khalil","author_string":"","year":2016,"abstract":"","llm_abstract":"This article presents a middle-out approach to build legal domain reference ontology for a Legal Knowledge Based System (LKBS). The proposed approach is a combination of top-down and bottom-up strategies. In particular, we propose to develop legal domain reference ontology, splitted into modules or fragments, based on merging two processes: Conceptual Modeling Process, by reusing foundational ontologies (top-down strategy) and Ontology Learning Process from textual resources (bottom-up strategy).","llm_keywords":["Conceptual modeling","domain reference ontology","legal ontology","modularization","ontology learning"],"classifications":["Resources"],"num_cited_by":32,"num_cited_by_title_only":32,"num_pages":7},{"id":"9ea2cb4e859a51d5375f4e73fe0ce6ad688dc5af1b6fb705b78fb3746cdcddaf144eef627ba6ffdfccd0ad866ecc1c85fe904de8a3b34125197edd56471174cc","file_path":"legal-nlp-survey-20250328-002/original/Ceross_2021_0458.pdf","title":"","llm_title":"Prediction of monetary penalties for data protection cases in multiple languages","authors":["Aaron Ceross","Tingting Zhu"],"llm_authors":"Aaron Ceross, Tingting Zhu","author_string":"","year":2021,"abstract":"","llm_abstract":"As the use of personal data becomes further entrenched in the function of societal interaction, the regulation of such data continues to grow as an important area of law. Nevertheless, it is unfortunately the case that data protection authorities have limited resources to address an increasing number of investigations. The leveraging of appropriate data-driven models, coupled with the automation of decision making, has the potential to help in such circumstances. In this paper, we evaluate machine learning models in the literature (such as Support Vector Machine (SVM), Random Forest, and Multinomial Naive Bayes (MNB) classifiers) for natural language processing in order to predict whether a monetary penalty was levied based on a description of case facts. We tested these models on a novel data set collected from the data protection authority of Macao across the three languages (i.e., Chinese, English, and Portuguese). Our experimental results show that the machine learning models provide the necessary predictability in order to automate the evaluation of data protection cases. In particular, SVM has consistent performance across three languages and achieving an AUROC of 0.725, 0.762, and 0.748 for Chinese, English, and Portuguese, respectively. We further evaluated the interpretability of the results independently for each of the languages and found that the salient texts that were identified are shared across the three languages.","llm_keywords":["data protection","machine learning","natural language processing","monetary penalties","Support Vector Machine","Random Forest","Multinomial Naive Bayes","regulation","automation","case evaluation"],"classifications":["Classification"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":5},{"id":"b0e621a912bdcb74139d361cd1d61abb2648a650cb2e8ae52382aceccfcb8a7da86b28af9e7acc788909dbd1b655c69151875aa7d1605e0640fde26e269fe6ce","file_path":"legal-nlp-survey-20250328-002/original/Mamakas_2022_0585.pdf","title":"","llm_title":"Processing Long Legal Documents with Pre-trained Transformers: Modding LegalBERT and Longformer","authors":["Dimitris Mamakas","Petros Tsotsi","Ion Androutsopoulos","Ilias Chalkidis"],"llm_authors":"Dimitris Mamakas, Petros Tsotsi, Ion Androutsopoulos, Ilias Chalkidis","author_string":"","year":2022,"abstract":"","llm_abstract":"Pre-trained Transformers currently dominate most NLP tasks. They impose, however, limits on the maximum input length (512 sub-words in BERT), which are too restrictive in the legal domain. Even sparse-attention models, such as Longformer and BigBird, which increase the maximum input length to 4,096 sub-words, severely truncate texts in three of the six datasets of LexGLUE. Simpler linear classifiers with TF-IDF features can handle texts of any length, require far less resources to train and deploy, but are usually outperformed by pre-trained Transformers. We explore two directions to cope with long legal texts: (i) modifying a Longformer warm-started from LegalBERT to handle even longer texts (up to 8,192 sub-words), and (ii) modifying LegalBERT to use TF-IDF representations. The first approach is the best in terms of performance, surpassing a hierarchical version of LegalBERT, which was the previous state of the art in LexGLUE. The second approach leads to computationally more efficient models at the expense of lower performance, but the resulting models still outperform overall a linear SVM with TF-IDF features in long legal document classification.","llm_keywords":["Transformers","LegalBERT","Longformer","legal documents","TF-IDF","NLP","LexGLUE","text classification","sparse-attention"],"classifications":["Classification","Resources","Pre-Processing"],"num_cited_by":40,"num_cited_by_title_only":40,"num_pages":13},{"id":"c10e8527fa3ac37b85d64205a22f4858a3fb5b25119e7deb1e509249ad177a3c9951ad0d309296998083ee48cfffb0ea80510a0d6b6e5a020f0a1de0de88430e","file_path":"legal-nlp-survey-20250328-002/original/de-Almeida_2020_0344.pdf","title":"","llm_title":"Legal Party Extraction from Legal Opinion Text with Sequence to Sequence Learning","authors":["Melonie de Almeida","Chamodi Samarawickrama","Nisansa de Silva","Gathika Ratnayaka","Amal Shehan Perera"],"llm_authors":"Melonie de Almeida, Chamodi Samarawickrama, Nisansa de Silva, Gathika Ratnayaka, Amal Shehan Perera","author_string":"","year":2021,"abstract":"","llm_abstract":"In the field of natural language processing, domain specific information retrieval using given documents has been a prominent and ongoing research area. The automatic extraction of the legal parties involved in a legal case has a significant impact on the proceedings of legal cases. This is a study proposing a novel way to extract the legal parties involved in a given legal document. The motivation behind this study is that there is the absence of a proper automated system to accurately identify the legal parties in a legal document. We combined several existing natural language processing annotators together with a sequence to sequence learning model to achieve the goal of extracting legal parties in a given court case document. Then, our methodology was evaluated with manually labeled court case sentences. The outcomes of the evaluation demonstrate that our system is successful in identifying legal parties.","llm_keywords":["Legal entity extraction","Natural language processing","Sequence to sequence learning","Information retrieval","Legal opinion text","Coreference resolution","NER"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":2,"num_cited_by_title_only":11,"num_pages":7},{"id":"b921c9beefde087ed3c558d8a271be421d7d0e39655e7ba2c81dfaad8a90789010249e3113dc783fd9542c2aace4a7e17a096ca092244790037f834f1fa7b5f1","file_path":"legal-nlp-survey-20250328-002/original/Amaludin_2021_0390.pdf","title":"","llm_title":"Analyze the Usage of Legal Definitions in Indonesian Regulation Using Text Mining Case Study: Treasury and Budget Law","authors":["Bakhtiar Amaludin","Fitria Ratna Wardika","Putu Jasprayana Mudana Putra","I Gede Yudi Paramartha"],"llm_authors":"Bakhtiar AMALUDIN, Fitria Ratna WARDIKA, Putu Jasprayana MUDANA PUTRA, I Gede Yudi PARAMARTHA","author_string":"","year":2021,"abstract":"","llm_abstract":"Legal definitions are an integral part of legal drafting practice to understand legal documents easily and prevent ambiguity. This research aims to describe how legal definitions are used among regulations in the domain of Indonesian Treasury and Budget. Simple text mining techniques are used to perform and deliver the process. We extracted definitions from more than 1.362 related regulations enacted through the period 2003-2020. We found that legal definitions were used in many variations which may lead to inconsistencies.","llm_keywords":["legal definition","legal term","consistency","harmonization","text mining"],"classifications":["Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":6},{"id":"000b89bbd28167a078bd068c9151702aa5f024a1053d58eb9e69452fbe864291da73cdd89df43bc29dfd2e43ad840a32d29567acb0e65adb3f247aa1e6d62a9e","file_path":"legal-nlp-survey-20250328-002/original/Sulea_2017_0125.pdf","title":"Exploring the Use of Text Classification in the Legal Domain","llm_title":"Exploring the Use of Text Classification in the Legal Domain","authors":["Octavia-Maria Șulea","Marcos Zampieri","Shervin Malmasi","Mihaela Vela","Liviu P. Dinu","Josef van Genabith"],"llm_authors":"Octavia-Maria Șulea, Marcos Zampieri, Shervin Malmasi, Mihaela Vela, Liviu P. Dinu, Josef van Genabith","author_string":"Octavia-Maria Sulea, Marcos Zampieri, Shervin Malmasi, Mihaela Vela, Liviu P. Dinu, Josef van Genabith","year":2017,"abstract":"","llm_abstract":"In this paper, we investigate the application of text classification methods to support law professionals. We present several experiments applying machine learning techniques to predict with high accuracy the ruling of the French Supreme Court and the law area to which a case belongs to. We also investigate the influence of the time period in which a ruling was made on the form of the case description and the extent to which we need to mask information in a full case ruling to automatically obtain training and test data that resembles case descriptions. We developed a mean probability ensemble system combining the output of multiple SVM classifiers. We report results of 98% average F1 score in predicting a case ruling, 96% F1 score for predicting the law area of a case, and 87.07% F1 score on estimating the date of a ruling.","llm_keywords":["text classification","legal domain","machine learning","French Supreme Court","SVM classifiers","court rulings","legal research","prediction accuracy","case description","decision support system"],"classifications":["Classification","Pre-Processing"],"num_cited_by":224,"num_cited_by_title_only":224,"num_pages":5},{"id":"47d67a77a9b5a99643669b355d76697a3520c3775cf5027c7e6f1a99b2453c926c6bf6c9bfe9b05df513fc8d44b9e5e3b2b7f41996454d7092dfffe4a92d1c0a","file_path":"legal-nlp-survey-20250328-002/original/Zhong_2020_0318.pdf","title":"","llm_title":"JEC-QA: A Legal-Domain Question Answering Dataset","authors":["Haoxi Zhong","Chaojun Xiao","Cunchao Tu","Tianyang Zhang","Zhiyuan Liu","Maosong Sun"],"llm_authors":"Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun","author_string":"","year":2019,"abstract":"","llm_abstract":"We present JEC-QA, the largest question answering dataset in the legal domain, collected from the National Judicial Examination of China. The examination is a comprehensive evaluation of professional skills for legal practitioners. College students are required to pass the examination to be certified as a lawyer or a judge. The dataset is challenging for existing question answering methods, because both retrieving relevant materials and answering questions require the ability of logic reasoning. Due to the high demand of multiple reasoning abilities to answer legal questions, the state-of-the-art models can only achieve about 28% accuracy on JEC-QA, while skilled humans and unskilled humans can reach 81% and 64% accuracy respectively, which indicates a huge gap between humans and machines on this task. We will release JEC-QA and our baselines to help improve the reasoning ability of machine comprehension models. You can access the dataset from http://jecqa.thunlp.org/.","llm_keywords":["Legal Question Answering","JEC-QA dataset","National Judicial Examination","Machine comprehension","Logic reasoning","Natural Language Processing","Legal domain","Multiple-choice questions"],"classifications":["Resources"],"num_cited_by":160,"num_cited_by_title_only":160,"num_pages":9},{"id":"269d5206742f40bd0dabd5d7217302a12cebbabeb5935cd9fd5ef3b36b4be069b092b7965015c401b7c2f14f1b049105128a323a053c29424e9dbebdea10c53b","file_path":"legal-nlp-survey-20250328-002/original/Liu_2019_0282.pdf","title":"Semantics and Structure Based Recommendation of Similar Legal Cases","llm_title":"Semantics and Structure Based Recommendation of Similar Legal Cases","authors":["Ying Liu","Xudong Luo","Xi Yang"],"llm_authors":"Ying Liu, Xudong Luo, Xi Yang","author_string":"","year":2020,"abstract":"","llm_abstract":"In order to realise the recommendation of similar legal cases, by integrating the latent semantics and structured data this paper proposes a method for calculating the similarity between criminal fact texts of two legal cases. In particular, due to the characteristics of different lengths of criminal fact texts and the high dimensional complexity of their features, we use TextRank algorithm to preprocess the criminal fact text of a legal case to realise the extraction of its key features. Finally, we conduct some experiments on 1,000 legal judgment documents of theft. More specifically, in term of the similarity between a recommended case and its real judgement, we benchmark our method with a state-of-art method and find ours significantly outperforms it.","llm_keywords":["similar case recommendation","natural language processing","structured data","text similarity","key feature extraction"],"classifications":["Pre-Processing","Information Extraction"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":8},{"id":"3c9c1feb22f32ce1f8a8146c061a6bd17b78a4e467b213b071d416643f00b29b54862e5155331c22080865b9ec9ad5fecc24326665da661486ee83c4823eb6bb","file_path":"legal-nlp-survey-20250328-002/original/Koreeda_2021_0485.pdf","title":"ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts","llm_title":"ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts","authors":["Yuta Koreeda","Christopher Manning"],"llm_authors":"Yuta Koreeda, Christopher D. Manning","author_string":"Yuta Koreeda ; Christopher Manning","year":2021,"abstract":"","llm_abstract":"Reviewing contracts is a time-consuming procedure that incurs large expenses to companies and social inequality to those who cannot afford it. In this work, we propose document-level natural language inference (NLI) for contracts, a novel, real-world application of NLI that addresses such problems. In this task, a system is given a set of hypotheses (such as “Some obligations of Agreement may survive termination.”) and a contract, and it is asked to classify whether each hypothesis is entailed by, contradicting to or not mentioned by (neutral to) the contract as well as identifying evidence for the decision as spans in the contract. We annotated and release the largest corpus to date consisting of 607 annotated contracts. We then show that existing models fail badly on our task and introduce a strong baseline, which (1) models evidence identification as multi-label classification over spans instead of trying to predict start and end tokens, and (2) employs more sophisticated context segmentation for dealing with long documents. We also show that linguistic characteristics of contracts, such as negations by exceptions, are contributing to the difficulty of this task and that there is much room for improvement.","llm_keywords":["Contract review","Natural Language Inference","Document-level NLI","Contracts dataset","Linguistic characteristics"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":103,"num_cited_by_title_only":103,"num_pages":13},{"id":"556e88b06550e97ec9c7f58003000eac7a9fc88a9aa9835f02be55995a98013bb13cd003d269d0e69e9da6889bb706d642f15174bdf80a66827b7a62afd40856","file_path":"legal-nlp-survey-20250328-002/original/Vacek_2017_0110.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"A Sequence Approach to Case Outcome Detection","authors":["Tom Vacek","Frank Schilder"],"llm_authors":"Tom Vacek, Frank Schilder","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"We describe a system to detect the outcome of U.S. Federal District Court cases based on PACER electronic dockets. We study the text processing components of the system and develop two model architectures in order to detect the outcome of a case per party (e.g., dismissed by Court or Verdict for Plaintiff!). We conclude that modeling cases as a linear-chain graphical model (i.e., Conditional Random Field (CRF)) offers significantly better performance than modeling the case entry-by-entry (i.e., Logistic Regression (LR)). We in particular show that a first-order modeling of the CRF significantly outperforms the factorized model for the CRF architecture.","llm_keywords":["sequence tagging","text classification","case outcome detection"],"classifications":["Classification"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":7},{"id":"7673df7e126872877fe69e4f659967a36431e587c6cbcade4289a3756fd58929e1130e07eeeb5a447db849fc72eba592a39c8eff9a070634af37b30d71c21f59","file_path":"legal-nlp-survey-20250328-002/original/Ning_2022_0534.pdf","title":"WCMC_6606588 1..8","llm_title":"Natural Language Processing Technology Used in Artificial Intelligence Scene of Law for Human Behavior","authors":["Jin Ning"],"llm_authors":"Jin Ning","author_string":"","year":2022,"abstract":"","llm_abstract":"In order to study the application of natural language processing (NLP) technology in artificial intelligence (AI) scene of law, NLP technology is used to construct a legal AI retrieval system and further simulate the system. Then, by inputting the subject matter of the case into the system, the system’s accuracy, recall rate, and error rate and other related indicators are evaluated, to analyze the performance of the legal retrieval system. The results show that in the case analysis of a single theme, the accuracy rate of the case with the theme of “impeding police enforcement” is low, and the accuracy rate of the other theme cases is over 70%, and the highest accuracy rate even reaches 95%. In the case retrieval analysis of multitheme, the accuracy rate of case retrieval is improved, higher than 75%, and the zero-detection rate is significantly reduced with the increase in keywords. In the analysis of network case retrieval, the average correct rate of the overall case retrieval will be nearly 65%. Further tests on its reliability show that during the continuous week of the retrieval test, the system has no faults and passed the reliability test. Therefore, through this study, it is found that the application of NLP technology in the legal AI retrieval system has a reliable accuracy, which meets the expectation of this paper.","llm_keywords":["Natural Language Processing","Artificial Intelligence","Legal AI retrieval system","Judicial field","Human-computer interaction"],"classifications":["Information Retrieval"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":8},{"id":"e9dd019760e23c8fbc92700e2200e995d5e2a3d58c665a7a24a9fc6b42b1f4cc4dd2054215401181ea0281e3fd1bde62d54261473b4900799a18eae567bbd5e8","file_path":"legal-nlp-survey-20250328-002/original/Chi_2022_0562.pdf","title":"","llm_title":"PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English","authors":["Jianfeng Chi","Wasi Uddin Ahmad","Yuan Tian","Kai-Wei Chang"],"llm_authors":"Jianfeng Chi, Wasi Uddin Ahmad, Yuan Tian, Kai-Wei Chang","author_string":"","year":2022,"abstract":"","llm_abstract":"Privacy policies provide individuals with information about their rights and how their personal information is handled. Natural language understanding (NLU) technologies can support individuals and practitioners to understand better privacy practices described in lengthy and complex documents. However, existing efforts that use NLU technologies are limited by processing the language in a way exclusive to a single task focusing on certain privacy practices. To this end, we introduce the Privacy Policy Language Understanding Evaluation (PLUE) benchmark, a multi-task benchmark for evaluating the privacy policy language understanding across various tasks. We also collect a large corpus of privacy policies to enable privacy policy domain-specific language model pre-training. We demonstrate that domain-specific pre-training offers performance improvements across all tasks. We release the benchmark to encourage future research in this domain.","llm_keywords":["Privacy policies","Natural language understanding","PLUE benchmark","Privacy practices","Domain-specific pre-training","Text classification","Question answering","Semantic parsing","Named-entity recognition"],"classifications":["Pre-Processing","Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":8},{"id":"85b14c975cfd8edbafc12e4f2718651d0df44d1511242ca449a9ab9bde49321932469c4ab15887af372889090ac8e370a38585cc09da08d84dac8e92bc38662f","file_path":"legal-nlp-survey-20250328-002/original/D.-Zhang_2021_0459.pdf","title":"WCMC_1783260 1..11","llm_title":"Recognition of Chinese Legal Elements Based on Transfer Learning and Semantic Relevance","authors":["Dian Zhang","Hewei Zhang","Long Wang","Jiamei Cui","Wen Zheng"],"llm_authors":"Dian Zhang, Hewei Zhang, Long Wang, Jiamei Cui, Wen Zheng","author_string":"","year":2022,"abstract":"","llm_abstract":"","llm_keywords":["Chinese Legal Elements","Transfer Learning","Semantic Relevance","BERT","Judicial AI","LegalAI","Deep Learning","Document Processing","Legal Document Analysis"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":11},{"id":"07cdc05a51f88b371cda953a2b16d0a03489df360880100477d390698d46c86f6e4b6e55098664e7f2e45034e0208a367e62f1ebb80f1d2930713cb24d53714b","file_path":"legal-nlp-survey-20250328-002/original/Jungiewicz_2014_0047.pdf","title":"","llm_title":"Unsupervised Keyword Extraction From Polish Legal Texts","authors":["Michał Jungiewicz","Michał Łopuszyński"],"llm_authors":"Michał Jungiewicz, Michał Łopuszyński","author_string":"","year":2015,"abstract":"","llm_abstract":"In this work, we present an application of the recently proposed unsupervised keyword extraction algorithm RAKE to a corpus of Polish legal texts from the field of public procurement. RAKE is essentially a language and domain independent method. Its only language-specific input is a stoplist containing a set of non-content words. The performance of the method heavily depends on the choice of such a stoplist, which should be domain adopted. Therefore, we complement RAKE algorithm with an automatic approach to selecting non-content words, which is based on the statistical properties of term distribution.","llm_keywords":["keyword extraction","unsupervised learning","legal texts","RAKE algorithm","Polish legal texts","stoplist generation","term distribution"],"classifications":["Information Extraction","Resources"],"num_cited_by":19,"num_cited_by_title_only":19,"num_pages":7},{"id":"59436888ab08360e81b3507ffdaad3c4f4cb724944f97b18140f01bb3f6487db9bc34b51340175f58323c07b21c8761b02a9fd06d77d35302d391b7ec820d14a","file_path":"legal-nlp-survey-20250328-002/original/Raghav_2016_0080.pdf","title":"","llm_title":"Analyzing the Extraction of Relevant Legal Judgments using Paragraph-level and Citation Information","authors":["K Raghav","P Krishna Reddy","V Balakista Reddy"],"llm_authors":"K. Raghav, P. Krishna Reddy, V. Balakista Reddy","author_string":"","year":2016,"abstract":"","llm_abstract":"Building efficient search systems to extract relevant information from a huge volume of legal judgments is a research issue. In the literature, efforts are being made to build efficient search systems in the legal domain by extending information retrieval approaches. We are making efforts to investigate improved approaches to extract relevant legal judgments for a given input judgment by exploiting text and citation information of legal judgments. Typically, legal judgments are very large text documents and contain several intricate legal concepts. In this paper, we analyze how the paragraph-level and citation information of the judgments could be exploited for retrieving relevant legal judgments for the given judgment. In this paper, we have proposed improved ranking approach to find the relevant legal judgments of a given judgment based on the similarity between the paragraphs of the judgments by employing Okapi retrieval model and citation information. The user evaluation study on legal judgments data set delivered by Supreme Court of India shows that the proposed approach improves the ranking performance over the baseline approach. Overall, the analysis shows that there is a scope to exploit the paragraph-level and citation information of the judgments to improve the search performance.","llm_keywords":["Legal judgments","Information retrieval","Paragraph-level analysis","Citation information","Okapi retrieval model","Legal search systems","Common law","Precedents","Legal concepts","Ranking improvement"],"classifications":["Information Retrieval"],"num_cited_by":43,"num_cited_by_title_only":43,"num_pages":8},{"id":"37a785b9efa03de3932cc0158939e0375b560613b9a0fe1e8ed06d3a5303707732f24e38cf7117bc71ac08b74bf93cc15abc82872f390f00d8f4367344725501","file_path":"legal-nlp-survey-20250328-002/original/Sadeghian_2016_0102.pdf","title":"","llm_title":"Semantic Edge Labeling over Legal Citation Graphs","authors":["Ali Sadeghian","Laksshman Sundaram","Daisy Zhe Wang","William F. Hamilton","Karl Branting","Craig Pfeifer"],"llm_authors":"Ali Sadeghian, Laksshman Sundaram, Daisy Zhe Wang, William F. Hamilton, Karl Branting, Craig Pfeifer","author_string":"","year":2016,"abstract":"","llm_abstract":"Citations, as in when a certain statute is being cited in another statute, differ in meaning, and we aim to annotate each edge with a semantic label that expresses this meaning or purpose. Our efforts involve defining, annotating and automatically assigning each citation edge with a specific semantic label. In this paper we define a gold set of labels that cover a vast majority of citation types that appear in the United States Code (US Code) but still specific enough to meaningfully group each citation. We proposed a Linear-Chain CRF based model to extract the useful features needed to label each citation. The extracted features were then mapped to a vector space using a word embedding technique and we used clustering methods to group the citations to their corresponding labels. This paper analyzes the content and structure of the US Code, but most of the techniques used can be easily generalized to other legal documents. It is worth mentioning that during this process we also collected a human labeled data set of the US Code that can be very useful for future research.","llm_keywords":["US Code","Legal citation graph","Automatic citation analysis","Conditional Random Fields","K-means clustering"],"classifications":["Information Extraction","Classification","Resources"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":6},{"id":"b8ec88a01643ef17178de825a7c29e3243185c2875ffda4dbd0e648a8855c23c92526ec052c692c72ddbddc8b3d8d9fceb4c40c5d4386fa9674e7057dcabd87d","file_path":"legal-nlp-survey-20250328-002/original/Gianfelice_2013_0020.pdf","title":"","llm_title":"Modificatory Provisions Detection: a Hybrid NLP Approach","authors":["Davide Gianfelice","Leonardo Lesmo","Monica Palmirani","Daniele Perlo","Daniele P. Radicioni"],"llm_authors":"Davide Gianfelice, Leonardo Lesmo, Monica Palmirani, Daniele Perlo, Daniele P. Radicioni","author_string":"","year":2013,"abstract":"","llm_abstract":"In the last few years University of Turin and CIRSFID University of Bologna collaborated to pair NLP techniques and legal knowledge to detect modificatory provisions in normative texts. Annotating these modifications is a relevant and interesting problem, in that modifications affect the whole normative system; and legal language, though more regular than unrestricted language, is sometimes particularly convoluted, and poses specific linguistic issues. This paper focuses on two major aspects. First, we explore a combination between parsing and regular expressions; to the best of our knowledge, such hybrid strategy has never been proposed before to tackle the problem at hand. Secondly, we significantly extend past works coverage (basically focussed on substitution, integration and repeal modifications) in order to account for further twelve modification kinds. For the sake of conciseness, we fully illustrate and discuss only few modification types that are more relevant and interesting: suspension, prorogation of efficacy, postponement of efficacy and exception/derogation. These sorts of modifications appear particularly challenging, in that modifications in these categories make use of similar linguistic speech acts and verbs, and exhibit strong similarities in the linguistic syntactical patterns, to such an extent that to discern them is difficult for the legal expert, too. We describe the implemented system and report about an extensive experimentation on the new modificatory provisions. Results are discussed in order to improve both system’s accuracy and annotation practice.","llm_keywords":["Natural Language Processing","Modificatory Provisions","Legal Domain","Information Extraction","Text Analysis","Hybrid NLP Approach","Parsing","Regular Expressions","Semantic Annotation","Legal Language"],"classifications":["Information Extraction"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":11},{"id":"1e51dcb7dd975c0702335b97395c4c893d8e02c1d3d4ad4d77d0bc4825684540f9a1e262f78a825cd990492d29765794cea99d4a65986f773de2a6c2d90aa0ac","file_path":"legal-nlp-survey-20250328-002/original/Ferro_2019_0279.pdf","title":"Scalable Methods for Annotating Legal-Decision Corpora","llm_title":"Scalable Methods for Annotating Legal-Decision Corpora","authors":["Lisa Ferro","John Aberdeen","Karl Branting","Craig Pfeifer","Alexander Yeh","Amartya Chakraborty"],"llm_authors":"Lisa Ferro, John Aberdeen, Karl Branting, Craig Pfeifer, Alexander Yeh, Amartya Chakraborty","author_string":"Lisa Ferro ; John Aberdeen ; Karl Branting ; Craig Pfeifer ; Alexander Yeh ; Amartya Chakraborty","year":2019,"abstract":"","llm_abstract":"Recent research has demonstrated that judicial and administrative decisions can be predicted by machine-learning models trained on prior decisions. However, to have any practical application, these predictions must be explainable, which in turn requires modeling a rich set of features. Such approaches face a roadblock if the knowledge engineering required to create these features is not scalable. We present an approach to developing a feature-rich corpus of administrative rulings about domain name disputes, an approach which leverages a small amount of manual annotation and prototypical patterns present in the case documents to automatically extend feature labels to the entire corpus. To demonstrate the feasibility of this approach, we report results from systems trained on this dataset.","llm_keywords":["legal decision prediction","machine learning","feature-rich corpus","administrative rulings","annotation","domain name disputes","explainable AI","legal argumentation"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":9},{"id":"d8fbb46c447515a437a6163b5cd47600eaf560199930b12f0b09a5d098cceac9998fdc845d3edaf6ef95ac515fd5458b73ca05780ce6a9f5766fb5bf007f2d20","file_path":"legal-nlp-survey-20250328-002/original/Nanda_2017_0111.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"A Unifying Similarity Measure for Automated Identification of National Implementations of European Union Directives","authors":["Rohan Nanda","Luigi Di Caro","Guido Boella","Hristo Konstantinov","Tenyo Tyankov","Daniel Traykov","Hristo Hristov","Francesco Costamagna","Llio Humphreys","Livio Robaldo","Michele Romano"],"llm_authors":"Rohan Nanda, Luigi Di Caro, Guido Boella, Hristo Konstantinov, Tenyo Tyankov, Daniel Traykov, Hristo Hristov, Francesco Costamagna, Llio Humphreys, Livio Robaldo, Michele Romano","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"This paper presents a unifying text similarity measure (USM) for automated identification of national implementations of European Union (EU) directives. The proposed model retrieves the transposed provisions of national law at a fine-grained level for each article of the directive. USM incorporates methods for matching common words, common sequences of words and approximate string matching. It was used for identifying transpositions on a multilingual corpus of four directives and their corresponding national implementing measures (NIMs) in three different languages: English, French and Italian. We further utilized a corpus of four additional directives and their corresponding NIMs in English language for a thorough test of the USM approach. We evaluated the model by comparing our results with a gold standard consisting of official correlation tables (where available) or correspondences manually identified by domain experts. Our results indicate that USM was able to identify transpositions with average F-score values of 0.808, 0.736 and 0.708 for French, Italian and English Directive-NIM pairs respectively in the multilingual corpus. A comparison with state-of-the-art methods for text similarity illustrates that USM achieves a higher F-score and recall across both the corpora.","llm_keywords":["European law","legal information retrieval","transposition","text similarity","EU directives","national implementing measures","multilingual corpus","conformity checking","correlation tables","automated identification"],"classifications":["Information Retrieval"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":10},{"id":"23469242f4f94052b675274f6f596d0abceebb080bb736d9e7537432fd9954b397ead3c0db1714a4f9a83fe7dce477c5d345b32c4feb429ea737961569085df2","file_path":"legal-nlp-survey-20250328-002/original/Mukherjee_2020_0330.pdf","title":"","llm_title":"Immigration Document Classification and Automated Response Generation","authors":["Sourav Mukherjee","Tim Oates","Vince DiMascio","Huguens Jean","Rob Ares","David Widmark","Jaclyn Harder"],"llm_authors":"Sourav Mukherjee, Tim Oates, Vince DiMascio, Huguens Jean, Rob Ares, David Widmark, Jaclyn Harder","author_string":"","year":2020,"abstract":"","llm_abstract":"In this paper, we consider the problem of organizing supporting documents vital to U.S. work visa petitions, as well as responding to Requests For Evidence (RFE) issued by the U.S. Citizenship and Immigration Services (USCIS). Typically, both processes require a significant amount of repetitive manual effort. To reduce the burden of mechanical work, we apply machine learning methods to automate these processes, with humans in the loop to review and edit output for submission. In particular, we use an ensemble of image and text classifiers to categorize supporting documents. We also use a text classifier to automatically identify the types of evidence being requested in an RFE, and used the identified types in conjunction with response templates and extracted fields to assemble draft responses. Empirical results suggest that our approach achieves considerable accuracy while significantly reducing processing time.","llm_keywords":["Immigration","Document Classification","Automated Response","Machine Learning","U.S. Work Visa","Requests for Evidence","OCR","Text Classification","Image Classification"],"classifications":["Classification","Information Extraction"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":8},{"id":"32b10f17aa95a172f7c22153ee53152fe23d9e70ba95b7967711d36201ca4a12b08c9636f76a0857daf850349fef52d6bdcb0ce9c4e7ee5ae6f41610d8351a44","file_path":"legal-nlp-survey-20250328-002/original/Bhattacharya_2022_0521.pdf","title":"Legal case document similarity: You need both network and text","llm_title":"Legal case document similarity: You need both network and text","authors":["Paheli Bhattacharya","Kripabandhu Ghosh","Arindam Pal","Saptarshi Ghosh"],"llm_authors":"Paheli Bhattacharya, Kripabandhu Ghosh, Arindam Pal, Saptarshi Ghosh","author_string":"Paheli Bhattacharya","year":2022,"abstract":"","llm_abstract":"Estimating the similarity between two legal case documents is an important and challenging problem, having various downstream applications such as prior-case retrieval and citation recommendation. There are two broad approaches for the task — citation network-based and text-based. Prior citation network-based approaches consider citations only to prior-cases (also called precedents) (PCNet). This approach misses important signals inherent in Statutes (written laws of a jurisdiction). In this work, we propose Hier-SPCNet that augments PCNet with a heterogeneous network of Statutes. We incorporate domain knowledge for legal document similarity into Hier-SPCNet, thereby obtaining state-of-the-art results for network-based legal document similarity. Both textual and network similarity provide important signals for legal case similarity; but till now, only trivial attempts have been made to unify the two signals. In this work, we apply several methods for combining textual and network information for estimating legal case similarity. We perform extensive experiments over legal case documents from the Indian judiciary, where the gold standard similarity between document-pairs is judged by law experts from two reputed Law institutes in India. Our experiments establish that our proposed network-based methods significantly improve the correlation with domain experts’ opinion when compared to the existing methods for network-based legal document similarity. Our best-performing combination method (that combines network-based and text-based similarity) improves the correlation with domain experts’ opinion by 11.8% over the best text-based method and 20.6% over the best network-based method. We also establish that our best-performing method can be used to recommend/retrieve citable and similar cases for a source (query) case, which are well appreciated by legal experts.","llm_keywords":["Legal IR","Legal document similarity","Citation network","Heterogeneous network","Network embeddings","Text embeddings","Combining text and network similarity"],"classifications":["Information Retrieval","Classification"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":24},{"id":"9794cbaea27e249fe7db6bad1b3314a524d15d6baf952e1cce1089dd30dbd8d69f67399092af67aad49fb0b353e6136b56d0a369fef3bf11d7218b844e056165","file_path":"legal-nlp-survey-20250328-002/original/Son_2015_0071.pdf","title":"Recognizing logical parts in Vietnamese legal texts using Conditional Random Fields","llm_title":"Recognizing logical parts in Vietnamese Legal Texts using Conditional Random Fields","authors":["Truong Son Nguyen","Thi Phuong Duyen Nguyen","Bao Quoc Ho","Le Minh Nguyen"],"llm_authors":"Nguyen Truong Son, Nguyen Thi Phuong Duyen, Ho Bao Quoc, Nguyen Le Minh","author_string":"","year":2015,"abstract":"","llm_abstract":"Analyzing the structure of legal sentences in legal document is an important phase to build a knowledge management system in Legal Engineering. This paper proposes a new approach to recognize logical parts in Vietnamese legal documents based on a statistic machine learning method - Conditional Random Fields. Beside linguistic features such as word features, part of speech features, we use semantic features of logical parts such as trigger features and ontology features to improve the result of the annotation system. Experiments were conducted in a Vietnamese Business Law data set and obtained 78.12% at precision and 68.72% at recall measure. Compare to state-of-the-art systems, it improves the result for recognizing some logical parts.","llm_keywords":["legal text mining","semantic annotation","machine learning","conditional random field","named entities recognition"],"classifications":["Information Extraction"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":6},{"id":"a5adeb9fc4cd3e3ca0e1d4c48d3b54b54496af856c3d9c95ab51d15a532376db045b91a30c140d00bb4f66619197e22c1af76528482f934c60eb9e3f01e7cdf6","file_path":"legal-nlp-survey-20250328-002/original/Ahmed_2022_0570.pdf","title":"Comparison of Transformer Models for Information Extraction from Court Room Records in Pakistan","llm_title":"Comparison of Transformer Models for Information Extraction from Court Room Records in Pakistan","authors":["Nida Ahmed","Seemab Latif","Rabia Irfan","Adnan Ul-Hasan","Faisal Shafait"],"llm_authors":"Nida Ahmed, Seemab Latif, Rabia Irfan, Adnan Ul-Hasan, Faisal Shafait","author_string":"Nida Ahmed; Seemab Latif; Rabia Irfan; Adnan Ul-Hasan; Faisal Shafait","year":2022,"abstract":"","llm_abstract":"The legal domain has many opportunities when it comes to improvement and innovation through computational advancements. In Pakistan, as the number of reported judgments continues to grow at a rapid rate, it has become essential to process this massive chunk of data to better meet the requirements of the respective stakeholders. However, extracting the required information from this unstructured legal text is challenging. In this paper, we have compared different variations of BERT to see which would be more suited for a machine learning system that can automatically extract information from these publicly available judgments of the Supreme Court of Pakistan. A labelled dataset comprising of thirteen entities has been created using the publicly available legal judgments from the Supreme Court. Different pre-trained BERT models, namely BERTBASE-uncased, BERTBASE-cased and LegalBERT, are then further trained and fine-tuned on the created dataset for Named Entity with F1 scores of 92.47%, 94.72% and 92.51% respectively. The BERT models have been found to improve the F1 scores of previous studies on a dataset available from Lahore High Court, having smaller number of labels, with the F1 scores of 82.3%, 93.21% and 85.06%, respectively.","llm_keywords":["Transformer Models","BERT","Information Extraction","Legal Text","Named Entity Recognition","Court Records","Pakistan","Supreme Court Judgments","Machine Learning"],"classifications":["Information Extraction","Resources","Pre-Processing"],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":6},{"id":"64978cc169becddf62465e1b1f84e36248986b6ca4c06b812685c3b591b651ea9a0677e492e4792cd982f6a72275ae268d13365f96047e19d2ecc753e9b41161","file_path":"legal-nlp-survey-20250328-002/original/Yoshioka_2021_0401.pdf","title":"","llm_title":"BERT-based Ensemble Methods with Data Augmentation for Legal Textual Entailment in COLIEE Statute Law Task","authors":["Masaharu Yoshioka","Yasuhiro Aoki","Youta Suzuki"],"llm_authors":"Masaharu Yoshioka, Yasuhiro Aoki, Youta Suzuki","author_string":"","year":2021,"abstract":"","llm_abstract":"The Competition on Legal Information Extraction/Entailment (COLIEE) statute law legal textual entailment task (task 4) is a task to make a system judge whether a given question statement is true or not by provided articles. In the last COLIEE 2020, the best performance system used bidirectional encoder representations from transformers (BERT), a deep-learning-based natural language processing tool for handling word semantics by considering their context. However, there are problems related to the small amount of training data and the variability of the questions. In this paper, we propose a BERT-based ensemble method with data augmentation to solve this problem. For the data augmentation, we propose a systematic method to make training data for understanding the syntactic structure of the questions and articles for entailment. In addition, due to the nature of the non-deterministic characteristics of BERT fine-tuning and the variability of the questions, we propose a method to construct multiple BERT fine-tuning models and select an appropriate set of models for ensemble. The accuracy of our proposed method for task 4 was 0.7037, which was the best performance among all submissions.","llm_keywords":["Textual entailment","Data augmentation","BERT","Ensemble method","Legal information extraction"],"classifications":["Information Extraction"],"num_cited_by":37,"num_cited_by_title_only":37,"num_pages":7},{"id":"76a0be7b5d9e1193bc6f44ac3734b79dce2c9269ec9389b9c10430bbe246987b8488f14f33086c242b7e2c6dee5c98eefd631f0f8ece34ebd7460d2173dc4403","file_path":"legal-nlp-survey-20250328-002/original/Boer_2016_0095.pdf","title":"","llm_title":"Making a Cold Start in Legal Recommendation: an Experiment","authors":["Alexander Boer","Radboud Winkels"],"llm_authors":"Alexander Boer and Radboud Winkels","author_string":"","year":2016,"abstract":"","llm_abstract":"Since the OpenLaws portal is envisioned as an open environment for collaboration between legal professionals, recommendation will eventually become a collaborative filtering problem. This paper addresses the cold start problem for such a portal, where initial recommendations will have to be given, while collaborative filtering data is initially too sparse to produce recommendations. We implemented a hybrid recommendation approach, starting with a latent dirichlet allocation topic model, and progressing to collaborative filtering, and critically evaluated it. Main conclusion is that giving recommendations, even bad ones, will influence user selections.","llm_keywords":["OpenLaws portal","collaborative filtering","cold start problem","latent Dirichlet allocation","legal recommendation","user influence","recommendation system"],"classifications":["Information Retrieval"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":8},{"id":"06de3d1ac6e10f92cf6d2f8ac5cda2e96560d785e43eeab7320447b1763752472a73b26bff41d5395bf2aace7712e8b01f160fbe6a523b7416f89cafc79527ee","file_path":"legal-nlp-survey-20250328-002/original/Remmits_2017_0127.pdf","title":"","llm_title":"Finding the Topics of Case Law: Latent Dirichlet Allocation on Supreme Court Decisions","authors":["Ylja Remmits"],"llm_authors":"Ylja Remmits","author_string":"","year":2017,"abstract":"","llm_abstract":"The law produces a large amount case law, which is still mostly processed by hand. The Case Law Analytics project aims to develop a technology that assists the legal community in analyzing case law. As a part of this project, this thesis explores the possibilities of finding accurate and useful legal topics with LDA and whether or not legal experts and people with a non-legal background agree in their judgments about this. To this end I investigated possible methods suited for evaluation of the model’s results. I evaluated the topics as well as their assignment to the documents using human evaluation. I found that the topics evaluated to cohere most, are easy to label. Human subjects were also mostly able to differentiate between topics assigned to a document with high probability and topics that do not belong to this document. However less than half the topics were evaluated as coherent by the subjects and according to the subjects the main topic of a document was not found by the model for most of the documents. I also found that domain experts and non domain experts might evaluate topics differently. I argue that the usability of the results depends on the intended application and introduce some complications specific to the legal domain, which should be taken into account as well.","llm_keywords":["case law","Latent Dirichlet Allocation","Supreme Court decisions","legal topics","human evaluation","legal analytics","topic modeling","legal research","network approach","automated legal analysis"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":20,"num_cited_by_title_only":20,"num_pages":31},{"id":"e7c9fffe7967d84bf7415f2927eb9d6a918f3cdee786b7319fb71004032d9bd172501051a58d8e822d7f940b14b829591eea01c16cfff5b184a65942c6289fe8","file_path":"legal-nlp-survey-20250328-002/original/Hamann_2016_0087.pdf","title":"","llm_title":"Computer Assisted Legal Linguistics (CAL²)","authors":["Hanjo Hamann","Friedemann Vogel","Isabelle Gauer"],"llm_authors":"Hanjo HAMANN, Friedemann VOGEL, Isabelle GAUER","author_string":"","year":2016,"abstract":"","llm_abstract":"We introduce Computer Assisted Legal Linguistics (CAL²) as a semi-automated method to “make sense” of legal discourse by systematically analyzing large collections of legal texts. Such digital corpora have been increasingly used in computational linguistics in recent years, as part of a quantitative research strategy designed to complement (rather than supplant) the more qualitative methods used hitherto. This use of statistical algorithms to analyze large bodies of text meets with an increasing demand by lawyers for empirical data and the recent turn towards evidence-based jurisprudence. Together, these research strands open exciting avenues for research and for developing useful IT tools to support legal decision-making, as we exemplify using our reference corpus of about 1 billion tokens from the language of German jurisprudence and legal academia.","llm_keywords":["Computational linguistics","corpus linguistics","legal semantics","law and language","CAL²"],"classifications":["Information Extraction","Resources","Machine Summarization"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":4},{"id":"85735550df953797dcb7e4a61fc282b022cf3cfa291502bfff9eb3e54f4d91c50e321643d78bcf6eca4ad906be0777445dd02906cfbfc0545119a4536710b510","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2022_0586.pdf","title":"","llm_title":"An Exploration of Hierarchical Attention Transformers for Efficient Long Document Classification","authors":["Ilias Chalkidis","Xiang Dai","Manos Fergadiotis","Prodromos Malakasiotis","Desmond Elliott"],"llm_authors":"Ilias Chalkidis, Xiang Dai, Manos Fergadiotis, Prodromos Malakasiotis, Desmond Elliott","author_string":"","year":2022,"abstract":"","llm_abstract":"Non-hierarchical sparse attention Transformer-based models, such as Longformer and Big Bird, are popular approaches to working with long documents. There are clear benefits to these approaches compared to the original Transformer in terms of efficiency, but Hierarchical Attention Transformer (HAT) models are a vastly understudied alternative. We develop and release fully pre-trained HAT models that use segment-wise followed by cross-segment encoders and compare them with Longformer models and partially pre-trained HATs. In several long document downstream classification tasks, our best HAT model outperforms equally-sized Longformer models while using 10-20% less GPU memory and processing documents 40-45% faster. In a series of ablation studies, we find that HATs perform best with cross-segment contextualization throughout the model than alternative configurations that implement either early or late cross-segment contextualization. Our code is on GitHub: https://github.com/coastalcph/hierarchical-transformers.","llm_keywords":["Hierarchical Attention Transformers","Long Document Classification","Sparse Attention Transformers","Longformer","Big Bird","Cross-segment Attention","Pre-trained Models","Transformer-based Models"],"classifications":[],"num_cited_by":33,"num_cited_by_title_only":33,"num_pages":16},{"id":"8db5492fcd8857c2cc9898df9f89393973193c0bb0e835b5545fea9012150443d6f67e0b800735143fd1f0bbc7ee6bb7a71f41c44c9930f27899f13db1565324","file_path":"legal-nlp-survey-20250328-002/original/Yang_2019_0211.pdf","title":"152_Yang.pdf","llm_title":"A Regularization Approach to Combining Keywords and Training Data in Technology-Assisted Review","authors":["Eugene Yang","David D. Lewis","Ophir Frieder"],"llm_authors":"Eugene Yang, David D. Lewis, Ophir Frieder","author_string":"","year":2019,"abstract":"","llm_abstract":"Manual keyword queries and supervised learning (technology-assisted review) have been viewed as conflicting approaches to high recall retrieval tasks (such as civil discovery and sunshine law requests) in the law. We propose a synthesis that uses a keyword list as a regularizer when learning a logistic regression model from labeled examples. Balancing keywords against training data requires knowing how the regularization penalty should scale with training set size. We show, however, that advice on scaling from theory is contradictory, software defaults are inconsistent, and standard practice (validation-based tuning) is impractical in many high-recall retrieval settings. Through experiments on simulated e-discovery data sets, we show that the penalization scheme suggested by a Bayesian interpretation is substantially safer than alternatives from stochastic optimization and computational learning theory. Combining keywords and training data provides better effectiveness on our datasets than using either alone, showing that both approaches bring value.","llm_keywords":["technology-assisted review","Bayesian priors","informative priors","text categorization","regularization","logistic regression","keywords"],"classifications":["Information Retrieval"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":10},{"id":"1663ad3e8003d4fa2d5ba1446df98d9fd1ef0abc138aad954259f02a26758857437cb959adc069c76a3808507c0f2709bbc93eb55b680f25384d9455d7603482","file_path":"legal-nlp-survey-20250328-002/original/Chriqui_2022_0522.pdf","title":"Overleaf Example","llm_title":"Legal HeBERT: A BERT-based NLP Model for Hebrew Legal, Judicial and Legislative Texts","authors":["Avihay Chriqui","Inbal Yahav","Ittai Bar-Siman-Tov"],"llm_authors":"Avihay Chriqui, Inbal Yahav & Ittai Bar-Siman-Tov","author_string":"Avihay Chriqui, Inbal Yahav & Ittai Bar-Siman-Tov Avihay Chriqui is a PhD student at the Coller School of Management; Inbal Yahav is a Senior Lecturer at the Coller School of Management and a member of the TAU Data Science community; Ittai Bar-Siman-Tov is Senior Lecturer and Head of the LawData lab at Bar-Ilan University Faculty of Law, and Senior Fellow at the Jean Monnet Centre of Excellence on Digital Governance. We are indebted to Gaili Ben-Or, Guy Eitingon, Yair Gardin, Nir Kosti, Jonathan Schler, Elhanan Schwarts, and Ayelet Sela for generously sharing with us their databases and for helpful suggestions © 2022, the Authors. ;","year":2022,"abstract":"","llm_abstract":"In this work in progress, we offer a BERT-based Hebrew NLP model for the legal, legislative and judicial domains. To the best of our knowledge, this is the first ever BERT-based Hebrew NLP model developed for legal tasks. We illustrate the superiority of our model when applied to both supervised and unsupervised tasks in these domains. Our model is freely offered for public use.","llm_keywords":["BERT","Hebrew NLP","legal texts","legislative texts","judicial texts","domain adaptation","language model","HeBERT","AlephBERT"],"classifications":["Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":11},{"id":"d98f782008e683d2a225a04dbadaa24228ed87beb7b3ec0c109590a5a3eba9d51ec1eef50532791e2515cfda4fbe8db870fbcf591bbfbbc300937f154ebd6750","file_path":"legal-nlp-survey-20250328-002/original/Smywinski-Pohl_2019_0219.pdf","title":"","llm_title":"Application of Character-Level Language Models in the Domain of Polish Statutory Law","authors":["Aleksander Smywinski-Pohl","Krzysztof Wróbel","Karol Lasocki","Michał Jungiewicz"],"llm_authors":"Aleksander Smywinski-Pohl, Krzysztof Wróbel, Karol Lasocki, Michał Jungiewicz","author_string":"","year":2019,"abstract":"","llm_abstract":"Polish statutory law so far is distributed as PDF, HTML and text files, where the structure of the rules and the references to internal and external regulations is provided only implicitly. As a result, automatic processing of the regulations in legal information systems is complicated since the semi-structured text needs to be converted to a structured form. In this research, we show how character-level language models help in this task. We apply them to the problems of detecting the cross-references to structural units (e.g. articles, points, etc.) and detecting the cross-references to statutory laws (titles of laws and ordinances). We obtain 98.7% macro-average F1 in the first problem and 95.8% F1 in the second problem.","llm_keywords":["character-level language models","cross-reference recognition","language modelling","legal text processing","Polish law"],"classifications":["Information Extraction","Pre-Processing","Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":6},{"id":"1891b8d0dab1d6adacd14849df27a8fb2dd3b324293357e9584f8d29da1077618edbc4524b5773586fdd6c4588cbc71f1e29db837db3bcb7e95c2f3ec0b9345f","file_path":"legal-nlp-survey-20250328-002/original/Wagh_2020_0339.pdf","title":"","llm_title":"Legal document similarity: a multi-criteria decision-making perspective","authors":["Rupali Wagh","Deepa Anand"],"llm_authors":"Rupali S. Wagh and Deepa Anand","author_string":"","year":2020,"abstract":"","llm_abstract":"The vast volume of documents available in legal databases demands effective information retrieval approaches which take into consideration the intricacies of the legal domain. Relevant document retrieval is the backbone of the legal domain. The concept of relevance in the legal domain is very complex and multi-faceted. In this work, we propose a novel approach of concept based similarity estimation among court judgments. We use a graph-based method, to identify prominent concepts present in a judgment and extract sentences representative of these concepts. The sentences and concepts so mined are used to express/visualize likeness among concepts between a pair of documents from different perspectives. We also propose to aggregate the different levels of matching so obtained into one measure quantifying the level of similarity between a judgment pair. We employ the ordered weighted average (OWA) family of aggregation operators for obtaining the similarity value. The experimental results suggest that the proposed approach of concept based similarity is effective in the extraction of relevant legal documents and performs better than other competing techniques. Additionally, the proposed two-level abstraction of similarity enables informative visualization for deeper insights into case relevance.","llm_keywords":["Legal Information Retrieval","Concept Based Similarity","Multi-Dimensional Similarity","OWA","Concept interaction graph"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":21,"num_cited_by_title_only":21,"num_pages":20},{"id":"0b0d670e1f794e5a3c17d3cdd56b2e85d6a74b812bef6b82fb37494b5be1b717470c75caae9329d4ad4988e2a62fd9ad9ce978015726e9fcfc9f07fd6362133b","file_path":"legal-nlp-survey-20250328-002/original/Novotna_2021_0426.pdf","title":"","llm_title":"Human Evaluation Experiment of Legal Information Retrieval Methods","authors":["Tereza Novotná"],"llm_authors":"Tereza Novotná","author_string":"","year":2021,"abstract":"","llm_abstract":"In this article, I present the results of the human evaluation experiment of three commonly used methods in legal information retrieval and a new 'multilayered' approach. I use the doc2vec model, citation network analysis and two topic modelling algorithms for the Czech Supreme Court decisions retrieval and evaluate their performance. To improve the accuracy of the results of these methods, I combine the methods in a 'multilayered' way and perform the subsequent evaluation. Both evaluation experiments are conducted with a group of legal experts to assess the applicability and usability of the methods for legal information retrieval. The combination of the doc2vec and citations is found satisfactory accurate for practical use for the Czech court decisions retrieval.","llm_keywords":["human evaluation","court decisions retrieval","doc2vec","citation analysis","LDA","multilayered approach","legal information retrieval","semantic similarity","Czech court decisions","NLP methods"],"classifications":["Information Retrieval"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":7},{"id":"c3848506e4b12d17923db3bbc5d7219fa57ebef5fa325ad4c6264a723eaf3dea1af494f2e52b0b7078f239556b1a0227519f75c803b62d83d9824d5ece0bda01","file_path":"legal-nlp-survey-20250328-002/original/Douka_2021_0434.pdf","title":"JuriBERT: A Masked-Language Model Adaptation for French Legal Text","llm_title":"JuriBERT: A Masked-Language Model Adaptation for French Legal Text","authors":["Stella Douka","Hadi Abdine","Michalis Vazirgiannis","Rajaa El Hamdani","David Restrepo Amariles"],"llm_authors":"Stella Douka, Hadi Abdine, Michalis Vazirgiannis, Rajaa El Hamdani, David Restrepo Amariles","author_string":"Stella Douka ; Hadi Abdine ; Michalis Vazirgiannis ; Rajaa El Hamdani ; David Restrepo Amariles","year":2021,"abstract":"","llm_abstract":"Language models have proven to be very useful when adapted to specific domains. Nonetheless, little research has been done on the adaptation of domain-specific BERT models in the French language. In this paper, we focus on creating a language model adapted to French legal text with the goal of helping law professionals. We conclude that some specific tasks do not benefit from generic language models pre-trained on large amounts of data. We explore the use of smaller architectures in domain-specific sub-languages and their benefits for French legal text. We prove that domain-specific pre-trained models can perform better than their equivalent generalised ones in the legal domain. Finally, we release JuriBERT, a new set of BERT models adapted to the French legal domain.","llm_keywords":["language models","French legal text","BERT","domain-specific adaptation","JuriBERT","natural language processing","legal domain","model pre-training"],"classifications":[],"num_cited_by":46,"num_cited_by_title_only":46,"num_pages":7},{"id":"b22cfd46189b7671b929bd1733273b1a646fba634fe3194305a386970a55fe07f9dd3933da25dac567b079aab08a61f6ef6284d9d336110331c1e90006263472","file_path":"legal-nlp-survey-20250328-002/original/Gianola_2020_0307.pdf","title":"","llm_title":"Information in Official EU Languages for Public Administrations: The MAPA Project","authors":["Lucie Gianola","Eriks Ajausks","Victoria Arranz","Chomicha Bendahman","Laurent Bié","Claudia Borg","Aleix Cerdà","Khalid Choukri","Montse Cuadros","Ona De Gibert","Hans Degroote","Elena Edelman","Thierry Etchegoyhen","Ángela Franco Torres","Mercedes García Hernandez","Aitor García Pablos","Albert Gatt","Cyril Grouin","Manuel Herranz","Alejandro Adolfo Kohan","Thomas Lavergne","Maite Melero","Patrick Paroubek","Mickaël Rigault","Mike Rosner","Roberts Rozis","Lonneke Van Der Plas","Rinalds Vīksna","Pierre Zweigenbaum"],"llm_authors":"Lucie GIANOLA, Eriks AJAUSKS, Victoria ARRANZ, Chomicha BENDAHMAN, Laurent BIÉ, Claudia BORG, Aleix CERDÀ, Khalid CHOUKRI, Montse CUADROS, Ona DE GIBERT, Hans DEGROOTE, Elena EDELMAN, Thierry ETCHEGOYHEN, Ángela FRANCO TORRES, Mercedes GARCÍA HERNANDEZ, Aitor GARCÍA PABLOS, Albert GATT, Cyril GROUIN, Manuel HERRANZ, Alejandro Adolfo KOHAN, Thomas LAVERGNE, Maite MELERO, Patrick PAROUBEK, Mickaël RIGAULT, Mike ROSNER, Roberts ROZIS, Lonneke VAN DER PLAS, Rinalds VĪKSNA, Pierre ZWEIGENBAUM","author_string":"","year":2020,"abstract":"","llm_abstract":"The European MAPA (Multilingual Anonymisation for Public Administrations) project aims at developing an open-source solution for automatic de-identification of medical and legal documents. We introduce here the context, partners and aims of the project, and report on preliminary results.","llm_keywords":["automatic de-identification","legal documents","open-source","multilingual","anonymisation","public administrations","data sharing","GDPR","mapa project"],"classifications":["Information Extraction","Resources","Classification"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":4},{"id":"d267ebb4d20a0711f4e29831c1fff19081a7377f1167da06b15d5e75341d77716364f0faf277a7e9714e31a32fa7f8bf7311f644d515ca25a49c2413faf8a0a3","file_path":"legal-nlp-survey-20250328-002/original/Tonguz_2021_0400.pdf","title":"Automating Claim Construction in Patent Applications: The CMUmine Dataset","llm_title":"Automating Claim Construction in Patent Applications: The CMUmine Dataset","authors":["Ozan K. Tonguz","Yiwei Qin","Yimeng Gu","Hyun Hannah Moon"],"llm_authors":"Ozan K. Tonguz, Yiwei Qin, Yimeng Gu, Hyun (Hannah) Moon","author_string":"Ozan Tonguz ; Yiwei Qin ; Yimeng Gu ; Hyun Hannah Moon","year":2021,"abstract":"","llm_abstract":"Intellectual Property (IP) in the form of issued patents is a critical and very desirable element of innovation in high-tech. In this position paper, we explore the possibility of automating the legal task of Claim Construction in patent applications via Natural Language Processing (NLP) and Machine Learning (ML). To this end, we first create a large dataset known as CMUmine™and then demonstrate that, using NLP and ML techniques the Claim Construction in patent applications, a crucial legal task currently performed by IP attorneys, can be automated. To the best of our knowledge, this is the first public patent application dataset. Our results look very promising in automating the patent application process.","llm_keywords":["Patent applications","Claim Construction","Natural Language Processing","Machine Learning","Intellectual Property","Automation","High-tech innovation","CMUmine dataset"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":5},{"id":"787f6d968a37364b32627c9f6352a93aa7acad945ef82ad23592337ad5c78d81a0fa24a74ed05d04ce6a90f5534b959b4ddf14a4da2671ac73461381db974c44","file_path":"legal-nlp-survey-20250328-002/original/Gray_2020_0329.pdf","title":"","llm_title":"Identifying the Factors of Suspicion","authors":["Morgan Gray","Wesley Oliver","Arthur Crivella"],"llm_authors":"Morgan A. Gray, Wesley M. Oliver, and Arthur Crivella","author_string":"","year":2020,"abstract":"","llm_abstract":"Probable cause determinations are problematic. Like all court decisions using totality-of-the-circumstances tests, it is difficult to use one decision – or even a few – to foresee a subsequent outcome. No human is capable of reading all the relevant Fourth Amendment opinions relevant to resolving any search and seizure issue. Machines may be capable of this task and to do so they will need to be able to identify particular types of suspicious factors from the various ways courts describe the factors. This project examines the ability of three machine learning models to examine the relevant text of opinions to identify the suspicious factors courts used to determine whether adequate suspicion existed from an intrusion protected by the Fourth Amendment.","llm_keywords":["information retrieval","reasonable suspicion","totality of the circumstances","k-nearest neighbor","decision tree","logistic regression"],"classifications":["Classification","Information Extraction"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":4},{"id":"988614d2fd08bfb78870f4634705b1136322d43d99ab9293f3799dd43aa8e59879eb07e51299ccf8e6222d2348edb60f850b66ed4ec85235a070c4aba53e6a33","file_path":"legal-nlp-survey-20250328-002/original/Skylaki_2021_0438.pdf","title":"Legal Entity Extraction using a Pointer Generator Network","llm_title":"Legal Entity Extraction using a Pointer Generator Network","authors":["Stavroula Skylaki","Ali Oskooei","Omar Bari","Nadja Herger","Zac Kriegman"],"llm_authors":"Stavroula Skylaki, Nadja Herger, Ali Oskooei, Zac Kriegman, Omar Bari","author_string":"Stavroula Skylaki; Ali Oskooei; Omar Bari; Nadja Herger; Zac Kriegman","year":2022,"abstract":"","llm_abstract":"Named Entity Recognition (NER) is the task of identifying and classifying named entities in unstructured text. In the legal domain, named entities of interest may include the case parties, judges, names of courts, case numbers, references to laws, etc. We study the problem of legal named entity extraction from noisy text extracted from PDF files of filed court cases from US courts. The “gold standard” training data for classical NER systems provide annotation for each token of the text with the corresponding entity or non-entity label. We work with only partially complete training data, which differ from the gold standard NER data in that the exact location of the entities in the text is unknown and the entities may contain typos and/or OCR mistakes. To overcome the challenges of our noisy training data, e.g., text extraction errors and/or typos and unknown label indices, we frame the NER task as a sequence generation task (seq2seq) and train a pointer generator network to generate the entities in the document rather than label them. We attempt to create a NER gold standard dataset via sequence matching and use this dataset to train classical NER baselines and compare them with our seq2seq approach for Named Entity (NE) extraction. We show that the seq2seq approach can effectively extract legal named entities, in the absence of gold standard data, and outperform the common neural network architectures for NER in long legal documents.","llm_keywords":["legal","named entity extraction","seq2seq","Pointer Generator Network","OCR errors","sequence generation","legal documents","NER challenges"],"classifications":[],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":6},{"id":"18f8a4aeed818de441cc07b7ae9932a3fe3f30cbabbca6bd94ec83a4ad5a4ae8ba4c23873230be20ac95311479712f1bc885e03ff2050e8c78e53f6ebd1c630c","file_path":"legal-nlp-survey-20250328-002/original/Valvoda_2021_0484.pdf","title":"What About the Precedent: An Information-Theoretic Analysis of Common Law","llm_title":"What About the Precedent: An Information-Theoretic Analysis of Common Law","authors":["Josef Valvoda","Tiago Pimentel","Niklas Stoehr","Ryan Cotterell","Simone Teufel"],"llm_authors":"Josef Valvoda, Tiago Pimentel, Niklas Stoehr, Ryan Cotterell, Simone Teufel","author_string":"Josef Valvoda ; Tiago Pimentel ; Niklas Stoehr ; Ryan Cotterell ; Simone Teufel","year":2021,"abstract":"","llm_abstract":"In common law, the outcome of a new case is determined mostly by precedent cases, rather than by existing statutes. However, how exactly does the precedent influence the outcome of a new case? Answering this question is crucial for guaranteeing fair and consistent judicial decision-making. We are the first to approach this question computationally by comparing two longstanding jurisprudential views; Halsbury’s, who believes that the arguments of the precedent are the main determinant of the outcome, and Goodhart’s, who believes that what matters most is the precedent’s facts. We base our study on the corpus of legal cases from the European Court of Human Rights (ECtHR), which allows us to access not only the case itself, but also cases cited in the judges’ arguments (i.e. the precedent cases). Taking an information-theoretic view, and modeling the question as a case outcome classification task, we find that the precedent’s arguments share 0.38 nats of information with the case’s outcome, whereas precedent’s facts only share 0.18 nats of information (i.e., 58% less); suggesting Halsbury’s view may be more accurate in this specific court. We found however in a qualitative analysis that there are specific statues where Goodhart’s view dominates, and present some evidence these are the ones where the legal concept at hand is less straightforward.","llm_keywords":["common law","precedent","Halsbury","Goodhart","information theory","case outcome","European Court of Human Rights","jurisprudential views"],"classifications":["Classification","Information Retrieval"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":14},{"id":"e462b461ed07d0f3cb2d52a0dbe8d462435a6941ceb32ec029ba5189b7ec5dda4269f248f5f6398e8e1008ba2715cbdfc9f2bf596275a4178242e0687515da5c","file_path":"legal-nlp-survey-20250328-002/original/Pandey_2020_0309.pdf","title":"Building knowledge graphs of homicide investigation chronologies","llm_title":"Building knowledge graphs of homicide investigation chronologies","authors":["Ritika Pandey","P. Jeffrey Brantingham","Craig D. Uchida","George Mohler"],"llm_authors":"Ritika Pandey, P. Jeffrey Brantingham, Craig D. Uchida, George Mohler","author_string":"","year":2020,"abstract":"","llm_abstract":"Homicide investigations generate large and diverse data in the form of witness interview transcripts, physical evidence, photographs, DNA, etc. Homicide case chronologies are summaries of these data created by investigators that consist of short text-based entries documenting specific steps taken in the investigation. A chronology tracks the evolution of an investigation, including when and how persons involved and items of evidence became part of a case. In this article we discuss a framework for creating knowledge graphs of case chronologies that may aid investigators in analyzing homicide case data and also allow for post hoc analysis of the key features that determine whether a homicide is ultimately solved. Our method consists of 1) performing named entity recognition to determine witnesses, suspects, and detectives from chronology entries 2) using keyword expansion to identify documentary, physical, and forensic evidence in each entry and 3) linking entities and evidence to construct a homicide investigation knowledge graph. We compare the performance of several choices of methodologies for these sub-tasks using homicide investigation chronologies from Los Angeles, California. We then analyze the association between network statistics of the knowledge graphs and homicide solvability.","llm_keywords":["knowledge graph","named entity recognition","homicide investigation","homicide solvability","case chronologies","data analysis","investigative process","evidence extraction"],"classifications":["Information Extraction","Classification","Text Generation","Machine Summarization","Pre-Processing","Information Retrieval","Resources"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":9},{"id":"fccb571464b83fabf9688e67983e6a2246574a130c7905533853ab788ccc9b8a8618a065784d30bf2df7e0dcdeb8e9e52eab47b46f08562d92d769b9bcaf152b","file_path":"legal-nlp-survey-20250328-002/original/Bao_2019_0229.pdf","title":"","llm_title":"Charge Prediction with Legal Attention","authors":["Qiaoben Bao","Hongying Zan","Peiyuan Gong","Junyi Chen","Yanghua Xiao"],"llm_authors":"Qiaoben Bao, Hongying Zan, Peiyuan Gong, Junyi Chen, Yanghua Xiao","author_string":"","year":2019,"abstract":"","llm_abstract":"Charge prediction aims to predict the corresponding charges for a specific case. In civil law system, human judges will match the facts with relevant laws, and the final judgments are usually made in accordance with relevant law articles. Existing works either ignore this feature or simply model the relationship using multi-task learning, but neither make full use of relevant articles to assist the charge prediction task. To address this issue, we propose an attentional neural network, LegalAtt, which uses relevant articles to improve the performance and interpretability of charge prediction task. More specifically, our model works in a bidirectional approach: First, it uses the fact description to extract relevant articles; In return, the selected relevant articles assist to locate key information from the fact description, which helps improve the performance of charge prediction. Experimental results show that our model achieves the best performance on the real-world dataset compared with other state-of-the-art baselines. Our code is available at https://github.com/nlp208/legal attention.","llm_keywords":["Charge prediction","Text classification","Civil law system","Attentional neural network","Legal domain","Multi-label cases","Interpretability"],"classifications":["Classification","Information Extraction"],"num_cited_by":30,"num_cited_by_title_only":30,"num_pages":12},{"id":"b3e144c317bbcd4c8988b99d6cf0ab73c1b0b07cedaef0fb828edf432490f81996a97f9345c8e1687b45ff58d9a16a47c3e2aca4c4550b9aa187c4c8aee85d5e","file_path":"legal-nlp-survey-20250328-002/original/Tran_2013_0022.pdf","title":"Reference resolution in legal texts","llm_title":"Reference Resolution in Legal Texts","authors":["Oanh Thi Tran","Minh Le Nguyen","Akira Shimazu"],"llm_authors":"Oanh Thi Tran, Minh Le Nguyen, Akira Shimazu","author_string":"Oanh Thi Tran, Minh Le Nguyen, Akira Shimazu","year":2013,"abstract":"","llm_abstract":"Reference resolution is an important task which supports understanding natural language texts, especially in the legal domain, where legal articles are usually long and complicated. This paper focuses on the task of reference resolution in the legal domain, in which we extract references and resolve them to the referenced texts. We propose a four-step framework to deal with the task: mention detection, contextual information extraction, antecedent candidate extraction, and antecedent determination. We also show how machine learning methods can be exploited in each step. The final system achieves 80.06% in the F1 score for detecting references, 85.61% accuracy for resolving them, and 67.02% in the F1 score on the end-to-end setting task on the Japanese National Pension Law corpus. Our work provides promising results for further studies on this interesting task.","llm_keywords":["reference resolution","mention detection","legal texts","machine learning","Japanese National Pension Law corpus"],"classifications":["Information Extraction"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":10},{"id":"f2d3331c65f534707c8efb7b527f53f1e324bcb8ebd7fcc21e71f0dc1cfdc48d227bdb81ad85cfd099be821d315bf32ce7ce4fa5046c75ef021749198c2a8f80","file_path":"legal-nlp-survey-20250328-002/original/Yoshida_2014_0046.pdf","title":"","llm_title":"Towards Semi-Automatic Identification of Functional Requirements in Legal Texts for Public Administration","authors":["Yutaka Yoshida","Kozo Honda","Yuichi Sei","Hiroyuki Nakagawa","Yasuyuki Tahara","Akihiko Ohsuga"],"llm_authors":"Yutaka YOSHIDA, Kozo HONDA, Yuichi SEI, Hiroyuki NAKAGAWA, Yasuyuki TAHARA, Akihiko OHSUGA","author_string":"","year":2013,"abstract":"","llm_abstract":"There is a need for the development of systems that are compliant with laws in public administration, because their administrative activities are based on laws. When new laws are made or existing laws are amended, however, civil servants need to develop or modify the systems in the short time before the laws are issued. Related work in requirements elicitation from the legal texts includes approaches using ontology but there are difficulties in building an ontology for practical use. In this paper we propose pre-defined templates with the expression of functional requirements to identify legal texts, including their functional requirements, and a support tool consisting of two functions, one for automatic summary creation from complicated legal texts and one for the suggestion of the legal texts, including their functional requirements. We have also applied this approach to Japanese laws and have evaluated its accuracy. Our research revealed that using this approach can identify functional requirements with high accuracy.","llm_keywords":["Requirements Engineering","Templates","NLP","Public Administration","Legal Compliance","Functional Requirements","Legal Texts","Ontology","Japanese Laws","Requirements Elicitation"],"classifications":["Pre-Processing","Information Extraction","Machine Summarization","Classification"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":10},{"id":"a10d9844adc223b86b43531782fc3e7b8b0afc4ca7ffcca35715e59726a8adbc20286e4ee40929e708f16479b5a60e98a2df1828dd177d5c64c6f551c3f74e5e","file_path":"legal-nlp-survey-20250328-002/original/Shaghaghian_2020_0314.pdf","title":"","llm_title":"Customizing Contextualized Language Models for Legal Document Reviews","authors":["Shohreh Shaghaghian","Luna Yue Feng","Borna Jafarpour","Nicolai Pogrebnyakov"],"llm_authors":"Shohreh Shaghaghian, Luna (Yue) Feng, Borna Jafarpour, Nicolai Pogrebnyakov","author_string":"","year":2021,"abstract":"","llm_abstract":"Inspired by the inductive transfer learning on computer vision, many efforts have been made to train contextualized language models that boost the performance of natural language processing tasks. These models are mostly trained on large general-domain corpora such as news, books, or Wikipedia. Although these pre-trained generic language models well perceive the semantic and syntactic essence of a language structure, exploiting them in a real-world domain-specific scenario still needs some practical considerations to be taken into account such as token distribution shifts, inference time, memory, and their simultaneous proficiency in multiple tasks. In this paper, we focus on the legal domain and present how different language models trained on general-domain corpora can be best customized for multiple legal document reviewing tasks. We compare their efficiencies with respect to task performances and present practical considerations.","llm_keywords":["contextualized language models","legal document review","transfer learning","NLP","BERT","Transformer","domain-specific","fine-tuning","legal corpus","model adaptation"],"classifications":["Resources"],"num_cited_by":4,"num_cited_by_title_only":31,"num_pages":10},{"id":"7993039ba3adbfbcdf2da137d60b4400a36cdf943910f5c53e7d5714f9ebacc92d7d5798e1cc75e1104d3efe1027c0e1d4289a352b87780e1cd807c67df8bde3","file_path":"legal-nlp-survey-20250328-002/original/Condevaux_2019_0295.pdf","title":"","llm_title":"Weakly Supervised One-Shot Classification Using Recurrent Neural Networks with Attention: Application to Claim Acceptance Detection","authors":["Charles Condevaux","Sebastien Harispe","Stephane Mussard","Guillaume Zambrano"],"llm_authors":"Charles CONDEVAUX, Sebastien HARISPE, Stephane MUSSARD, Guillaume ZAMBRANO","author_string":"","year":2019,"abstract":"","llm_abstract":"Determining if a claim is accepted given judge arguments is an important non-trivial task in court decisions analyses. Application of recent efficient machine learning techniques may however be inappropriate for tackling this problem since, in the Legal domain, labelled datasets are most often small, scarce and expensive. This paper presents a deep learning model and a methodology for solving such complex classification tasks with only few labelled examples. We show in particular that mixing one-shot learning with recurrent neural networks and an attention mechanism enables obtaining efficient models while preserving some form of interpretability and limiting potential overfit. Results obtained on several types of claims in French court decisions, using different vectorization processes, are presented.","llm_keywords":["Classification","legal analysis","one-shot learning","deep learning","court decisions","attention mechanism","interpretability","recurrent neural networks","claim acceptance detection","machine learning"],"classifications":["Classification"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":10},{"id":"5e7d8fde1d93eacb577fd69814789f08a5dc28c78341ba23ac8a6d9111424bfaa1f1c53ef9138797b8ef21c564ff935e87ef661603c500347efe9e7e988b5f80","file_path":"legal-nlp-survey-20250328-002/original/Simonson_2019_0291.pdf","title":"Proceedings of the Natural Legal Language Processing Workshop 2019","llm_title":"Proceedings of the 2019 Workshop on Natural Legal Language Processing (NLLP)","authors":[],"llm_authors":"","author_string":"Association for Computational Linguistics","year":2019,"abstract":"","llm_abstract":"","llm_keywords":["Natural Language Processing","Legal Domain","Machine Learning","Legal Documents","NLP Applications","Legal Research"],"classifications":[],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":101},{"id":"05d51d2b34e7b030c7d07c763bcce79e82e558e2ae13a0242148fd62bac6c4e75b104b22c474d32db46cdeab52ced24bdba9f13bad7b30368335f33f62bc497f","file_path":"legal-nlp-survey-20250328-002/original/Wagh_2013_0016.pdf","title":"Knowledge Discovery from Legal Documents Dataset using Text Mining Techniques","llm_title":"Knowledge Discovery from Legal Documents Dataset using Text Mining Techniques","authors":["Rupali Sunil Wagh"],"llm_authors":"Rupali Sunil Wagh","author_string":"Rupali Sunil Wagh","year":2013,"abstract":"","llm_abstract":"Last few decades have witnessed exponential increase in the use of IT which has resulted into large amount of data being generated, stored and searched. Data may be highly structured stored as records of a DBMS, or may be totally unstructured like blog posts or plain text documents. With the abundance of information being available as text documents, the issue of retrieval of knowledge from such unstructured dataset is posing new challenges to the research community. Legal document analysis is one domain which generates and uses text information in semi structured as well as unstructured form. The process of legal reasoning and decision making is heavily dependent on information stored in text documents. Text Mining (TM) is defined as the process of extracting useful information from text data. Legal text documents are stored using natural languages. For efficient analysis of such documents, text mining, a specialized branch of machine learning can be suitably used. Text mining – which “mines text”, is heavily associated with natural language processing and Information Retrieval. TM techniques can be used for extracting relevant knowledge from stored legal documents. The extracted knowledge is used to simplify the preparation of case base, facilitate in decision making and legal reasoning or for automatic identification of legal arguments. Research in the fields of information extraction, natural language processing, artificial intelligence and expert system has augmented text mining process for enhancing the knowledge discovery process in this domain. This paper proposes a study which is aimed at grouping of legal documents based on the contents without taking any external input using unsupervised text mining techniques.","llm_keywords":["Text mining","legal document search","legal databases","unsupervised learning","natural language processing","information retrieval","machine learning","legal reasoning","knowledge discovery","clustering"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":27,"num_cited_by_title_only":27,"num_pages":3},{"id":"6d684e61668fad7b8686c28eac42de9121e825429c6e77b6f334027bb08b68064f56ce216142371428ce0533daba81249c17752d7a79c4ef306acd1d85e3e529","file_path":"legal-nlp-survey-20250328-002/original/Paley_2021_0422.pdf","title":"","llm_title":"From Data to Information: Automating Data Science to Explore the U.S. Court System","authors":["Andrew Paley","Andong L. Li Zhao","Harper Pack","Sergio Servantez","Rachel F. Adler","Marko Sterbentz","Adam Pah","David Schwartz","Cameron Barrie","Alexander Einarsson","Kristian Hammond"],"llm_authors":"Andrew Paley, Andong L. Li Zhao, Harper Pack, Sergio Servantez, Rachel F. Adler, Marko Sterbentz, Adam Pah, David Schwartz, Cameron Barrie, Alexander Einarsson, Kristian Hammond","author_string":"","year":2021,"abstract":"","llm_abstract":"The U.S. court system is the nation’s arbiter of justice, tasked with the responsibility of ensuring equal protection under the law. But hurdles to information access obscure the inner workings of the system, preventing stakeholders – from legal scholars to journalists and members of the public – from understanding the state of justice in America at scale. There is an ongoing data access argument here: U.S. court records are public data and should be freely available. But open data arguments represent a half-measure; what we really need is open information. This distinction marks the difference between downloading a zip file containing a quarter-million case dockets and getting the real-time answer to a question like “Are pro se parties more or less likely to receive fee waivers?” To help bridge that gap, we introduce a novel platform and user experience that provides users with the tools necessary to explore data and drive analysis via natural language statements. Our approach leverages an ontology configuration that adds domain-relevant data semantics to database schemas to provide support for user guidance and for search and analysis without user-entered code or SQL. The system is embodied in a “natural-language notebook” user experience, and we apply this approach to the space of case docket data from the U.S. federal court system. Additionally, we provide detail on the collection, ingestion and processing of the dockets themselves, including early experiments in the use of language modeling for docket entry classification with an initial focus on motions.","llm_keywords":["notebook interface","information extraction","data analytics","natural language processing","visualization","U.S. court system","data transparency","ontology configuration","legal data access","natural-language notebook"],"classifications":["Classification","Information Retrieval","Information Extraction","Resources"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":10},{"id":"ffde71bfb5b538978e68535b9ec04734a51ac9b08d8e392834578360f5fc2acf2ba65c30da8203ffcae2061305d7ce3b243d37828851fe1c132998a21c5899f9","file_path":"legal-nlp-survey-20250328-002/original/Zhong_2020_0301.pdf","title":"An Element-aware Multi-representation Model for Law Article Prediction","llm_title":"An Element-aware Multi-representation Model for Law Article Prediction","authors":["Huilin Zhong","Junsheng Zhou","Weiguang Qu","Yunfei Long","Yanhui Gu"],"llm_authors":"Huilin Zhong, Junsheng Zhou, Weiguang Qu, Yunfei Long, and Yanhui Gu","author_string":"Huilin Zhong ; Junsheng Zhou ; Weiguang QU ; Yunfei Long ; Yanhui Gu","year":2020,"abstract":"","llm_abstract":"Existing works have proved that using law articles as external knowledge can improve the performance of the Legal Judgment Prediction. However, they do not fully use law article information and most of the current work is only for single label samples. In this paper, we propose a Law Article Element-aware Multi-representation Model (LEMM), which can make full use of law article information and can be used for multi-label samples. The model uses the labeled elements of law articles to extract fact description features from multiple angles. It generates multiple representations of a fact for classification. Every label has a law-aware fact representation to encode more information. To capture the dependencies between law articles, the model also introduces a self-attention mechanism between multiple representations. Compared with baseline models like TopJudge, this model improves the accuracy of 5.84%, the macro F1 of 6.42%, and the micro F1 of 4.28%.","llm_keywords":["Law Article Prediction","Legal Judgment Prediction","Multi-representation Model","Self-attention Mechanism","Element-aware Model","Multi-label Classification","External Knowledge"],"classifications":["Classification","Information Extraction"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":6},{"id":"1b102c495d3f48b4d1938086c0f8588cfa3b1ed8a88bf658eebcf4169a7f17933ef2bcee96957d6faf3ec42655cdc6bb2fa2e9ead259fcf1503bdb8fc3aa913f","file_path":"legal-nlp-survey-20250328-002/original/Lopuszynski_2014_0029.pdf","title":"","llm_title":"Application of Topic Models to Judgments from Public Procurement Domain","authors":["Michał Lopuszyński"],"llm_authors":"Michał Lopuszyński","author_string":"","year":2021,"abstract":"","llm_abstract":"","llm_keywords":["topic modeling","latent Dirichlet allocation","public procurement","keyphrase extraction","National Appeal Chamber","Gibbs sampling","document analysis","time trends"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":3},{"id":"6f1520a190ac6c018c0a7e4df66a7032afff67e0e866e779486477c0c45d0458b2c46868895fdc519f6f5c132623baecb1dba1f4c5201e15025aed6ecb10823a","file_path":"legal-nlp-survey-20250328-002/original/Charmet_2022_0498.pdf","title":"Complex Labelling and Similarity Prediction in Legal Texts: Automatic Analysis of France's Court of Cassation Rulings","llm_title":"Complex Labelling and Similarity Prediction in Legal Texts: Automatic Analysis of France’s Court of Cassation Rulings","authors":["Thibault Charmet","Inès Cherichi","Matthieu Allain","Urszula Czerwinska","Amaury Fouret","Benoît Sagot","Rachel Bawden"],"llm_authors":"Thibault Charmet, Inès Cherichi, Matthieu Allain, Urszula Czerwinska, Amaury Fouret, Benoît Sagot, Rachel Bawden","author_string":"Thibault Charmet, Inès Cherichi, Matthieu Allain, Urszula Czerwinska, Amaury Fouret, Benoît Sagot, Rachel Bawden","year":2022,"abstract":"","llm_abstract":"Detecting divergences in the applications of the law (where the same legal text is applied differently by two rulings) is an important task. It is the mission of the French Cour de Cassation. The first step in the detection of divergences is to detect similar cases, which is currently done manually by experts. They rely on summarised versions of the rulings (syntheses and keyword sequences), which are currently produced manually and are not available for all rulings. There is also a high degree of variability in the keyword choices and the level of granularity used. In this article, we therefore aim to provide automatic tools to facilitate the search for similar rulings. We do this by (i) providing automatic keyword sequence generation models, which can be used to improve the coverage of the analysis, and (ii) providing measures of similarity based on the available texts and augmented with predicted keyword sequences. Our experiments show that the predictions improve correlations of automatically obtained similarities against our specially collected human judgments of similarity.","llm_keywords":["Legal NLP","Similarity Prediction","Classification","Summarisation","French Cour de Cassation","Divergence Detection","Natural Language Processing","Keyword Generation","Legal Text Retrieval"],"classifications":["Classification","Information Retrieval","Information Extraction","Text Generation"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":14},{"id":"9e22d3193e6e08b45c2956887ba349ebf0913f8018837233a7e81e5c43acb96fe89477a2861833516d5e4f51d09927c4b3046aac979eb92375cb047e2cec7711","file_path":"legal-nlp-survey-20250328-002/original/Gifford_2017_0139.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"LexrideLaw: An Argument Based Legal Search Engine","authors":["Matthew Giafford"],"llm_authors":"Matthew Giafford","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"Legal research search engines are overwhelmingly defined by adherence to the appellate case-law organizational model, whereby cases are discovered by relational keyword searches and case files are returned as results. We are proposing a new legal research search engine model where arguments are extracted from appellate cases and are accessible either through selecting nodes in a litigation issue ontology or through relational keyword searches.","llm_keywords":["Legal Search Engine","Argument Extraction","Natural Language Processing","Ontology Engineering","Text Mining"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":2},{"id":"cb2e164d74086c4193846f359254fdb24872e8b0192b738f68d7bd5cb0a8675b7283017d91ee85bbcfc5a2954f6bd55af1dda7b6e1d9aaf96cdb0ff4b0c5cea6","file_path":"legal-nlp-survey-20250328-002/original/Tarasconi_2020_0350.pdf","title":"","llm_title":"Natural Language Processing Applications in Case-Law Text Publishing","authors":["Francesco Tarasconi","Milad Botros","Matteo Caserio","Gianpiero Sportelli","Giuseppe Giacalone","Carlotta Uttini","Luca Vignati","Fabrizio Zanetta"],"llm_authors":"Francesco TARASCONI, Milad BOTROS, Matteo CASERIO, Gianpiero SPORTELLI, Giuseppe GIACALONE, Carlotta UTTINI, Luca VIGNATI, Fabrizio ZANETTA","author_string":"","year":2020,"abstract":"","llm_abstract":"Processing case-law contents for electronic publishing purposes is a time-consuming activity that encompasses several sub-tasks and usually involves adding annotations to the original text. On the other hand, recent trends in Artificial Intelligence and Natural Language Processing enable the automatic and efficient analysis of big textual data. In this paper we present our Machine Learning solution to three specific business problems, regularly met by a real world Italian publisher in their day-to-day work: recognition of legal references in text spans, new content ranking by relevance, and text classification according to a given tree of topics. Different approaches based on BERT language model were experimented with, together with alternatives, typically based on Bag-of-Words. The optimal solution, deployed in a controlled production environment, was in two out of three cases based on fine-tuned BERT (for the extraction of legal references and text classification), while, in the case of relevance ranking, a Random Forest model, with hand-crafted features, was preferred. We will conclude by discussing the concrete impact, as perceived by the publisher, of the developed prototypes.","llm_keywords":["natural language processing","applications","transfer learning","language models","text classification","information extraction","publishing industry","machine learning","BERT fine-tuning","random forest"],"classifications":["Pre-Processing","Classification","Information Extraction","Information Retrieval"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"c5f56db5c4b634655a90391cd91afec94ebbceb16d104c004cab594c6a467b0e13eef01c8b20c99758fef6d57e436ad70d803355042d03bdab8811defa068832","file_path":"legal-nlp-survey-20250328-002/original/Papaloukas_2021_0448.pdf","title":"Multi-granular Legal Topic Classification on Greek Legislation","llm_title":"Multi-granular Legal Topic Classification on Greek Legislation","authors":["Christos Papaloukas","Ilias Chalkidis","Konstantinos Athinaios","Despina Pantazi","Manolis Koubarakis"],"llm_authors":"Christos Papaloukas, Ilias Chalkidis, Konstantinos Athinaios, Despina-Athanasia Pantazi, Manolis Koubarakis","author_string":"Christos Papaloukas ; Ilias Chalkidis ; Konstantinos Athinaios ; Despina Pantazi ; Manolis Koubarakis","year":2021,"abstract":"","llm_abstract":"In this work, we study the task of classifying legal texts written in the Greek language. We introduce and make publicly available a novel dataset based on Greek legislation, consisting of more than 47 thousand official, categorized Greek legislation resources. We experiment with this dataset and evaluate a battery of advanced methods and classifiers, ranging from traditional machine learning and RNN-based methods to state-of-the-art Transformer-based methods. We show that recurrent architectures with domain-specific word embeddings offer improved overall performance while being competitive even to transformer-based models. Finally, we show that cutting-edge multilingual and monolingual transformer-based models brawl on the top of the classifiers’ ranking, making us question the necessity of training monolingual transfer learning models as a rule of thumb. To the best of our knowledge, this is the first time the task of Greek legal text classification is considered in an open research project, while also Greek is a language with very limited NLP resources in general.","llm_keywords":["Greek legislation","natural language processing","legal text classification","machine learning","Transformer-based models","recurrent architectures","NLP resources","dataset","classification methods","Greek legal text"],"classifications":["Classification"],"num_cited_by":35,"num_cited_by_title_only":35,"num_pages":13},{"id":"849e46d92af9d395e18fc66c2a1b7b81ebacfd70a11a4f82b19b617c6efdbe1a4be052b00c9aa5b9fb68cf9476192d1c52e3430196cffe711028eef2ca3ff1ac","file_path":"legal-nlp-survey-20250328-002/original/Jungiewicz_2015_0074.pdf","title":"","llm_title":"Towards Meaningful Maps of Polish Case Law","authors":["Michał Jungiewicz","Michał Łopuszyński"],"llm_authors":"Michał Jungiewicz, Michał Łopuszyński","author_string":"","year":2021,"abstract":"","llm_abstract":"","llm_keywords":["Polish case law","document maps","PCA","t-SNE","dimensionality reduction","exploratory analysis","judgment corpora"],"classifications":[],"num_cited_by":1,"num_cited_by_title_only":1,"num_pages":3},{"id":"10c1e937c8de4a9d1a8a1f4801187b2c4ba06dabdb57e054de10159aff542ff163f156a019ef4a51385fb1b5bacd5d5c9f1fa92b2d0dfaa933b373020a1eb358","file_path":"legal-nlp-survey-20250328-002/original/Hendrycks_2021_0409.pdf","title":"CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review","llm_title":"CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review","authors":["Dan Hendrycks","Collin Burns","Anya Chen","Spencer Ball"],"llm_authors":"Dan Hendrycks, Collin Burns, Anya Chen, Spencer Ball","author_string":"Dan Hendrycks and Collin Burns and Anya Chen and Spencer Ball","year":2021,"abstract":"","llm_abstract":"Many specialized domains remain untouched by deep learning, as large labeled datasets require expensive expert annotators. We address this bottleneck within the legal domain by introducing the Contract Understanding Atticus Dataset (CUAD), a new dataset for legal contract review. CUAD was created with dozens of legal experts from The Atticus Project and consists of over 13,000 annotations. The task is to highlight salient portions of a contract that are important for a human to review. We find that Transformer models have nascent performance, but that this performance is strongly influenced by model design and training dataset size. Despite these promising results, there is still substantial room for improvement. As one of the only large, specialized NLP benchmarks annotated by experts, CUAD can serve as a challenging research benchmark for the broader NLP community.","llm_keywords":["CUAD","NLP","legal contracts","dataset","machine learning","transformer models","expert annotation","contract review"],"classifications":["Resources","Information Extraction","Text Generation","Classification"],"num_cited_by":202,"num_cited_by_title_only":202,"num_pages":16},{"id":"d3799dc112b5814c24bc2f3517b975c0a81960453fe35610fffdd7aeb51f650b9f88352fcd3d3d3c201dbb80c71ec7ba434034ac7e2f8b1dab6a5ed681e726f8","file_path":"legal-nlp-survey-20250328-002/original/Gan_2022_0553.pdf","title":"","llm_title":"Exploiting Contrastive Learning and Numerical Evidence for Improving Confusing Legal Judgment Prediction","authors":["Leilei Gan","Baokui Li","Kun Kuang","Yi Yang","Fei Wu"],"llm_authors":"Leilei Gan, Baokui Li, Kun Kuang, Yi Yang, Fei Wu","author_string":"","year":2022,"abstract":"","llm_abstract":"Given the fact description text of a legal case, legal judgment prediction (LJP) aims to predict the case’s charge, law article and penalty term. A core problem of LJP is how to distinguish confusing legal cases, where only subtle text differences exist. Previous studies fail to distinguish different classification errors with a standard cross-entropy classification loss, and ignore the numbers in the fact description for predicting the term of penalty. To tackle these issues, in this work, first, we propose a moco-based supervised contrastive learning to learn distinguishable representations, and explore the best strategy to construct positive example pairs to benefit all three subtasks of LJP simultaneously. Second, in order to exploit the numbers in legal cases for predicting the penalty terms of certain cases, we further enhance the representation of the fact description with extracted crime amounts which are encoded by a pre-trained numeracy model. Extensive experiments on public benchmarks show that the proposed method achieves new state-of-the-art results, especially on confusing legal cases. Ablation studies also demonstrate the effectiveness of each component.","llm_keywords":["contrastive learning","legal judgment prediction","numerical evidence","penalty term prediction","confusing legal cases","supervised learning","moco-based learning","fact description","charge prediction"],"classifications":["Classification","Information Extraction","Pre-Processing","Text Generation","Machine Summarization","Information Retrieval","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":11},{"id":"5c1162e11d2e4abdfdee32792ddd244dcb0040c94438838f1c401fb65c6498b34b89eb5ed33aa9a9bbf7635f242d9b90b52eb6d3272f90447253db2c5d8127b0","file_path":"legal-nlp-survey-20250328-002/original/Garofalakis_2018_0161.pdf","title":"","llm_title":"A Project for the Transformation of Greek Legal Documents into Legal Open Data","authors":["John Garofalakis","Konstantinos Plessas","Athanasios Plessas","Panoraia Spiliopoulou"],"llm_authors":"John Garofalakis, Konstantinos Plessas, Athanasios Plessas, Panoraia Spiliopoulou","author_string":"","year":2018,"abstract":"","llm_abstract":"In modern states, the operation of the three branches of government (executive, legislative and judicial) results in the generation of a huge volume of data (e.g. legislative documents, decisions, reports, statistics etc.). Publication of government data in the form of Open Data is expected, among other benefits, to drive economic development and promote transparency. This is also true for legal data, since new services for citizens, companies, legal professionals and governments could emerge as a result of the availability of Legal Open Data. Since such information is usually published in unstructured formats, automated approaches could highly facilitate the transformation of unstructured data into structured Open Data, according to the 5-star Open Data scheme. In this paper, we present an ongoing project about the automated analysis and processing of Greek legal documents for their transformation into Legal Open Data. We briefly review the current state of Legal Open Data in Greece, we present the project’s research questions and analyze our initial thoughts for the implementation methodology; we discuss the challenges of such an effort and finally we elaborate the expected contributions.","llm_keywords":["Legal Open Data","Greek Legislation","Legal Text Analysis","Akoma Ntoso","Natural Language Processing","Public Open Data","Government Data","5-star Open Data scheme"],"classifications":["Classification","Information Extraction","Pre-Processing"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":6},{"id":"1da00cee32eeb392103ae8664e15738a3176b7680256e12fa6492c5adfef13db0969eb18682af91fa8e08351dc78422d3b58f9ff222e9a521d215680e7b3b22c","file_path":"legal-nlp-survey-20250328-002/original/Munnely_2018_0181.pdf","title":"Investigating Entity Linking in Early English Legal Documents","llm_title":"Investigating Entity Linking in Early English Legal Documents","authors":["Gary Munnelly","Séamus Lawless"],"llm_authors":"Gary Munnelly, Séamus Lawless","author_string":"Gary Munnelly and Séamus Lawless","year":2018,"abstract":"","llm_abstract":"In this paper we investigate the accuracy and overall suitability of a variety of Entity Linking systems for the task of disambiguating entities in 17th century depositions obtained during the 1641 Irish Rebellion. The depositions are extremely difficult for modern NLP tools to work with due to inconsistent spelling, use of language and archaic references. In order to assess the severity of difficulty faced by Entity Linking systems when working with these documents we use the depositions to create an evaluation corpus. This corpus is used as an input to the General Entity Annotator Benchmarking Framework, a standard benchmarking platform for entity annotation systems. Based on this corpus and the results obtained from the General Entity Annotator Benchmarking Framework we observe that the accuracy of existing Entity Linking systems is limited when applied to content like these depositions. This is due to a number of issues ranging from problems with existing state-of-the-art systems to poor representation of historic entities in modern knowledge bases. We discuss some interesting questions raised by this evaluation and put forward a plan for future work in order to learn more.","llm_keywords":["Entity Linking","Named Entity Disambiguation","Digital Humanities","Cultural Heritage","17th Century Depositions","1641 Irish Rebellion","Natural Language Processing"],"classifications":["Classification","Information Extraction","Information Retrieval"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":9},{"id":"d6c659a7a4e0a2c2f12e53c4dda3301837a0e750c0efd7927cf75874e634248ca7716f570572ebac2ac88b4f514b6f1bd7121ba1fe19b07b29253d8c43f783d9","file_path":"legal-nlp-survey-20250328-002/original/Katz_2020_0312.pdf","title":"","llm_title":"Complex Societies and the Growth of the Law","authors":["Daniel Martin Katz","Corinna Coupette","Janis Beckedorf","Dirk Hartung"],"llm_authors":"Daniel Martin Katz, Corinna Coupette, Janis Beckedorf, Dirk Hartung","author_string":"","year":2022,"abstract":"","llm_abstract":"While a large number of informal factors influence how people interact, modern societies rely upon law as a primary mechanism to formally control human behaviour. How legal rules impact societal development depends on the interplay between two types of actors: the people who create the rules and the people to which the rules potentially apply. We hypothesise that an increasingly diverse and interconnected society might create increasingly diverse and interconnected rules, and assert that legal networks provide a useful lens through which to observe the interaction between law and society. To evaluate these propositions, we present a novel and generalizable model of statutory materials as multidimensional, time-evolving document networks. Applying this model to the federal legislation of the United States and Germany, we find impressive expansion in the size and complexity of laws over the past two and a half decades. We investigate the sources of this development using methods from network science and natural language processing. To allow for cross-country comparisons over time, we algorithmically reorganise the legislative materials of the United States and Germany into cluster families that reflect legal topics. This reorganisation reveals that the main driver behind the growth of the law in both jurisdictions is the expansion of the welfare state, backed by an expansion of the tax state.","llm_keywords":["legal networks","societal development","statutory materials","document networks","law complexity","United States legislation","Germany legislation","welfare state","tax state","legal change"],"classifications":["Pre-Processing","Classification"],"num_cited_by":58,"num_cited_by_title_only":58,"num_pages":50},{"id":"977b1cb47487bd92fcb089d91baf801e925d50e50059eadd337b215af4ca316e36b674f054d8d826b7961dbcdf0816c4839bba745320b376f64529927761499f","file_path":"legal-nlp-survey-20250328-002/original/Mamakas_2022_0592.pdf","title":"Bag of Words BERT-based models for large legal document classification","llm_title":"Bag of Words BERT-based models for large legal document classification","authors":["Dimitrios Mamakas"],"llm_authors":"Dimitrios Mamakas","author_string":"Dimitrios Mamakas","year":2022,"abstract":"","llm_abstract":"Natural Language Processing (NLP) is a field of research that extensively deals with computationally processing, analyzing, and generating human language, with the primary purpose of achieving a successful interaction between humans and machines. Its main idea is to create efficient algorithms which will be able to analyze or generate natural language text, extract information from sources like websites or databases, perform machine translation, categorize documents, etc. In the terminology of Artificial Intelligence (AI), those algorithms are referred to as models, especially when neural networks are used. Generally, studying through the research that has already been conducted, reveals a major need for developing models which will be able to handle large texts, or simply texts which contain more than 500 words on average. This statement indicates that the models that have already been created are often not capable of dealing with long word sequences, or if they are, they do not perform as initially desired by being too slow at training time, or by not offering good testing results. In this thesis, we will mainly focus on providing solutions for this problem by combining already developed Transformer-based models like BERT with the traditional Bag of Words concept (BoW). For experimental needs, datasets from the LexGLUE benchmark will be used. This means that all the training, evaluation, and testing texts originate from the legal domain and especially from several court decisions and contracts. Finally, it should be mentioned that one of the main ambitions of this thesis is to be not only of scientific but also of commercial interest, for example, by achieving the shortest inference times possible for each model. This will facilitate the deployment in most relevant machines, thus limiting the final requirements in both hardware (GPUs, CPUs, etc.) and software.","llm_keywords":["Natural Language Processing","BERT","Bag of Words","Transformer models","legal document classification","machine learning","deep learning"],"classifications":["Pre-Processing","Classification","Information Extraction","Resources"],"num_cited_by":0,"num_cited_by_title_only":0,"num_pages":59},{"id":"2b2375f623eeef8c107dcb1f0ac089f33fe92422f23a898bcbcc7e6293ff27250d50cea9fb3b5ca7432a7d3a3d9ca269ce7ae7cffcebf7ab87733b34dbafebbf","file_path":"legal-nlp-survey-20250328-002/original/Jayasinghe_2021_0408.pdf","title":"","llm_title":"Critical Sentence Identification in Legal Cases Using Multi-Class Classification","authors":["Sahan Jayasinghe","Lakith Rambukkanage","Ashan Silva","Nisansa de Silva","Amal Shehan Perera"],"llm_authors":"Sahan Jayasinghe, Lakith Rambukkanage, Ashan Silva, Nisansa de Silva, Amal Shehan Perera","author_string":"","year":2021,"abstract":"","llm_abstract":"Inherently, the legal domain contains a vast amount of data in text format. Therefore it requires the application of Natural Language Processing (NLP) to cater to the analytically demanding needs of the domain. The advancement of NLP is spreading through various domains, such as the legal domain, in forms of practical applications and academic research. Identifying critical sentences, facts and arguments in a legal case is a tedious task for legal professionals. In this research we explore the usage of sentence embeddings for multi-class classification to identify critical sentences in a legal case, in the perspective of the main parties present in the case. In addition, a task-specific loss function is defined in order to improve the accuracy restricted by the straightforward use of categorical cross entropy loss.","llm_keywords":["Natural Language Processing","Sentence Embedding","Legal Domain","Information Extraction","Multi-Class Classification","Critical Sentences","Case Law","Legal Parties"],"classifications":["Classification"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":6},{"id":"420e1752906cf8edc3b08495ed17a6772d98ed7f9a29791d8789be75fc1150027501130c1d4949343097b6fb18a67be98d4c923d9b2ce5a90022afca4de28146","file_path":"legal-nlp-survey-20250328-002/original/Silva_2021_0481.pdf","title":"Using Natural Language Processing to  Detect Privacy Violations in Online Contracts","llm_title":"Using Natural Language Processing to Detect Privacy Violations in Online Contracts","authors":["Paulo Silva","Carolina Gonçalves","Carolina Godinho","Nuno Antunes","Marilia Curado"],"llm_authors":"Paulo Silva, Carolina Gonçalves, Carolina Godinho, Nuno Antunes, Marilia Curado","author_string":"Paulo Silva, Carolina Gonçalves, Carolina Godinho, Nuno Antunes, Marilia Curado","year":2021,"abstract":"","llm_abstract":"As information systems deal with contracts and documents in essential services, there is a lack of mechanisms to help organizations in protecting the involved data subjects. In this paper, we evaluate the use of named entity recognition as a way to identify, monitor and validate personally identifiable information. In our experiments, we use three of the most well-known Natural Language Processing tools (NLTK, Stanford CoreNLP, and spaCy). First, the effectiveness of the tools is evaluated in a generic dataset. Then, the tools are applied in datasets built based on contracts that contain personally identifiable information. The results show that models’ performance was highly positive in accurately classifying both the generic and the contracts’ data. Furthermore, we discuss how our proposal can effectively act as a Privacy Enhancing Technology.","llm_keywords":["Privacy Violations","Online Contracts","Natural Language Processing","Named Entity Recognition","Personally Identifiable Information"],"classifications":["Pre-Processing","Machine Summarization","Classification"],"num_cited_by":25,"num_cited_by_title_only":20,"num_pages":3},{"id":"11ec07e3f10c0452514a6682d83a49f7defac5e66d9a0edf6f783a9d0f88587573e389bc6ff1af1e467faa9ac274e767b0e2c82515d9803bb0331a7175cea8c7","file_path":"legal-nlp-survey-20250328-002/original/Polo_2021_0457.pdf","title":"","llm_title":"Predicting Legal Proceedings Status: Approaches Based on Sequential Text Data","authors":["Felipe Maia Polo","Itamar Ciochetti","Emerson Bertolo"],"llm_authors":"Felipe Maia Polo, Itamar Ciochetti, and Emerson Bertolo","author_string":"","year":2021,"abstract":"","llm_abstract":"","llm_keywords":["Legal Proceedings","Predictive Models","Sequential Text","Classifiers","Feature Extraction","Word2Vec","Doc2Vec","TFIDF","BERT","Machine Learning"],"classifications":[],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":2},{"id":"7472df9690a5deee00cb3b562ff01fe7687aa3984c5a40380a43aaa6138647da6b3ef88dfe49a5328d107e87f29b60835c0114efa99e7d76facfe0d42b8ebdaf","file_path":"legal-nlp-survey-20250328-002/original/Santosh_2022_0555.pdf","title":"","llm_title":"Deconfounding Legal Judgment Prediction for European Court of Human Rights Cases Towards Better Alignment with Experts","authors":["Santosh T.Y.S.S","Shanshan Xu","Oana Ichim","Matthias Grabmair"],"llm_authors":"Santosh T.Y.S.S, Shanshan Xu, Oana Ichim, Matthias Grabmair","author_string":"","year":2022,"abstract":"","llm_abstract":"This work demonstrates that Legal Judgement Prediction systems without expert-informed adjustments can be vulnerable to shallow, distracting surface signals that arise from corpus construction, case distribution, and confounding factors. To mitigate this, we use domain expertise to strategically identify statistically predictive but legally irrelevant information. We adopt adversarial training to prevent the system from relying on it. We evaluate our deconfounded models by employing interpretability techniques and comparing to expert annotations. Quantitative experiments and qualitative analysis show that our deconfounded model consistently aligns better with expert rationales than baselines trained for prediction only. We further contribute a set of reference expert annotations to the validation and testing partitions of an existing benchmark dataset of European Court of Human Rights cases.","llm_keywords":["Legal Judgment Prediction","European Court of Human Rights","Adversarial Training","Deconfounding","Natural Language Processing","Expert Alignment","Interpretability","Machine Learning","Legal Data"],"classifications":["Classification","Resources"],"num_cited_by":27,"num_cited_by_title_only":27,"num_pages":19},{"id":"c478b74343e1444bf523aab7bd2e308e0ceac55ac316068be07fa4d1c6a418aa44f3a6bc9be3d84915188c677ff0820c37ae529dbcd6dc46a00127000520ad4a","file_path":"legal-nlp-survey-20250328-002/original/Zhao_2022_0525.pdf","title":"Legal Judgment Prediction via Heterogeneous Graphs and Knowledge of Law Articles","llm_title":"Legal Judgment Prediction via Heterogeneous Graphs and Knowledge of Law Articles","authors":["Qihui Zhao","Tianhan Gao","Song Zhou","Dapeng Li","Yingyou Wen"],"llm_authors":"Qihui Zhao, Tianhan Gao, Song Zhou, Dapeng Li, Yingyou Wen","author_string":"Qihui Zhao, Tianhan Gao, Song Zhou, Dapeng Li and Yingyou Wen","year":2022,"abstract":"","llm_abstract":"Legal judgment prediction (LJP) is a crucial task in legal intelligence to predict charges, law articles and terms of penalties based on case fact description texts. Although existing methods perform well, they still have many shortcomings. First, the existing methods have significant limitations in understanding long documents, especially those based on RNNs and BERT. Secondly, the existing methods are not good at solving the problem of similar charges and do not fully and effectively integrate the information of law articles. To address the above problems, we propose a novel LJP method. Firstly, we improve the model’s comprehension of the whole document based on a graph neural network approach. Then, we design a graph attention network-based law article distinction extractor to distinguish similar law articles. Finally, we design a graph fusion method to fuse heterogeneous graphs of text and external knowledge (law article group distinction information). The experiments show that the method could effectively improve LJP performance. The experimental metrics are superior to the existing state of the art.","llm_keywords":["legal judgment prediction","heterogeneous graphs","graph convolutional network","graph attention network","graph fusion method"],"classifications":["Classification","Information Extraction"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":15},{"id":"d048fda4c16fa1f575cae9b07c36f648e616f09972a1a1cf4d21f49d2e44ac835f3f502500250e41f949761e36a52cd3f191c3ea220c735017ce8579fffa1f5e","file_path":"legal-nlp-survey-20250328-002/original/Sleimi_2018_0165.pdf","title":"Automated Extraction of Semantic Legal Metadata using Natural Language Processing","llm_title":"Automated Extraction of Semantic Legal Metadata Using Natural Language Processing","authors":["Amin Sleimi","Nicolas Sannier","Mehrdad Sabetzadeh","Lionel C. Briand","John Dann"],"llm_authors":"Amin Sleimi, Nicolas Sannier, Mehrdad Sabetzadeh, Lionel C. Briand, John Dann","author_string":"","year":2018,"abstract":"","llm_abstract":"[Context] Semantic legal metadata provides information that helps with understanding and interpreting the meaning of legal provisions. Such metadata is important for the systematic analysis of legal requirements. [Objectives] Our work is motivated by two observations: (1) The existing requirements engineering (RE) literature does not provide a harmonized view on the semantic metadata types that are useful for legal requirements analysis. (2) Automated support for the extraction of semantic legal metadata is scarce, and further does not exploit the full potential of natural language processing (NLP). Our objective is to take steps toward addressing these limitations. [Methods] We review and reconcile the semantic legal metadata types proposed in RE. Subsequently, we conduct a qualitative study aimed at investigating how the identified metadata types can be extracted automatically. [Results and Conclusions] We propose (1) a harmonized conceptual model for the semantic metadata types pertinent to legal requirements analysis, and (2) automated extraction rules for these metadata types based on NLP. We evaluate the extraction rules through a case study. Our results indicate that the rules generate metadata annotations with high accuracy.","llm_keywords":["semantic legal metadata","natural language processing","requirements engineering","legal compliance","metadata extraction"],"classifications":["Information Extraction","Resources"],"num_cited_by":95,"num_cited_by_title_only":95,"num_pages":12},{"id":"b53e47c6ddd4f35d81b01eb6df00df4ce24ec585318480adfe2ace68f8fbb662d646b677dadfde0e1f18c5b9cdef7c55defa0ceb1a82a699c8aa343e221ff619","file_path":"legal-nlp-survey-20250328-002/original/Mistica_2021_0463.pdf","title":"Semi-automatic Triage of Requests for Free Legal Assistance","llm_title":"Semi-automatic Triage of Requests for Free Legal Assistance","authors":["Meladel Mistica","Jey Han Lau","Brayden Merrifield","Kate Fazio","Timothy Baldwin"],"llm_authors":"Meladel Mistica, Jey Han Lau, Brayden Merrifield, Kate Fazio, Timothy Baldwin","author_string":"Meladel Mistica ; Jey Han Lau ; Brayden Merrifield ; Kate Fazio ; Timothy Baldwin","year":2021,"abstract":"","llm_abstract":"Free legal assistance is critically under-resourced, and many of those who seek legal help have their needs unmet. A major bottleneck in the provision of free legal assistance to those most in need is the determination of the precise nature of the legal problem. This paper describes a collaboration with a major provider of free legal assistance, and the deployment of natural language processing models to assign area-of-law categories to real-world requests for legal assistance. In particular, we focus on an investigation of models to generate efficiencies in the triage process, but also the risks associated with naive use of model predictions, including fairness across different user demographics.","llm_keywords":["free legal assistance","natural language processing","legal triage","model bias","area-of-law categorization","demographics","collaboration","text classification","Justice Connect"],"classifications":["Classification"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":11},{"id":"a143fcb26dc9b569c5032ee579ba3436944b0ff32581c0312b584f28eb6551efe4cda6f1ee6d9a137df88cdfda935379e77c49d9cd726db5a67f57b5d2a7ecbe","file_path":"legal-nlp-survey-20250328-002/original/Chen_2022_0488.pdf","title":"A comparative study of automated legal text classification using random forests and deep learning","llm_title":"A comparative study of automated legal text classification using random forests and deep learning","authors":["Haihua Chen","Lei Wu","Jiangping Chen","Wei Lu","Junhua Ding"],"llm_authors":"Haihua Chen, Lei Wu, Jiangping Chen, Wei Lu, Junhua Ding","author_string":"Haihua Chen","year":2022,"abstract":"","llm_abstract":"Automated legal text classification is a prominent research topic in the legal field. It lays the foundation for building an intelligent legal system. Current literature focuses on international legal texts, such as Chinese cases, European cases, and Australian cases. Little attention is paid to text classification for U.S. legal texts. Deep learning has been applied to improving text classification performance. Its effectiveness needs further exploration in domains such as the legal field. This paper investigates legal text classification with a large collection of labeled U.S. case documents through comparing the effectiveness of different text classification techniques. We propose a machine learning algorithm using domain concepts as features and random forests as the classifier. Our experiment results on 30,000 full U.S. case documents in 50 categories demonstrated that our approach significantly outperforms a deep learning system built on multiple pre-trained word embeddings and deep neural networks. In addition, applying only the top 400 domain concepts as features for building the random forests could achieve the best performance. This study provides a reference to select machine learning techniques for building high-performance text classification systems in the legal domain or other fields.","llm_keywords":["Legal text classification","Machine learning","Deep learning","Word embedding","Random forests"],"classifications":["Classification","Resources"],"num_cited_by":182,"num_cited_by_title_only":182,"num_pages":15},{"id":"a1cbbd70efd573d6dfd0d34569569cb4c8e30c05fd61d2739c131fbc7e9182e9e4e6a6774be2c1beb68701e15378e4c44edf776517794d29da738d7b887789f9","file_path":"legal-nlp-survey-20250328-002/original/Pais_2021_0451.pdf","title":"Named Entity Recognition in the Romanian Legal Domain","llm_title":"Named entity recognition in the Romanian legal domain","authors":["Vasile Pais","Maria Mitrofan","Carol Luca Gasan","Vlad Coneschi","Alexandru Ianov"],"llm_authors":"Vasile Pais, Maria Mitrofan, Carol Luca Gasan, Vlad Coneschi, Alexandru Ianov","author_string":"Vasile Pais ; Maria Mitrofan ; Carol Luca Gasan ; Vlad Coneschi ; Alexandru Ianov","year":2021,"abstract":"","llm_abstract":"Recognition of named entities present in text is an important step towards information extraction and natural language understanding. This work presents a named entity recognition system for the Romanian legal domain. The system makes use of the gold annotated LegalNERo corpus. Furthermore, the system combines multiple distributional representations of words, including word embeddings trained on a large legal domain corpus. All the resources, including the corpus, model and word embeddings are open sourced. Finally, the best system is available for direct usage in the RELATE platform.","llm_keywords":["Named Entity Recognition","Legal Domain","Romanian Language","Natural Language Processing","Word Embeddings","LegalNERo Corpus","Information Extraction","RELATE platform"],"classifications":["Information Extraction","Resources"],"num_cited_by":40,"num_cited_by_title_only":40,"num_pages":10},{"id":"58b2330fafd57fa2a4f9dc82ea1cb36a7b2cda5b59554515a2189e42fc2bed4cb07c488e982fa263f2b0a5b5f8a2d66437248e6badbe16b9bff1469e3b76272a","file_path":"legal-nlp-survey-20250328-002/original/Kourtin_2020_0300.pdf","title":"","llm_title":"A Legal Question Answering Ontology-Based System","authors":["Ismahane Kourtin","Samir Mbarki","Abdelaaziz Mouloudi"],"llm_authors":"Ismahane Kourtin, Samir Mbarki, Abdelaaziz Mouloudi","author_string":"","year":2020,"abstract":"","llm_abstract":"Question-answering systems (QASs) aim to provide a relevant and concise answer to questions asked in natural language by a user. In this article, we describe our method of developing a question-answering system, operating in the legal domain in Morocco, which mostly uses the French and Arabic languages, and sometimes English. Its purpose is to give relevant and concise answers to questions in the legal domain, stated in natural language by a user, without him having to go through the legal documents to find an answer to his question. The implementation of the proposed system is based on three processes: the first process consists of modeling the legal domain knowledge by an ontology, both (i) independent of the language, and (ii) capable of supporting several languages. The second process consists of extracting the RDF triplet components from the user’s question. The third process consists of reformulating the question by a SPARQL query(s) with which we can query the ontology and thus retrieve the appropriate answer to the question asked by the user.","llm_keywords":["Question-answering system","Ontology","Legal domain","Natural language processing","RDF","SPARQL"],"classifications":["Information Retrieval","Information Extraction","Text Generation"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":12},{"id":"554b49178e9343fd175ad0c134f949a95b9da55dd36dc9802bc8c7162114e97d8369cbabd64eab80a75a9e2862203a1d90b42fc9724fede587883669d24eb24d","file_path":"legal-nlp-survey-20250328-002/original/Tan_2013_0006.pdf","title":"","llm_title":"Automated reference resolution in legal texts","authors":["Oanh Thi Tran","Bach Xuan Ngo","Minh Le Nguyen","Akira Shimazu"],"llm_authors":"Oanh Thi Tran, Bach Xuan Ngo, Minh Le Nguyen, Akira Shimazu","author_string":"","year":2014,"abstract":"","llm_abstract":"This paper investigates the task of reference resolution in the legal domain. This is a new interesting task in Legal Engineering research. The goal is to create a system which can automatically detect references and then extracts their referents. Previous work limits itself to detect and resolve references at the document targets. In this paper, we go a step further in trying to resolve references to sub-document targets. Referents extracted are the smallest fragments of texts in documents, rather than the entire documents that contain the referenced texts. Based on analyzing the characteristics of reference phenomena in legal texts, we propose a four-step framework to deal with the task: mention detection, contextual information extraction, antecedent candidate extraction, and antecedent determination. We also show how machine learning methods can be exploited in each step. The final system achieves 80.06 % in the F1 score for detecting references, 85.61 % accuracy for resolving them, and 67.02 % in the F1 score for the end-to-end setting task on the Japanese National Pension Law corpus.","llm_keywords":["Reference resolution","Mention detection","Legal texts","Legal Engineering","JNPL corpus","Machine learning","Natural Language Processing","Japanese language","Legal domain"],"classifications":["Information Extraction","Resources"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":32},{"id":"ded2747c1ffae334d1b84c7450ee3b98674fe8854d70dfef6526ae1555e57875eb09888680ca7192c99cc8e2132750f359af110f4f4362d8d9fb39e7ea0a16dc","file_path":"legal-nlp-survey-20250328-002/original/Le_2020_0337.pdf","title":"","llm_title":"Learning to Predict Charges for Legal Judgment via Self-Attentive Capsule Network","authors":["Yuquan Le","Congqing He","Meng Chen","Youzheng Wu","Xiaodong He","Bowen Zhou"],"llm_authors":"Yuquan Le, Congqing He, Meng Chen, Youzheng Wu, Xiaodong He, Bowen Zhou","author_string":"","year":2020,"abstract":"","llm_abstract":"With the rapid development of deep learning technology, more and more traditional industries are changed by Artificial Intelligence. The legal industry is such a popular scenario which attracts lots of researchers’ interests. In this work, we focus on automatic charge prediction, which predicts the final charges according to the given fact descriptions in criminal cases. It is crucial for legal assistant systems and can help the judges improve work efficiency greatly. However, extremely imbalanced data distribution and lengthy fact descriptions make this task especially challenging. To tackle these two issues, we propose a novel model, namely Self-Attentive Capsule Network (dubbed as SAttCaps). In particular, we devise a self-attentive dynamic routing, which can not only capture long-range dependency more directly than vanilla dynamic routing, but also learn the high-level generalized features better. The experimental results on three real-world datasets demonstrate that our model significantly outperforms the baselines and creates new state-of-the-art performance. Moreover, our model performs much better than the baselines especially in the low-frequency charges and can bring 5.7% absolute improvement under F1 score.","llm_keywords":["charge prediction","legal judgment","deep learning","self-attentive capsule network","imbalanced data","dynamic routing","natural language processing"],"classifications":["Pre-Processing"],"num_cited_by":13,"num_cited_by_title_only":13,"num_pages":8},{"id":"c4bf6806f4a729b5ac8fefc67dcb9d2275212fbc2b0f434be7447d0fb29438db3963e3fefe6fa2abfd46c43c0c71f62ae0c459feefdc61b12e8bd32e600f8536","file_path":"legal-nlp-survey-20250328-002/original/Kolt_2022_0594.pdf","title":"Noam Kolt, Predicting Consumer Contracts (August 13, 2021)","llm_title":"PREDICTING CONSUMER CONTRACTS","authors":["Noam Kolt"],"llm_authors":"Noam Kolt","author_string":"","year":2021,"abstract":"","llm_abstract":"","llm_keywords":["consumer contracts","language models","GPT-3","legal domain","machine learning","contractual rights","anti-consumer bias","brittleness","policymakers","governance"],"classifications":[],"num_cited_by":42,"num_cited_by_title_only":42,"num_pages":54},{"id":"a88c3f10466646136c29d2eb46c589ddb49b9ad4f00626f0d1e44208e9488b72a4d9563e6aecc2565ed07aaecb23018ddaeec504ed0c6bd1acd20e45cca7573a","file_path":"legal-nlp-survey-20250328-002/original/van-Banerveld_2014_0038.pdf","title":"","llm_title":"Performance Evaluation of a Natural Language Processing approach applied in White Collar crime investigation","authors":["Maarten Van Barneveld","Nhien-An Le-Khac","M-Tahar Kechadi"],"llm_authors":"Maarten Van Barneveld, Nhien-An Le-Khac, M-Tahar Kechadi","author_string":"Nafnaf","year":2016,"abstract":"","llm_abstract":"In today’s world we are confronted with increasing amounts of information every day coming from a large variety of sources. People and corporations are producing data on a large scale, and since the rise of the internet, e-mail and social media the amount of produced data has grown exponentially. From a law enforcement perspective we have to deal with these huge amounts of data when a criminal investigation is launched against an individual or company. Relevant questions need to be answered like who committed the crime, who were involved, what happened and on what time, who were communicating and about what? Not only the amount of available data to investigate has increased enormously, but also the complexity of this data has increased. When these communication patterns need to be combined with for instance a seized financial administration or corporate document shares a complex investigation problem arises. Recently, criminal investigators face a huge challenge when evidence of a crime needs to be found in the Big Data environment where they have to deal with large and complex datasets especially in financial and fraud investigations. To tackle this problem, a financial and fraud investigation unit of a European country has developed a new tool named LES that uses Natural Language Processing (NLP) techniques to help criminal investigators handle large amounts of textual information in a more efficient and faster way. In this paper, we present briefly this tool and we focus on the evaluation its performance in terms of the requirements of forensic investigation: speed, smarter and easier for investigators. In order to evaluate this LES tool, we use different performance metrics. We also show experimental results of our evaluation with large and complex datasets from real-world application.","llm_keywords":["big data","natural language processing","financial investigation","fraud investigation","Hadoop","MapReduce","forensic investigation","criminal investigation","textual information","data analysis"],"classifications":["Information Retrieval","Information Extraction"],"num_cited_by":29,"num_cited_by_title_only":29,"num_pages":16},{"id":"bd0fc2075323848647cbd8412a227f50054684135735972c2722e235045e1ce9fdeca6f3b2ec6a924852705f286829354dfd0b0402636863f21705dc4a56164c","file_path":"legal-nlp-survey-20250328-002/original/García-Constantino_2017_0118.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"CLIEL: Context-Based Information Extraction from Commercial Law Documents","authors":["Matías García-Constantino","Katie Atkinson","Danushka Bollegala","Karl Chapman","Frans Coenen","Claire Roberts","Katy Robson"],"llm_authors":"Matías García-Constantino, Katie Atkinson, Danushka Bollegala, Karl Chapman, Frans Coenen, Claire Roberts, Katy Robson","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"The e!ectiveness of document Information Extraction (IE) is greatly a!ected by the structure and layout of the documents being con-sidered. In the case of legal documents relating to commercial law, an additional challenge is the many di!erent and varied formats, structures and layouts used. In this paper, we present work on a \"exible and scalable IE environment, the CLIEL (Commercial Law Information Extraction based on Layout) environment, for appli-cation to commercial law documentation that allows layout rules to be derived and then utilised to support IE. The proposed CLIEL environment operates using NLP (Natural Language Processing) techniques, JAPE (Java Annotation Patterns Engine) rules and some GATE (General Architecture for Text Engineering) modules. The system is fully described and evaluated using a commercial law document corpus. The results demonstrate that considering the layout is bene#cial for extracting data point instances from legal document collections.","llm_keywords":["Information Extraction","Commercial Law","Legal Documents","NLP","Document Layout","Data Points","JAPE","GATE","XML"],"classifications":["Information Extraction","Resources"],"num_cited_by":44,"num_cited_by_title_only":44,"num_pages":9},{"id":"f32251c3f052e483c6449fd076a8550385c73ded59fa5a5e59836d682bfc5047bfd429e8ae19d2180f8ce28e4fc15f7eb4fe4b0266db2db7f3c7c5d57e4985ab","file_path":"legal-nlp-survey-20250328-002/original/Isemann_2013_0023.pdf","title":"","llm_title":"Temporal Dependence in Legal Documents?","authors":["Daniel Isemann","Khurshid Ahmad","Tim Fernando","Carl Vogel"],"llm_authors":"Daniel Isemann, Khurshid Ahmad, Tim Fernando, Carl Vogel","author_string":"","year":2013,"abstract":"","llm_abstract":"Tasks and difficulties inherent in the largely open problem of temporal information extraction from legal text are outlined. We demonstrate the efficacy of tools and concepts available “off-the-shelf” and suggest refinements for such applications. In particular, the frequent references between regulatory texts have to be addressed as a separate named entity recognition task that bears relevance to an analysis of the temporal ordering of legislation. A regular expression-based approach as a robust first step towards addressing this problem is tested.","llm_keywords":["named entities","temporality","legal information extraction","temporal information","regulatory texts","named entity recognition","temporal ordering","legislation","regular expressions"],"classifications":["Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":8},{"id":"71c196c3d7f5a5531eebfc29fd5046cdc5abf8773c19704a57b70be56697e6db006336e5bf6d814a64be434ef8cd9e81111f4e82a8029765dcc6d44d12b0720c","file_path":"legal-nlp-survey-20250328-002/original/Bouadjenek_2013_0002.pdf","title":"","llm_title":"A Study of Query Reformulation for Patent Prior Art Search with Partial Patent Applications","authors":["Anne Gardner","Mohamed Reda Bouadjenek","Scott Sanner","Gabriela Ferraro"],"llm_authors":"Mohamed Reda Bouadjenek, Scott Sanner, Gabriela Ferraro","author_string":"Anne Gardner","year":2015,"abstract":"","llm_abstract":"Patents are used by legal entities to legally protect their inventions and represent a multi-billion dollar industry of licensing and litigation. In 2014, 326,033 patent applications were approved in the US alone – a number that has doubled in the past 15 years and which makes prior art search a daunting, but necessary task in the patent application process. In this work, we seek to investigate the efficacy of prior art search strategies from the perspective of the inventor who wishes to assess the patentability of their ideas prior to writing a full application. While much of the literature inspired by the evaluation framework of the CLEF-IP competition has aimed to assist patent examiners in assessing prior art for complete patent applications, less of this work has focused on patent search with queries representing partial applications. In the (partial) patent search setting, a query is often much longer than in other standard IR tasks, e.g., the description section may contain hundreds or even thousands of words. While the length of such queries may suggest query reduction strategies to remove irrelevant terms, intentional obfuscation and general language used in patents suggests that it may help to expand queries with additionally relevant terms. To assess the trade-offs among all of these pre-application prior art search strategies, we comparatively evaluate a variety of partial application search and query reformulation methods. Among numerous findings, querying with a full description, perhaps in conjunction with generic (non-patent specific) query reduction methods, is recommended for best performance. However, we also find that querying with an abstract represents the best trade-off in terms of writing effort vs. retrieval efficacy (i.e., querying with the description sections only lead to marginal improvements) and that for such relatively short queries, generic query expansion methods help.","llm_keywords":["Query Reformulation","Patent Search","Prior Art Search","Patent Applications","Information Retrieval"],"classifications":["Information Retrieval","Pre-Processing"],"num_cited_by":32,"num_cited_by_title_only":23,"num_pages":10},{"id":"e81a674b12a765540f90c9254b94a4e3ef72948ee0d411ee04ba578c4d7f1618522a36cec33571a6c2263538d1979098908d4c19101338f5292da1a11adcb151","file_path":"legal-nlp-survey-20250328-002/original/Zheng_2021_0486.pdf","title":"","llm_title":"When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset of 53,000+ Legal Holdings","authors":["Lucia Zheng","Neel Guha","Brandon R. Anderson","Peter Henderson","Daniel E. Ho"],"llm_authors":"Lucia Zheng, Neel Guha, Brandon R. Anderson, Peter Henderson, Daniel E. Ho","author_string":"","year":2021,"abstract":"","llm_abstract":"While self-supervised learning has made rapid advances in natural language processing, it remains unclear when researchers should engage in resource-intensive domain-specific pretraining (domain pretraining). The law, puzzlingly, has yielded few documented instances of substantial gains to domain pretraining in spite of the fact that legal language is widely seen to be unique. We hypothesize that these existing results stem from the fact that existing legal NLP tasks are too easy and fail to meet conditions for when domain pretraining can help. To address this, we first present CaseHOLD (Case Holdings On Legal Decisions), a new dataset comprised of over 53,000+ multiple choice questions to identify the relevant holding of a cited case. This dataset presents a fundamental task to lawyers and is both legally meaningful and difficult from an NLP perspective (F1 of 0.4 with a BiLSTM baseline). Second, we assess performance gains on CaseHOLD and existing legal NLP datasets. While a Transformer architecture (BERT) pretrained on a general corpus (Google Books and Wikipedia) improves performance, domain pretraining (on a corpus of ≈3.5M decisions across all courts in the U.S. that is larger than BERT’s) with a custom legal vocabulary exhibits the most substantial performance gains with CaseHOLD (gain of 7.2% on F1, representing a 12% improvement on BERT) and consistent performance gains across two other legal tasks. Third, we show that domain pretraining may be warranted when the task exhibits sufficient similarity to the pretraining corpus: the level of performance increase in three legal tasks was directly tied to the domain specificity of the task. Our findings inform when researchers should engage in resource-intensive pretraining and show that Transformer-based architectures, too, learn embeddings suggestive of distinct legal language.","llm_keywords":["law","natural language processing","pretraining","benchmark dataset","self-supervised learning","Transformer-based architectures","legal language","CaseHOLD dataset","domain-specific pretraining","legal NLP tasks"],"classifications":["Resources"],"num_cited_by":231,"num_cited_by_title_only":231,"num_pages":10},{"id":"1120e1d6a738f6676e2cb229f344528b27ee8a21fd108e1be2d0f8d0fa35cd660da57e0b8089435ac38bedb7ee0fe1d47fc8685dc260153256c654aa8763a677","file_path":"legal-nlp-survey-20250328-002/original/Josi_2022_0539.pdf","title":"","llm_title":"Preparing Legal Documents for NLP Analysis: Improving the Classification of Text Elements by Using Page Features","authors":["Frieda Josi","Christian Wartena","Ulrich Heid"],"llm_authors":"Frieda Josi, Christian Wartena, Ulrich Heid","author_string":"","year":2022,"abstract":"","llm_abstract":"Legal documents often have a complex layout with many different headings, headers and footers, side notes, etc. For the further processing, it is important to extract these individual components correctly from a legally binding document, for example a signed PDF. A common approach to do so is to classify each (text) region of a page using its geometric and textual features. This approach works well, when the training and test data have a similar structure and when the documents of a collection to be analyzed have a rather uniform layout. We show that the use of global page properties can improve the accuracy of text element classification: we first classify each page into one of three layout types. After that, we can train a classifier for each of the three page types and thereby improve the accuracy on a manually annotated collection of 70 legal documents consisting of 20,938 text elements. When we split by page type, we achieve an improvement from 0.95 to 0.98 for single-column pages with left marginalia and from 0.95 to 0.96 for double-column pages. We developed our own feature-based method for page layout detection, which we benchmark against a standard implementation of a CNN image classifier. The approach presented here is based on corpus of freely available German contracts and general terms and conditions. Both the corpus and all manual annotations are made freely available. The method is language agnostic.","llm_keywords":["PDF Document Analysis","Legal Documents","Layout Detection","Feature and Text Extraction","Classification","Machine Learning","Deep Convolutional Networks","Image Recognition"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":14},{"id":"2e8376bdc6a30a501a97035e743113547f91cf03ca7f5b6201ab255d2186a4769904425f38153f437e421f6baea370ad345f83ccf7f53d54e92224aaff5ee298","file_path":"legal-nlp-survey-20250328-002/original/Chitta_2019_0212.pdf","title":"149_Chitta.pdf","llm_title":"A Reliable and Accurate Multiple Choice Question Answering System for Due Diligence","authors":["Radha Chitta","Alexander K. Hudek"],"llm_authors":"Radha Chitta and Alexander K. Hudek","author_string":"","year":2019,"abstract":"","llm_abstract":"The problem of answering multiple choice questions, based on the content of documents has been studied extensively in the machine learning literature. We pose the due diligence problem, where lawyers study legal contracts and assess the risk in potential mergers and acquisitions, as a multiple choice question answering problem, based on the text of the contract. Existing frameworks for question answering are not suitable for this task, due to the inherent scarcity and imbalance in the legal contract data available for training. We propose a question answering system which first identifies the excerpt in the contract which potentially contains the answer to a given question, and then builds a multi-class classifier to choose the answer to the question, based on the content of this excerpt. Unlike existing question answering systems, the proposed system explicitly handles the imbalance in the data, by generating synthetic instances of the minority answer categories, using the Synthetic Minority Oversampling Technique. This ensures that the number of instances in all the classes are roughly equal to each other, thus leading to more accurate and reliable classification. We demonstrate that the proposed question answering system outperforms the existing systems with minimal amount of training data.","llm_keywords":["Question Answering","Due Diligence","Legal Contracts","Imbalance Handling","Machine Learning"],"classifications":["Classification","Information Extraction","Text Generation"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":5},{"id":"736532ce9258fd2caa8ff1c6bacefdcc924294170485be2fbf312b8e0b90621cb70004cfa3969009941f9cf1ab0478cc40d67cfd776cff78aee7d506a1640260","file_path":"legal-nlp-survey-20250328-002/original/Jablonowska_2021_0394.pdf","title":"","llm_title":"Assessing the Cross-Market Generalization Capability of the CLAUDETTE System","authors":["Agnieszka Jablonowska","Francesca Lagioia","Marco Lippi","Hans-Wolfgang Micklitz","Giovanni Sartor","Giacomo Tagiuri"],"llm_authors":"Agnieszka JABLONOWSKA, Francesca LAGIOIA, Marco LIPPI, Hans-Wolfgang MICKLITZ, Giovanni SARTOR, Giacomo TAGIURI","author_string":"","year":2021,"abstract":"","llm_abstract":"We present a study aimed at testing the CLAUDETTE system’s ability to generalise the concept of unfairness in consumer contracts across diverse market sectors. The data set includes 142 terms of services grouped in five sub-sets: travel and accommodation, games and entertainment, finance and payments, health and well-being, and the more general others. Preliminary results show that the classifier has satisfying performance on all the sectors.","llm_keywords":["Unfair clause detection","machine learning","cross-market analysis","consumer contracts","CLAUDETTE system","supervised machine learning","EU consumer law"],"classifications":["Classification"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":6},{"id":"9c9b9b31263f0083226e2da62ba16817a55c0bdcd15ebdd5bf4ed5353301c009d934e8c1a789e28542e4cd0ce2a06b4f3a164b552b6da6c13ee634c96653908d","file_path":"legal-nlp-survey-20250328-002/original/Barale_2022_0516.pdf","title":"","llm_title":"Human-Centered Computing in Legal NLP: An Application to Refugee Status Determination","authors":["Claire Barale"],"llm_authors":"Claire Barale","author_string":"","year":2022,"abstract":"","llm_abstract":"This paper proposes an approach to the design of an ethical human-AI reasoning support system for decision makers in refugee law. In the context of refugee status determination, practitioners mostly rely on text data. We therefore investigate human-AI cooperation in legal natural language processing. Specifically, we want to determine which design methods can be transposed to legal text analytics. Although little work has been done so far on human-centered design methods applicable to the legal domain, we assume that introducing iterative cooperation and user engagement in the design process is (1) a method to reduce technical limitations of an NLP system and (2) that it will help design more ethical and effective applications by taking users’ preferences and feedback into account. The proposed methodology is based on three main design steps: cognitive process formalization in models understandable by both humans and computers, speculative design of prototypes, and semi-directed interviews with a sample of potential users.","llm_keywords":["Human-AI cooperation","refugee status determination","human-centered computing","NLP","legal text analytics","ethical design","machine learning","trust in AI","legal decision support"],"classifications":[],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":6},{"id":"903bf2fec478a8908fb2d61f8a33d3ca83f6b98b851d2e89394850735b0121e1a882c3a5acd005bad120401918f6c0c33cd6fcc8c0accd450f9ffdd28a9ee0e9","file_path":"legal-nlp-survey-20250328-002/original/Yang_2017_0123.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"E!ectiveness Results for Popular e-Discovery Algorithms","authors":["Eugene Yang","David Grossman","Ophir Frieder","Roman Yurchak"],"llm_authors":"Eugene Yang, David Grossman, Ophir Frieder, Roman Yurchak","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"E-Discovery applications rely upon binary text categorization to determine relevance of documents to a particular case. Although many such categorization algorithms exist, at present, vendors often deploy tools that typically include only one text categorization approach. Unlike previous studies that vary many evaluation parameters simultaneously, fail to include common current algorithms, weights, or features, or used small document collections which are no longer meaningful, we systematically evaluate binary text categorization algorithms using modern benchmark e-Discovery queries (topics) on a benchmark e-Discovery data set. We demonstrate the wide variance of performance obtained using the different parameter combinations, motivating this evaluation. Specifically, we compare five text categorization algorithms, three term weighting techniques and two feature types on a large standard dataset and evaluate the results of this test suite (30 variations) using metrics of greatest interest to the e-Discovery community. Our findings systematically demonstrate that an e-Discovery project is better served by a suite of, rather than a single, algorithms since performance varies greatly depending on the topic, and no approach is uniformly superior across the range of conditions and topics. To that end, we developed an open source project called FreeDiscovery that provides e-Discovery projects with simplified access to a suite of algorithms.","llm_keywords":["e-Discovery","text categorization","binary text categorization","algorithms","information retrieval","supervised learning","Legal Track","document relevance","text classification","data mining"],"classifications":["Classification","Resources"],"num_cited_by":26,"num_cited_by_title_only":26,"num_pages":4},{"id":"91a67a7688ecf53db0d6fb7cab80751ae2ef81c6df06764e49162003208ae5f64075bd6535b3e583050308e07bf2adbeb21b33e27ea7f73fcaf734ce1077bd32","file_path":"legal-nlp-survey-20250328-002/original/Falakmasir_2017_0157.pdf","title":"","llm_title":"Utilizing Vector Space Models for Identifying Legal Factors from Text","authors":["Mohammad H. Falakmasir","Kevin D. Ashley"],"llm_authors":"Mohammad H. Falakmasir and Kevin D. Ashley","author_string":"","year":2017,"abstract":"","llm_abstract":"Vector Space Models (VSMs) represent documents as points in a vector space derived from term frequencies in the corpus. This level of abstraction provides a flexible way to represent complex semantic concepts through vectors, matrices, and higher-order tensors. In this paper we utilize a number of VSMs on a corpus of judicial decisions in order to classify cases in terms of legal factors, stereotypical fact patterns that tend to strengthen or weaken a side’s argument in a legal claim. We apply different VSMs to a corpus of trade secret misappropriation cases and compare their classification results. The experiment shows that simple binary VSMs work better than previously reported techniques but that more complex VSMs including dimensionality reduction techniques do not improve performance.","llm_keywords":["Vector Space Models","Legal Analytics","Semantic extraction","Trade Secret Law","Case Classification","Judicial Decisions"],"classifications":["Classification"],"num_cited_by":29,"num_cited_by_title_only":29,"num_pages":10},{"id":"c7774047014a0cda330d79bc981bb327f4cdbb5648e69dacd9da80e796ce14b2d2f80cc9d906f4eb2faeb38b75f354b2d1e1c37f2dd15e0836052d35c7d056a2","file_path":"legal-nlp-survey-20250328-002/original/Trappey,-A._2020_0331.pdf","title":"Intelligent compilation of patent summaries using machine learning and natural language processing techniques","llm_title":"Intelligent compilation of patent summaries using machine learning and natural language processing techniques","authors":["Amy J.C. Trappey","Charles V. Trappey","Jheng-Long Wu","Jack W.C. Wang"],"llm_authors":"Amy J.C. Trappey, Charles V. Trappey, Jheng-Long Wu, Jack W.C. Wang","author_string":"Amy J.C. Trappey","year":2019,"abstract":"","llm_abstract":"Patents are a type of intellectual property with ownership and monopolistic rights that are publicly accessible published documents, often with illustrations, registered by governments and international organizations. The registration allows people familiar with the domain to understand how to re-create the new and useful invention but restricts the manufacturing unless the owner licenses or enters into a legal agreement to sell ownership of the patent. Patents reward the costly research and development efforts of inventors while spreading new knowledge and accelerating innovation. This research uses artificial intelligence natural language processing, deep learning techniques and machine learning algorithms to extract the essential knowledge of patent documents within a given domain as a means to evaluate their worth and technical advantage. Manual patent abstraction is a time consuming, labor intensive, and subjective process which becomes cost and outcome ineffective as the size of the patent knowledge domain increases. This research develops an intelligent patent summarization methodology using artificial intelligence machine learning approaches to allow patent domains of extremely large sizes to be effectively and objectively summarized, especially for cases where the cost and time requirements of manual summarization is infeasible. The system learns to automatically summarize patent documents with natural language texts for any given technical domain. The machine learning solution identifies technical key terminologies (words, phrases, and sentences) in the context of the semantic relationships among training patents and corresponding summaries as the core of the summarization system. To ensure the high performance of the proposed methodology, ROUGE metrics are used to evaluate precision, recall, accuracy, and consistency of knowledge generated by the summarization system. The Smart machinery technologies domain, under the subdomains of control intelligence, sensor intelligence and intelligent decision-making provide the case studies for the patent summarization system training. The cases use 1708 training pairs of patents and summaries while testing uses 30 randomly selected patents. The case implementation and verification have shown the summary reports achieve 90% and 84% average precision and recall ratios respectively.","llm_keywords":["Artificial intelligence","Machine learning","Natural language processing","Deep learning","Patent analysis"],"classifications":["Machine Summarization","Information Extraction"],"num_cited_by":90,"num_cited_by_title_only":90,"num_pages":13},{"id":"7f1b88f324195625befa083fdf587d6682ea2ba59708db091cdc63e9bf56c1912cda98af080732033a4a7d5414e9822ff748138e6c1547e710547bc521cb7dbd","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2018_0199.pdf","title":"Obligation and Prohibition Extraction Using Hierarchical RNNs","llm_title":"Obligation and Prohibition Extraction Using Hierarchical RNNs","authors":["Ilias Chalkidis","Ion Androutsopoulos","Achilleas Michos"],"llm_authors":"Ilias Chalkidis, Ion Androutsopoulos, Achilleas Michos","author_string":"Ilias Chalkidis ; Ion Androutsopoulos ; Achilleas Michos","year":2018,"abstract":"","llm_abstract":"We consider the task of detecting contractual obligations and prohibitions. We show that a self-attention mechanism improves the performance of a BILSTM classifier, the previous state of the art for this task, by allowing it to focus on indicative tokens. We also introduce a hierarchical BILSTM, which converts each sentence to an embedding, and processes the sentence embeddings to classify each sentence. Apart from being faster to train, the hierarchical BILSTM outperforms the flat one, even when the latter considers surrounding sentences, because the hierarchical model has a broader discourse view.","llm_keywords":["contractual obligations","prohibitions","hierarchical RNNs","BILSTM","self-attention mechanism","legal text processing","sentence classification","deontic classification"],"classifications":["Classification","Pre-Processing"],"num_cited_by":78,"num_cited_by_title_only":78,"num_pages":6},{"id":"0f25aef96c6048586cd5e69188d2aca2286ea32b3b2a6623a14e3ddfcfbcc4825a5c106f31c1c3358e9a6eb86a2b73cb6350770641b8d9c2012ee2bd57e9c6fa","file_path":"legal-nlp-survey-20250328-002/original/Tufis_2020_0311.pdf","title":"Collection and Annotation of the Romanian Legal Corpus","llm_title":"Collection and Annotation of the Romanian Legal Corpus","authors":["Dan Tufiș","Maria Mitrofan","Vasile Păiș","Radu Ion","Andrei Coman"],"llm_authors":"Dan Tufis,, Maria Mitrofan, Vasile Pais ˘ ,, Radu Ion, Andrei Coman","author_string":"Dan Tufiș ; Maria Mitrofan ; Vasile Păiș ; Radu Ion ; Andrei Coman","year":2020,"abstract":"","llm_abstract":"We present the Romanian legislative corpus which is a valuable linguistic asset for the development of machine translation systems, especially for under-resourced languages. The knowledge that can be extracted from this resource is necessary for a deeper understanding of how law terminology is used and how it can be made more consistent. At this moment, the corpus contains more than 144k documents representing the legislative body of Romania. This corpus is processed and annotated at different levels: linguistically (tokenized, lemmatized and POS-tagged), dependency parsed, chunked, named entities identified and labeled with IATE terms and EUROVOC descriptors. Each annotated document has a CONLL-U Plus format consisting of 14 columns; in addition to the standard 10-column format, four other types of annotations were added. Moreover the repository will be periodically updated as new legislative texts are published. These will be automatically collected and transmitted to the processing and annotation pipeline. The access to the corpus is provided through ELRC infrastructure.","llm_keywords":["Romanian legal corpus","machine translation","language resources","annotation","EUROVOC","IATE","legislative documents","under-resourced languages"],"classifications":["Resources"],"num_cited_by":16,"num_cited_by_title_only":16,"num_pages":5},{"id":"e45537dfdc130325d55f3a4d532666e25648c206421a141ccf2a072d4290865c59ec938940d9e825f789be82948b5b36f00124f110ff1162721e049f8af4acec","file_path":"legal-nlp-survey-20250328-002/original/Shen_2020_0327.pdf","title":"Hierarchical Chinese Legal event extraction via Pedal Attention Mechanism","llm_title":"Hierarchical Chinese Legal Event Extraction via Pedal Attention Mechanism","authors":["Shirong Shen","Guilin Qi","Zhen Li","Sheng Bi","Lusheng Wang"],"llm_authors":"Shirong Shen, Guilin Qi, Zhen Li, Sheng Bi, Lusheng Wang","author_string":"Shirong Shen ; Guilin Qi ; Zhen Li ; Sheng Bi ; Lusheng Wang","year":2020,"abstract":"","llm_abstract":"Event extraction plays an important role in legal applications, including case push and auxiliary judgment. However, traditional event structure cannot express the connections between arguments, which are extremely important in legal events. Therefore, this paper defines a dynamic event structure for Chinese legal events. To distinguish between similar events, we design hierarchical event features for event detection. Moreover, to address the problem of long-distance semantic dependence and anaphora resolution in argument classification, we propose a novel pedal attention mechanism to extract the semantic relation between two words through their dependent adjacent words. We label a Chinese legal event dataset and evaluate our model on it. Experimental results demonstrate that our model can surpass other state-of-the-art models.","llm_keywords":["hierarchical event extraction","Chinese legal events","pedal attention mechanism","event detection","argument classification","legal applications","dynamic event structure"],"classifications":["Information Extraction","Classification"],"num_cited_by":44,"num_cited_by_title_only":44,"num_pages":14},{"id":"c32700ceac3989a093305265103fcd9bd4dd26202223ce5119ce84fafe903aefaf2ee353f114448479e8563bea14a07bce954739139fad8e3fc7539048476729","file_path":"legal-nlp-survey-20250328-002/original/Xu_2021_0384.pdf","title":"","llm_title":"Accounting for Sentence Position and Legal Domain Sentence Embedding in Learning to Classify Case Sentences","authors":["Huihui Xu","Jaromir Savelka","Kevin D. Ashley"],"llm_authors":"Huihui Xu, Jaromir Savelka, and Kevin D. Ashley","author_string":"","year":2021,"abstract":"","llm_abstract":"In this paper, we treat sentence annotation as a classification task. We employ sequence-to-sequence models to take sentence position information into account in identifying case law sentences as issues, conclusions, or reasons. We also compare the legal domain specific sentence embedding with other general purpose sentence embeddings to gauge the effect of legal domain knowledge, captured during pre-training, on text classification. We deployed the models on both summaries and full-text decisions. We found that the sentence position information is especially useful for full-text sentence classification. We also verified that legal domain specific sentence embeddings perform better, and that meta-sentence embedding can further enhance performance when sentence position information is included.","llm_keywords":["Information retrieval","Natural language processing","Annotation","Embedding","Legal domain","Sentence classification","Machine learning"],"classifications":["Classification","Pre-Processing"],"num_cited_by":22,"num_cited_by_title_only":22,"num_pages":10},{"id":"0e4a1c3aa25d3391b9e7bdc4ca82c1ded5459845f86316feee9f1d767baafac6ecfccc6218229a97e1ab136f556e335aaf9b490774e95b2493573721c2aaa6e0","file_path":"legal-nlp-survey-20250328-002/original/Sugisaki_2016_0081.pdf","title":"Automatic Annotation and Assessment of Syntactic Structures in Law Texts","llm_title":"Automatic Annotation and Assessment of Syntactic Structures in Law Texts Combining Rule-Based and Statistical Methods","authors":["Kyoko Sugisaki"],"llm_authors":"Kyoko Sugisaki","author_string":"Kyoko Sugisaki","year":2016,"abstract":"","llm_abstract":"In this thesis, I investigate and develop methods for automatically analyzing and assessing German syntactic structures in domain-specific texts. As domain-specific texts, I use Swiss German-language law texts. The automatic annotation of syntactic structures has long been studied in the research on natural language processing. Supervised statistical methods are regarded as state-of-the-art parsing methods, which are accurate but biased by the type of text. Consequently, the accuracy of statistical parsers decreases if they are used on domain-specific texts. The problem of domain bias in syntactic annotation should be solved if it directly affects the accuracy of an application. The syntactic assessment that I develop in this thesis is such an application that requires high accuracy of syntactic annotation. An effective solution to this problem would be the manual annotation of a large portion of the required domain texts. However, it is not feasible in practice because manual linguistic annotation is extremely labor intensive. To overcome this problem, I develop syntactic annotation methods that do not require the manual annotation of a large portion of the domain texts. The goal of this thesis is that the annotation accuracy on domain-specific texts is so high that it can be used for the application. For the automatic syntactic assessment, I demonstrate a novel approach to model domain-specific style choice by combining rule-based and statistical methods. In the rule-based approach, I present a method that automatically detects the violations of style rules in legislative style guidelines. In the statistical approach, domain-specific writing style is defined in terms of stylistic choice between syntactic alternations. The syntactic selection is statistically modeled by classifying syntactic alternatives according to their syntactic complexity. The syntactic assessment requires automatic syntactic annotation. For the automatic syntactic annotation, I present a linguistically motivated hybrid supertagger that analyzes topological dependency grammar relations in the German language. In this thesis, supertagging problems are seen as morphosyntactic ambiguity and syntactic resolution. Depending on the linguistic phenomena, the ambiguity is resolved by applying a rule-based and statistical tagging method: Morphological and syntactic hard constraints are applied in a constraint grammar approach. In contrast, lexical, semantic, and pragmatic soft and multivariate constraints are integrated into a conditional random fields model. The main contribution of this thesis to the study of natural language processing is to show that a linguistically motivated annotation method is a viable approach to achieving a high performance of syntactic analysis with a few hundreds of manually annotated sentences from the domain.","llm_keywords":["syntactic structures","law texts","rule-based methods","statistical methods","natural language processing","domain-specific texts","annotation accuracy","syntactic assessment","German language","hybrid supertagger"],"classifications":["Classification","Information Extraction","Pre-Processing","Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":270},{"id":"60edc1dab25cfa11587a5013d961b35991389fe832a2c4a0415017ac76294d514b04ff9c58d2416ef4511997542e5b5fb9849347f6d6048a94137df9df8d6174","file_path":"legal-nlp-survey-20250328-002/original/Zhong_2019_0258.pdf","title":"Legal Judgment Prediction via Topological Learning","llm_title":"Legal Judgment Prediction via Topological Learning","authors":["Haoxi Zhong","Zhipeng Guo","Cunchao Tu","Chaojun Xiao","Zhiyuan Liu","Maosong Sun"],"llm_authors":"Haoxi Zhong, Zhipeng Guo, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu, Maosong Sun","author_string":"Haoxi Zhong ; Guo Zhipeng ; Cunchao Tu ; Chaojun Xiao ; Zhiyuan Liu ; Maosong Sun","year":2018,"abstract":"","llm_abstract":"Legal Judgment Prediction (LJP) aims to predict the judgment result based on the facts of a case and becomes a promising application of artificial intelligence techniques in the legal field. In real-world scenarios, legal judgment usually consists of multiple subtasks, such as the decisions of applicable law articles, charges, fines, and the term of penalty. Moreover, there exist topological dependencies among these subtasks. While most existing works only focus on a specific subtask of judgment prediction and ignore the dependencies among subtasks, we formalize the dependencies among subtasks as a Directed Acyclic Graph (DAG) and propose a topological multi-task learning framework, TOPJUDGE, which incorporates multiple subtasks and DAG dependencies into judgment prediction. We conduct experiments on several real-world large-scale datasets of criminal cases in the civil law system. Experimental results show that our model achieves consistent and significant improvements over baselines on all judgment prediction tasks. The source code can be obtained from https://github.com/thunlp/TopJudge.","llm_keywords":["Legal Judgment Prediction","Topological Learning","Multi-task Learning","Directed Acyclic Graph","Artificial Intelligence","Legal AI","Subtasks Dependencies","Civil Law System"],"classifications":["Classification"],"num_cited_by":404,"num_cited_by_title_only":404,"num_pages":10},{"id":"208de52961ee19ffa2df44b05a48dfdfe434c6b6e240a08394a1a4d0ecf1b1e69573799a667aeca32ab3fee45eb86494fc1e920485d8cf1e694fc3943b8a4530","file_path":"legal-nlp-survey-20250328-002/original/Gumusel_2022_0493.pdf","title":"","llm_title":"An Annotation Schema for the Detection of Social Bias in Legal Text Corpora","authors":["Ece Gumusel","Vincent Quirante Malic","Devan Ray Donaldson","Kevin Ashley","Xiaozhong Liu"],"llm_authors":"Ece Gumusel, Vincent Quirante Malic, Devan Ray Donaldson, Kevin Ashley, Xiaozhong Liu","author_string":"","year":2022,"abstract":"","llm_abstract":"The rapid advancement of artificial intelligence in recent years has led to an increase in its use in legal contexts. At the same time, a growing body of research has expressed concerns that AI trained on large datasets may learn and model undesirable social biases. In this paper, we investigate the extent to which such social biases are inherent in a real-world legal corpus. We train a word2vec word embedding model on case law data and find evidence that NLP methods make undesirable distinctions between legally equivalent entities that vary only by race. Since legal AI applications that model such distinctions risk perpetuating these inequalities when used, we argue that the development of such applications must incorporate a means to detect and mitigate such biases. To this end, we propose an annotation schema that identifies and categorizes deviations from legal equivalence, so that debiasing may be more systematically incorporated into legal AI development. Future directions for research are discussed.","llm_keywords":["Artificial intelligence","Information ethics","Machine learning","Natural language processing"],"classifications":[],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":14},{"id":"6124c958522ec30bc0182dd182e3590a7d0a87533697a4bd597eefcbca3e6f6b7e9df7b95f158ecca05f8c469edaf161a0b0df42022c45091469c91a8a253b92","file_path":"legal-nlp-survey-20250328-002/original/Cumyn_2019_0259.pdf","title":"199_Cumyn.pdf","llm_title":"Legal Knowledge Representation Using a Faceted Scheme","authors":["Michelle Cumyn","Günter Reiner","Sabine Mas","David Lesieur"],"llm_authors":"Michelle Cumyn, Günter Reiner, Sabine Mas, David Lesieur","author_string":"","year":2019,"abstract":"","llm_abstract":"","llm_keywords":["legal knowledge representation","faceted classification","subject indexing","facet analysis","legal taxonomy","information retrieval","Ranganathan","Bliss Bibliographic Classification","legal domain"],"classifications":[],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":2},{"id":"694b9d9eeef5989eb68661569618ac0e9e52d9bcdac0b293ba94c70f7d70c483aa37b53b173753ffefd2fdb8192c62d6575744a2d016090b2f6343cf93520639","file_path":"legal-nlp-survey-20250328-002/original/Dal-Pont_2021_0405.pdf","title":"","llm_title":"Classification and Association Rules in Brazilian Supreme Court Judgments on Pre-trial Detention","authors":["Thiago Raulino Dal Pont","Isabela Cristina Sabo","Pablo Ernesto Vigneaux Wilton","Victor Araújo de Menezes","Rafael Copetti","Luciano Zambrota","Pablo Procópio Martins","Edjandir Corrêa Costa","Edimeia Liliani Schnitzler","Paloma Maria Santos","Rodrigo Rafael Cunha","Gerson Bovi Kaster","Aires José Rover"],"llm_authors":"Thiago Raulino Dal Pont, Isabela Cristina Sabo, Pablo Ernesto Vigneaux Wilton, Victor Araújo de Menezes, Rafael Copetti, Luciano Zambrota, Pablo Procópio Martins, Edjandir Corrêa Costa, Edimeia Liliani Schnitzler, Paloma Maria Santos, Rodrigo Rafael Cunha, Gerson Bovi Kaster, and Aires José Rover","author_string":"","year":2021,"abstract":"","llm_abstract":"Brazil has a large prison population, which places it as the third country in the world with the most incarceration rate. In addition, the criminal caseload is increasing in Brazilian Judiciary, which is encouraging AI usage to advance in e-Justice. Within this context, the paper presents a case study with a dataset composed of 2,200 judgments from the Supreme Federal Court (STF) about pre-trial detention. These are cases in which a provisional prisoner requests for freedom through habeas corpus. We applied Machine Learning (ML) and Natural Language Processing (NLP) techniques to predict whether STF will release or not the provisional prisoner (text classification), and also to find a reliable association between the judgment outcome and the prisoners’ crime and/or the judge responsible for the case (association rules). We obtained satisfactory results in both tasks. Classification results show that, among the models used, Convolutional Neural Network (CNN) is the best, with 95% accuracy and 0.91 F1-Score. Association results indicate that, among the rules generated, there is a high probability of drug law crimes leading to a dismissed habeas corpus (which means the maintenance of pre-trial detention). We concluded that STF has not interfered in first degree decisions about pre-trial detention and that is necessary to discuss the drug criminalization in Brazil. The main contribution of the paper is to provide models that can support judges and pre-trial detainees.","llm_keywords":["E-justice","Criminal law","Pre-trial detention","Text classification","Association rules","Machine learning"],"classifications":["Classification","Information Extraction"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":14},{"id":"515f78186bff6c1f003dce705e9864b4c52bae0a0ebdec106d577924db49d9e1f69680b5950078faffebcc1013086ac975b05d243c4a8408cde114646bd8577b","file_path":"legal-nlp-survey-20250328-002/original/Kim_2019_0285.pdf","title":"214_Kim.pdf","llm_title":"Statute Law Information Retrieval and Entailment","authors":["Mi-Young Kim","Juliano Rabelo","Randy Goebel"],"llm_authors":"Mi-Young Kim, Juliano Rabelo, Randy Goebel","author_string":"","year":2019,"abstract":"","llm_abstract":"Our Yes/No statute law question answering system combines components for both statute law information retrieval and confirmation of textual entailment between statues and legal questions. We describe a statute law question answering system that exploits TF-IDF and a language model for information retrieval, and inter-paragraph entailment. We have evaluated our system using the data from the competition on legal information extraction/entailment (COLIEE-2019). The competition consists of four tasks: Tasks 1 and 2 are for the case law information extraction/entailment, and Tasks 3 and 4 are for the statute law information extraction/entailment. Here we explain our methods and evaluation results for Tasks 3 and 4. Task 3 requires the identification of civil law articles relevant to Japan legal bar exam query. For this task, we used TF-IDF and language model-based information retrieval approaches. Task 4 requires a decision on yes/no answer for previously unseen queries given relevant civil law articles. Our approach compares the approximate meanings of queries with relevant articles. Because many statute law and queries consist of more than one paragraph, we need an inter-paragraph entailment method. Our inter-paragraph entailment process exploits an analysis of statute law structure, and negation patterns to predict entailments. Using our heuristic selection of attributes, we perform two experiments which provide the basis for making a decision on the yes/no questions. One experiment uses an SVM model, and the other uses a general heuristic rule. Our experimental evaluation demonstrates the value of our method, and the results show that our method was ranked No. 1 in both of the Tasks 3 and 4 in COLIEE 2019.","llm_keywords":["Textual entailment","question answering","information retrieval","legal AI","TF-IDF","language model","statute law","legal bar exams","SVM model","heuristic rule"],"classifications":["Information Retrieval","Information Extraction","Classification"],"num_cited_by":40,"num_cited_by_title_only":40,"num_pages":7},{"id":"b8b78e456a887b9f6b7642a13440f3d3c24db052c4ed4a4d4e0fa93725072b067687c9bb32d2121f58a5738d5a593dfcb3008dcd410cbb517081a9bddaf912fa","file_path":"legal-nlp-survey-20250328-002/original/Huang_2021_0406.pdf","title":"","llm_title":"Context-Aware Legal Citation Recommendation using Deep Learning","authors":["Zihan Huang","Charles Low","Mengqiu Teng","Hongyi Zhang","Daniel E. Ho","Mark S. Krass","Matthias Grabmair"],"llm_authors":"Zihan Huang, Charles Low, Mengqiu Teng, Hongyi Zhang, Daniel E. Ho, Mark S. Krass, Matthias Grabmair","author_string":"","year":2021,"abstract":"","llm_abstract":"Lawyers and judges spend a large amount of time researching the proper legal authority to cite while drafting decisions. In this paper, we develop a citation recommendation tool that can help improve efficiency in the process of opinion drafting. We train four types of machine learning models, including a citation-list based method (collaborative filtering) and three context-based methods (text similarity, BiLSTM and RoBERTa classifiers). Our experiments show that leveraging local textual context improves recommendation, and that deep neural models achieve decent performance. We show that non-deep text-based methods benefit from access to structured case metadata, but deep models only benefit from such access when predicting from context of insufficient length. We also find that, even after extensive training, RoBERTa does not outperform a recurrent neural model, despite its benefits of pretraining. Our behavior analysis of the RoBERTa model further shows that predictive performance is stable across time and citation classes.","llm_keywords":["legal citation recommendation","deep learning","natural language processing","legal text analysis","machine learning","contextual metadata","collaborative filtering","text similarity","BiLSTM","RoBERTa"],"classifications":["Classification","Information Retrieval"],"num_cited_by":46,"num_cited_by_title_only":46,"num_pages":10},{"id":"9c4cca58ca90ea5baeb15539e4539460ad642f1807c1314d304ddb407630e0ebbc974855b50db06a8bfc8ff66d915ba1364c52520062f6f26421f5e85fea35c7","file_path":"legal-nlp-survey-20250328-002/original/Aumiller_2021_0468.pdf","title":"","llm_title":"Structural Text Segmentation of Legal Documents","authors":["Dennis Aumiller","Satya Almasian","Sebastian Lackner","Michael Gertz"],"llm_authors":"Dennis Aumiller, Satya Almasian, Sebastian Lackner, Michael Gertz","author_string":"","year":2021,"abstract":"","llm_abstract":"The growing complexity of legal cases has lead to an increasing interest in legal information retrieval systems that can effectively satisfy user-specific information needs. However, such downstream systems typically require documents to be properly formatted and segmented, which is often done with relatively simple pre-processing steps, disregarding topical coherence of segments. Systems generally rely on representations of individual sentences or paragraphs, which may lack crucial context, or document-level representations, which are too long for meaningful search results. To address this issue, we propose a segmentation system that can predict topical coherence of sequential text segments spanning several paragraphs, effectively segmenting a document and providing a more balanced representation for downstream applications. We build our model on top of popular transformer networks and formulate structural text segmentation as topical change detection, by performing a series of independent classifications that allow for efficient fine-tuning on task-specific data. We crawl a novel dataset consisting of roughly 74,000 online Terms-of-Service documents, including hierarchical topic annotations, which we use for training. Results show that our proposed system significantly outperforms baselines, and adapts well to structural peculiarities of legal documents. We release both data and trained models to the research community for future work.","llm_keywords":["Legal Documents","Text Segmentation","Information Retrieval","Topical Coherence","Transformer Networks","Topic Change Detection","Document Understanding","Outline Generation","Structural Text Segmentation"],"classifications":["Classification","Information Retrieval","Pre-Processing","Resources"],"num_cited_by":40,"num_cited_by_title_only":40,"num_pages":10},{"id":"a2a75e9075b5d959b052871e838b2f83855d157050088fd4e54a884cdc4de8d19f1f962f09147601499e55c3dcdb609a8cafe5d68b2d119736e2b828b641fc83","file_path":"legal-nlp-survey-20250328-002/original/Mumford_2022_0550.pdf","title":"","llm_title":"Reasoning with Legal Cases: A Hybrid ADF-ML Approach","authors":["Jack Mumford","Katie Atkinson","Trevor Bench-Capon"],"llm_authors":"Jack Mumford, Katie Atkinson, and Trevor Bench-Capon","author_string":"","year":2022,"abstract":"","llm_abstract":"Reasoning with legal cases has long been modelled using symbolic methods. In recent years, the increased availability of legal data together with improved machine learning techniques has led to an explosion of interest in data-driven methods being applied to the problem of predicting outcomes of legal cases. Although encouraging results have been reported, they are unable to justify the outcomes produced in satisfactory legal terms and do not exploit the structure inherent within legal domains; in particular, with respect to the issues and factors relevant to the decision. In this paper we present the technical foundations of a novel hybrid approach to reasoning with legal cases, using Abstract Dialectical Frameworks (ADFs) in conjunction with hierarchical BERT. ADFs are used to represent the legal knowledge of a domain in a structured way to enable justifications and improve performance. The machine learning is targeted at the task of factor ascription; once factors present in a case are ascribed, the outcome follows from reasoning over the ADF. To realise this hybrid approach, we present a new hybrid system to enable factor ascription, envisioned for use in legal domains, such as the European Convention on Human Rights that is used frequently in modelling experiments.","llm_keywords":["Abstract Dialectical Frameworks","Argumentation Frameworks","Reasoning with legal cases","Hybrid machine learning-argumentation"],"classifications":["Classification","Information Extraction"],"num_cited_by":21,"num_cited_by_title_only":21,"num_pages":10},{"id":"780102e558e257a328aac2ef995e9653550ef5114d10191aafc54ab15efcf71dca368cd1425cc5182d501e6e2efb65fcb0026af01fb28ad15d9c41df4f0375a0","file_path":"legal-nlp-survey-20250328-002/original/Nazarenko_2021_0383.pdf","title":"","llm_title":"A Pragmatic Approach to Semantic Annotation for Search of Legal Texts - An Experiment on GDPR","authors":["Adeline Nazarenko","François Levy","Adam Wyner"],"llm_authors":"Adeline NAZARENKO, François LEVY, Adam WYNER","author_string":"","year":2021,"abstract":"","llm_abstract":"Tools must be developed to help draft, consult, and explore textual legal sources. Between statistical information retrieval and the formalization of textual rules for automated legal reasoning, we defend a more pragmatic third way that enriches legal texts with a coarse-grained, interpretation-neutral, semantic annotation layer. The aim is that legal texts can be enriched on a large scale at a reasonable cost, paving the way for new search capabilities that will facilitate mining of legal sources. This new approach is illustrated on a proof-of-concept experiment that consisted in semantically annotating a significant part of the French version of the GDPR. The paper presents the design methodology of the annotation language, a first version of a Core Legal Annotation Language (CLAL), together with its formalization in XML, the gold standard resulting from the annotation of GDPR, and examples of user questions that can be better answered by semantic than by plain text search. This experimentation demonstrates the potential of the proposed approach and provides a basis for further development. All resources developed for that GDPR experiment are language independent and are publicly available.","llm_keywords":["Semantic annotation","GDPR","Legal texts","Information retrieval","Annotation methodology","Semantic search","Core Legal Annotation Language","XML","Legal analysis"],"classifications":["Pre-Processing","Information Retrieval","Resources"],"num_cited_by":11,"num_cited_by_title_only":11,"num_pages":10},{"id":"53be2eb23042b9add49f556f0921bbef4d1a7b52a164a54b0b2443d4f9caf002cd0845b1bbdfddfa5f07db9c8d34cd099b093c807a6d71b8ca1887389a2b0789","file_path":"legal-nlp-survey-20250328-002/original/Ruggeri_2022_0505.pdf","title":"Detecting and explaining unfairness in consumer contracts through memory networks","llm_title":"Detecting and explaining unfairness in consumer contracts through memory networks","authors":["Federico Ruggeri","Francesca Lagioia","Marco Lippi","Paolo Torroni"],"llm_authors":"Federico Ruggeri, Francesca Lagioia, Marco Lippi, Paolo Torroni","author_string":"Federico Ruggeri","year":2021,"abstract":"","llm_abstract":"Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents. However, a shortcoming of data-driven approaches is poor explainability. We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales. We thus consider several configurations of memory-augmented neural networks where rationales are given a special role in the modeling of context knowledge. Our results show that rationales not only contribute to improve the classification accuracy, but are also able to offer meaningful, natural language explanations of otherwise opaque classifier outcomes.","llm_keywords":["Unfair clause detection","Deep learning","Memory networks","Explainability","Legal rationales"],"classifications":["Classification","Information Extraction"],"num_cited_by":38,"num_cited_by_title_only":38,"num_pages":34},{"id":"5b01680023756d6d5955803a9758446f6af34750e15cd0669b2981e7a0b39bd5fcd7cd0baff35b88d0c8735f0fcfc18b21d5d1b1ed0eb10ffe62048dff113610","file_path":"legal-nlp-survey-20250328-002/original/Leone_2019_0245.pdf","title":"","llm_title":"Frequent Use Cases Extraction from Legal Texts in the Data Protection Domain","authors":["Valentina Leone","Luigi Di Caro"],"llm_authors":"Valentina LEONE and Luigi DI CARO","author_string":"","year":2019,"abstract":"","llm_abstract":"Because of the recent entry into force of the General Data Protection Regulation (GDPR), a growing of documents issued by the European Union institutions and authorities often mention and discuss various use cases to be handled to comply with GDPR principles. This contribution addresses the problem of extracting recurrent use cases from legal documents belonging to the data protection domain by exploiting existing Ontology Design Patterns (ODPs). An analysis of ODPs that could be looked for inside data protection related documents is provided. Moreover, a first insight on how Natural Language Processing techniques could be exploited to identify recurrent ODPs from legal texts is presented. Thus, the proposed approach aims to identify standard use cases in the data protection field at EU level to promote the reuse of existing formalisations of knowledge.","llm_keywords":["legal ontologies","ontology design patterns","NLP for legal texts","GDPR","data protection","ontology design","Natural Language Processing","compliance checking","Semantic Web","Linked Data"],"classifications":["Information Extraction","Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":6},{"id":"1d276a105aae6737ee3e71b541249676558c99e975ea197ff956c27e11afa25290240c5da6c2664918cdb0e492a7b36f4b0ecc65422848111b6205c9eeb8bcd8","file_path":"legal-nlp-survey-20250328-002/original/Wang_2022_0503.pdf","title":"","llm_title":"D2GCLF: Document-to-Graph Classifier for Legal Document Classification","authors":["Qiqi Wang","Kaiqi Zhao","Robert Amor","Benjamin Liu","Ruofan Wang"],"llm_authors":"Qiqi Wang, Kaiqi Zhao, Robert Amor, Benjamin Liu, Ruofan Wang","author_string":"","year":2022,"abstract":"","llm_abstract":"Legal document classification is an essential task in law intelligence to automate the labor-intensive law case filing process. Unlike traditional document classification problems, legal documents should be classified by reasons and facts instead of topics. We propose a Document-to-Graph Classifier (D2GCLF), which extracts facts as relations between key participants in the law case and represents a legal document with four relation graphs. Each graph is responsible for capturing different relations between the litigation participants. We further develop a graph attention network on top of the four relation graphs to classify the legal documents. Experiments on a real-world legal document dataset show that D2GCLF outperforms the state-of-the-art methods in terms of accuracy.","llm_keywords":["Legal document classification","Graph classification","Graph attention network","Legal AI","Text classification","Document structure","Legal case filing","Entity relations","Machine learning","Deep learning"],"classifications":["Classification","Information Extraction"],"num_cited_by":8,"num_cited_by_title_only":8,"num_pages":14},{"id":"4ac935dba393a9ea7e2e217c889ede38df4a1397719d0566c18a7de716847afe4b5d9b47454216e8556490e978c708a1d95d8630ba0c8949f419a84d72977421","file_path":"legal-nlp-survey-20250328-002/original/Sangkeettrakarn_2019_0246.pdf","title":"Fuzziness Detection in Thai Law Texts Using Deep Learning","llm_title":"Fuzziness Detection in Thai Law Texts Using Deep Learning","authors":["Chatchawal Sangkeettrakarna","Choochart Haruechaiyasak","Thanaruk Theeramunkong"],"llm_authors":"Chatchawal Sangkeettrakarna, Choochart Haruechaiyasak, Thanaruk Theeramunkong","author_string":"","year":2019,"abstract":"","llm_abstract":"Machine understanding research aims to build machine intelligences. To make a machine understand, precise concepts are necessary. Numerous domains contain vague meanings when making decisions, such as a diagnosis or a legal interpretation. Once an artificial intelligence pretends to be human while dealing with imprecise data, a fuzziness in knowledges must be detected before constructing. This paper presents the methodology to detect a fuzziness in Thai law texts using a deep learning method. The experiments are designed to compare the performances of four well-known text classification methods, namely Decision Tree, Random Forest, Support Vector Machine, and Convolutional Neural Network. The fuzziness in this study refers to an imprecise meaning in law texts which may be ambiguous when interpreted by a machine. We built a labelled corpus from four Thai Law codes namely 1) The Criminal Code 2) The Criminal Procedure Code 3) The Civil and Commercial Code and 4) The Civil Procedure Code. We proposed three conditions to identify the fuzziness, i.e. 1) a decision depends on a judge’s opinion 2) a decision that requires the production of evidence and 3) a decision which refers to other sections. The results of the experiment show that a Convolutional Neural Network significantly outperforms the others with 97.54% accuracy in comparison of all the dataset.","llm_keywords":["fuzziness detection","deep learning","Thai law texts","text classification","convolutional neural network"],"classifications":["Classification","Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":6},{"id":"7d70c525418dd6c7c73e128ced4d454c11cebdb30b1540b2afff8862bf307d4046e6dab24490eddb9057993d28b2b7e1e92aec6df4ba8c52df40b164211383dd","file_path":"legal-nlp-survey-20250328-002/original/Poudyal_2020_0319.pdf","title":"ECHR: Legal Corpus for Argument Mining","llm_title":"ECHR: Legal Corpus for Argument Mining","authors":["Prakash Poudyal","Jaromír Savelka","Aagje Ieven","Marie Francine Moens","Teresa Gonçalves","Paulo Quaresma"],"llm_authors":"Prakash Poudyal, Jaromír Savelka, Aagje Ieven, Marie Francine Moens, Teresa Gonçalves, Paulo Quaresma","author_string":"Prakash Poudyal ; Jaromir Savelka ; Aagje Ieven ; Marie Francine Moens ; Teresa Goncalves ; Paulo Quaresma","year":2020,"abstract":"","llm_abstract":"In this paper, we publicly release an annotated corpus of 42 decisions of the European Court of Human Rights (ECHR). The corpus is annotated in terms of three types of clauses useful in argument mining: premise, conclusion, and non-argument parts of the text. Furthermore, relationships among the premises and conclusions are mapped. We present baselines for three tasks that lead from unstructured texts to structured arguments. The tasks are argument clause recognition, clause relation prediction, and premise/conclusion recognition. Despite a straightforward application of the bidirectional encoders from Transformers (BERT), we obtained very promising results (F1 0.765 on argument recognition, 0.511 on relation prediction, and 0.859/0.628 on premise/conclusion recognition). The results suggest the usefulness of pre-trained language models based on deep neural network architectures in argument mining. Because of the simplicity of the baselines, there is ample space for improvement in future work based on the released corpus.","llm_keywords":["European Court of Human Rights","argumentation","argument mining","BERT","legal corpus"],"classifications":[],"num_cited_by":69,"num_cited_by_title_only":69,"num_pages":9},{"id":"63cb394399f07316107a7b46f8dac9c9bb9d474f01a8b20681f013e7336c85f331267a37363d32fc584edab336ca304335e67cd3082f922af4df6492c636fbfd","file_path":"legal-nlp-survey-20250328-002/original/Stellato_2018_0207.pdf","title":"","llm_title":"Towards the Assessment of Gold-Standard Alignments between Legal Thesauri","authors":["Armando Stellato","Andrea Turbati","Manuel Fiorelli","Tiziano Lorenzetti","Peter Schmitz","Enrico Francesconi","Najeh Hajlaoui","Brahim Batouche"],"llm_authors":"Armando STELLATO, Andrea TURBATI, Manuel FIORELLI, Tiziano LORENZETTI, Peter SCHMITZ, Enrico FRANCESCONI, Najeh HAJLAOUI, Brahim BATOUCHE","author_string":"","year":2018,"abstract":"","llm_abstract":"In this paper we report on the experience gathered in producing two gold-standard alignment datasets between the European Union thesaurus EuroVoc and two other notable resources adopted in legal environments: the thesaurus of the Italian Senate TESEO and the IATE European terminological resource. The realization of these two resources has been performed in the context of the PMKI project, an European Commission action aiming at creating a Public Multilingual Knowledge management Infrastructure to support e-commerce solutions in a multilingual environment. As of the numerous lexical and terminological resources involved in this project, ontology and thesaurus alignment and, as a consequence, the evaluation of automatically generated alignments, play a pivotal role for the success of the project.","llm_keywords":["legal thesauri","gold-standard alignments","semantic interoperability","ontology alignment","multilingual knowledge management","ontology mapping","public multilingual knowledge infrastructure","thesaurus alignment","semantic web","e-commerce solutions"],"classifications":["Resources"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":10},{"id":"b695dc9cef099274fff9207fcd15893fb671714aa2ea4a843e21caab21249d96ac201fbc83f1e9242e4c70edd90095344fdcf43a14429e89cfd38239090d6fc2","file_path":"legal-nlp-survey-20250328-002/original/Lippi_2017_0114.pdf","title":"","llm_title":"Automated Detection of Unfair Clauses in Online Consumer Contracts","authors":["Marco Lippi","Przemyslaw Palka","Giuseppe Contissa","Francesca Lagioia","Hans-Wolfgang Micklitz","Yannis Panagis","Giovanni Sartor","Paolo Torroni"],"llm_authors":"Marco LIPPI, Przemyslaw PALKA, Giuseppe CONTISSA, Francesca LAGIOIA, Hans-Wolfgang MICKLITZ, Yannis PANAGIS, Giovanni SARTOR, and Paolo TORRONI","author_string":"","year":2017,"abstract":"","llm_abstract":"Consumer contracts too often present clauses that are potentially unfair to the subscriber. We present an experimental study where machine learning is employed to automatically detect such potentially unfair clauses in online contracts. Results show that the proposed system could provide a valuable tool for lawyers and consumers alike.","llm_keywords":["Unfair terms detection","Consumer contract","Machine learning","Online contracts","Legal automation"],"classifications":["Classification"],"num_cited_by":32,"num_cited_by_title_only":32,"num_pages":10},{"id":"a3720272df59937eb6b263ce7aade47c2166ae9a6c501c57b9c1b673de1f015392e3101b68e22c027a959dda77c9490a487671fae2166abb56cda80394ecc708","file_path":"legal-nlp-survey-20250328-002/original/Wang_2020_0361.pdf","title":"","llm_title":"Study on Prediction of Legal Judgments Based on the CNN-BiGRU Model","authors":["Chenlu Wang","Xiaoning Jin"],"llm_authors":"Chenlu Wang, Xiaoning Jin","author_string":"Is Your Marriage Reliable? Divorce Analysis with Machine Learning Algorithms","year":2020,"abstract":"","llm_abstract":"As the cases exploded, leading legal judgment prediction becomes a promising application of artificial intelligence techniques in the legal field. The goal of legal judgment prediction is to predict the judgment results based on the facts information of a case. However, the classifier of the traditional method has poor accuracy performance and cost large computational time. The commonly used deep learning models are CNN and RNN. In this paper, CNN-BiGRU was established and analyzed, which combined the good extraction ability of CNN for local feature information and RNN for long-term dependencies information of the text. Compared with the CAIL 2018 dataset, the prediction accuracy of the charges, law articles and the terms of penalty are 94.8%, 93.6%, and 73.4%, respectively. Results showed that CNN-BiGRU has a higher prediction accuracy than CNN or RNN alone and a good training efficiency over baselines. The effectiveness and practicability of this model are validated.","llm_keywords":["artificial intelligence","judgment prediction","deep learning","natural language processing","gate recurrent unit","convolutional neural networks"],"classifications":["Classification","Information Extraction"],"num_cited_by":4,"num_cited_by_title_only":4,"num_pages":6},{"id":"0ff99b93af5fd8a12795971e21125a0613091f581360307821d5f76095a900d066adaf47bb2ec85c807e41a433ecab81b68ef4c205692823d35f3286b3512fd3","file_path":"legal-nlp-survey-20250328-002/original/Aletras_2016_0099.pdf","title":"","llm_title":"Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspective","authors":["Nikolaos Aletras","Dimitrios Tsarapatsanis","Daniel Preoțiuc-Pietro","Vasileios Lampos"],"llm_authors":"Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel Preoţiuc-Pietro, Vasileios Lampos","author_string":"","year":2016,"abstract":"","llm_abstract":"Recent advances in Natural Language Processing and Machine Learning provide us with the tools to build predictive models that can be used to unveil patterns driving judicial decisions. This can be useful, for both lawyers and judges, as an assisting tool to rapidly identify cases and extract patterns which lead to certain decisions. This paper presents the first systematic study on predicting the outcome of cases tried by the European Court of Human Rights based solely on textual content. We formulate a binary classification task where the input of our classifiers is the textual content extracted from a case and the target output is the actual judgment as to whether there has been a violation of an article of the convention of human rights. Textual information is represented using contiguous word sequences, i.e., N-grams, and topics. Our models can predict the court’s decisions with a strong accuracy (79% on average). Our empirical analysis indicates that the formal facts of a case are the most important predictive factor. This is consistent with the theory of legal realism suggesting that judicial decision-making is significantly affected by the stimulus of the facts. We also observe that the topical content of a case is another important feature in this classification task and explore this relationship further by conducting a qualitative analysis.","llm_keywords":["Natural Language Processing","Machine Learning","Judicial decisions","European Court of Human Rights","Text Mining","Legal Science","Artificial Intelligence"],"classifications":["Classification","Information Extraction"],"num_cited_by":1064,"num_cited_by_title_only":1064,"num_pages":19},{"id":"b3d99f44d27fb497f7d9093b90652836c1554df051b47df37486cc7a9425e5733dc58212e476448fc54a8269874456ba59ec10fb49bb8bea55c94e7b3d48dfda","file_path":"legal-nlp-survey-20250328-002/original/Koreeda_2021_0402.pdf","title":"Capturing Logical Structure of Visually Structured Documents with Multimodal Transition Parser","llm_title":"Capturing Logical Structure of Visually Structured Documents with Multimodal Transition Parser","authors":["Yuta Koreeda","Christopher Manning"],"llm_authors":"Yuta Koreeda, Christopher D. Manning","author_string":"Yuta Koreeda ; Christopher Manning","year":2021,"abstract":"","llm_abstract":"While many NLP pipelines assume raw, clean texts, many texts we encounter in the wild, including a vast majority of legal documents, are not so clean, with many of them being visually structured documents (VSDs) such as PDFs. Conventional preprocessing tools for VSDs mainly focused on word segmentation and coarse layout analysis, whereas fine-grained logical structure analysis (such as identifying paragraph boundaries and their hierarchies) of VSDs is underexplored. To that end, we proposed to formulate the task as prediction of transition labels between text fragments that maps the fragments to a tree, and developed a feature-based machine learning system that fuses visual, textual and semantic cues. Our system is easily customizable to different types of VSDs and it significantly outperformed baselines in identifying different structures in VSDs. For example, our system obtained a paragraph boundary detection F1 score of 0.953 which is significantly better than a popular PDF-to-text tool with an F1 score of 0.739.","llm_keywords":["NLP","legal documents","visually structured documents","machine learning","multimodal analysis","logical structure","PDF preprocessing","feature-based system","transition parser"],"classifications":["Pre-Processing","Classification"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":11},{"id":"493595bd02b168d96c79f354ec0183e14e3f3cd097fc6134328a0880bd2d641d3ad22fa2e99943475d9bc8cb377a055f8912a3408999bbfedd9a56edb5d78197","file_path":"legal-nlp-survey-20250328-002/original/Chalkidis_2018_0174.pdf","title":"Deep learning in law: early adaptation and legal word embeddings trained on large corpora","llm_title":"Deep learning in law: early adaptation and legal word embeddings trained on large corpora","authors":["Ilias Chalkidis","Dimitrios Kampas"],"llm_authors":"Ilias Chalkidis, Dimitrios Kampas","author_string":"Ilias Chalkidis","year":2018,"abstract":"","llm_abstract":"Deep Learning has been widely used for tackling challenging natural language processing tasks over the recent years. Similarly, the application of Deep Neural Networks in legal analytics has increased significantly. In this survey, we study the early adaptation of Deep Learning in legal analytics focusing on three main fields; text classification, information extraction, and information retrieval. We focus on the semantic feature representations, a key instrument for the successful application of deep learning in natural language processing. Additionally, we share pre-trained legal word embeddings using the word2vec model over large corpora, comprised legislations from UK, EU, Canada, Australia, USA, and Japan among others.","llm_keywords":["Deep learning","Natural language processing","Legal word vectors","Text classification","Information extraction","Information retrieval"],"classifications":[],"num_cited_by":232,"num_cited_by_title_only":232,"num_pages":28},{"id":"4e8b81f8dc0efa250b52040ba68f14788344f7f9dfdc25c5baaba51ef9f865f1920cd75123938c8fc8a67ba5aa38b2f80f24019eec63ce85d590d9852e5da3cb","file_path":"legal-nlp-survey-20250328-002/original/Almuslim_2022_0523.pdf","title":"Legal Judgment Prediction for Canadian Appeal Cases","llm_title":"Legal Judgment Prediction for Canadian Appeal Cases","authors":["Intisar Almuslim","Diana Inkpen"],"llm_authors":"Intisar Almuslim, Diana Inkpen","author_string":"Intisar Almuslim; Diana Inkpen","year":2022,"abstract":"","llm_abstract":"Law is one of the knowledge domains that are most reliant on textual material. Nowadays, however, it is very difficult and time-consuming for legal professionals to read, understand, and analyze all the available documents, due to the vast volume of case law that is published every day. In this age of legal big data, and with the increased availability of legal text online, many researchers have given more focus to the development of legal intelligent systems and applications. These intelligent systems can provide great services and solve many problems in legal domain. Over the last years, researchers have focused on predicting judicial case outcomes using Natural Language Processing (NLP) and Machine Learning (ML) methods over case documents. Thus, Legal Judgment Prediction (LJP) is the task of automatically predicting the outcome of a court case given only the text of the case. To the best of our knowledge, no prior research with this intention has been conducted in English for appeal courts in Canada, as of 2021. The NLP application to legal judgments, that our proposed methodology focuses on, is to predict the outcomes of cases by looking only at the description of cases written by the court. Because appeal court decisions are often binary, as in accept or reject, the task is defined as a binary classification problem between ’Allow’ and ’Dismiss’. This is the general approach in the literature as well. We employ various classification methods including classical classifiers, Deep Learning (DL) models, and compare their performances. Our best results are obtained using DL models with accuracy values reaching 93.46% and F1-scores reaching 0.92, which are on par with the best results in the literature. Through this study, we hope to establish the basis for future research on the legal system of Canada and offer a baseline for future work.","llm_keywords":["Natural Language Processing","Legal Judgment Prediction","Text Classification","Machine Learning","Deep Learning","Binary Classification","Canadian Appeal Cases"],"classifications":["Classification"],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":6},{"id":"38c6a3cda1cb5d65eed6cf7b7e36d25e759ac4b112a5029e891cd9b6cd9c0b217d2955ca9a854c14f9175a9d2928d9452c9650527a4b5db60c3d868d4d65517f","file_path":"legal-nlp-survey-20250328-002/original/Rajshekhar_2017_0112.pdf","title":"","llm_title":"ANALYTICS OF PATENT CASE RULINGS: EMPIRICAL EVALUATION OF MODELS FOR LEGAL RELEVANCE","authors":["Kripa Rajshekhar","Wlodek Zadrozny","Sri Sneha Varsha Garapati"],"llm_authors":"Kripa Rajshekhar, Wlodek Zadrozny, Sri Sneha Varsha Garapati","author_string":"","year":2017,"abstract":"","llm_abstract":"Recent progress in incorporating word order and semantics to the decades-old, tried-and-tested bag-of-words representation of text meaning has yielded promising results in computational text classification and analysis. This development, and the availability of a large number of legal rulings from the PTAB (Patent Trial and Appeal Board) motivated us to revisit possibilities for practical, computational models of legal relevance - starting with this narrow and approachable niche of jurisprudence. We present results from our analysis and experiments towards this goal using a corpus of approximately 8000 rulings from the PTAB. This work makes three important contributions towards the development of models for legal relevance semantics: (a) Using state-of-art Natural Language Processing (NLP) methods, we characterize the diversity and types of semantic relationships that are implicit in practical judgements of legal relevance at the PTAB (b) We achieve new state-of-art results on practical information retrieval using our customized semantic representations on this corpus (c) We outline promising avenues for future work in the area - including preliminary evidence from human-in-loop interaction, and new forms of text representation developed using input from over a hundred interviews with practitioners in the field. Finally, we argue that PTAB relevance is a practical and realistic baseline for performance measurement - with the desirable property of evaluating NLP improvements against “real world” legal judgement.","llm_keywords":["patent litigation","text analytics","semantic search","data sets","legal relevance","natural language processing","Patent Trial and Appeal Board","jurisprudence"],"classifications":["Information Retrieval","Classification"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":9},{"id":"a9fe3af223dbd3bae0fdf9b7f0a67557e8d1571eea20d2713539bb4ae392d347840fd68bb664c56da400db4dfa26c4b6a0923d66fec298406ad750f679df897c","file_path":"legal-nlp-survey-20250328-002/original/Fawei_2018_0160.pdf","title":"A Methodology for a Criminal Law and Procedure Ontology for Legal Question Answering","llm_title":"A Methodology for a Criminal Law and Procedure Ontology for Legal Question Answering","authors":["Biralatei Fawei","Jeff Z. Pan","Martin Kollingbaum","Adam Z. Wyner"],"llm_authors":"Biralatei Fawei, Jeff Z. Pan, Martin Kollingbaum, Adam Z. Wyner","author_string":"Biralatei Fawei","year":2018,"abstract":"","llm_abstract":"The Internet and the development of the semantic web have created the opportunity to provide structured legal data on the web. However, most legal information is in text. It is difficult to automatically determine the right natural language answer about the law to a given natural language question. One approach is to develop systems of legal ontologies and rules. Our example ontology represents semantic information about USA criminal law and procedure as well as the applicable legal rules. The purpose of the ontology is to provide reasoning support to an legal question answering tool that determines entailment between a pair of texts, one known as the Background information (Bg) and the other Question statement (Q), whether Bg entails Q based on the application of the law. The key contribution of this paper is a clear and well-structured methodology that serves to develop such criminal law ontologies and rules (CLOR).","llm_keywords":["Ontology","Legal rules","Bar examination","Criminal law","Legal question answering"],"classifications":[],"num_cited_by":37,"num_cited_by_title_only":37,"num_pages":17},{"id":"116a1ca55311a5a78adb268d4cb02ac4c3488a317420397e58983afed9670a1e279efa6698de4db5d195776662c609bace71601f9b19447560e8c8d14a87cf01","file_path":"legal-nlp-survey-20250328-002/original/Medvedeva_2021_0399.pdf","title":"","llm_title":"Automatically Identifying Eviction Cases and Outcomes Within Case Law of Dutch Courts of First Instance","authors":["Masha Medvedeva","Thijmen Dam","Martijn Wieling","Michel Vols"],"llm_authors":"Masha Medvedeva, Thijmen Dam, Martijn Wieling, Michel Vols","author_string":"","year":2021,"abstract":"","llm_abstract":"In this paper we attempt to identify eviction judgements within all case law published by Dutch courts in order to automate data collection, previously conducted manually. To do so we performed two experiments. The first focused on identifying judgements related to eviction, while the second focused on identifying the outcome of the cases in the judgements (eviction vs. dismissal of the landlord’s claim). In the process of conducting the experiments for this study, we have created a manually annotated dataset with eviction-related judgements and their outcomes.","llm_keywords":["outcome identification","case law","machine learning","judicial decision","eviction cases","Dutch judiciary"],"classifications":["Classification","Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":10},{"id":"c5d6cbf480f1239bcd8de2ee6fe4ed05773c59088612b61a9b144128627d7e535adb9442b9e6329b029f2a62cb4d74d4727ab61eb236f8bd8e3a5692ce5443ee","file_path":"legal-nlp-survey-20250328-002/original/Tieu_2021_0393.pdf","title":"","llm_title":"A Summary of the ALQAC 2021 Competition","authors":["Nguyen Ha Thanh","Bui Minh Quan","Chau Nguyen","Tung Le","Nguyen Minh Phuong","Dang Tran Binh","Vuong Thi Hai Yen","Teeradaj Racharak","Nguyen Le Minh","Tran Duc Vu","Phan Viet Anh","Nguyen Truong Son","Huy Tien Nguyen","Bhumindr Butr-indr","Peerapon Vateekul","Prachya Boonkwan"],"llm_authors":"Nguyen Ha Thanh, Bui Minh Quan, Chau Nguyen, Tung Le, Nguyen Minh Phuong, Dang Tran Binh, Vuong Thi Hai Yen, Teeradaj Racharak, Nguyen Le Minh, Tran Duc Vu, Phan Viet Anh, Nguyen Truong Son, Huy Tien Nguyen, Bhumindr Butr-indr, Peerapon Vateekul, Prachya Boonkwan","author_string":"","year":2022,"abstract":"","llm_abstract":"We summarize the evaluation of the first Automated Legal Question Answering Competition (ALQAC 2021). The competition this year contains three tasks, which aims at processing the statute law document, which are Legal Text Information Retrieval (Task 1), Legal Text Entailment Prediction (Task 2), and Legal Text Question Answering (Task 3). The final goal of these tasks is to build a system that can automatically determine whether a particular statement is lawful. There is no limit to the approaches of the participating teams. This year, there are 5 teams participating in Task 1, 6 teams participating in Task 2, and 5 teams participating in Task 3. There are in total 36 runs submitted to the organizer. In this paper, we summarize each team’s approaches, official results, and some discussion about the competition. Only results of the teams who successfully submit their approach description paper are reported in this paper.","llm_keywords":["ALQAC 2021","legal text processing","information retrieval","entailment prediction","question answering","statute law","Vietnamese dataset","Thai dataset","natural language processing","competition"],"classifications":["Information Retrieval","Classification"],"num_cited_by":8,"num_cited_by_title_only":13,"num_pages":5},{"id":"8b0ad4f92592d6b2b4c3df9228ceb472a075076a5c4b461c1da26a05928303373ebb82a68426953922dbf4bf095064fc950c3c72b4e0b52d17c953ea005473ce","file_path":"legal-nlp-survey-20250328-002/original/Rabelo_2019_0231.pdf","title":"215_Rabelo.pdf","llm_title":"Combining Similarity and Transformer Methods for Case Law Entailment","authors":["Juliano Rabelo","Mi-Young Kim","Randy Goebel"],"llm_authors":"Juliano Rabelo, Mi-Young Kim, Randy Goebel","author_string":"","year":2019,"abstract":"","llm_abstract":"We tackle the complex problem of determining entailment relationships between case law documents, one of the tasks in the Competition on Legal Information Extraction and Entailment (COLIEE). With input of an entailed fragment from a case coupled with a candidate entailing paragraph from a noticed case, our approach relies on four main components: (1) extraction of similarity measures between the two pieces of text; (2) application of a transformer-based technique on the input text; (3) applying a threshold-based classifier; and (4) post-processing the results considering the a priori probability determined by the data distribution on the training samples and combining the results of (1) and (2). Our experiments achieved an F-score of 0.70 on the official COLIEE test dataset, ranking first among all competitors for that task in the 2019 competition.","llm_keywords":["legal textual entailment","document similarity","binary classification","imbalanced datasets","information extraction","case law entailment","deep learning","BERT framework","transformer methods","COLIEE"],"classifications":["Classification"],"num_cited_by":41,"num_cited_by_title_only":41,"num_pages":7},{"id":"ce0194a9b92706fcc8127dba15a34c1ac987f51e9934c22e370ca8e61872a342a5f78e051910e207f337ee7d1a79832a27a7151092f3cb2e7943696012ff51ee","file_path":"legal-nlp-survey-20250328-002/original/Nakamura_2013_0011.pdf","title":"lvi2013mnakamur_cameraready","llm_title":"Extraction of Legal Definitions from a Japanese Statutory Corpus – Toward Construction of a Legal Term Ontology","authors":["Makoto Nakamura","Yasuhiro Ogawa","Katsuhiko Toyama"],"llm_authors":"Makoto Nakamura, Yasuhiro Ogawa, Katsuhiko Toyama","author_string":"mnakamur","year":2013,"abstract":"","llm_abstract":"We have been faced with several problems in the process of constructing the Japanese Law Translation Database, one of which is disunity for word selection. A legal terminology is useful for the unification of translation. Our purpose in this paper is to provide legal definitions and their explanations, which include semantic relations with other legal terms. We propose an automatic method for extracting them from a Japanese statutory corpus. Our experimental result shows that over 14,000 legal terms and their explanations in total were extracted with high precision, and the recall rate became better than the previous work. Since some definitions are explained with other legal terms, these relations would help to construct a legal term ontology.","llm_keywords":["terminology","Japanese statutes","automatic extraction","legal definitions","legal term ontology"],"classifications":["Information Extraction","Resources"],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":12},{"id":"bc9df2d04663d1db27ee095f2f56e0a3e250878c7bb9acd3c99a93324a1f00f057022402a9b11d1581a2d3d2b613b8a5a71e4653915cd0953a5e19925d09d52a","file_path":"legal-nlp-survey-20250328-002/original/Lam_2020_0367.pdf","title":"The Gap between Deep Learning and Law: Predicting Employment Notice","llm_title":"The Gap between Deep Learning and Law: Predicting Employment Notice","authors":["Jason T. Lam","David Liang","Samuel Dahan","Farhana Zulkernine"],"llm_authors":"Jason T. Lam, David Liang, Samuel Dahan, Farhana Zulkernine","author_string":"Jason T. Lam, David Liang, Samuel Dahan, and Farhana Zulkernine","year":2020,"abstract":"","llm_abstract":"This study aims to determine whether Natural Language Processing with deep learning models can shed new light on the Canadian calculation system for employment notice. In particular, we investigate whether deep learning can enhance the predictability of notice period, that is, whether it is possible to predict notice period with high accuracy. A major challenge with the classification of reasonable notice is the inconsistency of the case law. As argued by the Ontario Court of Appeal, the process of determining reasonable notice is 'more art than science'. In a previous study, we assessed the predictability of reasonable notice periods by applying statistical machine learning to a hand-annotated dataset of 850 cases. Building on this past study, this paper utilizes state-of-the-art deep learning models on a free-text summary of cases. We further experiment with a variety of domain adaptations of state-of-the-art pretrained BERT-esque models. Our results appear to show that the domain adaptations of BERT-esque models negatively affected performance. Our best performing model was an out-of-the-box RoBERTa base model which achieved a 69% accuracy using a +/-2 prediction window.","llm_keywords":["Deep Learning","Employment Law","Reasonable Notice","Employment Termination","Legal Analytics","Predictive Analytics","Consistency"],"classifications":["Classification","Resources"],"num_cited_by":15,"num_cited_by_title_only":15,"num_pages":5},{"id":"f9b02a374256174fe6a562a0f420f6bdf0752ac36bf8d31e32ff34b469de215730e7842a258d3be56b4244c5b9d229cecb7e72816449890963d0b8e065d3bade","file_path":"legal-nlp-survey-20250328-002/original/Montelongo_2020_0364.pdf","title":"Tasks performed in the legal domain through Deep Learning: A bibliometric review (1987&#x2013;2020)","llm_title":"Tasks performed in the legal domain through Deep Learning: A bibliometric review (1987-2020)","authors":["Alfredo Montelongo","Joao Luiz Becker"],"llm_authors":"Alfredo Montelongo, Joao Luiz Becker","author_string":"","year":2020,"abstract":"","llm_abstract":"Deep Learning (DL) has become the state-of-the-art method for Natural Language Processing (NLP). During the last 5 years DL became the primary Artificial Intelligence (AI) method in the legal domain. In this work we provide a systematic bibliometric review of the publications that have utilized DL as the primary methodology. In particular we analyzed the performed objectives (performed tasks), the corpus utilized to train the models and promising areas of research. The sample includes a total of 137 works published between 1987 and 2020. This analysis starts with the first DL models (formerly Neural Networks) in the legal domain until the latest articles in the ongoing year. Our results show an increment of 300% on the total number of publications during the last 5 years, mainly on information extraction and classification tasks. Moreover, classification is the category with most publications with 39% of the total sample. Finally, we have identified that summarization and text generation as promising areas of research. These findings show that DL in the legal domain is currently in a growing stage, and hence it will be a promising topic of research in the coming years.","llm_keywords":["Legal Corpus","Deep Learning","Neural Networks","Natural Language Processing","Artificial Intelligence","Legal domain","Classification","Information extraction","Summarization","Text generation"],"classifications":["Classification","Information Extraction","Machine Summarization","Text Generation","Resources"],"num_cited_by":5,"num_cited_by_title_only":5,"num_pages":7},{"id":"7f3666fde0f891f1f35cb4255e38f86d31f049892a3d25019a5f84ff8c8082b2558b641f1b374b08a54f4f4def624e55329e3438d75145dcb120b337c8800c19","file_path":"legal-nlp-survey-20250328-002/original/AL-Qurishi_2022_0580.pdf","title":"","llm_title":"AraLegal-BERT: A pretrained language model for Arabic Legal text","authors":["Muhammad AL-Qurishi","Sarah AlQaseemi","Riad Soussi"],"llm_authors":"Muhammad AL-Qurishi, Sarah AlQaseemi and Riad Soussi","author_string":"","year":2022,"abstract":"","llm_abstract":"The effectiveness of the BERT model on multiple linguistic tasks has been well documented. On the other hand, its potentials for narrow and specific domains such as Legal, have not been fully explored. In this paper, we examine how BERT can be used in the Arabic legal domain and try customizing this language model for several downstream tasks using several different domain-relevant training and testing datasets to train BERT from scratch. We introduce the AraLegal-BERT, a bidirectional encoder Transformer-based model that have been thoroughly tested and carefully optimized with the goal to amplify the impact of NLP-driven solution concerning jurisprudence, legal documents, and legal practice. We fine-tuned AraLegal-BERT and evaluated it against three BERT variations for Arabic language in three natural languages understanding (NLU) tasks. The results show that the base version of AraLegal-BERT achieve better accuracy than the general and original BERT over the Legal text.","llm_keywords":["AraLegal-BERT","Arabic legal text","BERT","language model","NLP","jurisprudence","legal documents","Transformer-based model","natural language understanding"],"classifications":["Resources","Classification"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":7},{"id":"f3afd235ba8a78f1bf57e702aef8b93f91b145fca5ab6c9eb1d3522383cb9fef0669b98b57e3f9c3becdd1f2c92643d8568700b02e93833303f94e61e147b246","file_path":"legal-nlp-survey-20250328-002/original/Rehm_2019_0236.pdf","title":"Developing and Orchestrating a Portfolio of Natural Legal Language Processing and Document Curation Services","llm_title":"Developing and Orchestrating a Portfolio of Natural Legal Language Processing and Document Curation Services","authors":["Georg Rehm","Julian Moreno-Schneider","Jorge Gracia","Artem Revenko","Victor Mireles","Maria Khvalchik","Ilan Kernerman","Andis Lagzdins","Marcis Pinnis","Arturs Vasilevskis","Elena Leitner","Jan Milde","Pia Weißenhorn"],"llm_authors":"Georg Rehm, Julian Moreno-Schneider, Jorge Gracia, Artem Revenko, Victor Mireles, Maria Khvalchik, Ilan Kernerman, Andis Lagzdins, Marcis Pinnis, Arturs Vasilevskis, Elena Leitner, Jan Milde, Pia Weißenhorn","author_string":"Georg Rehm ; Julian Moreno-Schneider ; Jorge Gracia ; Artem Revenko ; Victor Mireles ; Maria Khvalchik ; Ilan Kernerman ; Andis Lagzdins ; Marcis Pinnis ; Artus Vasilevskis ; Elena Leitner ; Jan Milde ; Pia Weißenhorn","year":2019,"abstract":"","llm_abstract":"We present a portfolio of natural legal language processing and document curation services currently under development in a collaborative European project. First, we give an overview of the project and the different use cases, while, in the main part of the article, we focus upon the 13 different processing services that are being deployed in different prototype applications using a flexible and scalable microservices architecture. Their orchestration is operationalised using a content and document curation workflow manager.","llm_keywords":["Natural Legal Language Processing","Document Curation","Microservices Architecture","Legal Knowledge Graph","Compliance","Machine Translation","Named Entity Recognition","Text Summarisation","Question Answering","Semantic Similarity"],"classifications":[],"num_cited_by":12,"num_cited_by_title_only":12,"num_pages":12},{"id":"6a26e763d77221d01a7789f70534951be4ef9a20e332cdfe01862ebe0b901e109b1a22b52ad6e1087079ba4c7937ab7f97dfbbd9ab0069a48da36568c51c2b09","file_path":"legal-nlp-survey-20250328-002/original/Edwards_2015_0049.pdf","title":"CSUR4801-15","llm_title":"A Systematic Survey of Online Data Mining Technology Intended for Law Enforcement","authors":["Matthew Edwards","Awais Rashid","Paul Rayson"],"llm_authors":"Matthew Edwards, Awais Rashid, and Paul Rayson","author_string":"","year":2015,"abstract":"","llm_abstract":"","llm_keywords":["systematic survey","online data mining","law enforcement","cybercrime","surveillance","privacy","state surveillance","data-mining techniques"],"classifications":[],"num_cited_by":61,"num_cited_by_title_only":61,"num_pages":54},{"id":"e9e3a4f638f5730f49565ca365ee489d0cf62747e5dd014d88f13c2b32a4def1e8929d2f5249afa5b404f37aa07db31f1afe2a6d9826c863624c08b3572af727","file_path":"legal-nlp-survey-20250328-002/original/Araujo_2020_0376.pdf","title":"VICTOR: a Dataset for Brazilian Legal Documents Classification","llm_title":"VICTOR: a dataset for Brazilian legal documents classification","authors":["Pedro Henrique Luz de Araujo","Teofilo Emidio de Campos","Fabricio Ataides Braz","Nilton Correia da Silva"],"llm_authors":"Pedro H. Luz de Araujo, Teofilo E. de Campos, Fabricio A. Braz, Nilton C. da Silva","author_string":"Pedro Henrique Luz de Araujo ; Teófilo Emídio de Campos ; Fabricio Ataides Braz ; Nilton Correia da Silva","year":2020,"abstract":"","llm_abstract":"This paper describes VICTOR, a novel dataset built from Brazil’s Supreme Court digitalized legal documents, composed of more than 45 thousand appeals, which includes roughly 692 thousand documents—about 4.6 million pages. The dataset contains labeled text data and supports two types of tasks: document type classification; and theme assignment, a multilabel problem. We present baseline results using bag-of-words models, convolutional neural networks, recurrent neural networks and boosting algorithms. We also experiment using linear-chain Conditional Random Fields to leverage the sequential nature of the lawsuits, which we find to lead to improvements on document type classification. Finally we compare a theme classification approach where we use domain knowledge to filter out the less informative document pages to the default one where we use all pages. Contrary to the Court experts’ expectations, we find that using all available data is the better method. We make the dataset available in three versions of different sizes and contents to encourage explorations of better models and techniques.","llm_keywords":["text classification","legal domain","language resources","dataset","machine learning","natural language processing","document type classification","multilabel classification","Brazilian legal documents"],"classifications":["Resources","Classification"],"num_cited_by":86,"num_cited_by_title_only":86,"num_pages":10},{"id":"e1d97fc56bba0ae2a7326cc898fa0cf49b481edc22e06567fbc9d89889850c758e8e9fadf9b05d5e08a1ee93188e378f5f3c203beb7e0b52aee447f1eeb1515a","file_path":"legal-nlp-survey-20250328-002/original/Morimoto_2017_0136.pdf","title":"","llm_title":"Legal Question Answering System using Neural Attention","authors":["Ayaka Morimoto","Daiki Kubo","Motoki Sato","Hiroyuki Shindo","Yuji Matsumoto"],"llm_authors":"Ayaka Morimoto, Daiki Kubo, Motoki Sato, Hiroyuki Shindo, and Yuji Matsumoto","author_string":"","year":2017,"abstract":"","llm_abstract":"This year’s COLIEE has two tasks called phases 1 and 2. The phase 1 needs to find the relevant article given a query t2, and the phase 2 needs to answer whether the given query t2 is yes or no according to Japan civil law articles. This paper presents our proposals for the phase 2 task. Two methods are presented. The first goes along the standard method taken by many authors, such that the relevant article t1 is selected by the similarity to the query t2 at the requirement (condition) and the effect (conclusion) descriptions of the articles. The second is our new proposal, in which Neural Networks with attention mechanism are applied to all the civil law articles in deciding the truthness of the query t2. This method takes into account all the articles by properly calculating their weighted sum.","llm_keywords":["Legal Information Extraction","Neural Attention","COLIEE 2017","Textual Entailment","Civil Law Articles","Word Representation","Neural Networks"],"classifications":["Information Retrieval","Classification"],"num_cited_by":24,"num_cited_by_title_only":24,"num_pages":11},{"id":"a27c87cd88bdef6b54cd584ccbf4f31f8f797e1586681b5b6ef70413109385030180d64078fa8c87b19f7f067cbc5dc4565be0f4df42c2269eb4f385c60231b5","file_path":"legal-nlp-survey-20250328-002/original/Winter_2018_0175.pdf","title":"Untitled-3","llm_title":"Detecting Constraints and Their Relations from Regulatory Documents Using NLP Techniques","authors":["Karolin Winter","Stefanie Rinderle-Ma"],"llm_authors":"Karolin Winter, Stefanie Rinderle-Ma","author_string":"0002624","year":2021,"abstract":"","llm_abstract":"Extracting constraints and process models from natural language text is an ongoing challenge. While the focus of current research is merely on the extraction itself, this paper presents a three step approach to group constraints as well as to detect and display relations between constraints in order to ease their implementation. For this, the approach uses NLP techniques to extract sentences containing constraints, group them by, e.g., stakeholders or topics, and detect redundant, subsuming, and conflicting pairs of constraints. These relations are displayed using network maps. The approach is prototypically implemented and evaluated based on regulatory documents from the financial sector as well as expert interviews.","llm_keywords":["NLP","regulatory documents","constraints detection","text mining","process models","compliance","requirement extraction","network maps"],"classifications":["Information Extraction"],"num_cited_by":12,"num_cited_by_title_only":38,"num_pages":19},{"id":"fc2fb4419cdebe7ef2166b3d79a073eb771785f3e07873ad70078210fb748d715fec01c5fb0f3705b94fb92b06f9b9a3d3933e402f50eadbcbe0e96601873cab","file_path":"legal-nlp-survey-20250328-002/original/Lupu_2017_0130.pdf","title":"Information retrieval, machine learning, and Natural Language Processing for intellectual property information","llm_title":"Information retrieval, machine learning, and Natural Language Processing for intellectual property information","authors":["Mihai Lupu"],"llm_authors":"","author_string":"Mihai Lupu","year":2017,"abstract":"","llm_abstract":"Readers of this journal are well aware that automation technology has played a significant role in searching for patent information and, as artificial intelligence is once again (after the first, 1960s, and second, 1980s, golden eras of AI) a trending topic at both academic and industry conferences, the editorial team of this journal would like to encourage contributions that cover any aspect of automation as applied to intellectual property information. As a new Associate Editor of World Patent Information, I take the opportunity to advertise the availability of the editorial team to submissions from computer science teams, in addition to the existing contributions from the IP community. By way of introduction, I have taken the liberty to provide an extremely brief overview of efforts and contributions that the computer science community has made to the field of intellectual property. This summary focuses on patents, but that is not to say that trademarks or other forms of intellectual property have not triggered the interest of computer scientists. In fact, to call this summary short is already giving it too much credit. It is but a seed, upon which I hope that a forest of contributions and publications from my fellow computer scientists will grow.","llm_keywords":["Patent information","Machine learning","Information retrieval","Natural Language Processing","Automation technology","Intellectual property"],"classifications":[],"num_cited_by":34,"num_cited_by_title_only":34,"num_pages":3},{"id":"75871f9a34665c0191a028cbec5daa2a4d1b20ce7206f50c04cfa8ac00bf2a05f2cf4113d2e946de58d42788a63ff15bb2f5a5737a92a791186b03398efb02cc","file_path":"legal-nlp-survey-20250328-002/original/Yang_2020_0346.pdf","title":"Leniency to those who confess? Predicting the Legal Judgement via Multi-Modal Analysis","llm_title":"Leniency to those who confess? Predicting the Legal Judgement via Multi-Modal Analysis","authors":["Liang Yang","Jingjie Zeng","Tao Peng","Xi Luo","Jinghui Zhang","Hongfei Lin"],"llm_authors":"Liang Yang, Jingjie Zeng, Tao Peng, Xi Luo, Jinghui Zhang, Hongfei Lin","author_string":"Liang Yang, Jingjie Zeng, Tao Peng, Xi Luo, Jinghui Zhang, and Hongfei Lin","year":2020,"abstract":"","llm_abstract":"The Legal Judgement Prediction (LJP) is now under the spotlight. And it usually consists of multiple sub-tasks, such as penalty prediction (fine and imprisonment) and the prediction of articles of law. For penalty prediction, they are often closely related to the trial process, especially the attitude analysis of criminal suspects, which will influence the judgment of the presiding judge to some extent. In this paper, we firstly construct a multi-modal dataset with 517 cases of intentional assault, which contains trial information as well as the attitude of the suspect. Then, we explore the relationship between suspect‘s attitude and term of imprisonment. Finally, we use the proposed multi-modal model to predict the suspect’s attitude, and compare it with several strong baselines. Our experimental results show that the attitude of the criminal suspect is closely related to the penalty prediction, which provides a new perspective for LJP.","llm_keywords":["Legal Judgement Prediction","Multi-Modal Analysis","Attitude Prediction","Penalty Prediction","Natural Language Processing","Trial Process","Criminal Suspect","Imprisonment","Legal Consulting","Judgment Result"],"classifications":["Classification"],"num_cited_by":3,"num_cited_by_title_only":3,"num_pages":5},{"id":"5d4a0291abbf26076b9920558d2c60981c188830ecc3656b50c35eb996c31167c2ac5db93b607d1ad823af445791712b40ab3e37df4245753f157db8052af27d","file_path":"legal-nlp-survey-20250328-002/original/Lippi_2019_0230.pdf","title":"CLAUDETTE: an automated detector of potentially unfair clauses in online terms of service","llm_title":"CLAUDETTE: an automated detector of potentially unfair clauses in online terms of service","authors":["Marco Lippi","Przemysław Pałka","Giuseppe Contissa","Francesca Lagioia","Hans-Wolfgang Micklitz","Giovanni Sartor","Paolo Torroni"],"llm_authors":"Marco Lippi, Przemysław Pałka, Giuseppe Contissa, Francesca Lagioia, Hans-Wolfgang Micklitz, Giovanni Sartor, Paolo Torroni","author_string":"Marco Lippi","year":2019,"abstract":"","llm_abstract":"Terms of service of on-line platforms too often contain clauses that are potentially unfair to the consumer. We present an experimental study where machine learning is employed to automatically detect such potentially unfair clauses. Results show that the proposed system could provide a valuable tool for lawyers and consumers alike.","llm_keywords":["Machine learning","Terms of service","Potentially unfair clauses","Natural language processing","Sentence classification","Consumer protection","Automated detection"],"classifications":["Classification"],"num_cited_by":228,"num_cited_by_title_only":228,"num_pages":23},{"id":"3fd46ab9f1f44da3ce653f223bbd981cb71e80a98e3ef23aa69ae3127600af280aca9651bb19ff37f02c0b71614c987f9602940538e3416e7914986a1f594384","file_path":"legal-nlp-survey-20250328-002/original/Berdyugina_2020_0360.pdf","title":"Setting up Context-Sensitive Real-Time Contradiction Matrix of a Given Field Using Unstructured Texts of Patent Contents and Natural Language Processing","llm_title":"Setting Up Context-Sensitive Real-Time Contradiction Matrix of a Given Field Using Unstructured Texts of Patent Contents and Natural Language Processing","authors":["Daria Berdyugina","Denis Cavallucci"],"llm_authors":"Daria Berdyugina and Denis Cavallucci","author_string":"Daria Berdyugina","year":2020,"abstract":"","llm_abstract":"It is well known that Altshuller matrix is the most frequently used tool by TRIZ practitioners. While experts often turn away from it in favor of more recent (and reputedly more effective) tools such as Vepoles and ARIZ85C, it is clear that beginners prefer the matrix because of its simplicity. Nevertheless, two sensitive phases in its use call it into question. The association of the user’s specific problem with one of the 39 generic parameters that listed in matrix and the interpretation that can be made of the inventive principles proposed to users. We have developed an approach based on Natural Language Processing to process a specific corpus of patents corresponding to a given technical field in real time. This leads to a new approach developed in this article to propose to users a new matrix for each study but which considers the vocabulary of a given domain to describe the oppositions between parameters. Such a matrix could constitute a state of the art in form of contradictions of the field being explored, which we believe will ease its use upstream of inventive studies processes in order to target the resolution of key and up-to-date contradictions of the same field.","llm_keywords":["Altshuller matrix","Automatic extraction","NLP","TRIZ","Contradiction matrix","Patent analysis","Natural Language Processing","Inventive Design Method","Topic mapping","Semantic distribution"],"classifications":["Text Generation","Information Extraction","Classification"],"num_cited_by":9,"num_cited_by_title_only":9,"num_pages":10},{"id":"f5d20ba091e5e0b3bb0787469a34d7e403db5d4c1772b4089642f93118bc46a557b1feeceaf6a963ee2862c4562b8c96a2b0520abcc5f60d7d530411ed89986a","file_path":"legal-nlp-survey-20250328-002/original/Smywinski-Pohl_2021_0397.pdf","title":"","llm_title":"Automatic Extraction of Amendments from Polish Statutory Law","authors":["Aleksander Smywiński-Pohl","Mateusz Piech","Zbigniew Kaleta","Krzysztof Wróbel"],"llm_authors":"Aleksander Smywiński-Pohl, Mateusz Piech, Zbigniew Kaleta, Krzysztof Wróbel","author_string":"","year":2021,"abstract":"","llm_abstract":"The article discusses the problem of automatic detection of amendments found in the Polish statutory law. We treat the problem as a token-classification task and we introduce a scheme constructed by analysis of more than 200 amending bills. We apply recent neural architectures such as BERT and BiRNN to the task of token classification. The achieved results of all models are very high as micro average F1 score ranges from 96.3% to 98.2% for BiRNN. The presented solution is a first step towards fully automatic structuring and application of amendments in the Polish statutory law.","llm_keywords":["amendment extraction","information extraction","named entity recognition","legal information system","Polish statutory law"],"classifications":["Classification"],"num_cited_by":2,"num_cited_by_title_only":2,"num_pages":5},{"id":"ebde75809f4936e2b82c52cea3f635ab64d5f7f746c9adfafd697c0ad6c27e21806361ae706cc7cc545d745a402be4c0e8f8c64202c720a0a32153e306a755ad","file_path":"legal-nlp-survey-20250328-002/original/Guo_2019_0278.pdf","title":"","llm_title":"RnRTD: Intelligent Approach Based on the Relationship-Driven Neural Network and Restricted Tensor Decomposition for Multiple Accusation Judgment in Legal Cases","authors":["Xiaoding Guo","Hongli Zhang","Lin Ye","Shang Li"],"llm_authors":"Xiaoding Guo, Hongli Zhang, Lin Ye, Shang Li","author_string":"","year":2019,"abstract":"","llm_abstract":"","llm_keywords":["intelligent judgment","legal cases","big data","artificial intelligence","multiple accusations","relationship-driven recurrent neural network","restricted tensor decomposition","classification","prediction","accuracy"],"classifications":[],"num_cited_by":6,"num_cited_by_title_only":6,"num_pages":19},{"id":"d4e08f20d180053c0f20d08f4b947bd77c333ae49d69c78bcbc4161365c5d964c05403626203d2b9f60614dd8c83192d87ccabff4f247d43092fd80bdb970e5f","file_path":"legal-nlp-survey-20250328-002/original/Deroy_2021_0385.pdf","title":"","llm_title":"An Analytical Study of Algorithmic and Expert Summaries of Legal Cases","authors":["Aniket Deroy","Paheli Bhattacharya","Kripabandhu Ghosh","Saptarshi Ghosh"],"llm_authors":"Aniket Deroy, Paheli Bhattacharya, Kripabandhu Ghosh, Saptarshi Ghosh","author_string":"","year":2021,"abstract":"","llm_abstract":"Automatic summarization of legal case documents is an important and challenging problem, where algorithms attempt to generate summaries that match well with expert-generated summaries. This work takes the first step in analyzing expert-generated summaries and algorithmic summaries of legal case documents. We try to uncover how law experts write summaries for a legal document, how various generic as well as domain-specific extractive algorithms generate summaries, and how the expert summaries vary from the algorithmic summaries. We also analyze which important sentences of a legal case document are missed by most algorithms while generating summaries, in terms of the rhetorical roles of the sentences and the positions of the sentences in the legal document.","llm_keywords":["Case document summarization","extractive summarization","rhetorical roles","lead bias","legal documents","algorithmic summaries","expert-generated summaries","ROUGE scores","legal domain","position of sentences"],"classifications":["Machine Summarization"],"num_cited_by":22,"num_cited_by_title_only":22,"num_pages":10},{"id":"40bc0a2e2046239bf168fb0de97af70333edab97fcd1f00e8d3ae62aaac7a8c9576c102bdde3ed66ef635b5ac745fdb6d094828dd30d634c0fc62c44941b3d58","file_path":"legal-nlp-survey-20250328-002/original/Valvoda_2018_0208.pdf","title":"","llm_title":"Using Agreement Statements to Identify","authors":["Josef Valvoda","Oliver Ray","Ken Satoh"],"llm_authors":"Josef VALVODA, Oliver RAY, Ken SATOH","author_string":"","year":2018,"abstract":"","llm_abstract":"This paper is concerned with the task of finding majority opinion (MO) in UK House of Lords (UKHL) case law by analysing agreement statements (AS) that explicitly express the appointed judges’ acceptance of each other’s reasoning. We introduce a corpus of 300 UKHL cases in which the relevant AS and MO have been annotated by three legal experts; and we introduce an AI system that automatically identifies this AS and MO with a performance comparable to humans.","llm_keywords":["Agreement Statements","Majority Opinion","UK House of Lords","AI system","case law","legal corpus","natural language processing"],"classifications":["Classification","Information Extraction","Resources"],"num_cited_by":3,"num_cited_by_title_only":8,"num_pages":10},{"id":"43220105480b930f3a085655575b57af87e5248335eef3748e330358a09eaa21c428f034efc9ef79da3854e526072d61edf20e95ebc9746ba66ba802ac7472a5","file_path":"legal-nlp-survey-20250328-002/original/de-Vargas-Feijó_2019_0286.pdf","title":"Summarizing Legal Rulings: Comparative Experiments","llm_title":"Summarizing Legal Rulings: Comparative Experiments","authors":["Diego de Vargas Feijo","Viviane Pereira Moreira"],"llm_authors":"Diego de Vargas Feijo, Viviane Pereira Moreira","author_string":"Diego Feijo ; Viviane Moreira","year":2019,"abstract":"","llm_abstract":"In the context of text summarization, texts in the legal domain have peculiarities related to their length and to their specialized vocabulary. Recent neural network-based approaches can achieve high-quality scores for text summarization. However, these approaches have been used mostly for generating very short abstracts for news articles. Thus, their applicability to the legal domain remains an open issue. In this work, we experimented with ten extractive and four abstractive models in a real dataset of legal rulings. These models were compared with an extractive baseline based on heuristics to select the most relevant parts of the text. Our results show that abstractive approaches significantly outperform extractive methods in terms of ROUGE scores.","llm_keywords":["text summarization","legal texts","extractive methods","abstractive methods","neural networks","ROUGE scores","Brazilian Supreme Court","dataset","language models","legal domain"],"classifications":["Machine Summarization"],"num_cited_by":18,"num_cited_by_title_only":18,"num_pages":10},{"id":"827187b22d5ef2c6bad8f91dcd5ed1db0ef59e315eef01f64cea47a6fff508cf4dcee24359510285db83dc149ec877e83b2b1de7ef8b14cf6d8afcb68aacee9b","file_path":"legal-nlp-survey-20250328-002/original/Adedjouma_2014_0030.pdf","title":"","llm_title":"Automated Detection and Resolution of Legal Cross References: Approach and A Study of Luxembourg’s Legislation","authors":["Morayo Adedjouma","Mehrdad Sabetzadeh","Lionel Briand"],"llm_authors":"Morayo Adedjouma, Mehrdad Sabetzadeh, Lionel Briand","author_string":"","year":2014,"abstract":"","llm_abstract":"When identifying and elaborating compliance requirements, analysts often need to follow the cross references in the underlying legal texts and consider the additional information in the cited provisions. To enable easier navigation and handling of cross references, automation is necessary for recognizing the natural language patterns used in cross reference expressions (cross reference detection), and for interpreting these expressions and linking them to the target provisions (cross reference resolution). Numerous approaches have been developed over the years to automate the detection and resolution of cross references in legal texts; however, certain facets, e.g., the natural language patterns used in cross references, remain under-explored. Salient gaps also remain towards a systematic understanding of the cross reference resolution process. In this paper, we propose a flexible solution for automated detection and resolution of cross references in legal texts, aimed at addressing the observed gaps. We ground our work on Luxembourg’s legislative texts, both for studying the natural language patterns in cross reference expressions and for evaluating the effectiveness of our solution.","llm_keywords":["Legal Compliance","Cross References","Natural Language Processing","Detection","Resolution","Legislation","Automation","Luxembourg","Legal Texts"],"classifications":["Information Extraction"],"num_cited_by":33,"num_cited_by_title_only":33,"num_pages":11},{"id":"5e3730597bfdb23428d9186d8b9baa7cdb591cd636123648ac71ebb6235f9e64a1289e3617a471bc56ff9e1ad038e0d215e0849b270a3eab49ed94198051a94b","file_path":"legal-nlp-survey-20250328-002/original/Grabmair_2017_0150.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"Predicting Trade Secret Case Outcomes using Argument Schemes and Learned Quantitative Value Effect Tradeoffs","authors":["Matthias Grabmair"],"llm_authors":"Matthias Grabmair","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"This paper presents the Value Judgment Formalism and its experimental implementation in the VJAP system, which is capable of arguing about, and predicting outcomes of, a set of trade secret misappropriation cases. VJAP creates an argument graph for each case using argument schemes and a representation of values underlying trade secret law and effects of facts on these values. It balances effects on values in each case and analogizes it to tradeoffs in precedents. It predicts case outcomes using a confidence measure computed from the graph and generates textual legal arguments justifying its predictions. The confidence propagation uses quantitative weights learned from past cases using an iterative optimization method. Prediction performance on a limited dataset is competitive with common machine learning models. The results and VJAP’s behavior are discussed in detail.","llm_keywords":["Artificial Intelligence & law","Case-based Reasoning","Legal Reasoning","Computational Models of Argument","Machine Learning"],"classifications":["Text Generation"],"num_cited_by":57,"num_cited_by_title_only":57,"num_pages":10},{"id":"37ae3cf647c4c0e347051ca167bf51940cd4de7dcb8b8a7f39c11b24e2aefce65bb9289d0f1843fd2bd2e8a10838281960d1edfec24ab629533256596826a1ad","file_path":"legal-nlp-survey-20250328-002/original/Harasta_2017_0154.pdf","title":"","llm_title":"Toward Linking Heterogenous References in Czech Court Decisions to Content","authors":["Jakub Harašta","Jaromír Savelka"],"llm_authors":"Jakub Harašta, Jaromír Savelka","author_string":"","year":2017,"abstract":"","llm_abstract":"In this paper we present initial results from our effort to automatically detect references in decisions of the courts in the Czech Republic and link these references to their content. We focus on references to case-law and legal literature. To deal with wide variety in how references are expressed we use a novel distributed approach to reference recognition. Instead of attempting to recognize the references as a whole we focus on their lower level constituents. We assembled a corpus of 350 decisions and annotated it with more than 50,000 annotations corresponding to different reference constituents. Here we present our first attempt to detect these constituents automatically.","llm_keywords":["case law analysis","reference recognition","conditional random fields","information extraction","legal information retrieval","court decisions","citation standards"],"classifications":["Information Extraction","Resources"],"num_cited_by":7,"num_cited_by_title_only":7,"num_pages":6},{"id":"8f03ab2d8a4a1bc75519164efcf60ad4389806c97979758cd68244f3aee90a007fcd53a93ded4a1bb029cb6d33a20b45aeec58e8075e60f7e7471480bc528aa0","file_path":"legal-nlp-survey-20250328-002/original/Medvedeva_2020_0335.pdf","title":"","llm_title":"JURI SAYS: An Automatic Judgement Prediction System for the European Court of Human Rights","authors":["Masha Medvedeva","Xiao Xu","Martijn Wieling","Michel Vols"],"llm_authors":"Masha MEDVEDEVA, Xiao XU, Martijn WIELING, Michel VOLS","author_string":"","year":2020,"abstract":"","llm_abstract":"In this paper we present the web platform JURI SAYS that automatically predicts decisions of the European Court of Human Rights based on communicated cases, which are published by the court early in the proceedings and are often available many years before the final decision is made. Our system therefore predicts future judgements of the court. The platform is available at jurisays.com and shows the predictions compared to the actual decisions of the court. It is automatically updated every month by including the prediction for the new cases. Additionally, the system highlights the sentences and paragraphs that are most important for the prediction (i.e. violation vs. no violation of human rights).","llm_keywords":["European Court of Human Rights","machine learning","web platform","judgement prediction","legal data","automated decision-making","ECtHR cases"],"classifications":["Classification"],"num_cited_by":21,"num_cited_by_title_only":21,"num_pages":4},{"id":"b3e3f739927660ff5379c67eeb839b83109f0d6f27f94a03db944548e301b0750eb4140fffda035929bb571cfc119bd1a03f8affbf457976728165ebd8ee1cbd","file_path":"legal-nlp-survey-20250328-002/original/Leitner_2020_0299.pdf","title":"A Dataset of German Legal Documents for Named Entity Recognition","llm_title":"A Dataset of German Legal Documents for Named Entity Recognition","authors":["Elena Leitner","Georg Rehm","Julian Moreno-Schneider"],"llm_authors":"Elena Leitner, Georg Rehm, Julian Moreno-Schneider","author_string":"Elena Leitner ; Georg Rehm ; Julian Moreno-Schneider","year":2020,"abstract":"","llm_abstract":"We describe a dataset developed for Named Entity Recognition in German federal court decisions. It consists of approx. 67,000 sentences with over 2 million tokens. The resource contains 54,000 manually annotated entities, mapped to 19 fine-grained semantic classes: person, judge, lawyer, country, city, street, landscape, organization, company, institution, court, brand, law, ordinance, European legal norm, regulation, contract, court decision, and legal literature. The legal documents were, furthermore, automatically annotated with more than 35,000 TimeML-based time expressions. The dataset, which is available under a CC-BY 4.0 license in the CoNNL-2002 format, was developed for training an NER service for German legal documents in the EU project Lynx.","llm_keywords":["Named Entity Recognition","NER","Legal Documents","Legal Domain","Corpus Creation","Corpus Annotation"],"classifications":[],"num_cited_by":74,"num_cited_by_title_only":74,"num_pages":8},{"id":"50883994b8b5d9f146883323b235ef8aed0c19faafcce4a86b9f3fe890cf71a5ed792cad84e27a760c5049c798ceb50a17f098b87ad9ad1a8eea49b6a9ba51a0","file_path":"legal-nlp-survey-20250328-002/original/Zanuz_2022_0511.pdf","title":"","llm_title":"Fostering Judiciary Applications with New Fine-Tuned Models for Legal Named Entity Recognition in Portuguese","authors":["Luciano Zanuz","Sandro José Rigo"],"llm_authors":"Luciano Zanuz and Sandro José Rigo","author_string":"","year":2022,"abstract":"","llm_abstract":"Artificial Intelligence applied to Law is getting attention in the community, both from the Judiciary and the lawyers, due to possible gains in procedural celerity and the automation of repetitive tasks, among other use cases. Many of its benefits can be derived from Natural Language Processing since legal proceedings are textual document-based. Named Entity Recognition is the NLP task of identifying and classifying named entities in unstructured text to help achieve these goals. In recent years, transformers emerged as the new state-of-the-art architecture for some tasks in NLP systems. NLP resources in Portuguese, such as models and datasets, are needed to allow Portuguese speaking countries to benefit from this new NLP level. This paper presents the first fine-tuned BERT models trained exclusively on Brazilian Portuguese for Legal NER. The models achieved new state-of-the-art on LeNER-Br dataset, a Portuguese NER corpus for the legal domain. We also built a prototype application for Judiciary users to evaluate how the model performed with authentic law documents. The results showed that the models were able to extract information with good quality. Both the models and the prototype application are publicly available for the community.","llm_keywords":["Natural Language Processing","Named Entity Recognition","Artificial Intelligence","Law","Portuguese","BERT models","Legal NER","Datasets","Transformer architecture"],"classifications":["Information Extraction","Resources"],"num_cited_by":10,"num_cited_by_title_only":10,"num_pages":12},{"id":"c2ecf8a3352b9bc43230780ef5c8d4b35956f98ce2c86f068a14fd2824becf7d3a79f260059d9bc73bc659550679b61fa6f3ab68f7f66e52c031b648870c0171","file_path":"legal-nlp-survey-20250328-002/original/O'Neill_2017_0117.pdf","title":"blackThe 16th International Conference on Artificial Intelligence and Law","llm_title":"Classifying Sentential Modality in Legal Language: A Use Case in Financial Regulations, Acts and Directives","authors":["James O' Neill","Paul Buitelaar","Cecile Robin","Leona O' Brien"],"llm_authors":"James O’ Neill, Paul Buitelaar, Cecile Robin, Leona O’ Brien","author_string":"black[Proceedings editor], [University]","year":2017,"abstract":"","llm_abstract":"Texts expressed in legal language are often difficult and time-consuming for lawyers to read through, particularly for the purpose of identifying relevant deontic modalities (obligations, prohibitions and permissions). By nature, the language of law is strict, hence the predominant use of modal logic as a substitute for the syntactical ambiguity in natural language, specifically, deontic and alethic logic for the respective modalities. However, deontic modalities which express obligations, prohibitions and permissions can have varying degrees and preciseness to which they correspond to a matter, strict deontic logic does not allow for such quantitative measures. Therefore, this paper outlines a data-driven approach by classifying deontic modalities using ensembled Artificial Neural Networks (ANN) that incorporate domain-specific legal distributional semantic model (DSM) representations, in combination with, a general DSM representation. We propose to use well-calibrated probability estimates from these classifiers as an approximation to the degree to which an obligation/prohibition or permission belongs to a given class based on SME annotated sentences. Best results show 82.33% accuracy on a held-out test set.","llm_keywords":["Legal Language","Deontic Modality","Artificial Neural Networks","Financial Regulations","Modal Logic"],"classifications":["Classification"],"num_cited_by":58,"num_cited_by_title_only":58,"num_pages":10}]